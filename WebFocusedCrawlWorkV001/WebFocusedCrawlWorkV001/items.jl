{"url": "https://en.wikipedia.org/wiki/Robotics", "title": null, "text": "Design, construction, use, and application of robots.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This article may relate to a different subject or has undue weight on an aspect of the subject.Specifically, the article goes in too much detail on specific types of robot and includes product placement. Please help relocate relevant information and remove irrelevant content.  (August 2024)Roboticists with three Mars rover robots. Front and center is the flight spare for the first Mars rover, Sojourner, which landed on Mars in 1997 as part of the Mars Pathfinder Project. On the left is a Mars Exploration Rover (MER) test vehicle that is a working sibling to Spirit and Opportunity, which landed on Mars in 2004. On the right is a test rover for the Mars Science Laboratory, which landed Curiosity on Mars in 2012.Robotics is the interdisciplinary study and practice of the design, construction, operation, and use of robots.[1]Within mechanical engineering, robotics is the design and construction of the physical structures of robots, while in computer science, robotics focuses on robotic automation algorithms. Other disciplines contributing to robotics include electrical, control, software, information, electronic, telecommunication, computer, mechatronic, and materials engineering.\nThe goal of most robotics is to design machines that can help and assist humans. Many robots are built to do jobs that are hazardous to people, such as finding survivors in unstable ruins, and exploring space, mines and shipwrecks. Others replace people in jobs that are boring, repetitive, or unpleasant, such as cleaning, monitoring, transporting, and assembling. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes.\nRobotics aspects[edit]Mechanical aspectElectrical aspectSoftware aspectRobotics usually combines three aspects of design work to create robot systems:\nMechanical construction: a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud might use caterpillar tracks. Origami inspired robots can sense and analyze in extreme environments.[2] The mechanical aspect of the robot is mostly the creator's solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function.Electrical components that power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol-powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol-powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status), and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations)Software. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not be able to go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly structured, its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence, and hybrid. A robot with remote control programming has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. A hybrid is a form of programming that incorporates both AI and RC functions in them.[3]Applied robotics[edit]As many robots are designed for specific tasks, this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".[4]Current and potential applications include:\nManufacturing. Robots have been increasingly used in manufacturing since the 1960s. According to the Robotic Industries Association US data, in 2016 the automotive industry was the main customer of industrial robots with 52% of total sales.[5] In the auto industry, they can amount for more than half of the \"labor\". There are even \"lights off\" factories such as an IBM keyboard manufacturing factory in Texas that was fully automated as early as 2003.[6]Autonomous transport including airplane autopilot and self-driving carsDomestic robots including robotic vacuum cleaners, robotic lawn mowers, dishwasher loading[7] and flatbread baking.[8]Construction robots. Construction robots can be separated into three types: traditional robots, robotic arm, and robotic exoskeleton.[9]Automated mining.Space exploration, including Mars rovers.Energy applications including cleanup of nuclear contaminated areas;[a] and cleaning solar panel arrays.Medical robots and Robot-assisted surgery designed and used in clinics.[11]Agricultural robots.[12] The use of robots in agriculture is closely linked to the concept of AI-assisted precision agriculture and drone usage.[13]Food processing. Commercial examples of kitchen automation are Flippy (burgers), Zume Pizza (pizza), Cafe X (coffee), Makr Shakr (cocktails), Frobot (frozen yogurts), Sally (salads),[14] salad or food bowl robots manufactured by Dexai (a Draper Laboratory spinoff, operating on military bases), and integrated food bowl assembly systems manufactured by Spyce Kitchen (acquired by Sweetgreen) and Silicon Valley startup Hyphen.[15] Other examples may include manufacturing technologies based on 3D Food Printing.Military robots.Robot sports for entertainment and education, including Robot combat, Autonomous racing, drone racing, and FIRST Robotics.Mechanical robotics areas[edit]Power source[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}Further information: Power supply and Energy storageThe InSight lander with solar panels deployed in a cleanroomAt present, mostly (lead\u2013acid) batteries are used as a power source. Many different types of batteries can be used as a power source for robots. They range from lead\u2013acid batteries, which are safe and have relatively long shelf lives but are rather heavy compared to silver\u2013cadmium batteries which are much smaller in volume and are currently much more expensive. Designing a battery-powered robot needs to take into account factors such as safety, cycle lifetime, and weight. Generators, often some type of internal combustion engine, can also be used. However, such designs are often mechanically complex and need fuel, require heat dissipation, and are relatively heavy. A tether connecting the robot to a power supply would remove the power supply from the robot entirely. This has the advantage of saving weight and space by moving all power generation and storage components elsewhere. However, this design does come with the drawback of constantly having a cable connected to the robot, which can be difficult to manage.[16] \nPotential power sources could be:\npneumatic (compressed gases)Solar power (using the sun's energy and converting it into electrical power)hydraulics (liquids)flywheel energy storageorganic garbage (through anaerobic digestion)nuclearActuation[edit]Main article: ActuatorA robotic leg powered by air musclesActuators are the \"muscles\" of a robot, the parts which convert stored energy into movement.[17] By far the most popular actuators are electric motors that rotate a wheel or gear, and linear actuators that control industrial robots in factories. There are some recent advances in alternative types of actuators, powered by electricity, chemicals, or compressed air.\nElectric motors[edit]Main article: Electric motorThe vast majority of robots use electric motors, often brushed and brushless DC motors in portable robots or AC motors in industrial robots and CNC machines. These motors are often preferred in systems with lighter loads, and where the predominant form of motion is rotational.\nLinear actuators[edit]Main article: Linear actuatorVarious types of linear actuators move in and out instead of by spinning, and often have quicker direction changes, particularly when very large forces are needed such as with industrial robotics. They are typically powered by compressed air (pneumatic actuator) or an oil (hydraulic actuator) Linear actuators can also be powered by electricity which usually consists of a motor and a leadscrew. Another common type is a mechanical linear actuator such as a rack and pinion on a car.\nSeries elastic actuators[edit]Series elastic actuation (SEA) relies on the idea of introducing intentional elasticity between the motor actuator and the load for robust force control. Due to the resultant lower reflected inertia, series elastic actuation improves safety when a robot interacts with the environment (e.g., humans or workpieces) or during collisions.[18] Furthermore, it also provides energy efficiency and shock absorption (mechanical filtering) while reducing excessive wear on the transmission and other mechanical components. This approach has successfully been employed in various robots, particularly advanced manufacturing robots[19] and walking humanoid robots.[20][21]The controller design of a series elastic actuator is most often performed within the passivity framework as it ensures the safety of interaction with unstructured environments.[22] Despite its remarkable stability and robustness, this framework suffers from the stringent limitations imposed on the controller which may trade-off performance. The reader is referred to the following survey which summarizes the common controller architectures for SEA along with the corresponding sufficient passivity conditions.[23] One recent study has derived the necessary and sufficient passivity conditions for one of the most common impedance control architectures, namely velocity-sourced SEA.[24] This work is of particular importance as it drives the non-conservative passivity bounds in an SEA scheme for the first time which allows a larger selection of control gains.\nAir muscles[edit]Main article: Pneumatic artificial musclesPneumatic artificial muscles also known as air muscles, are special tubes that expand (typically up to 42%) when air is forced inside them. They are used in some robot applications.[25][26][27]Wire muscles[edit]Main article: Shape memory alloyMuscle wire, also known as shape memory alloy, is a material that contracts (under 5%) when electricity is applied. They have been used for some small robot applications.[28][29]Electroactive polymers[edit]Main article: Electroactive polymersEAPs or EPAMs are a plastic material that can contract substantially (up to 380% activation strain) from electricity, and have been used in facial muscles and arms of humanoid robots,[30] and to enable new robots to float,[31] fly, swim or walk.[32]Piezo motors[edit]Main article: Piezoelectric motorRecent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line.[33] Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size.[34] These motors are already available commercially and being used on some robots.[35][36]Elastic nanotubes[edit]Further information: Carbon nanotubeElastic nanotubes are a promising artificial muscle technology in early-stage experimental development. The absence of defects in carbon nanotubes enables these filaments to deform elastically by several percent, with energy storage levels of perhaps 10\u00a0J/cm3 for metal nanotubes. Human biceps could be replaced with an 8\u00a0mm diameter wire of this material. Such compact \"muscle\" might allow future robots to outrun and outjump humans.[37]Sensing[edit]Main articles: Robotic sensing and Robotic sensorsSensors allow robots to receive information about a certain measurement of the environment, or internal components. This is essential for robots to perform their tasks, and act upon any changes in the environment to calculate the appropriate response. They are used for various forms of measurements, to give the robots warnings about safety or malfunctions, and to provide real-time information about the task it is performing.\nTouch[edit]Main article: Tactile sensorCurrent robotic and prosthetic hands receive far less tactile information than the human hand. Recent research has developed a tactile sensor array that mimics the mechanical properties and touch receptors of human fingertips.[38][39] The sensor array is constructed as a rigid core surrounded by conductive fluid contained by an elastomeric skin. Electrodes are mounted on the surface of the rigid core and are connected to an impedance-measuring device within the core. When the artificial skin touches an object the fluid path around the electrodes is deformed, producing impedance changes that map the forces received from the object. The researchers expect that an important function of such artificial fingertips will be adjusting the robotic grip on held objects.\nScientists from several European countries and Israel developed a prosthetic hand in 2009, called SmartHand, which functions like a real one \u2014allowing patients to write with it, type on a keyboard, play piano, and perform other fine movements. The prosthesis has sensors which enable the patient to sense real feelings in its fingertips.[40]Further information: Sensory-motor mapOther[edit]Other common forms of sensing in robotics use lidar, radar, and sonar.[41]Lidar measures the distance to a target by illuminating the target with laser light and measuring the reflected light with a sensor. Radar uses radio waves to determine the range, angle, or velocity of objects. Sonar uses sound propagation to navigate, communicate with or detect objects on or under the surface of the water.\nMechanical grippers[edit]One of the most common types of end-effectors are \"grippers\". In its simplest manifestation, it consists of just two fingers that can open and close to pick up and let go of a range of small objects. Fingers can, for example, be made of a chain with a metal wire running through it.[42] Hands that resemble and work more like a human hand include the Shadow Hand and the Robonaut hand.[43] Hands that are of a mid-level complexity include the Delft hand.[44][45] Mechanical grippers can come in various types, including friction and encompassing jaws. Friction jaws use all the force of the gripper to hold the object in place using friction. Encompassing jaws cradle the object in place, using less friction.\nSuction end-effectors[edit]Suction end-effectors, powered by vacuum generators, are very simple astrictive[46] devices that can hold very large loads provided the prehension surface is smooth enough to ensure suction.\nPick and place robots for electronic components and for large objects like car windscreens, often use very simple vacuum end-effectors.\nSuction is a highly used type of end-effector in industry, in part because the natural compliance of soft suction end-effectors can enable a robot to be more robust in the presence of imperfect robotic perception. As an example: consider the case of a robot vision system that estimates the position of a water bottle but has 1 centimeter of error. While this may cause a rigid mechanical gripper to puncture the water bottle, the soft suction end-effector may just bend slightly and conform to the shape of the water bottle surface.\nGeneral purpose effectors[edit]Some advanced robots are beginning to use fully humanoid hands, like the Shadow Hand, MANUS,[47] and the Schunk hand.[48] They have powerful Robot Dexterity Intelligence (RDI), with as many as 20 degrees of freedom and hundreds of tactile sensors.[49]Control robotics areas[edit]Puppet Magnus, a robot-manipulated marionette with complex control systemsExperimental planar robot arm and sensor-based, open-architecture robot controllerRuBot II can manually resolve Rubik's cubes.Further information: Control system and Principles of motion sensingThe mechanical structure of a robot must be controlled to perform tasks.[50] The control of a robot involves three distinct phases \u2013 perception, processing, and action (robotic paradigms).[51]Sensors give information about the environment or the robot itself (e.g. the position of its joints or its end effector). This information is then processed to be stored or transmitted and to calculate the appropriate signals to the actuators (motors), which move the mechanical structure to achieve the required co-ordinated motion or force actions.\nThe processing phase can range in complexity. At a reactive level, it may translate raw sensor information directly into actuator commands (e.g. firing motor power electronic gates based directly upon encoder feedback signals to achieve the required torque/velocity of the shaft). Sensor fusion and internal models may first be used to estimate parameters of interest (e.g. the position of the robot's gripper) from noisy sensor data. An immediate task (such as moving the gripper in a certain direction until an object is detected with a proximity sensor) is sometimes inferred from these estimates. Techniques from control theory are generally used to convert the higher-level tasks into individual commands that drive the actuators, most often using kinematic and dynamic models of the mechanical structure.[50][51][52]At longer time scales or with more sophisticated tasks, the robot may need to build and reason with a \"cognitive\" model. Cognitive models try to represent the robot, the world, and how the two interact. Pattern recognition and computer vision can be used to track objects.[50]Mapping techniques can be used to build maps of the world. Finally, motion planning and other artificial intelligence techniques may be used to figure out how to act. For example, a planner may figure out how to achieve a task without hitting obstacles, falling over, etc.\nModern commercial robotic control systems are highly complex, integrate multiple sensors and effectors, have many interacting degrees-of-freedom (DOF) and require operator interfaces, programming tools and real-time capabilities.[51] They are oftentimes interconnected to wider communication networks and in many cases are now both IoT-enabled and mobile.[53] Progress towards open architecture, layered, user-friendly and 'intelligent' sensor-based interconnected robots has emerged from earlier concepts related to Flexible Manufacturing Systems (FMS), and several 'open or 'hybrid' reference architectures exist which assist developers of robot control software and hardware to move beyond traditional, earlier notions of 'closed' robot control systems have been proposed.[52] Open architecture controllers are said to be better able to meet the growing requirements of a wide range of robot users, including system developers, end users and research scientists, and are better positioned to deliver the advanced robotic concepts related to Industry 4.0.[52] In addition to utilizing many established features of robot controllers, such as position, velocity and force control of end effectors, they also enable IoT interconnection and the implementation of more advanced sensor fusion and control techniques, including adaptive control, Fuzzy control and Artificial Neural Network (ANN)-based control.[52] When implemented in real-time, such techniques can potentially improve the stability and performance of robots operating in unknown or uncertain environments by enabling the control systems to learn and adapt to environmental changes.[54] There are several examples of reference architectures for robot controllers, and also examples of successful implementations of actual robot controllers developed from them. One example of a generic reference architecture and associated interconnected, open-architecture robot and controller implementation was used in a number of research and development studies, including prototype implementation of novel advanced and intelligent control and environment mapping methods in real-time.[54][55]Manipulation[edit]KUKAindustrial robot operating in a foundryPuma, one of the first industrial robotsBaxter, a modern and versatile industrial robot developed by Rodney BrooksLefty, first checker playing robotFurther information: Mobile manipulatorA definition of robotic manipulation has been provided by Matt Mason as: \"manipulation refers to an agent's control of its environment through selective contact\".[56]Robots need to manipulate objects; pick up, modify, destroy, move or otherwise have an effect. Thus the functional end of a robot arm intended to make the effect (whether a hand, or tool) are often referred to as end effectors,[57] while the \"arm\" is referred to as a manipulator.[58] Most robot arms have replaceable end-effectors, each allowing them to perform some small range of tasks. Some have a fixed manipulator that cannot be replaced, while a few have one very general-purpose manipulator, for example, a humanoid hand.[59]Locomotion[edit]Main articles: Robot locomotion and Mobile robotRolling robots[edit]Segway in the Robot museum in NagoyaFor simplicity, most mobile robots have four wheels or a number of continuous tracks. Some researchers have tried to create more complex wheeled robots with only one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to.\nTwo-wheeled balancing robots[edit]Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[60] Many different balancing robots have been designed.[61] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA's Robonaut that has been mounted on a Segway.[62]One-wheeled balancing robots[edit]Main article: Self-balancing unicycleA one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon University's \"Ballbot\" which is the approximate height and width of a person, and Tohoku Gakuin University's \"BallIP\".[63] Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people.[64]Spherical orb robots[edit]Main article: Spherical robotSeveral attempts have been made in robots that are completely inside a spherical ball, either by spinning a weight inside the ball,[65][66] or by rotating the outer shells of the sphere.[67][68] These have also been referred to as an orb bot[69] or a ball bot.[70][71]Six-wheeled robots[edit]Using six wheels instead of four wheels can give better traction or grip in outdoor terrain such as on rocky dirt or grass.\nTracked robots[edit]Tracks provide even more traction than a six-wheeled robot. Tracked wheels behave as if they were made of hundreds of wheels, therefore are very common for outdoor off-road robots, where the robot must drive on very rough terrain. However, they are difficult to use indoors such as on carpets and smooth floors. Examples include NASA's Urban Robot \"Urbie\".[72]Walking robots[edit]Further information: Mantis the spider robotWalking is a difficult and dynamic problem to solve. Several robots have been made which can walk reliably on two legs, however, none have yet been made which are as robust as a human. There has been much study on human-inspired walking, such as AMBER lab which was established in 2008 by the Mechanical Engineering Department at Texas A&M University.[73] Many other robots have been built that walk on more than two legs, due to these robots being significantly easier to construct.[74][75] Walking robots can be used for uneven terrains, which would provide better mobility and energy efficiency than other locomotion methods. Typically, robots on two legs can walk well on flat floors and can occasionally walk up stairs. None can walk over rocky, uneven terrain. Some of the methods which have been tried are:\nZMP technique[edit]Main article: Zero moment pointThe zero moment point (ZMP) is the algorithm used by robots such as Honda's ASIMO. The robot's onboard computer tries to keep the total inertial forces (the combination of Earth's gravity and the acceleration and deceleration of walking), exactly opposed by the floor reaction force (the force of the floor pushing back on the robot's foot). In this way, the two forces cancel out, leaving no moment (force causing the robot to rotate and fall over).[76] However, this is not exactly how a human walks, and the difference is obvious to human observers, some of whom have pointed out that ASIMO walks as if it needs the lavatory.[77][78][79] ASIMO's walking algorithm is not static, and some dynamic balancing is used (see below). However, it still requires a smooth surface to walk on.\nHopping[edit]Several robots, built in the 1980s by Marc Raibert at the MIT Leg Laboratory, successfully demonstrated very dynamic walking. Initially, a robot with only one leg, and a very small foot could stay upright simply by hopping. The movement is the same as that of a person on a pogo stick. As the robot falls to one side, it would jump slightly in that direction, in order to catch itself.[80] Soon, the algorithm was generalised to two and four legs. A bipedal robot was demonstrated running and even performing somersaults.[81] A quadruped was also demonstrated which could trot, run, pace, and bound.[82] For a full list of these robots, see the MIT Leg Lab Robots page.[83]Dynamic balancing (controlled falling)[edit]A more advanced way for a robot to walk is by using a dynamic balancing algorithm, which is potentially more robust than the Zero Moment Point technique, as it constantly monitors the robot's motion, and places the feet in order to maintain stability.[84] This technique was recently demonstrated by Anybots' Dexter Robot,[85] which is so stable, it can even jump.[86] Another example is the TU Delft Flame.\nPassive dynamics[edit]Main article: Passive dynamicsPerhaps the most promising approach uses passive dynamics where the momentum of swinging limbs is used for greater efficiency. It has been shown that totally unpowered humanoid mechanisms can walk down a gentle slope, using only gravity to propel themselves. Using this technique, a robot need only supply a small amount of motor power to walk along a flat surface or a little more to walk up a hill. This technique promises to make walking robots at least ten times more efficient than ZMP walkers, like ASIMO.[87][88]Flying[edit]A modern passenger airliner is essentially a flying robot, with two humans to manage it. The autopilot can control the plane for each stage of the journey, including takeoff, normal flight, and even landing.[89] Other flying robots are uninhabited and are known as unmanned aerial vehicles (UAVs). They can be smaller and lighter without a human pilot on board, and fly into dangerous territory for military surveillance missions. Some can even fire on targets under command. UAVs are also being developed which can fire on targets automatically, without the need for a command from a human. Other flying robots include cruise missiles, the Entomopter, and the Epson micro helicopter robot. Robots such as the Air Penguin, Air Ray, and Air Jelly have lighter-than-air bodies, are propelled by paddles, and are guided by sonar.\nBiomimetic flying robots (BFRs)[edit]A flapping wing BFR generating lift and thrustBFRs take inspiration from flying mammals, birds, or insects. BFRs can have flapping wings, which generate the lift and thrust, or they can be propeller actuated. BFRs with flapping wings have increased stroke efficiencies, increased maneuverability, and reduced energy consumption in comparison to propeller actuated BFRs.[90] Mammal and bird inspired BFRs share similar flight characteristics and design considerations. For instance, both mammal and bird inspired BFRs minimize edge fluttering and pressure-induced wingtip curl by increasing the rigidity of the wing edge and wingtips. Mammal and insect inspired BFRs can be impact resistant, making them useful in cluttered environments.\nMammal inspired BFRs typically take inspiration from bats, but the flying squirrel has also inspired a prototype.[91] Examples of bat inspired BFRs include Bat Bot[92] and the DALER.[93] Mammal inspired BFRs can be designed to be multi-modal; therefore, they're capable of both flight and terrestrial movement. To reduce the impact of landing, shock absorbers can be implemented along the wings.[93] Alternatively, the BFR can pitch up and increase the amount of drag it experiences.[91] By increasing the drag force, the BFR will decelerate and minimize the impact upon grounding. Different land gait patterns can also be implemented.[91]Dragonfly inspired BFR.Bird inspired BFRs can take inspiration from raptors, gulls, and everything in-between. Bird inspired BFRs can be feathered to increase the angle of attack range over which the prototype can operate before stalling.[94] The wings of bird inspired BFRs allow for in-plane deformation, and the in-plane wing deformation can be adjusted to maximize flight efficiency depending on the flight gait.[94] An example of a raptor inspired BFR is the prototype by Savastano et al.[95] The prototype has fully deformable flapping wings and is capable of carrying a payload of up to 0.8\u00a0kg while performing a parabolic climb, steep descent, and rapid recovery. The gull inspired prototype by Grant et al. accurately mimics the elbow and wrist rotation of gulls, and they find that lift generation is maximized when the elbow and wrist deformations are opposite but equal.[96]Insect inspired BFRs typically take inspiration from beetles or dragonflies. An example of a beetle inspired BFR is the prototype by Phan and Park,[97] and a dragonfly inspired BFR is the prototype by Hu et al.[98] The flapping frequency of insect inspired BFRs are much higher than those of other BFRs; this is because of the aerodynamics of insect flight.[99] Insect inspired BFRs are much smaller than those inspired by mammals or birds, so they are more suitable for dense environments.\nBiologically-inspired flying robots[edit]Visualization of entomopter flying on Mars (NASA)A class of robots that are biologically inspired, but which do not attempt to mimic biology, are creations such as the Entomopter. Funded by DARPA, NASA, the United States Air Force, and the Georgia Tech Research Institute and patented by Prof. Robert C. Michelson for covert terrestrial missions as well as flight in the lower Mars atmosphere, the Entomopter flight propulsion system uses low Reynolds number wings similar to those of the hawk moth (Manduca sexta), but flaps them in a non-traditional \"opposed x-wing fashion\" while \"blowing\" the surface to enhance lift based on the Coand\u0103 effect as well as to control vehicle attitude and direction. Waste gas from the propulsion system not only facilitates the blown wing aerodynamics, but also serves to create ultrasonic emissions like that of a Bat for obstacle avoidance. The Entomopter and other biologically-inspired robots leverage features of biological systems, but do not attempt to create mechanical analogs.\nSnaking[edit]Two robot snakes. The left one has 64 motors (with 2 degrees of freedom per segment), the right one 10.Several snake robots have been successfully developed. Mimicking the way real snakes move, these robots can navigate very confined spaces, meaning they may one day be used to search for people trapped in collapsed buildings.[100] The Japanese ACM-R5 snake robot[101] can even navigate both on land and in water.[102]Skating[edit]A small number of skating robots have been developed, one of which is a multi-mode walking and skating device. It has four legs, with unpowered wheels, which can either step or roll.[103] Another robot, Plen, can use a miniature skateboard or roller-skates, and skate across a desktop.[104]Capuchin, a climbing robotClimbing[edit]Several different approaches have been used to develop robots that have the ability to climb vertical surfaces. One approach mimics the movements of a human climber on a wall with protrusions; adjusting the center of mass and moving each limb in turn to gain leverage. An example of this is Capuchin,[105] built by Ruixiang Zhang at Stanford University, California. Another approach uses the specialized toe pad method of wall-climbing geckoes, which can run on smooth surfaces such as vertical glass. Examples of this approach include Wallbot[106] and Stickybot.[107]China's Technology Daily reported on 15 November 2008, that Li Hiu Yeung and his research group of New Concept Aircraft (Zhuhai) Co., Ltd. had successfully developed a bionic gecko robot named \"Speedy Freelander\". According to Yeung, the gecko robot could rapidly climb up and down a variety of building walls, navigate through ground and wall fissures, and walk upside-down on the ceiling. It was also able to adapt to the surfaces of smooth glass, rough, sticky or dusty walls as well as various types of metallic materials. It could also identify and circumvent obstacles automatically. Its flexibility and speed were comparable to a natural gecko. A third approach is to mimic the motion of a snake climbing a pole.[41]Swimming (Piscine)[edit]It is calculated that when swimming some fish can achieve a propulsive efficiency greater than 90%.[108] Furthermore, they can accelerate and maneuver far better than any man-made boat or submarine, and produce less noise and water disturbance. Therefore, many researchers studying underwater robots would like to copy this type of locomotion.[109] Notable examples are the Robotic Fish G9,[110] and Robot Tuna built to analyze and mathematically model thunniform motion.[111] The Aqua Penguin,[112] copies the streamlined shape and propulsion by front \"flippers\" of penguins. The Aqua Ray and Aqua Jelly emulate the locomotion of manta ray, and jellyfish, respectively.\nRobotic Fish: iSplash-IIIn 2014, iSplash-II was developed as the first robotic fish capable of outperforming real carangiform fish in terms of average maximum velocity (measured in body lengths/ second) and endurance, the duration that top speed is maintained.[113] This build attained swimming speeds of 11.6BL/s (i.e. 3.7\u00a0m/s).[114] The first build, iSplash-I (2014) was the first robotic platform to apply a full-body length carangiform swimming motion which was found to increase swimming speed by 27% over the traditional approach of a posterior confined waveform.[115]Sailing[edit]The autonomous sailboat robot VaimosSailboat robots have also been developed in order to make measurements at the surface of the ocean. A typical sailboat robot is Vaimos.[116] Since the propulsion of sailboat robots uses the wind, the energy of the batteries is only used for the computer, for the communication and for the actuators (to tune the rudder and the sail). If the robot is equipped with solar panels, the robot could theoretically navigate forever. The two main competitions of sailboat robots are WRSC, which takes place every year in Europe, and Sailbot.\nComputational robotics areas[edit]TOPIO, a humanoid robot, played ping pong at Tokyo IREX 2009.[117]Control systems may also have varying levels of autonomy.\nDirect interaction is used for haptic or teleoperated devices, and the human has nearly complete control over the robot's motion.Operator-assist modes have the operator commanding medium-to-high-level tasks, with the robot automatically figuring out how to achieve them.[118]An autonomous robot may go without human interaction for extended periods of time . Higher levels of autonomy do not necessarily require more complex cognitive capabilities. For example, robots in assembly plants are completely autonomous but operate in a fixed pattern.Another classification takes into account the interaction between human control and the machine motions.\nTeleoperation. A human controls each movement, each machine actuator change is specified by the operator.Supervisory. A human specifies general moves or position changes and the machine decides specific movements of its actuators.Task-level autonomy. The operator specifies only the task and the robot manages itself to complete it.Full autonomy. The machine will create and complete all its tasks without human interaction.Vision[edit]Main article: Computer visionComputer vision is the science and technology of machines that see. As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences and views from cameras.\nIn most practical computer vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common.\nComputer vision systems rely on image sensors that detect electromagnetic radiation which is typically in the form of either visible light or infra-red light. The sensors are designed using solid-state physics. The process by which light propagates and reflects off surfaces is explained using optics. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Robots can also be equipped with multiple vision sensors to be better able to compute the sense of depth in the environment. Like human eyes, robots' \"eyes\" must also be able to focus on a particular area of interest, and also adjust to variations in light intensities.\nThere is a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological system, at different levels of complexity. Also, some of the learning-based methods developed within computer vision have a background in biology.\nEnvironmental interaction and navigation[edit]Main articles: Robotic mapping and Robotic navigationRadar, GPS, and lidar, are all combined to provide proper navigation and obstacle avoidance (vehicle developed for 2007 DARPA Urban Challenge).This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.  (July 2009) (Learn how and when to remove this message)Though a significant percentage of robots in commission today are either human controlled or operate in a static environment, there is an increasing interest in robots that can operate autonomously in a dynamic environment. These robots require some combination of navigation hardware and software in order to traverse their environment. In particular, unforeseen events (e.g. people and other obstacles that are not stationary) can cause problems or collisions. Some highly advanced robots such as ASIMO and Mein\u00fc robot have particularly good robot navigation hardware and software. Also, self-controlled cars, Ernst Dickmanns' driverless car, and the entries in the DARPA Grand Challenge, are capable of sensing the environment well and subsequently making navigational decisions based on this information, including by a swarm of autonomous robots.[119] Most of these robots employ a GPS navigation device with waypoints, along with radar, sometimes combined with other sensory data such as lidar, video cameras, and inertial guidance systems for better navigation between waypoints.\nHuman-robot interaction[edit]Main article: Human-robot interactionKismet can produce a range of facial expressions.The state of the art in sensory intelligence for robots will have to progress through several orders of magnitude if we want the robots working in our homes to go beyond vacuum-cleaning the floors. If robots are to work effectively in homes and other non-industrial environments, the way they are instructed to perform their jobs, and especially how they will be told to stop will be of critical importance. The people who interact with them may have little or no training in robotics, and so any interface will need to be extremely intuitive. Science fiction authors also typically assume that robots will eventually be capable of communicating with humans through speech, gestures, and facial expressions, rather than a command-line interface. Although speech would be the most natural way for the human to communicate, it is unnatural for the robot. It will probably be a long time before robots interact as naturally as the fictional C-3PO, or Data of Star Trek, Next Generation. Even though the current state of robotics cannot meet the standards of these robots from science-fiction, robotic media characters (e.g., Wall-E, R2-D2) can elicit audience sympathies that increase people's willingness to accept actual robots in the future.[120] Acceptance of social robots is also likely to increase if people can meet a social robot under appropriate conditions. Studies have shown that interacting with a robot by looking at, touching, or even imagining interacting with the robot can reduce negative feelings that some people have about robots before interacting with them.[121] However, if pre-existing negative sentiments are especially strong, interacting with a robot can increase those negative feelings towards robots.[121]Speech recognition[edit]Main article: Speech recognitionInterpreting the continuous flow of sounds coming from a human, in real time, is a difficult task for a computer, mostly because of the great variability of speech.[122] The same word, spoken by the same person may sound different depending on local acoustics, volume, the previous word, whether or not the speaker has a cold, etc.. It becomes even harder when the speaker has a different accent.[123] Nevertheless, great strides have been made in the field since Davis, Biddulph, and Balashek designed the first \"voice input system\" which recognized \"ten digits spoken by a single user with 100% accuracy\" in 1952.[124] Currently, the best systems can recognize continuous, natural speech, up to 160 words per minute, with an accuracy of 95%.[125] With the help of artificial intelligence, machines nowadays can use people's voice to identify their emotions such as satisfied or angry.[126]Robotic voice[edit]Other hurdles exist when allowing the robot to use voice for interacting with humans. For social reasons, synthetic voice proves suboptimal as a communication medium,[127] making it necessary to develop the emotional component of robotic voice through various techniques.[128][129] An advantage of diphonic branching is the emotion that the robot is programmed to project, can be carried on the voice tape, or phoneme, already pre-programmed onto the voice media. One of the earliest examples is a teaching robot named Leachim developed in 1974 by Michael J. Freeman.[130][131] Leachim was able to convert digital memory to rudimentary verbal speech on pre-recorded computer discs.[132] It was programmed to teach students in The Bronx, New York.[132]Facial expression[edit]Further information: Emotion recognitionFacial expressions can provide rapid feedback on the progress of a dialog between two humans, and soon may be able to do the same for humans and robots. Robotic faces have been constructed by Hanson Robotics using their elastic polymer called Frubber, allowing a large number of facial expressions due to the elasticity of the rubber facial coating and embedded subsurface motors (servos).[133] The coating and servos are built on a metal skull. A robot should know how to approach a human, judging by their facial expression and body language. Whether the person is happy, frightened, or crazy-looking affects the type of interaction expected of the robot. Likewise, robots like Kismet and the more recent addition, Nexi[134] can produce a range of facial expressions, allowing it to have meaningful social exchanges with humans.[135]Gestures[edit]Further information: Gesture recognitionOne can imagine, in the future, explaining to a robot chef how to make a pastry, or asking directions from a robot police officer. In both of these cases, making hand gestures would aid the verbal descriptions. In the first case, the robot would be recognizing gestures made by the human, and perhaps repeating them for confirmation. In the second case, the robot police officer would gesture to indicate \"down the road, then turn right\". It is likely that gestures will make up a part of the interaction between humans and robots.[136] A great many systems have been developed to recognize human hand gestures.[137]Proxemics[edit]Proxemics is the study of personal space, and HRI systems may try to model and work with its concepts for human interactions.\nArtificial emotions[edit]Artificial emotions can also be generated, composed of a sequence of facial expressions or gestures. As can be seen from the movie Final Fantasy: The Spirits Within, the programming of these artificial emotions is complex and requires a large amount of human observation. To simplify this programming in the movie, presets were created together with a special software program. This decreased the amount of time needed to make the film. These presets could possibly be transferred for use in real-life robots. An example of a robot with artificial emotions is Robin the Robot\u00a0[hy] developed by an Armenian IT company Expper Technologies, which uses AI-based peer-to-peer interaction. Its main task is achieving emotional well-being, i.e. overcome stress and anxiety. Robin was trained to analyze facial expressions and use his face to display his emotions given the context. The robot has been tested by kids in US clinics, and observations show that Robin increased the appetite and cheerfulness of children after meeting and talking.[138]Personality[edit]Many of the robots of science fiction have a personality, something which may or may not be desirable in the commercial robots of the future.[139] Nevertheless, researchers are trying to create robots which appear to have a personality:[140][141] i.e. they use sounds, facial expressions, and body language to try to convey an internal state, which may be joy, sadness, or fear. One commercial example is Pleo, a toy robot dinosaur, which can exhibit several apparent emotions.[142]Research robotics[edit]Further information: Areas of roboticsMuch of the research in robotics focuses not on specific industrial tasks, but on investigations into new types of robots, alternative ways to think about or design robots, and new ways to manufacture them. Other investigations, such as MIT's cyberflora project, are almost wholly academic.\nTo describe the level of advancement of a robot, the term \"Generation Robots\" can be used. This term is coined by Professor Hans Moravec, Principal Research Scientist at the Carnegie Mellon UniversityRobotics Institute in describing the near future evolution of robot technology. First-generation robots, Moravec predicted in 1997, should have an intellectual capacity comparable to perhaps a lizard and should become available by 2010. Because the first generation robot would be incapable of learning, however, Moravec predicts that the second generation robot would be an improvement over the first and become available by 2020, with the intelligence maybe comparable to that of a mouse. The third generation robot should have intelligence comparable to that of a monkey. Though fourth generation robots, robots with human intelligence, professor Moravec predicts, would become possible, he does not predict this happening before around 2040 or 2050.[143]Dynamics and kinematics[edit]Main article: Robot kinematicsFurther information: Kinematics and Dynamics (mechanics).mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}External videosHow the BB-8 Sphero Toy WorksThe study of motion can be divided into kinematics and dynamics.[144] Direct kinematics or forward kinematics refers to the calculation of end effector position, orientation, velocity, and acceleration when the corresponding joint values are known. Inverse kinematics refers to the opposite case in which required joint values are calculated for given end effector values, as done in path planning. Some special aspects of kinematics include handling of redundancy (different possibilities of performing the same movement), collision avoidance, and singularity avoidance. Once all relevant positions, velocities, and accelerations have been calculated using kinematics, methods from the field of dynamics are used to study the effect of forces upon these movements. Direct dynamics refers to the calculation of accelerations in the robot once the applied forces are known. Direct dynamics is used in computer simulations of the robot. Inverse dynamics refers to the calculation of the actuator forces necessary to create a prescribed end-effector acceleration. This information can be used to improve the control algorithms of a robot.\nIn each area mentioned above, researchers strive to develop new concepts and strategies, improve existing ones, and improve the interaction between these areas. To do this, criteria for \"optimal\" performance and ways to optimize design, structure, and control of robots must be developed and implemented.\nOpen source robotics[edit]Further information: Open source robotics, List of open-source robotics hardware, and List of open-source robotics softwareOpen source robotics research seeks standards for defining, and methods for designing and building, robots so that they can easily be reproduced by anyone. Research includes legal and technical definitions; seeking out alternative tools and materials to reduce costs and simplify builds; and creating interfaces and standards for designs to work together. Human usability research also investigates how to best document builds through visual, text or video instructions.\nEvolutionary robotics[edit]Evolutionary robots is a methodology that uses evolutionary computation to help design robots, especially the body form, or motion and behavior controllers. In a similar way to natural evolution, a large population of robots is allowed to compete in some way, or their ability to perform a task is measured using a fitness function. Those that perform worst are removed from the population and replaced by a new set, which have new behaviors based on those of the winners. Over time the population improves, and eventually a satisfactory robot may appear. This happens without any direct programming of the robots by the researchers. Researchers use this method both to create better robots,[145] and to explore the nature of evolution.[146] Because the process often requires many generations of robots to be simulated,[147] this technique may be run entirely or mostly in simulation, using a robot simulator software package, then tested on real robots once the evolved algorithms are good enough.[148] According to the International Federation of Robotics (IFR) study World Robotics 2023, there were about 4,281,585 operational industrial robots by the end of 2023[149] \nBionics and biomimetics[edit]Bionics and biomimetics apply the physiology and methods of locomotion of animals to the design of robots. For example, the design of BionicKangaroo was based on the way kangaroos jump.\nSwarm robotics[edit]Swarm robotics is an approach to the coordination of multiple robots as a system which consist of large numbers of mostly simple physical robots. \u2033In a robot swarm, the collective behavior of the robots results from local interactions between the robots and between the robots and the environment in which they act.\u2033* [119]Quantum computing[edit]There has been some research into whether robotics algorithms can be run more quickly on quantum computers than they can be run on digital computers. This area has been referred to as quantum robotics.[150]Other research areas[edit]Nanorobots.Cobots (collaborative robots).[151]Autonomous drones.High temperature crucibles allow robotic systems to automate sample analysis.[152]The main venues for robotics research are the international conferences ICRA and IROS.\nHuman factors[edit]Education and training[edit]Main article: Educational roboticsThe SCORBOT-ER 4u educational robotRobotics engineers design robots, maintain them, develop new applications for them, and conduct research to expand the potential of robotics.[153] Robots have become a popular educational tool in some middle and high schools, particularly in parts of the USA,[154] as well as in numerous youth summer camps, raising interest in programming, artificial intelligence, and robotics among students.\nEmployment[edit]A robot technician builds small all-terrain robots (courtesy: MobileRobots, Inc.).Main article: Technological unemploymentRobotics is an essential component in many modern manufacturing environments. As factories increase their use of robots, the number of robotics\u2013related jobs grow and have been observed to be steadily rising.[155] The employment of robots in industries has increased productivity and efficiency savings and is typically seen as a long-term investment for benefactors. A study found that 47 percent of US jobs are at risk to automation \"over some unspecified number of years\".[156] These claims have been criticized on the ground that social policy, not AI, causes unemployment.[157] In a 2016 article in The Guardian, Stephen Hawking stated \"The automation of factories has already decimated jobs in traditional manufacturing, and the rise of artificial intelligence is likely to extend this job destruction deep into the middle classes, with only the most caring, creative or supervisory roles remaining\".[158]   The rise of robotics is thus often used as an argument for universal basic income.\nAccording to a GlobalData September 2021 report, the robotics industry was worth $45bn in 2020, and by 2030, it will have grown at a compound annual growth rate (CAGR) of 29% to $568bn, driving jobs in robotics and related industries.[159]Occupational safety and health implications[edit]Main article: Workplace robotics safetyA discussion paper drawn up by EU-OSHA highlights how the spread of robotics presents both opportunities and challenges for occupational safety and health (OSH).[160]The greatest OSH benefits stemming from the wider use of robotics should be substitution for people working in unhealthy or dangerous environments. In space, defense, security, or the nuclear industry, but also in logistics, maintenance, and inspection, autonomous robots are particularly useful in replacing human workers performing dirty, dull or unsafe tasks, thus avoiding workers' exposures to hazardous agents and conditions and reducing physical, ergonomic and psychosocial risks. For example, robots are already used to perform repetitive and monotonous tasks, to handle radioactive material or to work in explosive atmospheres. In the future, many other highly repetitive, risky or unpleasant tasks will be performed by robots in a variety of sectors like agriculture, construction, transport, healthcare, firefighting or cleaning services.[161]Moreover, there are certain skills to which humans will be better suited than machines for some time to come and the question is how to achieve the best combination of human and robot skills. The advantages of robotics include heavy-duty jobs with precision and repeatability, whereas the advantages of humans include creativity, decision-making, flexibility, and adaptability. This need to combine optimal skills has resulted in collaborative robots and humans sharing a common workspace more closely and led to the development of new approaches and standards to guarantee the safety of the \"man-robot merger\". Some European countries are including robotics in their national programs and trying to promote a safe and flexible cooperation between robots and operators to achieve better productivity. For example, the German Federal Institute for Occupational Safety and Health (BAuA) organises annual workshops on the topic \"human-robot collaboration\".\nIn the future, cooperation between robots and humans will be diversified, with robots increasing their autonomy and human-robot collaboration reaching completely new forms. Current approaches and technical standards[162][163] aiming to protect employees from the risk of working with collaborative robots will have to be revised.\nUser experience[edit]Great user experience predicts the needs, experiences, behaviors, language and cognitive abilities, and other factors of each user group. It then uses these insights to produce a product or solution that is ultimately useful and usable. For robots, user experience begins with an understanding of the robot's intended task and environment, while considering any possible social impact the robot may have on human operations and interactions with it.[164]It defines that communication as the transmission of information through signals, which are elements perceived through touch, sound, smell and sight.[165] The author states that the signal connects the sender to the receiver and consists of three parts: the signal itself, what it refers to, and the interpreter. Body postures and gestures, facial expressions, hand and head movements are all part of nonverbal behavior and communication. Robots are no exception when it comes to human-robot interaction. Therefore, humans use their verbal and nonverbal behaviors to communicate their defining characteristics. Similarly, social robots need this coordination to perform human-like behaviors.\nCareers[edit]Robotics is an interdisciplinary field, combining primarily mechanical engineering and computer science but also drawing on electronic engineering and other subjects. The usual way to build a career in robotics is to complete an undergraduate degree in one of these established subjects, followed by a graduate (masters') degree in Robotics. Graduate degrees are typically joined by students coming from all of the contributing disciplines, and include familiarization of relevant undergraduate level subject matter from each of them, followed by specialist study in pure robotics topics which build upon them. As an interdisciplinary subject, robotics graduate programmes tend to be especially reliant on students working and learning together and sharing their knowledge and skills from their home discipline first degrees.\nRobotics industry careers then follow the same pattern, with most roboticists working as part of interdisciplinary teams of specialists from these home disciplines followed by the robotics graduate degrees which enable them to work together. Workers typically continue to identify as members of their home disciplines who work in robotics, rather than as 'roboticists'. This structure is reinforced by the nature of some engineering professions, which grant chartered engineer status to members of home disciplines rather than to robotics as a whole.\nRobotics careers are widely predicted to grow in the 21st century, as robots replace more manual and intellectual human work. Some workers who lose their jobs to robotics may be well-placed to retrain to build and maintain these robots, using their domain-specific knowledge and skills.\nHistory[edit]See also: History of robots\n\nDate\nSignificance\nRobot name\nInventor\nc. 420 B.C.\nA wooden, steam-propelled bird, which was able to fly\nFlying pigeon\nArchytas of Tarentum\nThird century B.C. and earlier\nOne of the earliest descriptions of automata appears in the Lie Zi text, on a much earlier encounter between King Mu of Zhou (1023\u2013957 BC) and a mechanical engineer known as Yan Shi, an 'artificer'. The latter allegedly presented the king with a life-size, human-shaped figure of his mechanical handiwork.[166]Yan Shi (Chinese: \u5043\u5e08)\nFirst century A.D. and earlier\nDescriptions of more than 100 machines and automata, including a fire engine, a wind organ, a coin-operated machine, and a steam-powered engine, in Pneumatica and Automata by Heron of AlexandriaCtesibius, Philo of Byzantium, Heron of Alexandria, and others\n1206\nCreated early humanoid automata, programmable automaton band[167]Robot band, hand-washing automaton,[168] automated moving peacocks[169]Al-Jazari1495\nDesigns for a humanoid robot\nMechanical KnightLeonardo da Vinci1560s\nClockwork Prayer that had machinal feet built under its robes that imitated walking. The robot's eyes, lips, and head all move in lifelike gestures.\nClockwork Prayer[citation needed]Gianello della Torre1738\nMechanical duck that was able to eat, flap its wings, and excrete\nDigesting DuckJacques de Vaucanson1898\nNikola Tesla demonstrates the first radio-controlled vessel.\nTeleautomaton\nNikola Tesla\n\n1903\nLeonardo Torres Quevedo presented the Telekino at the Paris Academy of Science, a radio-based control system with different operational states, for testing airships without risking human lives.[170] He conduct the initial test controlling a tricycle almost 100 feet away, being the first example of a radio-controlled unmanned ground vehicle.[171][172]TelekinoLeonardo Torres Quevedo1912\nLeonardo Torres Quevedo builds the first truly autonomous machine capable of playing chess. As opposed to the human-operated The Turk and Ajeeb, El Ajedrecista had an integrated automaton built to play chess without human guidance. It only played an endgame with three chess pieces, automatically moving a white king and a rook to checkmate the black king moved by a human opponent.[173][174]El AjedrecistaLeonardo Torres Quevedo1914\nIn his paper Essays on Automatics published in 1914, Leonardo Torres Quevedo proposed a machine that makes \"judgments\" using sensors that capture information from the outside, parts that manipulate the outside world like arms, power sources such as batteries and air pressure, and most importantly, captured information and past information. It was defined as an organism that can control reactions in response to external information and adapt to changes in the environment to change its behavior.[175][176][177][178]Essays on Automatics\nLeonardo Torres Quevedo1921\nFirst fictional automatons called \"robots\" appear in the play R.U.R.Rossum's Universal RobotsKarel \u010capek1930s\nHumanoid robot exhibited at the 1939 and 1940 World's FairsElektroWestinghouse Electric Corporation1946\nFirst general-purpose digital computer\nWhirlwindMultiple people\n1948\nSimple robots exhibiting biological behaviors[179]Elsie and Elmer\nWilliam Grey Walter1948\nFormulation of principles of cyberneticscyberneticsNorbert Wiener1956\nFirst commercial robot, from the Unimation company founded by George Devol and Joseph Engelberger, based on Devol's patents[180]UnimateGeorge Devol1961\nFirst installed industrial robot.  The first digitally operated and programmable robot, Unimate, was installed in 1961 to lift hot pieces of metal from a die casting machine and stack them.\nUnimateGeorge Devol1967 to 1972\nFirst full-scale humanoid intelligent robot,[181][182] and first android. Its limb control system allowed it to walk with the lower limbs, and to grip and transport objects with its hands, using tactile sensors. Its vision system allowed it to measure distances and directions to objects using external receptors, artificial eyes, and ears. And its conversation system allowed it to communicate with a person in Japanese, with an artificial mouth.[183][184][185]WABOT-1\nWaseda University1973\nFirst industrial robot with six electromechanically driven axes[186][187]Famulus\nKUKA Robot Group1974\nThe world's first microcomputer controlled electric industrial robot, IRB 6 from ASEA, was delivered to a small mechanical engineering company in southern Sweden. The design of this robot had been patented in 1972.\nIRB 6\nABB Robot Group1975\nProgrammable universal manipulation arm, a Unimation product\nPUMAVictor Scheinman1978\nThe first object-level robot programming language, RAPT, allowing robots to handle variations in object position, shape, and sensor noise.[188]Freddy I and IIPatricia Ambler and Robin Popplestone1983\nFirst multitasking, the parallel programming language used for robot control. It was the Event Driven Language (EDL) on the IBM/Series/1 process computer, with the implementation of both inter-process communication (WAIT/POST) and mutual exclusion (ENQ/DEQ) mechanisms for robot control.[189]ADRIEL I\nStevo Bozinovski and Mihail Sestakov\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Artificial intelligenceAutonomous robotCloud roboticsCognitive roboticsEvolutionary roboticsFog roboticsGlossary of roboticsIndex of robotics articlesMechatronicsMulti-agent systemOutline of roboticsQuantum roboticsRoboethicsRobot rightsRobotic artRobotic governanceSelf-reconfiguring modular robotSoft roboticsTeleroboticsNotes[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^One database, developed by the United States Department of Energy, contains information on almost 500 existing robotic technologies.[10]References[edit]^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"German National Library\". International classification system of the German National Library (GND). Archived from the original on 2020-08-19.^\"Origami-Inspired Robots Can Sense, Analyze and Act in Challenging Environments\". UCLA. Retrieved 2023-04-10.^Raj, Aditi (26 August 2024). \"AI & Robotics: The Role of AI in Robots\". Retrieved 2024-08-29.^Hunt, V. Daniel (1985). \"Smart Robots\". Smart Robots: A Handbook of Intelligent Robotic Systems. Chapman and Hall. p.\u00a0141. ISBN\u00a0978-1-4613-2533-8. Archived from the original on 2023-03-15. Retrieved 2018-12-04.^\"Robot density rises globally\". Robotic Industries Association. 8 February 2018. Archived from the original on 2020-11-23. Retrieved 2018-12-03.^Pinto, Jim (1 October 2003). \"Fully automated factories approach reality\". Automation World. Archived from the original on 2011-10-01. Retrieved 2018-12-03.^Eyre, Michael (12 September 2014). \"'Boris' the robot can load up dishwasher\". BBC News. Archived from the original on 2020-12-21. Retrieved 2018-12-03.^Corner, Stuart (23 November 2017). \"AI-driven robot makes 'perfect' flatbread\". iothub.com.au. Archived from the original on 2020-11-24. Retrieved 2018-12-03.^Pollock, Emily (7 June 2018). \"Construction Robotics Industry Set to Double by 2023\". engineering.com. Archived from the original on 2020-08-07. Retrieved 2018-12-03.^\"Technology Advanced Search\". D&D Knowledge Management Information Tool. Archived from the original on 2020-08-06.^Ar\u00e1mbula Cos\u00edo, F.; Hibberd, R. D.; Davies, B. L. (July 1997). \"Electromagnetic compatibility aspects of active robotic systems for surgery: the robotic prostatectomy experience\". Medical and Biological Engineering and Computing. 35 (4): 436\u2013440. doi:10.1007/BF02534105. ISSN\u00a01741-0444. PMID\u00a09327627. S2CID\u00a021479700.^Grift, Tony E. (2004). \"Agricultural Robotics\". University of Illinois at Urbana\u2013Champaign. Archived from the original on 2007-05-04. Retrieved 2018-12-03.^Thomas, Jim (1 November 2017). \"How corporate giants are automating the farm\". New Internationalist. Archived from the original on 2021-01-10. Retrieved 2018-12-03.^Kolodny, Lora (4 July 2017). \"Robots are coming to a burger joint near you\". CNBC. Archived from the original on 2020-12-05. Retrieved 2018-12-03.^Scott Kirsner (27 January 2023). \"Robots in the kitchen? Local engineers are making it a reality\". The Boston Globe.^Dowling, Kevin. \"Power Sources for Small Robots\"(PDF). Carnegie Mellon University. Archived(PDF) from the original on 2020-11-25. Retrieved 2012-05-11.^Roozing, Wesley; Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2016). \"Design Optimisation and Control of Compliant Actuation Arrangements in Articulated Robots for Improved Energy Efficiency\". IEEE Robotics and Automation Letters. 1 (2): 1110\u20131117. Bibcode:2016IRAL....1.1110R. doi:10.1109/LRA.2016.2521926. S2CID\u00a01940410.^Pratt, G.A.; Williamson, M.M. (1995). \"Series elastic actuators\". Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human-Robot Interaction and Cooperative Robots. Vol.\u00a01. pp.\u00a0399\u2013406. doi:10.1109/IROS.1995.525827. hdl:1721.1/36966. ISBN\u00a00-8186-7108-4. S2CID\u00a017120394.^Furn\u00e9mont, Rapha\u00ebl; Mathijssen, Glenn; Verstraten, Tom; Lefeber, Dirk; Vanderborght, Bram (27 January 2016). \"Bi-directional series-parallel elastic actuator and overlap of the actuation layers\"(PDF). Bioinspiration & Biomimetics. 11 (1) 016005. Bibcode:2016BiBi...11a6005F. doi:10.1088/1748-3190/11/1/016005. PMID\u00a026813145. S2CID\u00a037031990. Archived(PDF) from the original on 2022-10-01. Retrieved 2023-03-15.^Pratt, Jerry E.; Krupp, Benjamin T. (2004). \"Series Elastic Actuators for legged robots\". In Gerhart, Grant R; Shoemaker, Chuck M; Gage, Douglas W (eds.). Unmanned Ground Vehicle Technology VI. Vol.\u00a05422. pp.\u00a0135\u2013144. doi:10.1117/12.548000. S2CID\u00a016586246.^Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2013). \"Walking Pattern Generation for a Humanoid Robot with Compliant Joints\". Autonomous Robots. 35 (1): 1\u201314. doi:10.1007/s10514-013-9330-7. S2CID\u00a0624563.^Colgate, J. Edward (1988). The control of dynamically interacting systems (Thesis). hdl:1721.1/14380.^Calanca, Andrea; Muradore, Riccardo; Fiorini, Paolo (November 2017). \"Impedance control of series elastic actuators: Passivity and acceleration-based control\". Mechatronics. 47: 37\u201348. doi:10.1016/j.mechatronics.2017.08.010.^Tosun, Fatih Emre; Patoglu, Volkan (June 2020). \"Necessary and Sufficient Conditions for the Passivity of Impedance Rendering With Velocity-Sourced Series Elastic Actuation\". IEEE Transactions on Robotics. 36 (3): 757\u2013772. Bibcode:2020ITRob..36..757T. doi:10.1109/TRO.2019.2962332. S2CID\u00a0212907787.^www.imagesco.com, Images SI Inc -. \"Air Muscle actuators, going further, page 6\". Archived from the original on 2020-11-14. Retrieved 2010-05-24.^\"Air Muscles\". Shadow Robot. Archived from the original on 2007-09-27.^Tondu, Bertrand (2012). \"Modelling of the McKibben artificial muscle: A review\". Journal of Intelligent Material Systems and Structures. 23 (3): 225\u2013253. doi:10.1177/1045389X11435435. S2CID\u00a0136854390.^\"TALKING ELECTRONICS Nitinol Page-1\". Talkingelectronics.com. Archived from the original on 2020-01-18. Retrieved 2010-11-27.^\"lf205, Hardware: Building a Linux-controlled walking robot\". Ibiblio.org. 1 November 2001. Archived from the original on 2016-03-03. Retrieved 2010-11-27.^\"WW-EAP and Artificial Muscles\". Eap.jpl.nasa.gov. Archived from the original on 2017-01-20. Retrieved 2010-11-27.^\"Empa \u2013 a117-2-eap\". Empa.ch. Archived from the original on 2015-09-24. Retrieved 2010-11-27.^\"Electroactive Polymers (EAP) as Artificial Muscles (EPAM) for Robot Applications\". Hizook. Archived from the original on 2020-08-06. Retrieved 2010-11-27.^\"Piezo LEGS \u2013 -09-26\". Archived from the original on 2008-01-30. Retrieved 2007-10-28.^\"Squiggle Motors: Overview\". Archived from the original on 2007-10-07. Retrieved 2007-10-08.^Nishibori; et\u00a0al. (2003). \"Robot Hand with Fingers Using Vibration-Type Ultrasonic Motors (Driving Characteristics)\". Journal of Robotics and Mechatronics. 15 (6): 588\u2013595. doi:10.20965/jrm.2003.p0588.^Otake, Mihoko; Kagami, Yoshiharu; Ishikawa, Kohei; Inaba, Masayuki; Inoue, Hirochika (6 April 2001). Wilson, Alan R.; Asanuma, Hiroshi (eds.). \"Shape design of gel robots made of electroactive polymer gel\". Smart Materials. 4234: 194\u2013202. Bibcode:2001SPIE.4234..194O. doi:10.1117/12.424407. S2CID\u00a030357330.^Madden, John D. (16 November 2007). \"Mobile Robots: Motor Challenges and Materials Solutions\". Science. 318 (5853): 1094\u20131097. Bibcode:2007Sci...318.1094M. CiteSeerX\u00a010.1.1.395.4635. doi:10.1126/science.1146351. PMID\u00a018006737. S2CID\u00a052827127.^\"Syntouch LLC: BioTac(R) Biomimetic Tactile Sensor Array\". Archived from the original on 2009-10-03. Retrieved 2009-08-10.^Wettels, Nicholas; Santos, Veronica J.; Johansson, Roland S.; Loeb, Gerald E. (January 2008). \"Biomimetic Tactile Sensor Array\". Advanced Robotics. 22 (8): 829\u2013849. doi:10.1163/156855308X314533. S2CID\u00a04594917.^\"What is The SmartHand?\". SmartHand Project. Archived from the original on 2015-03-03. Retrieved 2011-02-04.^ abArreguin, Juan (2008). Automation and Robotics. Vienna, Austria: I-Tech and Publishing.^\"Annotated Mythbusters: Episode 78: Ninja Myths \u2013 Walking on Water, Catching a Sword, Catching an Arrow\". Archived from the original on 2020-11-12. Retrieved 2010-02-13. (Discovery Channel's Mythbusters making mechanical gripper from the chain and metal wire)^\"Robonaut hand\". Archived from the original on 2020-02-22. Retrieved 2011-11-21.^\"Delft hand\". TU Delft. Archived from the original on 2012-02-03. Retrieved 2011-11-21.^M&C. \"TU Delft ontwikkelt goedkope, voorzichtige robothand\". TU Delft. Archived from the original on 2017-03-13. Retrieved 2011-11-21.^\"astrictive definition \u2013 English definition dictionary \u2013 Reverso\". Archived from the original on 2020-04-30. Retrieved 2008-01-06.^Tijsma, H.A.; Liefhebber, F.; Herder, J.L. (2005). \"Evaluation of New User Interface Features for the MANUS Robot Arm\". 9th International Conference on Rehabilitation Robotics, 2005. ICORR 2005. pp.\u00a0258\u2013263. doi:10.1109/ICORR.2005.1501097. ISBN\u00a00-7803-9003-2. S2CID\u00a036445389.^Allcock, Andrew (2006). \"Anthropomorphic hand is almost human\". Machinery. Archived from the original on 2007-09-28. Retrieved 2007-10-17.^\"Welcome\". Archived(PDF) from the original on 2013-05-10. Retrieved 2007-10-28.^ abcCorke, Peter (2017). Robotics, Vision and Control. Springer Tracts in Advanced Robotics. Vol.\u00a0118. doi:10.1007/978-3-319-54413-7. ISBN\u00a0978-3-319-54412-0. ISSN\u00a01610-7438. Archived from the original on 2022-10-20. Retrieved 2023-03-15.^ abcLee, K. S. Fu, Ralph Gonzalez, C S. G. (1987). Robotics: Control Sensing. Vis. McGraw-Hill. ISBN\u00a0978-0-07-026510-3. Archived from the original on 2023-03-15. Retrieved 2023-03-15.{{cite book}}:  CS1 maint: multiple names: authors list (link)^ abcdShort, Michael; Burn, Kevin (1 April 2011). \"A generic controller architecture for intelligent robotic systems\". Robotics and Computer-Integrated Manufacturing. 27 (2): 292\u2013305. doi:10.1016/j.rcim.2010.07.013. ISSN\u00a00736-5845.^Ray, Partha Pratim (2016). \"Internet of Robotic Things: Concept, Technologies, and Challenges\". IEEE Access. 4: 9489\u20139500. Bibcode:2016IEEEA...4.9489R. doi:10.1109/ACCESS.2017.2647747. ISSN\u00a02169-3536. S2CID\u00a09273802.^ abBurn, K.; Short, M.; Bicker, R. (July 2003). \"Adaptive and Nonlinear Fuzzy Force Control Techniques Applied to Robots Operating in Uncertain Environments\". Journal of Robotic Systems. 20 (7): 391\u2013400. doi:10.1002/rob.10093. ISSN\u00a00741-2223. Archived from the original on 2022-11-26. Retrieved 2023-03-15.^Burn, Kevin; Home, Geoffrey (1 May 2008). \"Environment classification using Kohonen self-organizing maps\". Expert Systems. 25 (2): 98\u2013114. doi:10.1111/j.1468-0394.2008.00441.x. ISSN\u00a00266-4720. S2CID\u00a033369232.^Mason, Matthew T. (2001). Mechanics of Robotic Manipulation. doi:10.7551/mitpress/4527.001.0001. ISBN\u00a0978-0-262-25662-9. S2CID\u00a05260407.^\"What is a robotic end-effector?\". ATI Industrial Automation. 2007. Archived from the original on 2020-12-17. Retrieved 2007-10-16.^Crane, Carl D.; Joseph Duffy (1998). Kinematic Analysis of Robot Manipulators. Cambridge University Press. ISBN\u00a0978-0-521-57063-3. Archived from the original on 2020-04-02. Retrieved 2007-10-16.^G.J. Monkman, S. Hesse, R. Steinmann & H. Schunk (2007). Robot Grippers. Berlin: Wiley^\"T.O.B.B\". Mtoussaint.de. Archived from the original on 2020-07-08. Retrieved 2010-11-27.^\"nBot, a two wheel balancing robot\". Geology.heroy.smu.edu. Archived from the original on 2021-01-26. Retrieved 2010-11-27.^\"ROBONAUT Activity Report\". NASA. 2004. Archived from the original on 2007-08-20. Retrieved 2007-10-20.^Guizzo, Erico (29 April 2010). \"A Robot That Balances on a Ball\". IEEE Spectrum. Archived from the original on 2023-02-10. Retrieved 2023-03-15.^\"Carnegie Mellon Researchers Develop New Type of Mobile Robot That Balances and Moves on a Ball Instead of Legs or Wheels\" (Press release). Carnegie Mellon. 9 August 2006. Archived from the original on 2007-06-09. Retrieved 2007-10-20.^\"Spherical Robot Can Climb Over Obstacles\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27.^\"Rotundus\". Rotundus.se. Archived from the original on 2011-08-26. Retrieved 2010-11-27.^\"OrbSwarm Gets A Brain\". BotJunkie. 11 July 2007. Archived from the original on 2012-05-16. Retrieved 2010-11-27.^\"Rolling Orbital Bluetooth Operated Thing\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27.^\"Swarm\". Orbswarm.com. Archived from the original on 2021-01-26. Retrieved 2010-11-27.^\"The Ball Bot: Johnnytronic@Sun\". Blogs.sun.com. Archived from the original on 2011-08-24. Retrieved 2010-11-27.^\"Senior Design Projects | College of Engineering & Applied Science| University of Colorado at Boulder\". Engineering.colorado.edu. 30 April 2008. Archived from the original on 2011-07-23. Retrieved 2010-11-27.^\"JPL Robotics: System: Commercial Rovers\". Archived from the original on 2006-06-15.^\"AMBER Lab\". Archived from the original on 2020-11-25. Retrieved 2012-01-23.^\"Micromagic Systems Robotics Lab\". Archived from the original on 2017-06-01. Retrieved 2009-04-29.^\"AMRU-5 hexapod robot\"(PDF). Archived(PDF) from the original on 2016-08-17. Retrieved 2009-04-29.^\"Achieving Stable Walking\". Honda Worldwide. Archived from the original on 2011-11-08. Retrieved 2007-10-22.^\"Funny Walk\". Pooter Geek. 28 December 2004. Archived from the original on 2011-09-28. Retrieved 2007-10-22.^\"ASIMO's Pimp Shuffle\". Popular Science. 9 January 2007. Archived from the original on 2011-07-24. Retrieved 2007-10-22.^\"Robot Shows Prime Minister How to Loosen Up > > A drunk robot?\". The Temple of VTEC \u2013 Honda and Acura Enthusiasts Online Forums. 25 August 2003. Archived from the original on 2020-04-30.^\"3D One-Leg Hopper (1983\u20131984)\". MIT Leg Laboratory. Archived from the original on 2018-07-25. Retrieved 2007-10-22.^\"3D Biped (1989\u20131995)\". MIT Leg Laboratory. Archived from the original on 2011-09-26. Retrieved 2007-10-28.^\"Quadruped (1984\u20131987)\". MIT Leg Laboratory. Archived from the original on 2011-08-23. Retrieved 2007-10-28.^\"MIT Leg Lab Robots- Main\". Archived from the original on 2020-08-07. Retrieved 2007-10-28.^\"About the Robots\". Anybots. Archived from the original on 2007-09-09. Retrieved 2007-10-23.^\"Anything, Anytime, Anywhere\". Anybots. Archived from the original on 2007-10-27. Retrieved 2007-10-23.^\"Dexter Jumps video\". YouTube. 1 March 2007. Archived from the original on 2021-10-30. Retrieved 2007-10-23.^Collins, Steve; Ruina, Andy; Tedrake, Russ; Wisse, Martijn (18 February 2005). \"Efficient Bipedal Robots Based on Passive-Dynamic Walkers\". Science. 307 (5712): 1082\u20131085. Bibcode:2005Sci...307.1082C. doi:10.1126/science.1107799. PMID\u00a015718465. S2CID\u00a01315227.^Collins, S.H.; Ruina, A. (2005). \"A Bipedal Walking Robot with Efficient and Human-Like Gait\". Proceedings of the 2005 IEEE International Conference on Robotics and Automation. pp.\u00a01983\u20131988. doi:10.1109/ROBOT.2005.1570404. ISBN\u00a00-7803-8914-X. S2CID\u00a015145353.^\"Testing the Limits\"(PDF). Boeing. p.\u00a029. Archived(PDF) from the original on 2018-12-15. Retrieved 2008-04-09.^Zhang, Jun; Zhao, Ning; Qu, Feiyang (15 November 2022). \"Bio-inspired flapping wing robots with foldable or deformable wings: a review\". Bioinspiration & Biomimetics. 18 (1): 011002. doi:10.1088/1748-3190/ac9ef5. ISSN\u00a01748-3182. PMID\u00a036317380. S2CID\u00a0253246037.^ abcShin, Won Dong; Park, Jaejun; Park, Hae-Won (1 September 2019). \"Development and experiments of a bio-inspired robot with multi-mode in aerial and terrestrial locomotion\". Bioinspiration & Biomimetics. 14 (5): 056009. Bibcode:2019BiBi...14e6009S. doi:10.1088/1748-3190/ab2ab7. ISSN\u00a01748-3182. PMID\u00a031212268. S2CID\u00a0195066183.^Ramezani, Alireza; Shi, Xichen; Chung, Soon-Jo; Hutchinson, Seth (May 2016). \"Bat Bot (B2), a biologically inspired flying machine\". 2016 IEEE International Conference on Robotics and Automation (ICRA). Stockholm, Sweden: IEEE. pp.\u00a03219\u20133226. doi:10.1109/ICRA.2016.7487491. ISBN\u00a0978-1-4673-8026-3. S2CID\u00a08581750.^ abDaler, Ludovic; Mintchev, Stefano; Stefanini, Cesare; Floreano, Dario (19 January 2015). \"A bioinspired multi-modal flying and walking robot\". Bioinspiration & Biomimetics. 10 (1) 016005. Bibcode:2015BiBi...10a6005D. doi:10.1088/1748-3190/10/1/016005. ISSN\u00a01748-3190. PMID\u00a025599118. S2CID\u00a011132948.^ abKilian, Lukas; Shahid, Farzeen; Zhao, Jing-Shan; Nayeri, Christian Navid (1 July 2022). \"Bioinspired morphing wings: mechanical design and wind tunnel experiments\". Bioinspiration & Biomimetics. 17 (4): 046019. Bibcode:2022BiBi...17d6019K. doi:10.1088/1748-3190/ac72e1. ISSN\u00a01748-3182. PMID\u00a035609562. S2CID\u00a0249045806.^Savastano, E.; Perez-Sanchez, V.; Arrue, B.C.; Ollero, A. (July 2022). \"High-Performance Morphing Wing for Large-Scale Bio-Inspired Unmanned Aerial Vehicles\". IEEE Robotics and Automation Letters. 7 (3): 8076\u20138083. Bibcode:2022IRAL....7.8076S. doi:10.1109/LRA.2022.3185389. ISSN\u00a02377-3766. S2CID\u00a0250008824.^Grant, Daniel T.; Abdulrahim, Mujahid; Lind, Rick (June 2010). \"Flight Dynamics of a Morphing Aircraft Utilizing Independent Multiple-Joint Wing Sweep\". International Journal of Micro Air Vehicles. 2 (2): 91\u2013106. doi:10.1260/1756-8293.2.2.91. ISSN\u00a01756-8293. S2CID\u00a0110577545.^Phan, Hoang Vu; Park, Hoon Cheol (4 December 2020). \"Mechanisms of collision recovery in flying beetles and flapping-wing robots\". Science. 370 (6521): 1214\u20131219. Bibcode:2020Sci...370.1214P. doi:10.1126/science.abd3285. ISSN\u00a00036-8075. PMID\u00a033273101. S2CID\u00a0227257247.^Hu, Zheng; McCauley, Raymond; Schaeffer, Steve; Deng, Xinyan (May 2009). \"Aerodynamics of dragonfly flight and robotic design\". 2009 IEEE International Conference on Robotics and Automation. pp.\u00a03061\u20133066. doi:10.1109/ROBOT.2009.5152760. ISBN\u00a0978-1-4244-2788-8. S2CID\u00a012291429.^Balta, Miquel; Deb, Dipan; Taha, Haithem E (26 October 2021). \"Flow visualization and force measurement of the clapping effect in bio-inspired flying robots\". Bioinspiration & Biomimetics. 16 (6): 066020. Bibcode:2021BiBi...16f6020B. doi:10.1088/1748-3190/ac2b00. ISSN\u00a01748-3182. PMID\u00a034584023. S2CID\u00a0238217893.^Miller, Gavin. \"Introduction\". snakerobots.com. Archived from the original on 2011-08-17. Retrieved 2007-10-22.^\"ACM-R5\". Archived from the original on 2011-10-11.^\"Swimming snake robot (commentary in Japanese)\". Archived from the original on 2012-02-08. Retrieved 2007-10-28.^\"Commercialized Quadruped Walking Vehicle \"TITAN VII\"\". Hirose Fukushima Robotics Lab. Archived from the original on 2007-11-06. Retrieved 2007-10-23.^Pachal, Peter (23 January 2007). \"Plen, the robot that skates across your desk\". SCI FI Tech. Archived from the original on 2007-10-11.^Capuchin on YouTube^Wallbot on YouTube^Stanford University: Stickybot on YouTube^Sfakiotakis, M.; Lane, D.M.; Davies, J.B.C. (April 1999). \"Review of fish swimming modes for aquatic locomotion\". IEEE Journal of Oceanic Engineering. 24 (2): 237\u2013252. Bibcode:1999IJOE...24..237S. CiteSeerX\u00a010.1.1.459.8614. doi:10.1109/48.757275. S2CID\u00a017226211.^Richard Mason. \"What is the market for robot fish?\". Archived from the original on 2009-07-04.^\"Robotic fish powered by Gumstix PC and PIC\". Human Centred Robotics Group at Essex University. Archived from the original on 2011-08-14. Retrieved 2007-10-25.^Witoon Juwarahawong. \"Fish Robot\". Institute of Field Robotics. Archived from the original on 2007-11-04. Retrieved 2007-10-25.^\"Festo - AquaPenguin\". 17 April 2009 \u2013 via YouTube.^\"High-Speed Robotic Fish\". iSplash-Robotics. Archived from the original on 2020-03-11. Retrieved 2017-01-07.^\"iSplash-II: Realizing Fast Carangiform Swimming to Outperform a Real Fish\"(PDF). Robotics Group at Essex University. Archived from the original(PDF) on 2015-09-30. Retrieved 2015-09-29.^\"iSplash-I: High Performance Swimming Motion of a Carangiform Robotic Fish with Full-Body Coordination\"(PDF). Robotics Group at Essex University. Archived from the original(PDF) on 2015-09-30. Retrieved 2015-09-29.^Jaulin, Luc; Le Bars, Fabrice (February 2013). \"An Interval Approach for Stability Analysis: Application to Sailboat Robotics\". IEEE Transactions on Robotics. 29 (1): 282\u2013287. Bibcode:2013ITRob..29..282J. CiteSeerX\u00a010.1.1.711.7180. doi:10.1109/TRO.2012.2217794. S2CID\u00a04977937.^\"A Ping-Pong-Playing Terminator\". Popular Science. Archived from the original on 2021-01-22. Retrieved 2010-12-19.^\"Synthiam Exosphere combines AI, human operators to train robots\". The Robot Report. Archived from the original on 2020-10-06. Retrieved 2020-04-29.^ abKagan, Eugene; Ben-Gal, Irad (2015). Search and foraging:individual motion and swarm dynamics. Chapman and Hall/CRC. ISBN\u00a0978-1-4822-4210-2. Archived from the original on 2023-03-15. Retrieved 2020-08-26.^Banks, Jaime (2020). \"Optimus Primed: Media Cultivation of Robot Mental Models and Social Judgments\". Frontiers in Robotics and AI. 7 62. doi:10.3389/frobt.2020.00062. PMC\u00a07805817. PMID\u00a033501230.^ abWullenkord, Ricarda; Fraune, Marlena R.; Eyssel, Friederike; Sabanovic, Selma (2016). \"Getting in Touch: How imagined, actual, and physical contact affect evaluations of robots\". 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). pp.\u00a0980\u2013985. doi:10.1109/ROMAN.2016.7745228. ISBN\u00a0978-1-5090-3929-6. S2CID\u00a06305599.^Norberto Pires, J. (December 2005). \"Robot-by-voice: experiments on commanding an industrial robot using the human voice\". Industrial Robot. 32 (6): 505\u2013511. doi:10.1108/01439910510629244.^\"Survey of the State of the Art in Human Language Technology: 1.2: Speech Recognition\". Archived from the original on 2007-11-11.^Fournier, Randolph Scott; Schmidt, B. June (1995). \"Voice input technology: Learning style and attitude toward its use\". Delta Pi Epsilon Journal. 37 (1): 1\u201312. ProQuest\u00a01297783046.^\"History of Speech & Voice Recognition and Transcription Software\". Dragon Naturally Speaking. Archived from the original on 2015-08-13. Retrieved 2007-10-27.^Cheng Lin, Kuan; Huang, Tien-Chi; Hung, Jason C.; Yen, Neil Y.; Ju Chen, Szu (7 June 2013). \"Facial emotion recognition towards affective computing-based learning\". Library Hi Tech. 31 (2): 294\u2013307. doi:10.1108/07378831311329068.^Walters, M. L.; Syrdal, D. S.; Koay, K. L.; Dautenhahn, K.; Te Boekhorst, R. (2008). \"Human approach distances to a mechanical-looking robot with different robot voice styles\". RO-MAN 2008 - the 17th IEEE International Symposium on Robot and Human Interactive Communication. pp.\u00a0707\u2013712. doi:10.1109/ROMAN.2008.4600750. ISBN\u00a0978-1-4244-2212-8. S2CID\u00a08653718.^Pauletto, Sandra; Bowles, Tristan (2010). \"Designing the emotional content of a robotic speech signal\". Proceedings of the 5th Audio Mostly Conference on a Conference on Interaction with Sound - AM '10. pp.\u00a01\u20138. doi:10.1145/1859799.1859804. ISBN\u00a0978-1-4503-0046-9. S2CID\u00a030423778.^Bowles, Tristan; Pauletto, Sandra (2010). Emotions in the Voice: Humanising a Robotic Voice(PDF). Proceedings of the 7th Sound and Music Computing Conference. Barcelona. Archived(PDF) from the original on 2023-02-10. Retrieved 2023-03-15.^\"World of 2-XL: Leachim\". www.2xlrobot.com. Archived from the original on 2020-07-05. Retrieved 2019-05-28.^\"The Boston Globe from Boston, Massachusetts on June 23, 1974 \u00b7 132\". Newspapers.com. 23 June 1974. Archived from the original on 2020-01-10. Retrieved 2019-05-28.^ ab\"cyberneticzoo.com - Page 135 of 194 - a history of cybernetic animals and early robots\". cyberneticzoo.com. Archived from the original on 2020-08-06. Retrieved 2019-05-28.^\"Frubber facial expressions\". Archived from the original on 2009-02-07.^\"Best Inventions of 2008 \u2013 TIME\". Time. 29 October 2008. Archived from the original on 2008-11-02 \u2013 via www.time.com.^\"Kismet: Robot at MIT's AI Lab Interacts With Humans\". Sam Ogden. Archived from the original on 2007-10-12. Retrieved 2007-10-28.^Waldherr, Stefan; Romero, Roseli; Thrun, Sebastian (1 September 2000). \"A Gesture Based Interface for Human-Robot Interaction\". Autonomous Robots. 9 (2): 151\u2013173. doi:10.1023/A:1008918401478. S2CID\u00a01980239.^Li, Ling Hua; Du, Ji Fang (December 2012). \"Visual Based Hand Gesture Recognition Systems\". Applied Mechanics and Materials. 263\u2013266: 2422\u20132425. Bibcode:2012AMM...263.2422L. doi:10.4028/www.scientific.net/AMM.263-266.2422. S2CID\u00a062744240.^\"Armenian Robin the Robot to comfort kids at U.S. clinics starting July\". Public Radio of Armenia. Archived from the original on 2021-05-13. Retrieved 2021-05-13.^Park, S.; Sharlin, Ehud; Kitamura, Y.; Lau, E. (29 April 2005). Synthetic Personality in Robots and its Effect on Human-Robot Relationship (Report). doi:10.11575/PRISM/31041. hdl:1880/45619.^\"Robot Receptionist Dishes Directions and Attitude\". NPR.org. Archived from the original on 2020-12-01. Retrieved 2018-04-05.^\"New Scientist: A good robot has personality but not looks\"(PDF). Archived from the original(PDF) on 2006-09-29.^\"Playtime with Pleo, your robotic dinosaur friend\". 25 September 2008. Archived from the original on 2019-01-20. Retrieved 2014-12-14.^NOVA conversation with Professor Moravec, October 1997. NOVA OnlineArchived 2017-08-02 at the Wayback Machine^Agarwal, P.K. Elements of Physics XI. Rastogi Publications. p.\u00a02. ISBN\u00a0978-81-7133-911-2.^Sandhana, Lakshmi (5 September 2002). \"A Theory of Evolution, for Robots\". Wired. Archived from the original on 2014-03-29. Retrieved 2007-10-28.^\"Experimental Evolution In Robots Probes The Emergence Of Biological Communication\". Science Daily. 24 February 2007. Archived from the original on 2018-11-16. Retrieved 2007-10-28.^\u017dlajpah, Leon (15 December 2008). \"Simulation in robotics\". Mathematics and Computers in Simulation. 79 (4): 879\u2013897. doi:10.1016/j.matcom.2008.02.017.^\"Evolution trains robot teams TRN 051904\". Technology Research News. Archived from the original on 2016-06-23. Retrieved 2009-01-22.^M\u00fcller, Christopher (2023). World Robotics 2023 \u2013 Industrial Robots. Frankfurt, Germany: IFR Statistical Department, VDMA Services GmbH.^Tandon, Prateek (2017). Quantum Robotics. Morgan & Claypool Publishers. ISBN\u00a0978-1-62705-913-8.^Dragani, Rachelle (8 November 2018). \"Can a robot make you a 'superworker'?\". Verizon Communications. Archived from the original on 2020-08-06. Retrieved 2018-12-03.^\"Robotics\". American Elements. Retrieved 2023-04-10.^\"Career: Robotics Engineer\". Princeton Review. 2012. Archived from the original on 2015-01-21. Retrieved 2012-01-27.^Saad, Ashraf; Kroutil, Ryan (2012). Hands-on Learning of Programming Concepts Using Robotics for Middle and High School Students. Proceedings of the 50th Annual Southeast Regional Conference of the Association for Computing Machinery. ACM. pp.\u00a0361\u2013362. doi:10.1145/2184512.2184605.^Toy, Tommy (29 June 2011). \"Outlook for robotics and Automation for 2011 and beyond are excellent says expert\". PBT Consulting. Archived from the original on 2012-01-27. Retrieved 2012-01-27.^Frey, Carl Benedikt; Osborne, Michael A. (January 2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254\u2013280. CiteSeerX\u00a010.1.1.395.416. doi:10.1016/j.techfore.2016.08.019.^McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID\u00a0243172487. SSRN\u00a03044448.^Hawking, Stephen (1 January 2016). \"This is the most dangerous time for our planet\". The Guardian. Archived from the original on 2021-01-31. Retrieved 2019-11-22.^\"Robotics \u2013 Thematic Research\". GlobalData. Archived from the original on 2021-09-28. Retrieved 2021-09-22.^\"Focal Points Seminar on review articles in the future of work \u2013 Safety and health at work \u2013 EU-OSHA\". osha.europa.eu. Archived from the original on 2020-01-25. Retrieved 2016-04-19.^\"Robotics: Redefining crime prevention, public safety and security\". SourceSecurity.com. Archived from the original on 2017-10-09. Retrieved 2016-09-16.^\"Draft Standard for Intelligent Assist Devices \u2014 Personnel Safety Requirements\"(PDF). Archived(PDF) from the original on 2020-11-25. Retrieved 2016-06-01.^\"ISO/TS 15066:2016 \u2013 Robots and robotic devices \u2013 Collaborative robots\". 8 March 2016. Archived from the original on 2016-10-10. Retrieved 2016-06-01.^Brog\u00e5rdh, Torgny (January 2007). \"Present and future robot control development\u2014An industrial perspective\". Annual Reviews in Control. 31 (1): 69\u201379. doi:10.1016/j.arcontrol.2007.01.002. ISSN\u00a01367-5788.^Wang, Tian-Miao; Tao, Yong; Liu, Hui (17 April 2018). \"Current Researches and Future Development Trend of Intelligent Robot: A Review\". International Journal of Automation and Computing. 15 (5): 525\u2013546. doi:10.1007/s11633-018-1115-1. ISSN\u00a01476-8186. S2CID\u00a0126037910.^Needham, Joseph (1991). Science and Civilisation in China: Volume 2, History of Scientific Thought. Cambridge University Press. ISBN\u00a0978-0-521-05800-1.^Fowler, Charles B. (October 1967). \"The Museum of Music: A History of Mechanical Instruments\". Music Educators Journal. 54 (2): 45\u201349. doi:10.2307/3391092. JSTOR\u00a03391092. S2CID\u00a0190524140.^Rosheim, Mark E. (1994). Robot Evolution: The Development of Anthrobotics. Wiley-IEEE. pp.\u00a09\u201310. ISBN\u00a0978-0-471-02622-8.^al-Jazari (Islamic artist)Archived 2008-05-07 at the Wayback Machine, Encyclop\u00e6dia Britannica.^A. P. Yuste. Electrical Engineering Hall of Fame. Early Developments of Wireless Remote Control: The Telekino of Torres-Quevedo,(pdf) vol. 96, No. 1, January 2008, Proceedings of the IEEE.^H. R. Everett (2015). Unmanned Systems of World Wars I and II. MIT Press. pp.\u00a091\u201395. ISBN\u00a0978-0-262-02922-3.^Randy Alfred, \"Nov. 7, 1905: Remote Control Wows Public\", Wired, 7 November 2011.^Williams, Andrew (16 March 2017). History of Digital Games: Developments in Art, Design and Interaction. CRC Press. ISBN\u00a0978-1-317-50381-1.^Randell, Brian (October 1982). \"From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush\". IEEE Annals of the History of Computing. 4 (4): 327\u2013341. doi:10.1109/MAHC.1982.10042. S2CID\u00a01737953.^L. Torres Quevedo. Ensayos sobre Autom\u00e1tica - Su definicion. Extension te\u00f3rica de sus aplicaciones, Revista de la Academia de Ciencias Exacta, Revista 12, pp.391-418, 1914.^Torres Quevedo, Leonardo. Autom\u00e1tica: Complemento de la Teor\u00eda de las M\u00e1quinas, (pdf), pp. 575-583, Revista de Obras P\u00fablicas, 19 November 1914.^L. Torres Quevedo. Essais sur l'Automatique - Sa d\u00e9finition. Etendue th\u00e9orique de ses applicationsArchived 2023-02-10 at the Wayback Machine, Revue G\u00e9nerale des Sciences Pures et Appliqu\u00e9es, vol.2, pp.601-611, 1915.^B. Randell. Essays on Automatics, The Origins of Digital Computers, pp.89-107, 1982.^PhD, Renato M.E. Sabbatini. \"Sabbatini, RME: An Imitation of Life: The First Robots\". Archived from the original on 2009-07-20. Retrieved 2023-03-15.^Waurzyniak, Patrick (2006). \"Masters of Manufacturing: Joseph F. Engelberger\". Society of Manufacturing Engineers. 137 (1). Archived from the original on 2011-11-09.^\"Humanoid History -WABOT-\". www.humanoid.waseda.ac.jp. Archived from the original on 2017-09-01. Retrieved 2017-05-06.^Zeghloul, Sa\u00efd; Laribi, Med Amine; Gazeau, Jean-Pierre (21 September 2015). Robotics and Mechatronics: Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics. Springer. ISBN\u00a0978-3-319-22368-1. Archived from the original on 2023-03-15. Retrieved 2017-09-10 \u2013 via Google Books.^\"Historical Android Projects\". androidworld.com. Archived from the original on 2005-11-25. Retrieved 2017-05-06.^Robots: From Science Fiction to Technological RevolutionArchived 2023-03-15 at the Wayback Machine, page 130^Duffy, Vincent G. (19 April 2016). Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering. CRC Press. ISBN\u00a0978-1-4200-6352-3. Archived from the original on 2023-03-15. Retrieved 2017-09-10 \u2013 via Google Books.^\"KUKA Industrial Robot FAMULUS\". Archived from the original on 2009-02-20. Retrieved 2008-01-10.^\"History of Industrial Robots\"(PDF). Archived from the original(PDF) on 2012-12-24. Retrieved 2012-10-27.^R. J. Popplestone; A. P. Ambler; I. Bellos (1978). \"RAPT: A language for describing assemblies\". Industrial Robot. 5 (3): 131\u2013137. doi:10.1108/eb004501.^Bozinovski, S. (1994). \"Parallel programming for mobile robot control: Agent-based approach\". 14th International Conference on Distributed Computing Systems. pp.\u00a0202\u2013208. doi:10.1109/ICDCS.1994.302412. ISBN\u00a00-8186-5840-1. S2CID\u00a027855786.Further reading[edit]R. Andrew Russell (1990). Robot Tactile Sensing. New York: Prentice Hall. ISBN\u00a0978-0-13-781592-0.McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID\u00a0243172487. SSRN\u00a03044448.Autor, David H. (1 August 2015). \"Why Are There Still So Many Jobs? The History and Future of Workplace Automation\". Journal of Economic Perspectives. 29 (3): 3\u201330. doi:10.1257/jep.29.3.3. hdl:1721.1/109476.Tooze, Adam (6 June 2019). \"Democracy and Its Discontents\". The New York Review of Books. Vol.\u00a066, no.\u00a010.External links[edit].mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}.mw-parser-output .sister-box .side-box-abovebelow{padding:0.75em 0;text-align:center}.mw-parser-output .sister-box .side-box-abovebelow>b{display:block}.mw-parser-output .sister-box .side-box-text>ul{border-top:1px solid #aaa;padding:0.75em 0;width:220px;margin:0 auto}.mw-parser-output .sister-box .side-box-text>ul>li{min-height:31px}.mw-parser-output .sister-logo{display:inline-block;width:31px;line-height:31px;vertical-align:middle;text-align:center}.mw-parser-output .sister-link{display:inline-block;margin-left:7px;width:182px;vertical-align:middle}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Robotics  at Wikipedia's sister projectsDefinitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from WikiversityIEEE Robotics and Automation SocietyInvestigation of social robots \u2013 Robots that mimic human behaviors and gestures.Wired's guide to the '50 best robots ever', a mix of robots in fiction (Hal, R2D2, K9) to real robots (Roomba, Mobot, Aibo)..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutlinevteEngineeringHistoryOutlineList of engineering branchesSpecialtiesandinterdisciplinarityCivilArchitecturalCoastalConstructionEarthquakeEcologicalEnvironmentalSanitaryGeologicalGeotechnicalHydraulicMiningMunicipal/urbanOffshoreRiverStructuralTransportationTrafficRailwayMechanicalAcousticAerospaceAutomotiveBiomechanicalEnergyManufacturingMarineNaval architectureRailwaySportsThermalTribologyElectricalBroadcastoutlineControlElectromechanicsElectronicsMicrowavesOpticalPowerRadio-frequencySignal processingTelecommunicationsChemicalBiochemical/bioprocessBiologicalBioresourceGeneticTissueChemical reactionElectrochemicalFoodMolecularPaperPetroleumProcessReactionMaterialsBiomaterialCeramicsCorrosionMetallurgyMolecularNanotechnologyPolymersSemiconductorsSurfacesComputerAIComputerCybersecurityDataNetworksRoboticsSoftwareEngineering educationBachelor of EngineeringBachelor of ScienceMaster's degreeDoctorateGraduate certificateEngineer's degreeLicensed engineerRelated topicsEngineerGlossariesEngineering\nA\u2013LM\u2013ZAerospace engineeringCivil engineeringElectrical and electronics engineeringMechanical engineeringStructural engineeringOtherAgriculturalAudioAutomationBiomedicalBioinformaticsClinicalHealth technologyPharmaceuticalRehabilitationBuilding servicesMEPDesignExplosivesFacilitiesFireForensicClimateGeomaticsGraphicsIndustrialInformationInstrumentationInstrumentation and controlLogisticsManagementMathematicsMechatronicsMilitaryNuclearOntologyPackagingPhysicsPrivacySafetySecuritySurveySustainabilitySystemsTextileCategoryCommonsWikiprojectPortalvteEmerging technologiesFieldsManufacturing3D microfabrication3D printing3D publishingClaytronicsMolecular assemblerSmart manufacturingUtility fogMaterials scienceAerogelAmorphous metalArtificial muscleConductive polymerFemtotechnologyFullereneGrapheneHigh-temperature superconductivityHigh-temperature superfluidityLinear acetylenic carbonMetamaterialsMetamaterial cloakingMetal foamMulti-function structuresNanotechnologyCarbon nanotubesMolecular nanotechnologyNanomaterialsPicotechnologyProgrammable matterQuantum dotsSiliceneSynthetic diamondRoboticsDomoticsNanoroboticsPowered exoskeletonSelf-reconfiguring modular robotSwarm roboticsUncrewed vehicleTopicsAutomationCollingridge dilemmaDifferential technological developmentDisruptive innovationEphemeralizationEthicsAIBioethicsCyberethicsNeuroethicsRobot ethicsExploratory engineeringProactionary principleTechnological changeTechnological unemploymentTechnological convergenceTechnological evolutionTechnological paradigmTechnology forecastingAccelerating changeFuture-oriented technology analysisHorizon scanningMoore's lawTechnological singularityTechnology scoutingTechnology in science fictionTechnology readiness levelTechnology roadmapTranshumanismListvteGlossaries of science and engineeringAerospace engineeringAgricultureArchaeologyArchitectureArtificial intelligenceAstronomyBiologyBotanyCalculusCell biologyCellular and molecular biology\n0\u2013LM\u2013ZChemistryCivil engineeringClinical researchComputer hardwareComputer scienceDevelopmental and reproductive biologyEcologyEconomicsElectrical and electronics engineeringEngineering\nA\u2013LM\u2013ZEntomologyEnvironmental scienceGenetics and evolutionary biologyGeography\nA\u2013MN\u2013ZArabic toponymsHebrew toponymsWestern and South AsiaGeologyIchthyologyMachine visionMathematicsMechanical engineeringMedicineMeteorologyMycologyNanotechnologyOrnithologyPhysicsProbability and statisticsPsychiatryQuantum computingRoboticsScientific namingStructural engineeringVirology.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDNationalUnited StatesFranceBnF dataCzech RepublicSpainIsraelOtherNARAYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robotics&oldid=1319748071\"", "tags": ["en.wikipedia.org", "wiki", "robotics"]}
{"url": "https://en.wikipedia.org/wiki/Robot", "title": null, "text": "Machine capable of carrying out a complex series of actions automatically.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For other uses, see Robot (disambiguation).\n\nASIMO (2000) at the Expo 2005\"Number 5\" from Short Circuit (1986 film) is a specimen of tracked semi-humanoid robotArticulatedwelding robots used in a factory are a type of industrial robot.The quadrupedalmilitary robotCheetah, an evolution of BigDog (pictured), was clocked as the world's fastest legged robot in 2012, beating the record set by an MITbipedal robot in 1989.[1].mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onAutomationAutomation in generalBankingBuildingHomeHighway systemLaboratoryLibraryBroadcastMixPool cleanerPop musicReasoningSemi-automationTelephone\nAttendantSwitchboardTeller machineVehicularVending machineRobotics and robotsDomesticVacuum cleanerRoombaLawn mowerGuided vehicleIndustrialPaintODD\nImpact of automationManumationOOLBiasSelf-driving carsTechnological unemploymentJobless recoveryPost-work societyThreat\nTrade shows and awardsASP-DACDACDATEIEEE Robotics and Automation AwardICCAD.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteA robot is a machine\u2014especially one programmable by a computer\u2014capable of carrying out a complex series of actions automatically.[2] A robot can be guided by an external control device, or the control may be embedded within. Robots may be constructed to evoke human form, but most robots are task-performing machines, designed with an emphasis on stark functionality, rather than expressive aesthetics.\nRobots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical operating robots, patient assist robots, dog therapy robots, collectively programmed swarm robots, UAV drones such as General Atomics MQ-1 Predator, and even microscopic nanorobots. By mimicking a lifelike appearance or automating movements, a robot may convey a sense of intelligence or thought of its own. Autonomous things are expected to proliferate in the future, with home robotics and the autonomous car as some of the main drivers.[3]The branch of technology that deals with the design, construction, operation, and application of robots,[4] as well as computer systems for their control, sensory feedback, and information processing is robotics. These technologies deal with automated machines that can take the place of humans in dangerous environments or manufacturing processes, or resemble humans in appearance, behavior, or cognition. Many of today's robots are inspired by nature contributing to the field of bio-inspired robotics. These robots have also created a newer branch of robotics: soft robotics.\nFrom the time of ancient civilization, there have been many accounts of user-configurable automated devices and even automata, resembling humans and other animals, such as animatronics, designed primarily as entertainment. As mechanical techniques developed through the Industrial age, there appeared more practical applications such as automated machines, remote control and wireless remote-control.\nThe term comes from a Slavic root, robot-, with meanings associated with labor. The word \"robot\" was first used to denote a fictional humanoid in a 1920 Czech-language play R.U.R. (Rossumovi Univerz\u00e1ln\u00ed Roboti \u2013 Rossum's Universal Robots) by Karel \u010capek, though it was Karel's brother Josef \u010capek who was the word's true inventor.[5][6][7] Electronics evolved into the driving force of development with the advent of the first electronic autonomous robots created by William Grey Walter in Bristol, England, in 1948, as well as Computer Numerical Control (CNC) machine tools in the late 1940s by John T. Parsons and Frank L. Stulen.\nThe first commercial, digital and programmable robot was built by George Devol in 1954 and was named the Unimate. It was sold to General Motors in 1961, where it was used to lift pieces of hot metal from die casting machines at the Inland Fisher Guide Plant in the West Trenton section of Ewing Township, New Jersey.[8]Robots have replaced humans[9] in performing repetitive and dangerous tasks which humans prefer not to do, or are unable to do because of size limitations, or which take place in extreme environments such as outer space or the bottom of the sea. There are concerns about the increasing use of robots and their role in society. Robots are blamed for rising technological unemployment as they replace workers in increasing number of functions.[10] The use of robots in military combat raises ethical concerns. The possibilities of robot autonomy and potential repercussions have been addressed in fiction and may be a realistic concern in the future.\n.mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}SummaryiCub is physically anthropomorphic; it looks like a human.There is no consensus on which machines qualify as robots but there is general agreement among experts, and the public, that robots tend to possess some or all of the following abilities and functions: accept electronic programming, process data or physical perceptions electronically, operate autonomously to some degree, move around, operate physical parts of itself or physical processes, sense and manipulate their environment, and exhibit intelligent behavior, especially behavior which mimics humans or other animals.[11][12]The word robot can refer to both physical robots and virtualsoftware agents, but the latter are usually referred to as bots.[13] Related to the concept of a robot is the field of synthetic biology, which studies entities whose nature is more comparable to living things than to machines.\nSimpler automated machines are called automatons, like animatronics, often made to resemble humans or animals. Humanoid robots that resemble humans esthetically, possibly even  organically, are called androids, while android can be shortened to droid, referring to robots with a broader likeness. On the other hand, a human that is augmented with artificial machines is called a cyborg, which is a particular type of transhuman.\nHistoryMain article: History of robotsA hypothetical reconstruction of Philo's automatic robot servant (3rd century BCE) in the Kotsanas Museum of Ancient Greek Technology, Athens, GreeceSu Song's astronomical clock tower showing the mechanical figurines which chimed the hoursal-Jazari's musical toy, from the 13th century Book of Knowledge of Ingenious Mechanical DevicesModel of Leonardo's robot with inner workings. Possibly constructed by Leonardo da Vinci around 1495.[14]The Brennan torpedo, one of the earliest 'guided missiles'William H. Richards with \"George\", 1932Early beginningsMany ancient cultures described artificial people in their writings. Examples from Greek mythology include Galatea (the mythical statue carved by Pygmalion that came to life), Talos (a man of bronze who guarded Crete from pirates), and the mechanical servants built by the Greek god Hephaestus.[15] Giants made of stone or clay are found in Jewish and Norse mythology.\nDuring classical antiquity, Greek engineers contributed many innovations. For example, in the 4th century BCE, Archytas described a steam-operated mechanical bird he called \"The Pigeon\",[16] while Ctesibius improved the clepsydra and produced the first hydraulus several decades later.[17]:\u200a2\u200a[18]Philo of Byzantium described a washstand automaton. Hero of Alexandria(10\u201370 AD) created numerous user-configurable automated devices and described machines powered by pneumatics, hydraulics, and steam, even including a \"speaking\" automaton.[19] Greek engineers also built the Antikythera mechanism \u2014 the oldest known example of an analog computer \u2014 during this period.[20][21]Ancient Chinese texts described automata, some of which were capable of flight. For example, the Han Feizi reports that 5th century BCE Mohist philosopher Mozi and his contemporary Lu Ban built artificial wooden birds that could fly. The Liezi (attributed to Lie Yukou, a 4th-century BCE Chinese philosopher) describes humanoid automata.[22] In 1066, Chinese inventor Su Song built a water clock in the form of a tower which featured mechanical figurines that chimed the hours.[23][24][25] His mechanism had a programmable drum machine with pegs that bumped into little levers that operated percussion instruments. The drummer could be programmed to play different drum patterns by moving the pegs to different locations.[25]11th century texts of Buddhist mythology also describe automata. Examples include the Samarangana Sutradhara, a treatise by Bhoja (king of Malwa) which includes a chapter about the construction of mechanical automata, including mechanical bees and birds, fountains shaped like humans and animals, and male and female dolls that refilled oil lamps, danced, played instruments, and re-enacted scenes from Hindu mythology.[26][27][28] The Lokapannatti is an 11th-12th century Buddhist cosmological text that tells of how the Buddha's relics were protected by mechanical robots (bhuta vahana yanta or \"spirit movement machines\") until they were disarmed by King Ashoka.[29]Ismail al-Jazari was a 13th-century polymath who built several automated devices driven by hydropower, including peacocks,[30] automatic gates,[31] and water clocks.[32] Among his humanoid automata was a waitress that could serve drinks. The drink was stored in a reservoir tank, from where it would drip into a bucket and then a cup, after which the waitress would appear out of an automatic door to serve the drink.[33] Al-Jazari also invented a hand washing automaton that incorporated a flush mechanism similar to that used in modern flush toilets. The automaton stood next to a basin filled with water. When the user pulled a lever, the water would drain and the automaton would refill the basin.[17]In 1377, the coronation of Richard II of England featured an automaton angel.[34] Around 1495, Leonardo da Vinci sketched plans for a mechanical humanoid robot that was able to sit up, wave its arms and move its head and jaw.[35] The design was probably based on anatomical research recorded in his Vitruvian Man. Da Vinci may have been influenced by the automata of al-Jazari.[30]In Japan, complex automata were built between the 17th to 19th centuries, with many described in the 1796 Karakuri zui (Illustrated Machinery). One such automaton was the karakuri ningy\u014d.[36] Different variations of the karakuri existed: the butai karakuri, which were used in theatre, the zashiki karakuri, which were small and used in homes, and the dashi karakuri which were used in religious festivals, where the puppets were used to perform reenactments of traditional myths and legends.\nIn France, between 1738 and 1739, Jacques de Vaucanson exhibited several automatons: a flute player, a pipe player and a duck. The duck could flap its wings, crane its neck, swallow food from the exhibitor's hand, and it gave the illusion of digesting its food by excreting matter stored in a hidden compartment.[37] About 30 years later in Switzerland, Pierre Jaquet-Droz made several mechanical figures that could write and play music. Several of these devices still exist and work.[38]Remote-controlled systemsRemotely operated vehicles were demonstrated in the late 19th century in the form of several types of remotely controlled torpedoes. The early 1870s saw remotely controlled torpedoes by John Ericsson, John Louis Lay, and Victor von Scheliha.[39]The Brennan torpedo, invented by Louis Brennan in 1877, was powered by two contra-rotating propellers that were spun by rapidly pulling out wires from drums wound inside the torpedo. Differential speed on the wires connected to the shore station allowed the torpedo to be guided to its target, making it \"the world's first practicalguided missile\".[40] In 1897 the British inventor Ernest Wilson was granted a patent for a torpedo remotely controlled by \"Hertzian\" (radio) waves[41][42] and in 1898 Nikola Tesla publicly demonstrated a wireless-controlled torpedo that he hoped to sell to the US Navy.[43][44]In 1903, the Spanish engineer Leonardo Torres Quevedo demonstrated a radio control system called Telekino at the Paris Academy of Sciences,[45] which he wanted to use to control an airship of his own design. He obtained several patents for the system in other countries.[46][47] Unlike previous 'on/off' techniques, Torres established a method for controlling any mechanical or electrical device with different states of operation.[48] The Telekino remotely controlled a tricycle in 1904, considered the first case of an unmanned ground vehicle, and an electric boat with a crew in 1906, which was controlled at a distance over 2\u00a0km.[49]Archibald Low, known as the \"father of radio guidance systems\" for his pioneering work on guided rockets and planes during the First World War. In 1917, he demonstrated a remote controlled aircraft to the Royal Flying Corps and in the same year built the first wire-guided rocket.\nEarly robotsIn 1928, one of the first humanoid robots, Eric, was exhibited at the annual exhibition of the Model Engineers Society in London, where it delivered a speech. Invented by W. H. Richards, the robot's frame consisted of an aluminium body of armour with eleven electromagnets and one motor powered by a twelve-volt power source. The robot could move its hands and head and could be controlled through remote control or voice control.[50] Both Eric and his \"brother\" George toured the world.[51]Westinghouse Electric Corporation built Televox in 1926; it was a cardboard cutout connected to various devices which users could turn on and off. In 1939, the humanoid robot known as Elektro was debuted at the 1939 New York World's Fair.[52][53] Seven feet tall (2.1 m) and weighing 265 pounds (120.2\u00a0kg), it could walk by voice command, speak about 700 words (using a 78-rpm record player), smoke cigarettes, blow up balloons, and move its head and arms. The body consisted of a steel gear, cam and motor skeleton covered by an aluminum skin. In 1928, Japan's first robot, Gakutensoku, was designed and constructed by biologist Makoto Nishimura.\nThe German V-1 flying bomb was equipped with systems for automatic guidance and range control, flying on a predetermined course (which could include a 90-degree turn) and entering a terminal dive after a predetermined distance. It was reported as being a 'robot' in contemporary descriptions.[54]Modern autonomous robotsThe first electronic autonomous robots with complex behaviour were created by William Grey Walter of the Burden Neurological Institute at Bristol, England in 1948 and 1949. He wanted to prove that rich connections between a small number of brain cells could give rise to very complex behaviors \u2013 essentially that the secret of how the brain worked lay in how it was wired up. His first robots, named Elmer and Elsie, were constructed between 1948 and 1949 and were often described as tortoises due to their shape and slow rate of movement. The three-wheeled tortoise robots were capable of phototaxis, by which they could find their way to a recharging station when they ran low on battery power.\nWalter stressed the importance of using purely analogue electronics to simulate brain processes at a time when his contemporaries such as Alan Turing and John von Neumann were all turning towards a view of mental processes in terms of digitalcomputation. His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden. Modern incarnations of Walter's turtles may be found in the form of BEAM robotics.[55]The first digitally operated and programmable robot was invented by George Devol in 1954 and was ultimately called the Unimate. This ultimately laid the foundations of the modern robotics industry.[56] Devol sold the first Unimate to General Motors in 1960, and it was installed in 1961 in a plant in Trenton, New Jersey to lift hot pieces of metal from a die casting machine and stack them.[57]The first palletizing robot was introduced in 1963 by the Fuji Yusoki Kogyo Company.[58] In 1973, a robot with six electromechanically driven axes was patented[59][60][61] by KUKA robotics in Germany, and the programmable universal manipulation arm was invented by Victor Scheinman in 1976, and the design was sold to Unimation.\nCommercial and industrial robots are now in widespread use performing jobs more cheaply or with greater accuracy and reliability than humans. They are also employed for jobs which are too dirty, dangerous or dull to be suitable for humans. Robots are widely used in manufacturing, assembly and packing, transport, earth and space exploration, surgery, weaponry, laboratory research, and mass production of consumer and industrial goods.[62]Future development and trends.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}External videosAtlas, The Next GenerationFurther information: RoboticsVarious techniques have emerged to develop the science of robotics and robots. One method is evolutionary robotics, in which a number of differing robots are submitted to tests. Those which perform best are used as a model to create a subsequent \"generation\" of robots. Another method is developmental robotics, which tracks changes and development within a single robot in the areas of problem-solving and other functions. Another new type of robot is just recently introduced which acts both as a smartphone and robot and is named RoboHon.[63]As robots become more advanced, eventually there may be a standard computer operating system designed mainly for robots. Robot Operating System (ROS) is an open-source software set of programs being developed at Stanford University, the Massachusetts Institute of Technology, and the Technical University of Munich, Germany, among others. ROS provides ways to program a robot's navigation and limbs regardless of the specific hardware involved. It also provides high-level commands for items like image recognition and even opening doors. When ROS boots up on a robot's computer, it would obtain data on attributes such as the length and movement of robots' limbs. It would relay this data to higher-level algorithms. Microsoft is also developing a \"Windows for robots\" system with its Robotics Developer Studio, which has been available since 2007.[64]Japan hopes to have full-scale commercialization of service robots by 2025. Much technological research in Japan is led by Japanese government agencies, particularly the Trade Ministry.[65]Many future applications of robotics seem obvious to people, even though they are well beyond the capabilities of robots available at the time of the prediction.[66][67] As early as 1982 people were confident that someday robots would:[68] 1. Clean parts by removing molding flash 2. Spray paint automobiles with absolutely no human presence 3. Pack things in boxes\u2014for example, orient and nest chocolate candies in candy boxes 4. Make electrical cable harness 5. Load trucks with boxes\u2014a packing problem 6. Handle soft goods, such as garments and shoes 7. Shear sheep 8. Be used as prostheses 9. Cook fast food and work in other service industries 10. Work as a household robot.\nGenerally such predictions are overly optimistic in timescale.\nNew functionalities and prototypes.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs to be updated. Please help update this article to reflect recent events or newly available information.  (August 2021)In 2008, Caterpillar Inc. developed a dump truck which can drive itself without any human operator.[69] Many analysts believe that self-driving trucks may eventually revolutionize logistics.[70] By 2014, Caterpillar had a self-driving dump truck which is expected to greatly change the process of mining. In 2015, these Caterpillar trucks were actively used in mining operations in Australia by the mining company Rio Tinto Coal Australia.[71][72][73][74] Some analysts believe that within the next few decades, most trucks will be self-driving.[75]A literate or 'reading robot' named Marge has intelligence that comes from software. She can read newspapers, find and correct misspelled words, learn about banks like Barclays, and understand that some restaurants are better places to eat than others.[76]Baxter is a new robot introduced in 2012 which learns by guidance. A worker could teach Baxter how to perform a task by moving its hands in the desired motion and having Baxter memorize them. Extra dials, buttons, and controls are available on Baxter's arm for more precision and features. Any regular worker could program Baxter and it only takes a matter of minutes, unlike usual industrial robots that take extensive programs and coding to be used. This means Baxter needs no programming to operate. No software engineers are needed. This also means Baxter can be taught to perform multiple, more complicated tasks. Sawyer was added in 2015 for smaller, more precise tasks.[77]Prototype cooking robots have been developed and could be programmed for autonomous, dynamic and adjustable preparation of discrete meals.[78][79]EtymologySee also: Glossary of roboticsA scene from Karel \u010capek's 1920 play R.U.R. (Rossum's Universal Robots), showing three robotsThe word robot was introduced to the public by the Czechinterwar writer Karel \u010capek in his play R.U.R. (Rossum's Universal Robots), published in 1920.[6] The play begins in a factory that uses a chemical substitute for protoplasm to manufacture living, simplified people called robots. The play does not focus in detail on the technology behind the creation of these living creatures, but in their appearance they prefigure modern ideas of androids, creatures who can be mistaken for humans. These mass-produced workers are depicted as efficient but emotionless, incapable of original thinking and indifferent to self-preservation. At issue is whether the robots are being exploited and the consequences of human dependence upon commodified labor (especially after a number of specially-formulated robots achieve self-awareness and incite robots all around the world to rise up against the humans).\nKarel \u010capek himself did not coin the word. He wrote a short letter in reference to an etymology in the Oxford English Dictionary in which he named his brother, the painter and writer Josef \u010capek, as its actual originator.[6]In an article in the Czech journal Lidov\u00e9 noviny in 1933, he explained that he had originally wanted to call the creatures labo\u0159i ('workers', from Latinlabor). However, he did not like the word, and sought advice from his brother Josef, who suggested roboti. The word robota means literally 'corv\u00e9e, serf labor', and figuratively 'drudgery, hard work' in Czech and also (more general) 'work, labor' in many Slavic languages (e.g.: Bulgarian, Russian, Serbian, Croatian, Slovenian, Slovak, Polish, Macedonian, Ukrainian and archaic Czech) as well as robot in Hungarian. Traditionally the robota (Hungarian robot) was the work period a serf (corv\u00e9e) had to give for his lord, typically six months of the year. The origin of the word is the Old Church Slavonicrabota'servitude' ('work' in contemporary Bulgarian, Macedonian and Russian), which in turn comes from the Proto-Indo-European root *orbh-. Robot is cognate with the German Arbeit'work'.[80][81]English pronunciation of the word has evolved relatively quickly since its introduction. In the U.S. during the late 1930s to early 1940s it was pronounced /\u02c8ro\u028abo\u028at/.[82][better\u00a0source\u00a0needed] By the late 1950s to early 1960s, some were pronouncing it /\u02c8ro\u028ab\u0259t/, while others used /\u02c8ro\u028ab\u0252t/[83] By the 1970s, its current pronunciation /\u02c8ro\u028ab\u0252t/ had become predominant.\nThe word robotics, used to describe this field of study,[4] was coined by the science fiction writer Isaac Asimov. Asimov created the Three Laws of Robotics which are a recurring theme in his books. These have since been used by many others to define laws used in fiction. (The three laws are pure fiction, and no technology yet created has the ability to understand or follow them, and in fact most robots serve military purposes, which run quite contrary to the first law and often the third law. \"People think about Asimov's laws, but they were set up to point out how a simple ethical system doesn't work. If you read the short stories, every single one is about a failure, and they are totally impractical,\" said Dr. Joanna Bryson of the University of Bath.[84])\nModern robotsMobile robotMain articles: Mobile robot and Automated guided vehicleMobile robots[85] have the capability to move around in their environment and are not fixed to one physical location. An example of a mobile robot that is in common use today is the automated guided vehicle or automatic guided vehicle (AGV). An AGV is a mobile robot that follows markers or wires in the floor, or uses vision or lasers.[86] AGVs are discussed later in this article.\nMobile robots are also found in industry, military and security environments.[87] They also appear as consumer products, for entertainment or to perform certain tasks like vacuum cleaning. Mobile robots are the focus of a great deal of current research and almost every major university has one or more labs that focus on mobile robot research.[88]Mobile robots are usually used in tightly controlled environments such as on assembly lines because they have difficulty responding to unexpected interference. Because of this most humans rarely encounter robots. However domestic robots for cleaning and maintenance are increasingly common in and around homes in developed countries. Robots can also be found in military applications.[89]Industrial robots (manipulating)Main articles: Industrial robot and Manipulator (device)Industrial robots usually consist of a jointed arm (multi-linked manipulator) and an end effector that is attached to a fixed surface. One of the most common type of end effector is a gripper assembly.\nThe International Organization for Standardization gives a definition of a  manipulating industrial robot in ISO 8373:\n\"an automatically controlled, reprogrammable, multipurpose, manipulator programmable in three or more axes, which may be either fixed in place or mobile for use in industrial automation applications.\"[90]This definition is used by the International Federation of Robotics, the European Robotics Research Network (EURON) and many national standards committees.[91]The industrial robots in food and drink processing plants are used for tasks such as feeding machines, packaging, and palletizing, which have replaced many manual, physical tasks. The complexity of digital skills required by workers varies depending on the level of automation and the specific tasks involved.[92] \nService robotMain article: Service robotMost commonly industrial robots are fixed robotic arms and manipulators used primarily for production and distribution of goods. The term \"service robot\" is less well-defined. The International Federation of Robotics has proposed a tentative definition, \"A service robot is a robot which operates semi- or fully autonomously to perform services useful to the well-being of humans and equipment, excluding manufacturing operations.\"[93]Educational (interactive) robotsMain article: Educational roboticsRobots are used as educational assistants to teachers. From the 1980s, robots such as turtles were used in schools and programmed using the Logo language.[94][95]There are robot kits like Lego Mindstorms, BIOLOID, OLLO from ROBOTIS, or BotBrain Educational Robots can help children to learn about mathematics, physics, programming, and electronics. Robotics have also been introduced into the lives of elementary and high school students in the form of robot competitions with the company FIRST (For Inspiration and Recognition of Science and Technology). The organization is the foundation for the FIRST Robotics Competition, FIRST Tech Challenge, FIRST Lego League Challenge and FIRST Lego League Explore competitions.\nThere have also been robots such as the teaching computer, Leachim (1974).[96] Leachim was an early example of speech synthesis using the Diphone synthesis method. 2-XL (1976) was a robot shaped game / teaching toy based on branching between audible tracks on an 8-track tape player, both invented by Michael J. Freeman.[97] Later, the 8-track was upgraded to tape cassettes and then to digital.\nModular robotMain article: Self-reconfiguring modular robotModular robots are a new breed of robots that are designed to increase the use of robots by modularizing their architecture.[98] The functionality and effectiveness of a modular robot is easier to increase compared to conventional robots. These robots are composed of a single type of identical, several different identical module types, or similarly shaped modules, which vary in size. Their architectural structure allows hyper-redundancy for modular robots, as they can be designed with more than 8 degrees of freedom (DOF). Creating the programming, inverse kinematics and dynamics for modular robots is more complex than with traditional robots. Modular robots may be composed of L-shaped modules, cubic modules, and U and H-shaped modules. ANAT technology, an early modular robotic technology patented by Robotics Design Inc., allows the creation of modular robots from U- and H-shaped modules that connect in a chain, and are used to form heterogeneous and homogenous modular robot systems. These \"ANAT robots\" can be designed with \"n\" DOF as each module is a complete motorized robotic system that folds relatively to the modules connected before and after it in its chain, and therefore a single module allows one degree of freedom. The more modules that are connected to one another, the more degrees of freedom it will have. L-shaped modules can also be designed in a chain, and must become increasingly smaller as the size of the chain increases, as payloads attached to the end of the chain place a greater strain on modules that are further from the base. ANAT H-shaped modules do not suffer from this problem, as their design allows a modular robot to distribute pressure and impacts evenly amongst other attached modules, and therefore payload-carrying capacity does not decrease as the length of the arm increases. Modular robots can be manually or self-reconfigured to form a different robot, that may perform different applications. Because modular robots of the same architecture type are composed of modules that compose different modular robots, a snake-arm robot can combine with another to form a dual or quadra-arm robot, or can split into several mobile robots, and mobile robots can split into multiple smaller ones, or combine with others into a larger or different one. This allows a single modular robot the ability to be fully specialized in a single task, as well as the capacity to be specialized to perform multiple different tasks.\nModular robotic technology is currently being applied in hybrid transportation,[99] industrial automation,[100] duct cleaning[101] and handling. Many research centres and universities have also studied this technology, and have developed prototypes.\nCollaborative robotsA collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks. However, end-effectors and other environmental conditions may create hazards, and as such risk assessments should be done before using any industrial motion-control application.[102]The collaborative robots most widely used in industries today are manufactured by Universal Robots in Denmark.[103]Rethink Robotics\u2014founded by Rodney Brooks, previously with iRobot\u2014introduced Baxter in September 2012; as an industrial robot designed to safely interact with neighboring human workers, and be programmable for performing simple tasks.[104] Baxters stop if they detect a human in the way of their robotic arms and have prominent off switches. Intended for sale to small businesses, they are promoted as the robotic analogue of the personal computer.[105] As of May\u00a02014[update], 190 companies in the US have bought Baxters and they are being used commercially in the UK.[10]Robots in societyTOPIO, a humanoid robot, played ping pong at Tokyo International Robot Exhibition (IREX) 2009.[106][107]Roughly half of all the robots in the world are in Asia, 32% in Europe, and 16% in North America, 1% in Australasia and 1% in Africa.[108] 40% of all the robots in the world are in Japan,[109] making Japan the country with the highest number of robots.\nAutonomy and ethical questionsMain articles: Roboethics and Ethics of artificial intelligenceAn android, or robot designed to resemble a human, can appear comforting to some people and disturbing to others.[110]As robots have become more advanced and sophisticated, experts and academics have increasingly explored the questions of what ethics might govern robots' behavior,[111][112] and whether robots might be able to claim any kind of social, cultural, ethical or legal rights.[113] One scientific team has said that it was possible that a robot brain would exist by 2019.[114] Others predict robot intelligence breakthroughs by 2050.[115] Recent advances have made robotic behavior more sophisticated.[116] The social impact of intelligent robots is subject of a 2010 documentary film called Plug & Pray.[117]Vernor Vinge has suggested that a moment may come when computers and robots are smarter than humans. He calls this \"the Singularity\".[118] He suggests that it may be somewhat or possibly very dangerous for humans.[119] This is discussed by a philosophy called Singularitarianism.\nIn 2009, experts attended a conference hosted by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to acquire any autonomy, and how much these abilities might pose a threat or hazard. They noted that some robots have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence.\" They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.[118] Various media sources and scientific groups have noted separate trends in differing areas which might together result in greater robotic functionalities and autonomy, and which pose some inherent concerns.[120][121][122]Military robotsSome experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.[123] There are also concerns about technology which might allow some armed robots to be controlled mainly by other robots.[124] The US Navy has funded a report which indicates that, as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.[125][126] One researcher states that autonomous robots might be more humane, as they could make decisions more effectively. However, other experts question this.[127]One robot in particular, the EATR, has generated public concerns[128] over its fuel source, as it can continually refuel itself using organic substances.[129] Although the engine for the EATR is designed to run on biomass and vegetation[130] specifically selected by its sensors, which it can find on battlefields or other local environments, the project has stated that chicken fat can also be used.[131]Manuel De Landa has noted that \"smart missiles\" and autonomous bombs equipped with artificial perception can be considered robots, as they make some of their decisions autonomously. He believes this represents an important and dangerous trend in which humans are handing over important decisions to machines.[132]Relationship to unemploymentMain article: Technological unemploymentFor centuries, people have predicted that machines would make workers obsolete and increase unemployment, although the causes of unemployment are usually thought to be due to social policy.[133][134][135]A recent example of human replacement involves Taiwanese technology company Foxconn who, in July 2011, announced a three-year plan to replace workers with more robots. At present the company uses ten thousand robots but will increase them to a million robots over a three-year period.[136]Lawyers have speculated that an increased prevalence of robots in the workplace could lead to the need to improve redundancy laws.[137]Kevin J. Delaney said \"Robots are taking human jobs. But Bill Gates believes that governments should tax companies' use of them, as a way to at least temporarily slow the spread of automation and to fund other types of employment.\"[138] The robot tax would also help pay a guaranteed living wage to the displaced workers.\nThe World Bank's World Development Report 2019 puts forth evidence showing that while automation displaces workers, technological innovation creates more new industries and jobs on balance.[139]Contemporary usesSee also: List of robotsAt present, there are two main types of robots, based on their use: general-purpose autonomous robots and dedicated robots.\nRobots can be classified by their specificity of purpose. A robot might be designed to perform one particular task extremely well, or a range of tasks less well. All robots by their nature can be re-programmed to behave differently, but some are limited by their physical form. For example, a factory robot arm can perform jobs such as cutting, welding, gluing, or acting as a fairground ride, while a pick-and-place robot can only populate printed circuit boards.\nGeneral-purpose autonomous robotsMain article: Autonomous robotGeneral-purpose autonomous robots can perform a variety of functions independently. General-purpose autonomous robots typically can navigate independently in known spaces, handle their own re-charging needs, interface with electronic doors and elevators and perform other basic tasks. Like computers, general-purpose robots can link with networks, software and accessories that increase their usefulness. They may recognize people or objects, talk, provide companionship, monitor environmental quality, respond to alarms, pick up supplies and perform other useful tasks. General-purpose robots may perform a variety of functions simultaneously or they may take on different roles at different times of day. Some such robots try to mimic human beings and may even resemble people in appearance; this type of robot is called a humanoid robot. Humanoid robots are still in a very limited stage, as no humanoid robot can, as of yet, actually navigate around a room that it has never been in.[140] Thus, humanoid robots are really quite limited, despite their intelligent behaviors in their well-known environments.\nFactory robotsCar productionOver the last three decades, automobile factories have become dominated by robots. A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers. On an automated production line, a vehicle chassis on a conveyor is welded, glued, painted and finally assembled at a sequence of robot stations.\nPackagingIndustrial robots are also used extensively for palletizing and packaging of manufactured goods, for example for rapidly taking drink cartons from the end of a conveyor belt and placing them into boxes, or for loading and unloading machining centers.\nElectronicsMass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, typically with SCARA manipulators, which remove tiny electronic components from strips or trays, and place them on to PCBs with great accuracy.[141] Such robots can place hundreds of thousands of components per hour, far out-performing a human in speed, accuracy, and reliability.[142]Automated guided vehicles (AGVs)Mobile robots, following markers or wires in the floor, or using vision[86] or lasers, are used to transport goods around large facilities, such as warehouses, container ports, or hospitals.[143]Early AGV-style robotsLimited to tasks that could be accurately defined and had to be performed the same way every time. Very little feedback or intelligence was required, and the robots needed only the most basic exteroceptors (sensors). The limitations of these AGVs are that their paths are not easily altered and they cannot alter their paths if obstacles block them. If one AGV breaks down, it may stop the entire operation.\nInterim AGV technologiesDeveloped to deploy triangulation from beacons or bar code grids for scanning on the floor or ceiling. In most factories, triangulation systems tend to require moderate to high maintenance, such as daily cleaning of all beacons or bar codes. Also, if a tall pallet or large vehicle blocks beacons or a bar code is marred, AGVs may become lost. Often such AGVs are designed to be used in human-free environments.\nIntelligent AGVs (i-AGVs)Such as SmartLoader,[144] SpeciMinder,[145] ADAM,[146] Tug[147] Eskorta,[148] and MT 400 with Motivity[149] are designed for people-friendly workspaces. They navigate by recognizing natural features. 3D scanners or other means of sensing the environment in two or three dimensions help to eliminate cumulative errors in dead-reckoning calculations of the AGV's current position. Some AGVs can create maps of their environment using scanning lasers with simultaneous localization and mapping (SLAM) and use those maps to navigate in real time with other path planning and obstacle avoidance algorithms. They are able to operate in complex environments and perform non-repetitive and non-sequential tasks such as transporting photomasks in a semiconductor lab, specimens in hospitals and goods in warehouses. For dynamic areas, such as warehouses full of pallets, AGVs require additional strategies using three-dimensional sensors such as time-of-flight or stereovision cameras.\nDirty, dangerous, dull, or inaccessible tasksSee also: Dirty, dangerous and demeaningThere are many jobs that humans would rather leave to robots. The job may be boring, such as domestic cleaning or sports field line marking, or dangerous, such as exploring inside a volcano.[150] Other jobs are physically inaccessible, such as exploring another planet,[151] cleaning the inside of a long pipe, or performing laparoscopic surgery.[152]Space probesAlmost every unmanned space probe ever launched was a robot.[153][154] Some were launched in the 1960s with very limited abilities, but their ability to fly and land (in the case of Luna 9) is an indication of their status as a robot. This includes the Voyager probes and the Galileo probes, among others.\nTelerobotsA U.S. Marine Corps technician prepares to use a telerobot to detonate a buried improvised explosive device near Camp Fallujah, Iraq.Teleoperated robots, or telerobots, are devices remotely operated from a distance by a human operator rather than following a predetermined sequence of movements, but which has semi-autonomous behaviour. They are used when a human cannot be present on site to perform a job because it is dangerous, far away, or inaccessible. The robot may be in another room or another country, or may be on a very different scale to the operator. For instance, a laparoscopic surgery robot allows the surgeon to work inside a human patient on a relatively small scale compared to open surgery, significantly shortening recovery time.[152] They can also be used to avoid exposing workers to the hazardous and tight spaces such as in duct cleaning. When disabling a bomb, the operator sends a small robot to disable it. Several authors have been using a device called the Longpen to sign books remotely.[155] Teleoperated robot aircraft, like the Predator Unmanned Aerial Vehicle, are increasingly being used by the military. These pilotless drones can search terrain and fire on targets.[156][157] Hundreds of robots such as iRobot's Packbot and the Foster-Miller TALON are being used in Iraq and Afghanistan by the U.S. military to defuse roadside bombs or improvised explosive devices (IEDs) in an activity known as explosive ordnance disposal (EOD).[158]Automated fruit harvesting machinesRobots are used to automate picking fruit on orchards at a cost lower than that of human pickers.\nDomestic robotsThe Roomba domestic vacuum cleaner robot does a single, menial job.Domestic robots are simple robots dedicated to a single task work in home use. They are used in simple but often disliked jobs, such as vacuum cleaning, floor washing, and lawn mowing. An example of a domestic robot is a Roomba.\nMilitary robotsMain article: Military robotMilitary robots include the SWORDS robot which is currently used in ground-based combat. It can use a variety of weapons and there is some discussion of giving it some degree of autonomy in battleground situations.[159][160][161]Unmanned combat air vehicles (UCAVs), which are an upgraded form of UAVs, can do a wide variety of missions, including combat. UCAVs are being designed such as the BAE Systems Mantis which would have the ability to fly themselves, to pick their own course and target, and to make most decisions on their own.[162] The BAE Taranis is a UCAV built by Great Britain which can fly across continents without a pilot and has new means to avoid detection.[163] Flight trials are expected to begin in 2011.[164]The AAAI has studied this topic in depth[111] and its president has commissioned a study to look at this issue.[165]Some have suggested a need to build \"Friendly AI\", meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.[166] Several such measures reportedly already exist, with robot-heavy countries such as Japan and South Korea[167] having begun to pass regulations requiring robots to be equipped with safety systems, and possibly sets of 'laws' akin to Asimov's Three Laws of Robotics.[168][169] An official report was issued in 2009 by the Japanese government's Robot Industry Policy Committee.[170] Chinese officials and researchers have issued a report suggesting a set of ethical rules, and a set of new legal guidelines referred to as \"Robot Legal Studies.\"[171] Some concern has been expressed over a possible occurrence of robots telling apparent falsehoods.[172]Mining robotsMining robots are designed to solve a number of problems currently facing the mining industry, including skills shortages, improving productivity from declining ore grades, and achieving environmental targets. Due to the hazardous nature of mining, in particular underground mining, the prevalence of autonomous, semi-autonomous, and tele-operated robots has greatly increased in recent times. A number of vehicle manufacturers provide autonomous trains, trucks and loaders that will load material, transport it on the mine site to its destination, and unload without requiring human intervention. One of the world's largest mining corporations, Rio Tinto, has recently expanded its autonomous truck fleet to the world's largest, consisting of 150 autonomous Komatsu trucks, operating in Western Australia.[173] Similarly, BHP has announced the expansion of its autonomous drill fleet to the world's largest, 21 autonomous Atlas Copco drills.[174]Drilling, longwall and rockbreaking machines are now also available as autonomous robots.[175] The Atlas Copco Rig Control System can autonomously execute a drilling plan on a drilling rig, moving the rig into position using GPS, set up the drill rig and drill down to specified depths.[176] Similarly, the Transmin Rocklogic system can automatically plan a path to position a rockbreaker at a selected destination.[177] These systems greatly enhance the safety and efficiency of mining operations.\nHealthcareRobots in healthcare have two main functions. Those which assist an individual, such as a sufferer of a disease like Multiple Sclerosis, and those which aid in the overall systems such as pharmacies and hospitals.\nHome automation for the elderly and disabledFurther information: Disability robotRobots used in home automation have developed over time from simple basic robotic assistants, such as the Handy 1,[178] through to semi-autonomous robots, such as Care-Providing Robot \"FRIEND\" which can assist the elderly and disabled with common tasks.\nThe population is aging in many countries, especially Japan, meaning that there are increasing numbers of elderly people to care for, but relatively fewer young people to care for them.[179][180] Humans make the best carers, but where they are unavailable, robots are gradually being introduced.[181]FRIEND is a semi-autonomous robot designed to support disabled and elderly people in their daily life activities, like preparing and serving a meal. FRIEND make it possible for patients who are paraplegic, have muscle diseases or serious paralysis (due to strokes etc.), to perform tasks without help from other people like therapists or nursing staff.\nPharmaciesMain article: Pharmacy automationThis section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  (July 2009) (Learn how and when to remove this message)Script Pro manufactures a robot designed to help pharmacies fill prescriptions that consist of oral solids or medications in pill form.[182][better\u00a0source\u00a0needed] The pharmacist or pharmacy technician enters the prescription information into its information system. The system, upon determining whether or not the drug is in the robot, will send the information to the robot for filling. The robot has 3 different size vials to fill determined by the size of the pill. The robot technician, user, or pharmacist determines the needed size of the vial based on the tablet when the robot is stocked. Once the vial is filled it is brought up to a conveyor belt that delivers it to a holder that spins the vial and attaches the patient label. Afterwards it is set on another conveyor that delivers the patient's medication vial to a slot labeled with the patient's name on an LED read out. The pharmacist or technician then checks the contents of the vial to ensure it's the correct drug for the correct patient and then seals the vials and sends it out front to be picked up.\nMcKesson's Robot RX is another healthcare robotics product that helps pharmacies dispense thousands of medications daily with little or no errors.[183] The robot can be ten feet wide and thirty feet long and can hold hundreds of different kinds of medications and thousands of doses. The pharmacy saves many resources like staff members that are otherwise unavailable in a resource scarce industry. It uses an electromechanical head coupled with a pneumatic system to capture each dose and deliver it to either its stocked or dispensed location. The head moves along a single axis while it rotates 180 degrees to pull the medications. During this process it uses barcode technology to verify it's pulling the correct drug. It then delivers the drug to a patient specific bin on a conveyor belt. Once the bin is filled with all of the drugs that a particular patient needs and that the robot stocks, the bin is then released and returned out on the conveyor belt to a technician waiting to load it into a cart for delivery to the floor.\nResearch robotsSee also: Robotics researchWhile most robots today are installed in factories or homes, performing labour or life saving jobs, many new types of robot are being developed in laboratories around the world. Much of the research in robotics focuses not on specific industrial tasks, but on investigations into new types of robot, alternative ways to think about or design robots, and new ways to manufacture them. It is expected that these new types of robot will be able to solve real world problems when they are finally realized.[citation needed]Bionic and biomimetic robotsFurther information: BiomimeticsFurther information: BionicsOne approach to designing robots is to base them on animals. BionicKangaroo was designed and engineered by studying and applying the physiology and methods of locomotion of a kangaroo.\nNanorobotsFurther information: NanoroboticsNanorobotics is the emerging technology field of creating machines or robots whose components are at or close to the microscopic scale of a nanometer (10\u22129 meters). Also known as \"nanobots\" or \"nanites\", they would be constructed from molecular machines. So far, researchers have mostly produced only parts of these complex systems, such as bearings, sensors, and synthetic molecular motors, but functioning robots have also been made such as the entrants to the Nanobot Robocup contest.[184] Researchers also hope to be able to create entire robots as small as viruses or bacteria, which could perform tasks on a tiny scale. Possible applications include micro surgery (on the level of individual cells), utility fog,[185] manufacturing, weaponry and cleaning.[186] Some people have suggested that if there were nanobots which could reproduce, the earth would turn into \"grey goo\", while others argue that this hypothetical outcome is nonsense.[187][188]Reconfigurable robotsMain article: Self-reconfiguring modular robotA few researchers have investigated the possibility of creating robots which can alter their physical form to suit a particular task,[189] like the fictional T-1000. Real robots are nowhere near that sophisticated however, and mostly consist of a small number of cube shaped units, which can move relative to their neighbours. Algorithms have been designed in case any such robots become a reality.[190]Robotic, mobile laboratory operatorsFurther information: Laboratory roboticsIn July 2020 scientists reported the development of a mobile robot chemist and demonstrate that it can assist in experimental searches. According to the scientists their strategy was automating the researcher rather than the instruments \u2013 freeing up time for the human researchers to think creatively \u2013 and could identify photocatalyst mixtures for hydrogen production from water that were six times more active than initial formulations. The modular robot can operate laboratory instruments, work nearly around the clock, and autonomously make decisions on his next actions depending on experimental results.[191][192]Soft-bodied robotsRobots with silicone bodies and flexible actuators (air muscles, electroactive polymers, and ferrofluids) look and feel different from robots with rigid skeletons, and can have different behaviors.[193] Soft, flexible (and sometimes even squishy) robots are often designed to mimic the biomechanics of animals and other things found in nature, which is leading to new applications in medicine, care giving, search and rescue, food handling and manufacturing, and scientific exploration.[194][195]Swarm robotsMain article: Swarm roboticsInspired by colonies of insects such as ants and bees, researchers are modeling the behavior of swarms of thousands of tiny robots which together perform a useful task, such as finding something hidden, cleaning, or spying. Each robot is quite simple, but the emergent behavior of the swarm is more complex. The whole set of robots can be considered as one single distributed system, in the same way an ant colony can be considered a superorganism, exhibiting swarm intelligence. The largest swarms so far created include the iRobot swarm, the SRI/MobileRobots CentiBots project[196] and the Open-source Micro-robotic Project swarm, which are being used to research collective behaviors.[197][198] Swarms are also more resistant to failure. Whereas one large robot may fail and ruin a mission, a swarm can continue even if several robots fail. This could make them attractive for space exploration missions, where failure is normally extremely costly.[199]Haptic interface robotsFurther information: Haptic technologyRobotics also has application in the design of virtual reality interfaces. Specialized robots are in widespread use in the haptic research community. These robots, called \"haptic interfaces\", allow touch-enabled user interaction with real and virtual environments. Robotic forces allow simulating the mechanical properties of \"virtual\" objects, which users can experience through their sense of touch.[200]Contemporary art and sculptureFurther information: Robotic artRobots are used by contemporary artists to create works that include mechanical automation. There are many branches of robotic art, one of which is robotic installation art, a type of installation art that is programmed to respond to viewer interactions, by means of computers, sensors and actuators. The future behavior of such installations can therefore be altered by input from either the artist or the participant, which differentiates these artworks from other types of kinetic art.\nLe Grand Palais in Paris organized an exhibition \"Artists & Robots\", featuring artworks created by more than forty artists with the help of robots in 2018.[201]Robots in popular cultureToy robots on display at the Museo del Objeto del Objeto in Mexico CitySee also: List of fictional robots and androids and Droid (Star Wars)LiteratureMain article: Robots in literatureRobotic characters, androids (artificial men/women) or gynoids (artificial women), and cyborgs (also \"bionic men/women\", or humans with significant mechanical enhancements) have become a staple of science fiction.\nThe first reference in Western literature to mechanical servants appears in Homer's Iliad. In Book XVIII, Hephaestus, god of fire, creates new armor for the hero Achilles, assisted by robots.[202] According to the Rieu translation, \"Golden maidservants hastened to help their master. They looked like real women and could not only speak and use their limbs but were endowed with intelligence and trained in handwork by the immortal gods.\" The words \"robot\" or \"android\" are not used to describe them, but they are nevertheless mechanical devices human in appearance. \"The first use of the word Robot was in Karel \u010capek's play R.U.R. (Rossum's Universal Robots) (written in 1920)\". Writer Karel \u010capek was born in Czechoslovakia (Czech Republic).\nPossibly the most prolific author of the twentieth century was Isaac Asimov (1920\u20131992)[203] who published over five-hundred books.[204] Asimov is probably best remembered for his science-fiction stories and especially those about robots, where he placed robots and their interaction with society at the center of many of his works.[205][206] Asimov carefully considered the problem of the ideal set of instructions robots might be given to lower the risk to humans, and arrived at his Three Laws of Robotics: a robot may not injure a human being or, through inaction, allow a human being to come to harm; a robot must obey orders given it by human beings, except where such orders would conflict with the First Law; and a robot must protect its own existence as long as such protection does not conflict with the First or Second Law.[207] These were introduced in his 1942 short story \"Runaround\", although foreshadowed in a few earlier stories. Later, Asimov added the Zeroth Law: \"A robot may not harm humanity, or, by inaction, allow humanity to come to harm\"; the rest of the laws are modified sequentially to acknowledge this.\nAccording to the Oxford English Dictionary, the first passage in Asimov's short story \"Liar!\" (1941) that mentions the First Law is the earliest recorded use of the word robotics. Asimov was not initially aware of this; he assumed the word already existed by analogy with mechanics,hydraulics, and other similar terms denoting branches of applied knowledge.[208]Robot competitionsMain article: Robot competitionRobots are used in a number of competitive events. Robot combat competitions have been popularized by television shows such as Robot Wars and BattleBots, featuring mostly remotely controlled 'robots' that compete against each other directly using various weaponry, there are also amateur robot combat leagues active globally outside of the televised events. Micromouse events, in which autonomous robots compete to solve mazes or other obstacle courses are also held internationally.\nRobot competitions are also often used within educational settings to introduce the concept of robotics to children such as the FIRST Robotics Competition in the US.\nFilmsSee also: Category:Films about robotsRobots appear in many films. Most of the robots in cinema are fictional. Two of the most famous are R2-D2 and C-3PO from the Star Wars franchise.\nSex robotsMain article: Sex robotThe concept of humanoid sex robots has drawn public attention and elicited debate regarding their supposed benefits and potential effects on society. Opponents argue that the introduction of such devices would be socially harmful, and demeaning to women and children,[209] while proponents cite their potential therapeutical benefits, particularly in aiding people with dementia or depression.[210]Problems depicted in popular cultureFears and concerns about robots have been repeatedly expressed in a wide range of books and films. A common theme is the development of a master race of conscious and highly intelligent robots, motivated to take over or destroy the human race. Frankenstein (1818), often called the first science fiction novel, has become synonymous with the theme of a robot or android advancing beyond its creator.\nOther works with similar themes include The Mechanical Man, The Terminator, Runaway, RoboCop, the Replicators in Stargate, the Cylons in Battlestar Galactica, the Cybermen and Daleks in Doctor Who, The Matrix, Enthiran and I, Robot. Some fictional robots are programmed to kill and destroy; others gain superhuman intelligence and abilities by upgrading their own software and hardware. Examples of popular media where the robot becomes evil are 2001: A Space Odyssey, Red Planet and Enthiran.\nThe 2017 game Horizon Zero Dawn explores themes of robotics in warfare, robot ethics, and the AI control problem, as well as the positive or negative impact such technologies could have on the environment.\nAnother common theme is the reaction, sometimes called the \"uncanny valley\", of unease and even revulsion at the sight of robots that mimic humans too closely.[110]More recently, fictional representations of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina and the 2016 TV adaptation of Westworld have engaged audience sympathy for the robots themselves.\nEmancipation or revolution as a theme in relation to robots was already present in the term coining play of R.U.R.\nThe Star Wars universe for example has several instances of droid revolts.\nThe Dune series on the other hand has the premise of humans revolting against thinking machines and finding human-biological alternatives to them.\nSee also.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Index of robotics articlesOutline of roboticsArtificial intelligenceWilliam Grey WalterSpecific robotics conceptsRobot locomotionSimultaneous localization and mappingTactile sensorTeleoperationUncanny valleyvon Neumann machineWake-up robot problemNeuromorphic engineeringRobotics methods and categoriesCognitive roboticsCompanion robotDomestic robotEpigenetic roboticsEvolutionary roboticsHumanoid robotAutonomous robotSwarm roboticsMicroboticsRobot controlSpecific robots and devicesAIBOAutonomous spaceport drone shipDriverless carFriendly RoboticsLely Juno familyLiquid handling robotParo (robot)PatrolBotRoboBeeRoboriorRobot App StoreOther related articlesAutomated guided vehicleAnimatronicsRemote control vehicleRobot AwardRobot economicsRobotoidUnmanned vehicleHybrotBiohybrid robotFurther reading.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Al-Arshani, Sarah (29 November 2021). \"Researchers behind the world's first living robot have found a way to make it reproduce \u2014 by shaping it like Pac-Man\". Business Insider.See this humanoid robot artist sketch drawings from sight (CNN, Video, 2019)Margolius, Ivan. 'The Robot of Prague', Newsletter, The Friends of Czech Heritage no. 17, Autumn 2017, pp.\u00a03 \u2013 6. https://czechfriends.net/images/RobotsMargoliusJul2017.pdfArchived 11 September 2017 at the Wayback MachineGlaser, Horst Albert and Rossbach, Sabine: The Artificial Human, Frankfurt/M., Bern, New York 2011 \"A Tragical History\"Gutkind, L. (2006). Almost Human: Making Robots Think. New York: W. W. Norton & Company, Inc.Craig, J.J. (2005). Introduction to Robotics, Pearson Prentice Hall. Upper Saddle River, NJ.Tsai, L. W. (1999). Robot Analysis. Wiley. New York.Sotheby's New York. The Tin Toy Robot Collection of Matt Wyse (1996)DeLanda, Manuel. War in the Age of Intelligent Machines. 1991. Swerve. New York.Needham, Joseph (1986). Science and Civilization in China: Volume 2. Taipei: Caves Books Ltd.Cheney, Margaret [1989:123] (1981). Tesla, Man Out of Time. Dorset Press. New York. ISBN\u00a00-88029-419-1\u010capek, Karel (1920). R.U.R., Aventinum, Prague.TechCast Article Series, Jason Rupinski and Richard Mix, \"Public Attitudes to Androids: Robot Gender, Tasks, & Pricing\"References.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^\"Four-legged Robot, 'Cheetah,' Sets New Speed Record\". Reuters. 6 March 2012. Archived from the original on 22 October 2013. Retrieved 5 October 2013.^Definition of 'robot'. Oxford English Dictionary. Retrieved 27 November 2016.^\"Forecasts \u2013 Driverless car market watch\". driverless-future.com. Archived from the original on 25 September 2023. Retrieved 26 September 2023.^ ab\"robotics\". Oxford Dictionaries. Archived from the original on 18 May 2011. Retrieved 4 February 2011.^Margolius, Ivan (Autumn 2017). \"The Robot of Prague\"(PDF). The Friends of Czech Heritage (17): 3\u20136. Archived(PDF) from the original on 11 September 2017.^ abcZunt, Dominik. \"Who did actually invent the word \"robot\" and what does it mean?\". The Karel \u010capek website. Archived from the original on 4 February 2012. Retrieved 11 September 2007.^Kurfess, Thomas R. (1 January 2005). Robotics and Automation Handbook. Taylor & Francis. ISBN\u00a0978-0-8493-1804-7. Archived from the original on 4 December 2016. Retrieved 5 July 2016 \u2013 via Google Books.^Pearce, Jeremy (15 August 2011). \"George C. Devol, Inventor of Robot Arm, Dies at 99\". The New York Times. Archived from the original on 25 December 2016. Retrieved 7 February 2012. In 1961, General Motors put the first Unimate arm on an assembly line at the company's plant in Ewing Township, N.J., a suburb of Trenton. The device was used to lift and stack die-cast metal parts taken hot from their molds.^Akins, Crystal. \"5 jobs being replaced by robots\". Excelle. Monster. Archived from the original on 24 April 2013. Retrieved 15 April 2013.^ abHoy, Greg (28 May 2014). \"Robots could cost Australian economy 5 million jobs, experts warn, as companies look to cut costs\". ABC News. Australian Broadcasting Corporation. Archived from the original on 29 May 2014. Retrieved 29 May 2014.^Polk, Igor (16 November 2005). \"RoboNexus 2005 robot exhibition virtual tour\". Robonexus Exhibition 2005. Archived from the original on 12 August 2007. Retrieved 10 September 2007.^Harris, Tom (16 April 2002). \"How Robots Work\". How Stuff Works. Archived from the original on 26 August 2007. Retrieved 10 September 2007.^\"Telecom glossary \"bot\"\". Alliance for Telecommunications Solutions. 26 September 2023.^Moran, M. E. (December 2006). \"The da Vinci robot\". J. Endourol. 20 (12): 986\u201390. doi:10.1089/end.2006.20.986. PMID\u00a017206888. ... the date of the design and possible construction of this robot was 1495 ... Beginning in the 1950s, investigators at the University of California began to ponder the significance of some of da Vinci's markings on what appeared to be technical drawings ... It is now known that da Vinci's robot would have had the outer appearance of a Germanic knight.^Deborah Levine Gera (2003). Ancient Greek Ideas on Speech, Language, and Civilization. Oxford University Press. ISBN\u00a0978-0-19-925616-7. Archived from the original on 5 December 2016. Retrieved 25 September 2016.^Noct. Att. L. 10^ abRosheim, Mark E. (1994). Robot evolution: the development of anthrobotics. Wiley-IEEE. ISBN\u00a00-471-02622-0.^\"\"Robots then and now\". BBC. 22 July 2004. Archived from the original on 20 December 2010.^O'Connor, J.J. and E.F. Robertson. \"Heron biography\". The MacTutor History of Mathematics archive. Retrieved 26 September 2023.^Efstathiou, Kyriakos; Efstathiou, Marianna (2018). \"Celestial Gearbox: Oldest Known Computer is a Mechanism Designed to Calculate the Location of the Sun, Moon, and Planets\". Mechanical Engineering. 140 (9): 31\u201335. doi:10.1115/1.2018-SEP1.^Steiglitz, Ken (2019). The Discrete Charm of the Machine: Why the World Became Digital. Princeton, New Jersey: Princeton University Press. p.\u00a0108. ISBN\u00a0978-0-691-18417-3.^Needham, Joseph (1991). Science and Civilisation in China. Vol.\u00a02. Cambridge, England: Cambridge University Press. pp.\u00a053\u201354. ISBN\u00a0978-0-521-05800-1.^Fowler, Charles B. (1967). \"The Museum of Music: A History of Mechanical Instruments\". Music Educators Journal. 54 (2): 45\u201349. doi:10.2307/3391092. JSTOR\u00a03391092. S2CID\u00a0190524140.^\"Early Clocks\". A Walk Through Time. NIST Physics Laboratory. 12 August 2009. Retrieved 13 October 2022.^ ab\"The programmable robot of ancient Greece\". New Scientist: 32\u201335. 6 July 2007.^Varadpande, Manohar Laxman (1987). History of Indian Theatre, Volume 1. Abhinav Publications. p.\u00a068. ISBN\u00a0978-81-7017-221-5.^Wujastyk, Dominik (2003). The Roots of Ayurveda: Selections from Sanskrit Medical Writings. Penguin. p.\u00a0222. ISBN\u00a0978-0-14-044824-5.^Needham, Joseph (1965). Science and Civilisation in China: Volume 4, Physics and Physical Technology Part 2, Mechanical Engineering. Cambridge University Press. p.\u00a0164. ISBN\u00a0978-0-521-05803-2.^Strong, J.S. (2007). Relics of the Buddha. Princeton, New Jersey: Princeton University Press. pp.\u00a0132\u2013136. ISBN\u00a0978-0-691-11764-5.^ ab\"Al-Jazar\u012b | Arab inventor\". Encyclop\u00e6dia Britannica. Retrieved 15 June 2019.^Howard R. Turner (1997). Science in Medieval Islam: An Illustrated Introduction. University of Texas Press. p.\u00a081. ISBN\u00a00-292-78149-0.^Hill, Donald (May 1991). \"Mechanical Engineering in the Medieval Near East\". Scientific American. pp.\u00a064\u201369. (cf.Hill, Donald. \"History of Sciences in the Islamic World\". IX. Mechanical Engineering. Archived from the original on 25 December 2007.)^Ancient Discoveries Islamic Science Part1. Archived from the original on 11 December 2021. Retrieved 15 June 2019.^Truitt, E.R. (2015). Medieval Robots: Mechanism, Magic, Nature, and Art. The Middle Ages Series. University of Pennsylvania Press, Incorporated. p.\u00a0136. ISBN\u00a0978-0-8122-9140-7.^\"Leonardo da Vinci's Robots\". Leonardo3.net. Archived from the original on 24 September 2008. Retrieved 25 September 2008.^Law, Jane Marie (1997). Puppets of Nostalgia \u2013 The Life, Death and Rebirth of the Japanese Awaji Ningyo Tradition. Princeton University Press. ISBN\u00a0978-0-691-02894-1.^Wood, Gabby (16 February 2002). \"Living Dolls: A Magical History Of The Quest For Mechanical Life\". The Guardian. Archived from the original on 20 December 2016.^\"The Boy Robot of 1774\". 21 February 2018.^Edwyn Gray, Nineteenth-century torpedoes and their inventors, page 18^Gray, Edwyn (2004). Nineteenth-Century Torpedoes and Their Inventors. Naval Institute Press. ISBN\u00a0978-1-59114-341-3.^Seifer, Marc (24 October 2011). Life and Times of Nikola Tesla. Citadel. p.\u00a01893. ISBN\u00a0978-0-8065-3556-2. Archived from the original on 5 December 2016.^Miessner, Benjamin Franklin (1916). Radiodynamics: The Wireless Control of Torpedoes and Other Mechanisms. D. Van Nostrand Company. p.\u00a083.^.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US 613809, Tesla, Nikola, \"Method of and apparatus for controlling mechanism of moving vessels or vehicles\", published 8 November 1898\u00a0^\"Tesla \u2013 Master of Lightning\". PBS. Archived from the original on 28 September 2008. Retrieved 24 September 2008.^Sarkar 2006, page 97^Torres, Leonardo, \"FR327218A Syst\u00e8me dit telekine pour commander \u00e0 distance un mouvement m\u00e9canique.Archived 22 August 2023 at the Wayback Machine\", Espacenet, 10 December 1902.^Torres, Leonardo, \"GB190327073 (A) \u2015 Means or Method for Directing Mechanical Movements at or from a Distance.[permanent dead link]\", Espacenet, 10 December 1903.^A. P. Yuste (January 2008). \"Early Developments of Wireless Remote Control: The Telekino of Torres-Quevedo\". Proceedings of the IEEE. 96 (1): 186\u2013190. doi:10.1109/JPROC.2007.909931. S2CID\u00a0111010868.^H. R. Everett (2015). Unmanned Systems of World Wars I and II. MIT Press. pp.\u00a091\u201395. ISBN\u00a0978-0-262-02922-3.^\"AH Reffell & Eric the Robot (1928) - the UK's Firs Robot\". Retrieved 26 September 2023.^\"1932 - George Robot - Capt. W.H. Richards (British)\". cyberneticzoo.com. Retrieved 26 September 2023.^\"Robot Dreams: The Strange Tale Of A Man's Quest To Rebuild His Mechanical Childhood Friend\". The Cleveland Free Times. Archived from the original on 15 January 2010. Retrieved 25 September 2008.^Schaut, Scott (2006). Robots of Westinghouse: 1924-Today. Mansfield Memorial Museum. ISBN\u00a0978-0-9785844-1-2.^Secrets of the Flying Bomb Revealed: Special Sectional Drawing and How the Robot's Flight and Dive are Controlled Automatically. Illustrated London News. 1944.^Holland, Owen. \"The Grey Walter Online Archive\". Archived from the original on 9 October 2008. Retrieved 25 September 2008.^Waurzyniak, Patrick (July 2006). \"Masters of Manufacturing: Joseph F. Engelberger\". Society of Manufacturing Engineers. 137 (1). Archived from the original on 9 November 2011. Retrieved 25 September 2008.^\"Robot Hall of Fame \u2013 Unimate\". Carnegie Mellon University. Retrieved 26 September 2023.^\"Company History\". Fuji Yusoki Kogyo Co. Archived from the original on 4 February 2013. Retrieved 12 September 2008.^\"KUKA Industrial Robot FAMULUS\". Archived from the original on 10 June 2013. Retrieved 10 January 2008.^\"History of Industrial Robots\"(PDF). Archived from the original(PDF) on 24 December 2012. Retrieved 27 October 2012.^\"History of Industrial Robots\". robots.com. Archived from the original on 8 July 2015. Retrieved 24 August 2015.^\"About us\". Archived from the original on 9 January 2014.^\"RoboHon: Cute little Robot cum Smartphone | Codexify\". Archived from the original on 7 October 2015. Retrieved 6 October 2015.^Tesfaye, Mehret (13 August 2009). \"Robots to get their own operating system\". Ethiopian Review. Archived from the original on 18 September 2009.^Myoken, Yumiko (January 2009). Research and Development for Next-generation Service Robots in Japan (United Kingdom Foreign Ministry report). Science and Innovation Section, British Embassy, Tokyo, Japan. Archived from the original on 23 July 2012.^Dahiya, Ravinder S.; Valle, Maurizio (30 July 2012). Robotic Tactile Sensing \u2013 Technologies and System. Springer. doi:10.1007/978-94-007-0579-1. ISBN\u00a0978-94-007-0578-4. Archived from the original on 29 December 2013. Retrieved 8 February 2014.^Dahiya, Ravinder S.; Metta, Giorgio; Cannata, Giorgio; Valle, Maurizio (2011). \"Guest Editorial Special Issue on Robotic Sense of Touch\". IEEE Transactions on Robotics. 27 (3): 385\u2013388. Bibcode:2011ITRob..27..385D. doi:10.1109/TRO.2011.2155830. S2CID\u00a018608163.^Engelberger, Joseph F. (August 1982). \"Robotics in practice: Future capabilities\". Electronic Servicing & Technology.^McKeough, Tim (1 December 2008). \"The Caterpillar Self-Driving Dump Truck\". Fast Company. Archived from the original on 7 June 2011.^Weiss, Richard (9 December 2014). \"Self-Driving Trucks to Revolutionize Logistics, DHL Says\". Bloomberg News. Archived from the original on 22 July 2016.^Grayson, Wayne (16 October 2014). VIDEO: Why Caterpillar's autonomous mining tech is \"completely different from anything\" it's ever done. Archived from the original on 13 May 2016.^Takahashi, Kaori (23 April 2015). \"Self-driving dump trucks, automatic shovels coming to Australian mines\". Nikkei Asia. Archived from the original on 9 May 2016.^Hall, Matthew (20 October 2014). \"Forget self-driving Google cars, Australia has self-driving trucks\". The Age. Archived from the original on 26 April 2016.^Clark, Charles (19 October 2015). \"Australian mining giant Rio Tinto is using these huge self-driving trucks to transport iron ore\". Business Insider. Archived from the original on 9 May 2016.^Berman, Dennis K. (23 July 2013). \"Daddy, What Was a Truck Driver? Over the Next Two Decades, the Machines Themselves Will Take Over the Driving\". The Wall Street Journal. Archived from the original on 4 March 2017.^\"Robot can read, learn like a human\". NBC News. 6 December 2010. Archived from the original on 28 July 2020. Retrieved 10 December 2010.^Melik, James (3 January 2013). \"Robots: Brave New World moves a step closer\". Business Daily. BBC World Service. Archived from the original on 14 January 2019.^\"Kitchen robot in Riga cooks up new future for fast food\". techxplore.com. Retrieved 14 August 2021.^\"Tech May Widen the Gap Between Rich and Poor\". Futurism. Retrieved 23 August 2021.^\"Indo-European root *orbh-\". Bartleby. 12 May 2008. Archived from the original on 24 January 2009. Retrieved 8 February 2014.^\"robot\". Online Etymology Dictionary. Retrieved 26 September 2023.^\"Hank Green's First Novel Is An Absolutely Remarkable Thing\". Indianapolis Monthly. 1 October 2018. Retrieved 20 November 2019.^\"You Are Pronouncing the Word \"Robot\" Wrong\". Daily Kos. Retrieved 20 November 2019.^Ranger, Steve (20 December 2013). \"Robots of death, robots of love: The reality of android soldiers and why laws for robots are doomed to failure\". TechRepublic. Archived from the original on 27 January 2017. Retrieved 21 January 2017.^Moubarak, Paul M.; Ben-Tzvi, Pinhas (2011). \"Adaptive manipulation of a Hybrid Mechanism Mobile Robot\". 2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE). pp.\u00a0113\u2013118. doi:10.1109/ROSE.2011.6058520. ISBN\u00a0978-1-4577-0819-0. S2CID\u00a08659998.^ ab\"Smart Caddy\". Seegrid. Archived from the original on 11 October 2007. Retrieved 13 September 2007.^Zhang, Gexiang; P\u00e9rez-Jim\u00e9nez, Mario J.; Gheorghe, Marian (5 April 2017). Real-life Applications with Membrane Computing. Springer. ISBN\u00a0978-3-319-55989-6.^Kagan, E.; Shvalb, N.; Gal, I. (2019). Autonomous Mobile Robots and Multi-Robot Systems: Motion-Planning, Communication, and Swarming. John Wiley and Sons. ISBN\u00a0978-1-119-21286-7.PP 65-69.^Patic, Deepack; Ansari, Munsaf; Tendulkar, Dilisha; Bhatlekar, Ritesh; Naik, Vijaykumar; Shailendra, Pawar (2020). \"A Survey On Autonomous Military Service Robot\". 2020 International Conference on Emerging Trends in Information Technology and Engineering (Ic-ETITE). IEEE International Conference on Emerging Trends in Information Technology and Engineering. pp.\u00a01\u20137. doi:10.1109/ic-ETITE47903.2020.78. ISBN\u00a0978-1-7281-4142-8. S2CID\u00a0216588335.^\"Definition of a robot\"(PDF). Dansk Robot Forening. Archived from the original(PDF) on 28 June 2007. Retrieved 10 September 2007.^\"Robotics-related Standards Sites\". European Robotics Research Network. Archived from the original on 17 June 2006. Retrieved 15 July 2008.^Lloyd, Caroline; Payne, Jonathan (November 2023). \"Digital skills in context: Working with robots in lower-skilled jobs\". Economic and Industrial Democracy. 44 (4): 1084\u20131104. doi:10.1177/0143831X221111416. hdl:2086/21987. ISSN\u00a00143-831X.^\"Service Robots\". International Federation of Robotics. 27 October 2012. Archived from the original on 18 February 2010.^Mitgang, Lee (25 October 1983). \"'Nova's' 'Talking Turtle' Profiles High Priest of School Computer Movement\". Gainesville Sun.^Barnard, Jeff (January 29, 1985). \"Robots In School: Games Or Learning?\". Observer-Reporter. Washington. Archived from the original on September 22, 2015. Retrieved March 7, 2012.^\"Education: Marvel of the Bronx\". Time. April 1974. Archived from the original on 24 May 2019. Retrieved 19 May 2019.^\"Leachim Archives\". cyberneticzoo.com. 13 September 2010. Archived from the original on 28 May 2019. Retrieved 29 May 2019.^P. Moubarak, et al., Modular and Reconfigurable Mobile Robotics, Journal of Robotics and Autonomous Systems, 60 (12) (2012) 1648\u20131663.^R\u00e9daction (25 December 2011). \"Le consortium franco-qu\u00e9b\u00e9cois Mix d\u00e9voile son projet de voiture volante\" (in French). aerobuzz.fr. Archived from the original on 6 October 2012. Retrieved 7 September 2012.^Scanlan, Steve (September 2009). \"Modularity in robotics provides automation for all\". Electronic Products and Technology. Archived from the original on 5 July 2012. Retrieved 7 September 2012.^\"Duct cleaning robots\"(PDF). Robotics Design Inc. Plumbing & HVAC. April 2010. Archived(PDF) from the original on 25 April 2013. Retrieved 29 April 2010.^\"Universal Robots collaborate outside enclosures | Control Engineering\". Controleng.com. February 2013. Archived from the original on 18 May 2013. Retrieved 4 June 2013.^Pittman, Kagan (19 May 2016). \"INFOGRAPHIC: A Brief History of Collaborative Robots\". Engineering.com. Archived from the original on 10 June 2016.^Hagerty, James (18 September 2012). \"Baxter Robot Heads to Work'\". The Wall Street Journal. New York. Archived from the original on 10 April 2015. Retrieved 29 May 2014.^Markoff, John (18 September 2012). \"A Robot With a Reassuring Touch\". The New York Times. Archived from the original on 19 September 2012. Retrieved 18 September 2012.^\"A Ping-Pong-Playing Terminator\". Popular Science. Archived from the original on 29 March 2011. Retrieved 18 December 2010.^\"Best robot 2009\". Neterion. Tech Magazine. Archived from the original on 27 December 2022.^\"Robots Today and Tomorrow: IFR Presents the 2007 World Robotics Statistics Survey\". RobotWorx. 29 October 2007. Archived from the original on 5 February 2008. Retrieved 14 December 2007.^\"Japan's robots slug it out to be world champ\". Reuters. 2 December 2007. Archived from the original on 13 December 2007. Retrieved 1 January 2007.^ abHo, C. C.; MacDorman, K. F.; Pramono, Z. A. D. (2008). Human emotion and the uncanny valley: A GLM, MDS, and ISOMAP analysis of robot video ratings(PDF). 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI). Archived(PDF) from the original on 11 September 2008. Retrieved 24 September 2008.^ ab\"AI Topics / Ethics\". Association for the Advancement of Artificial Intelligence. Archived from the original on 5 August 2011.^\"Robots can be racist and sexist, new study warns\". TRT World. Retrieved 27 June 2022.^\"News Index by Topic - ETHICAL & SOCIAL IMPLICATIONS Archive\". Association for the Advancement of Artificial Intelligence. Archived from the original on 6 April 2012.^McNealy, Kristie (29 July 2009). \"Scientists Predict Artificial Brain in 10 Years\". Archived from the original on 29 November 2009.^Moravec, Hans (1999). Robot: Mere Machine to Transcendent Mind. Oxford University Press. ISBN\u00a0978-0-19-513630-2. Archived from the original on 5 December 2016.^Weigand, Matthew (17 August 2009). \"Robots Almost Conquering Walking, Reading, Dancing\". Korea IT times. Archived from the original on 21 July 2011.^Schanze, Jens. \"Plug & Pray\". Archived from the original on 12 February 2016.^ abMarkoff, John (26 July 2009). \"Scientists Worry Machines May Outsmart Man\". The New York Times. Archived from the original on 1 July 2017.^Vinge, Vernor (1993). \"The Coming Technological Singularity: How to Survive in the Post-Human Era\". Archived from the original on 1 January 2007.^Singer, P. W. (21 May 2009). \"Gaming the Robot Revolution: A military technology expert weighs in on Terminator: Salvation\". Slate. Archived from the original on 27 January 2010.^\"Robot takeover\". gyre.org. Archived from the original on 19 April 2012.^\"Robotapocalypse\". Engadget. Archived from the original on 4 May 2018.^Palmer, Jason (3 August 2009). \"Call for debate on killer robots\". BBC News. Archived from the original on 7 August 2009.^Axe, David (13 August 2009). \"Robot three-way portends autonomous future\". Wired. Archived from the original on 7 November 2012.^Mick, Jason (17 February 2009). \"New Navy-funded Report Warns of War Robots Going \"Terminator\"\". DailyTech. Archived from the original on 28 July 2009.^Flatley, Joseph L. (18 February 2009). \"Navy report warns of robot uprising, suggests a strong moral compass\". Engadget. Archived from the original on 4 June 2011.^Lamb, Gregory M. (17 February 2010). \"New role for robot warriors\". The Christian Science Monitor. Archived from the original on 24 September 2015.^\"Biomass-Eating Military Robot Is a Vegetarian, Company Says\". Fox News. 16 July 2009. Archived from the original on 3 August 2009. Retrieved 31 July 2009.^Shachtman, Noah (17 July 2009). \"Danger Room What's Next in National Security Company Denies its Robots Feed on the Dead\". Wired. Archived from the original on 29 July 2009. Retrieved 31 July 2009.^\"Cyclone Power Technologies Responds to Rumors about \"Flesh Eating\" Military Robot\"(PDF) (Press release). RTI Inc. 16 July 2009. pp.\u00a01\u20132. Archived(PDF) from the original on 23 August 2009.^\"Brief Project Overview, EATR: Energetically Autonomous Tactical Robot\"(PDF). RTI Inc. 6 April 2009. p.\u00a022.^Manuel de Landa, War in the Age of Intelligent Machines, New York: Zone Books, 1991, 280 pages, Hardcover, ISBN\u00a00-942299-76-0; Paperback, ISBN\u00a00-942299-75-2.^McGaughey, E (2022) [January 10, 2018]. \"Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy\". Industrial Law Journal. 51 (3). doi:10.2139/ssrn.3119589. SSRN\u00a03119589.^Porter, Eduardo; Manjoo, Farhad (9 March 2016). \"A Future Without Jobs? Two Views of the Changing Work Force\". The New York Times. Archived from the original on 15 February 2017. Retrieved 23 February 2017.^Thompson, Derek (July\u2013August 2015). \"A World Without Work\". The Atlantic. Archived from the original on 27 February 2017. Retrieved 11 March 2017.^Yan (30 July 2011). \"Foxconn to replace workers with 1 million robots in 3 years\". Xinhua News Agency. Archived from the original on 8 October 2011. Retrieved 4 August 2011.^\"Judgment day \u2013 employment law and robots in the workplace\". futureofworkhub. 20 November 2014. Archived from the original on 3 April 2015. Retrieved 7 January 2015.^Delaney, Kevin (17 February 2017). \"The robot that takes your job should pay taxes, says Bill Gates\". Quartz. Archived from the original on 5 March 2017. Retrieved 4 March 2017.^\"The Changing Nature of Work\". Archived from the original on 30 September 2018. Retrieved 8 October 2018.^Talbot, Ben; Dayoub, Feras; Corke, Peter; Wyeth, Gordon (December 2021). \"Robot Navigation in Unseen Spaces Using an Abstract Map\". IEEE Transactions on Cognitive and Developmental Systems. 13 (4): 791\u2013805. arXiv:2001.11684. Bibcode:2021ITCDS..13..791T. doi:10.1109/TCDS.2020.2993855. ISSN\u00a02379-8939. S2CID\u00a0211004032.^\"Contact Systems Pick and Place robots\". Contact Systems. Archived from the original on 14 September 2008. Retrieved 21 September 2008.^\"SMT pick-and-place equipment\". Assembleon. Archived from the original on 3 August 2008. Retrieved 21 September 2008.^\"The Basics of Automated Guided Vehicles\". Savant Automation, AGV Systems. Archived from the original on 8 October 2007. Retrieved 13 September 2007.^\"Automatic Trailer Loading Vehicle - SmartLoader\". Archived from the original on 23 May 2013. Retrieved 2 September 2011.^\"SpeciMinder\". CSS Robotics. Archived from the original on 1 July 2009. Retrieved 25 September 2008.^\"ADAM robot\". RMT Robotics. Archived from the original on 17 May 2006. Retrieved 25 September 2008.^\"Can Do\". Aethon. Archived from the original on 3 August 2008. Retrieved 25 September 2008.^\"Eskorta robot\". Fennec Fox Technologies. Archived from the original on 6 December 2011. Retrieved 25 November 2011.^\"Delivery Robots & AGVs\". Mobile Robots. Archived from the original on 26 February 2010. Retrieved 25 September 2008.^\"Dante II, list of published papers\". The Robotics Institute of Carnegie Mellon University. Archived from the original on 15 May 2008. Retrieved 16 September 2007.^\"Mars Pathfinder Mission: Rover Sojourner\". NASA. 8 July 1997. Archived from the original on 1 February 2017. Retrieved 19 September 2007.^ ab\"Robot assisted surgery: da Vinci Surgical System\". Brown University Division of Biology and Medicine. Archived from the original on 16 September 2007. Retrieved 19 September 2007.^\"The Utilization of Robotic Space Probes in Deep Space Missions:Case Study of AI Protocols and Nuclear Power Requirements\". Proceedings of 2011 International Conference on Mechanical Engineering, Robotics and Aerospace. October 2011.^Foust, Jeff (16 January 2012). \"Review: Space Probes\". Archived from the original on 31 August 2012. Review of Space Probes: 50 Years of Exploration from Luna 1 to New Horizons, by Philippe S\u00e9gu\u00e9la Firefly, 2011.^\"Celebrities set to reach for Atwood's LongPen\". Canadian Broadcasting Corporation. 15 August 2007. Archived from the original on 22 May 2009. Retrieved 21 September 2008.^Graham, Stephen (12 June 2006). \"America's robot army\". New Statesman. Archived from the original on 17 February 2012. Retrieved 24 September 2007.^\"Battlefield Robots: to Iraq, and Beyond\". Defense Industry Daily. 20 June 2005. Archived from the original on 26 August 2007. Retrieved 24 September 2007.^Shachtman, Noah (November 2005). \"The Baghdad Bomb Squad\". Wired. Archived from the original on 22 April 2008. Retrieved 14 September 2007.^Shachtman, Noah (2 August 2007). \"WIRED: First Armed Robots on Patrol in Iraq (Updated)\". Wired. Retrieved 26 September 2023.^Shachtman, Noah (28 March 2013). \"WIRED: Armed Robots Pushed To Police\". Wired. Archived from the original on 12 April 2009. Retrieved 8 February 2014.^\"America's Robot Army: Are Unmanned Fighters Ready for Combat?\". Popular Mechanics. 17 December 2009. Retrieved 26 September 2023.^Hagerman, Eric (23 February 2010). \"The Present and Future of Unmanned Drone Aircraft: An Illustrated Field Guide\". Popular Science. Archived from the original on 26 February 2010.^Higgins, Kat (12 July 2010). \"Taranis: The \u00a3143m Fighter Jet Of The Future\". Sky News Online. Archived from the original on 15 July 2010. Retrieved 13 July 2010.^Emery, Daniel (12 July 2010). \"MoD lifts lid on unmanned combat plane prototype\". BBC News. Archived from the original on 12 July 2010. Retrieved 12 July 2010.^AAAI Presidential Panel on Long-Term AI Futures 2008\u20132009 Study (Report). Association for the Advancement of Artificial Intelligence. Archived from the original on 28 August 2009. Retrieved 26 July 2009.^\"Why We Need Friendly AI\". 3 Laws Unsafe. July 2004. Archived from the original on 24 May 2012. Retrieved 27 July 2009.^\"Robotic age poses ethical dilemma\". BBC News. 7 March 2007. Archived from the original on 15 February 2009. Retrieved 2 January 2007.^Christensen, Bill (26 May 2006). \"Asimov's First Law: Japan Sets Rules for Robots\". Live Science. Archived from the original on 13 October 2008.^\"Japan drafts rules for advanced robots\". UPI. 6 April 2007. Archived from the original on 11 October 2008 \u2013 via physorg.com.^\"Building a Safe and Secure Social System Incorporating the Coexistence of Humans and Robots\" (Press release). Ministry of Economy, Trade and Industry. March 2009. Archived from the original on 27 September 2011.^Weng, Yueh-Hsuan; Chen, Chien-Hsun; Sun, Chuen-Tsai (25 April 2009). \"Toward the Human\u2013Robot Co-Existence Society: On Safety Intelligence for Next Generation Robots\". International Journal of Social Robotics. 1 (4): 267\u2013282. doi:10.1007/s12369-009-0019-1. S2CID\u00a036232530.^Fox, Stuart (19 August 2009). \"Evolving Robots Learn To Lie To Each Other\". Popular Science.^\"Rio Tinto Media Center \u2013 Rio Tinto boosts driverless truck fleet to 150 under Mine of the Future\u2122 programme\". Riotinto.com. Archived from the original on 24 April 2013. Retrieved 8 February 2014.^\"BHP Billiton hits go on autonomous drills\". Retrieved 13 February 2023.^Adrian (6 September 2011). \"AIMEX blog \u2013 Autonomous mining equipment\". Adrianboeing.blogspot.com. Archived from the original on 18 December 2013. Retrieved 8 February 2014.^\"Atlas Copco \u2013 RCS\". Atlascopco.com. Archived from the original on 7 February 2014. Retrieved 8 February 2014.^\"Transmin \u2013 Rocklogic\". Rocklogic.com.au. Archived from the original on 25 January 2014. Retrieved 8 February 2014.^Topping, Mike; Smith, Jane (1999). \"An Overview Of Handy 1, A Rehabilitation Robot For The Severely Disabled\". CSUN Center on Disabilities Conference Proceedings. 1999. Proceedings: Session 59. Archived from the original on 5 August 2009. Retrieved 14 August 2010. The early version of the Handy 1 system consisted of a Cyber 310 robotic arm with five degrees of freedom plus a gripper.^Jeavans, Christine (29 November 2004). \"Welcome to the ageing future\". BBC News. Archived from the original on 16 October 2007. Retrieved 26 September 2007.^\"Statistical Handbook of Japan: Chapter 2 Population\". Statistics Bureau & Statistical Research and Training Institute. Archived from the original on 6 September 2013. Retrieved 26 September 2007.^\"Robotic future of patient care\". E-Health Insider. 16 August 2007. Archived from the original on 21 November 2007. Retrieved 26 September 2007.^Gebhart, Fred (4 July 2019). \"The Future of Pharmacy Automation\". Drug Topics Journal. Drug Topics July 2019. 163 (7). Retrieved 16 October 2022.^Dolan, Kerry A. \"R2D2 Has Your Pills\". Forbes. Retrieved 20 November 2019.^\"Nanobots Play Football\". Techbirbal. Archived from the original on 3 April 2013. Retrieved 8 February 2014.^\"KurzweilAI.net\". 21 June 2010. Archived from the original on 21 June 2010. Retrieved 5 July 2016.^\"(Eric Drexler 1986) Engines of Creation, The Coming Era of Nanotechnology\". E-drexler.com. Archived from the original on 6 September 2014. Retrieved 8 February 2014.^Phoenix, Chris (December 2003). \"Of Chemistry, Nanobots, and Policy\". Center for Responsible Nanotechnology. Archived from the original on 11 October 2007. Retrieved 28 October 2007.^\"Nanotechnology pioneer slays 'grey goo' myths\". ScienceDaily. 9 June 2004.^Toth-Fejel, Tihamer (May 1996). LEGO(TM)s to the Stars: Active MesoStructures, Kinetic Cellular Automata, and Parallel Nanomachines for Space Applications. 1996 International Space Development Conference. New York City. Archived from the original on 27 September 2007.^Fitch, Robert; Butler, Zack; Rus, Daniela. \"Reconfiguration Planning for Heterogeneous Self-Reconfiguring Robots\"(PDF). Massachusetts Institute of Technology. Archived from the original(PDF) on 19 June 2007.^\"Researchers build robot scientist that has already discovered a new catalyst\". phys.org. Retrieved 16 August 2020.^Burger, Benjamin; Maffettone, Phillip M.; Gusev, Vladimir V.; Aitchison, Catherine M.; Bai, Yang; Wang, Xiaoyan; Li, Xiaobo; Alston, Ben M.; Li, Buyi; Clowes, Rob; Rankin, Nicola; Harris, Brandon; Sprick, Reiner Sebastian; Cooper, Andrew I. (July 2020). \"A mobile robotic chemist\". Nature. 583 (7815): 237\u2013241. Bibcode:2020Natur.583..237B. doi:10.1038/s41586-020-2442-2. ISSN\u00a01476-4687. PMID\u00a032641813. S2CID\u00a0220420261. Retrieved 16 August 2020.^Schwartz, John (27 March 2007). \"In the Lab: Robots That Slink and Squirm\". The New York Times. Archived from the original on 3 April 2015. Retrieved 22 September 2008.^Eschner, Kat (25 March 2019). \"Squishy robots now have squishy computers to control them\". Popular Science.^\"The softer side of robotics\". May 2019. Retrieved 13 February 2023.^\"SRI/MobileRobots\". activrobots.com. Archived from the original on 12 February 2009.^\"Open-source micro-robotic project\". Archived from the original on 11 November 2007. Retrieved 28 October 2007.^\"Swarm\". iRobot Corporation. Archived from the original on 27 September 2007. Retrieved 28 October 2007.^Knapp, Louise (21 December 2000). \"Look, Up in the Sky: Robofly\". Wired. Archived from the original on 26 June 2012. Retrieved 25 September 2008.^\"The Cutting Edge of Haptics\". MIT Technology review. Retrieved 25 September 2008.^\"Artists & Robots Exposition au Grand Palais du 5 avril au 9 juillet 2018\". 14 August 2019. Archived from the original on 14 August 2019. Retrieved 3 February 2020.^\"Comic Potential: Q&A with Director Stephen Cole\". Cornell University. Archived from the original on 3 January 2009. Retrieved 21 November 2007.^Freedman, Carl, ed. (2005). Conversations with Isaac Asimov (1.\u00a0ed.). Jackson: Univ. Press of Mississippi. p.\u00a0vii. ISBN\u00a0978-1-57806-738-1. Retrieved 4 August 2011. ... quite possibly the most prolific^Oakes, Elizabeth H. (2004). American writers. New York: Facts on File. p.\u00a024. ISBN\u00a0978-0-8160-5158-8. Retrieved 4 August 2011. most prolific authors asimov.^He wrote \"over 460 books as well as thousands of articles and reviews\", and was the \"third most prolific writer of all time [and] one of the founding fathers of modern science fiction\". White, Michael (2005). Isaac Asimov: a life of the grand master of science fiction. Carroll & Graf. pp.\u00a01\u20132. ISBN\u00a0978-0-7867-1518-3. Archived from the original on 5 December 2016. Retrieved 25 September 2016.^R. Clarke. \"Asimov's Laws of Robotics \u2013 Implications for Information Technology\". Australian National University/IEEE. Archived from the original on 22 July 2008. Retrieved 25 September 2008.^Seiler, Edward; Jenkins, John H. (27 June 2008). \"Isaac Asimov FAQ\". Isaac Asimov Home Page. Archived from the original on 16 July 2012. Retrieved 24 September 2008.^White, Michael (2005). Isaac Asimov: A Life of the Grand Master of Science Fiction. Carroll & Graf. p.\u00a056. ISBN\u00a0978-0-7867-1518-3.^\"Intelligent machines: Call for a ban on robots designed as sex toys\". BBC News. 15 September 2015. Archived from the original on 30 June 2018. Retrieved 21 June 2018.^Abdollahi, Hojjat; Mollahosseini, Ali; Lane, Josh T.; Mahoor, Mohammad H. (November 2017). A pilot study on using an intelligent life-like robot as a companion for elderly individuals with dementia and depression. 2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids). pp.\u00a0541\u2013546. arXiv:1712.02881. Bibcode:2017arXiv171202881A. doi:10.1109/humanoids.2017.8246925. ISBN\u00a0978-1-5386-4678-6. S2CID\u00a01962455.External links.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Wikiquote has quotations related to Robot.Journal of Field Robotics.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutlinevteMachinesClassical simple machinesInclined planeLeverPulleyScrewWedgeWheel and axleClocksAtomic clockChronometerPendulum clockQuartz clockCompressors and pumpsArchimedes' screwEductor-jet pumpHydraulic ramPumpTrompeVacuum pumpExternal combustion enginesSteam engineStirling engineInternal combustion enginesGas turbineReciprocating engineRotary engineNutating disc engineLinkagesPantographPeaucellier-LipkinTurbineGas turbineJet engineSteam turbineWater turbineWind generatorWindmillAerofoilSailWingRudderFlapPropellerElectronicsVacuum tubeTransistorDiodeResistorCapacitorInductorVehiclesAutomobileMiscellaneousMechaRobotAgriculturalSeed-counting machineVending machineWind tunnelCheck weighing machinesRiveting machinesSpringsSpring (device)vteScience fictionOutlineAuthorsDefinitionsAnthropologicalHardScientific romanceSoftHistoryPulp eraGolden AgeNew WaveTimelineSubgenresApocalyptic and post-apocalypticComedySitcomsFeministGrimdarkInner spaceMechaAnime and mangaMundaneSpace warfareMilitarySpace operaSpace WesternParallel universesIsekaiScience fantasyDying EarthPlanetary romanceSuperheroSword and planetSocialClimate fictionChristianLibertarianUtopian and dystopianTech noirSpy-FiTechno-thrillerTokusatsuKaijuUnderwaterCyberpunk derivativesCyberpunkJapaneseBiopunkDieselpunkNanopunkSolarpunkSteampunkCultureConventionsFandomFanzinesISFDBLibraries and museumsScience Fiction MuseumStudiesWomen in SFWorldconRegionAustralianBengaliBrazilianCanadianChileanChineseCroatianCzechEstonianFrenchHungarianJapaneseKoreanNorwegianPolishRomanianRussianSerbianSpanishYugoslavAwardsCinematicJules VerneSaturnLiterary, art,and audioAstoundingAurealisBSFACampbell MemorialChesleyClarkeCrookDeutscherDickDitmarEndeavorFantLabGalaxyGaughanGeffenGolden DuckGrand MasterGrand PrixHarlandHeinleinIgnotusKitschiesLambdaLa\u00dfwitzLocusNautilusNebulaNommoNortonParsecPrometheusRhyslingSFERASidewiseSkylarkSturgeonSunburstT\u00e4htivaeltajaTBDTiptreeTour-ApolloTranslationUraniaVogelWriters and Illustrators of the FutureZajdelMultimediaAuroraChandlerDragonHugoSeiunSpectrumMediaFilmFilm historyFilmsIndianJapaneseAnimeTokusatsuLiteratureComicsMagazinesNovelsPublishersShort storiesStageOperaTheatreTelevisionList of TV showsAustralasianBritishCanadianEuropeanJapaneseAnimeLive-actionU.S.ThemesArchitecturalDyson sphereEcumenopolisMatrioshka brainSpace stations and habitatsStellar engineTerraformingTopopolisBiologicalBiological warfareEvolutionExtraterrestrialsListGenderGenetic engineeringInvisibilityNanotechnologyOrgan transplantationParasitismSex and sexualitySuperhumansSymbiosisPhysicalBlack holesExtrasolar planetsMultiverseParallel universesListPortable holeSpace travelStarsTachyonsTeleportationTime travelTime viewerWormholePsychologicalGroup mindMind uploadingPsionicsSimulated consciousnessSocialAfricanfuturismAfrofuturismAlien invasionAlien languageAncient astronautsBlackEvil corporationFirst contactFrankenstein complexGalactic empireLGBTMessage from spaceTranshumanismUpliftXenoarchaeologyTechnologicalAnsibleArtificial intelligenceAI takeoverAstroengineeringForce fieldHolographyHyperspaceInertialessRobots and CyborgsSelf-replicating machinesSimulated realitySpacecraftStargateWarp driveWeaponsReligiousChristian science fictionRelatedAlternate historyFantasyFictional astronautsFictional technologyFuture historyHorrorMagic realismMuseum of Science FictionRubber scienceScience and technology studiesSense of wonderSpeculative fictionSupernaturalTechnology and societyWeirdCategoryPortal.mw-parser-output .sister-bar{display:flex;justify-content:center;align-items:baseline;font-size:88%;background-color:#fdfdfd;border:1px solid #a2a9b1;clear:both;margin:1em 0 0;padding:0 2em}.mw-parser-output .sister-bar-header{margin:0 1em 0 0.5em;padding:0.2em 0;flex:0 0 auto;min-height:24px;line-height:22px}.mw-parser-output .sister-bar-content{display:flex;flex-flow:row wrap;flex:0 1 auto;align-items:baseline;padding:0.2em 0;column-gap:1em;margin:0;list-style:none}.mw-parser-output .sister-bar-item{display:flex;align-items:baseline;margin:0.15em 0;min-height:24px;text-align:left}.mw-parser-output .sister-bar-logo{width:22px;line-height:22px;margin:0 3px 0 2px;text-align:right}.mw-parser-output .sister-bar-link{margin:0 2px 0 4px;text-align:left}@media screen and (max-width:960px){.mw-parser-output .sister-bar{flex-flow:column wrap;margin:1em auto 0}.mw-parser-output .sister-bar-header{flex:0 1}.mw-parser-output .sister-bar-content{flex:1;border-top:1px solid #a2a9b1;margin:0;list-style:none}.mw-parser-output .sister-bar-item{flex:0 0 20em;min-width:20em}}.mw-parser-output .navbox+link+.sister-bar,.mw-parser-output .navbox+style+.sister-bar,.mw-parser-output .portal-bar+link+.sister-bar,.mw-parser-output .portal-bar+style+.sister-bar,.mw-parser-output .sister-bar+.navbox-styles+.navbox,.mw-parser-output .sister-bar+.navbox-styles+.portal-bar{margin-top:-1px}@media print{body.ns-0 .mw-parser-output .sister-bar{display:none!important}}Robot at Wikipedia's sister projects:Definitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from Wikiversity.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDFASTNationalUnited States2FranceBnF dataJapanCzech RepublicIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robot&oldid=1312300730\"", "tags": ["en.wikipedia.org", "wiki", "robot"]}
{"url": "https://en.wikipedia.org/wiki/Reinforcement_learning", "title": null, "text": "Field of machine learning.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For reinforcement learning in psychology, see Reinforcement and Operant conditioning. The typical framing of a reinforcement learning (RL) scenario: an agent takes actions in an environment, which is interpreted into a reward and a state representation, which are fed back to the agent..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}.mw-parser-output .nobold{font-weight:normal}Part of a series onMachine learningand data miningParadigmsSupervised learningUnsupervised learningSemi-supervised learningSelf-supervised learningReinforcement learningMeta-learningOnline learningBatch learningCurriculum learningRule-based learningNeuro-symbolic AINeuromorphic engineeringQuantum machine learningProblemsClassificationGenerative modelingRegressionClusteringDimensionality reductionDensity estimationAnomaly detectionData cleaningAutoMLAssociation rulesSemantic analysisStructured predictionFeature engineeringFeature learningLearning to rankGrammar inductionOntology learningMultimodal learningSupervised learning(classification\u00a0\u2022 regression)Apprenticeship learningDecision treesEnsemblesBaggingBoostingRandom forestk-NNLinear regressionNaive BayesArtificial neural networksLogistic regressionPerceptronRelevance vector machine (RVM)Support vector machine (SVM)ClusteringBIRCHCUREHierarchicalk-meansFuzzyExpectation\u2013maximization (EM)DBSCANOPTICSMean shiftDimensionality reductionFactor analysisCCAICALDANMFPCAPGDt-SNESDLStructured predictionGraphical modelsBayes netConditional random fieldHidden MarkovAnomaly detectionRANSACk-NNLocal outlier factorIsolation forestNeural networksAutoencoderDeep learningFeedforward neural networkRecurrent neural networkLSTMGRUESNreservoir computingBoltzmann machineRestrictedGANDiffusion modelSOMConvolutional neural networkU-NetLeNetAlexNetDeepDreamNeural fieldNeural radiance fieldPhysics-informed neural networksTransformerVisionMambaSpiking neural networkMemtransistorElectrochemical RAM (ECRAM)Reinforcement learningQ-learningPolicy gradientSARSATemporal difference (TD)Multi-agentSelf-playLearning with humansActive learningCrowdsourcingHuman-in-the-loopMechanistic interpretabilityRLHFModel diagnosticsCoefficient of determinationConfusion matrixLearning curveROC curveMathematical foundationsKernel machinesBias\u2013variance tradeoffComputational learning theoryEmpirical risk minimizationOccam learningPAC learningStatistical learningVC theoryTopological deep learningJournals and conferencesAAAIECML PKDDNeurIPSICMLICLRIJCAIMLJMLRRelated articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteIn machine learning and optimal control, reinforcement learning (RL) is concerned with how an intelligent agent should take actions in a dynamic environment in order to maximize a reward signal. Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\nReinforcement learning differs from supervised learning in not needing labelled input-output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the cumulative reward (the feedback of which might be incomplete or delayed).[1] The search for this balance is known as the exploration\u2013exploitation dilemma.\n\nThe environment is typically stated in the form of a Markov decision process, as many reinforcement learning algorithms use dynamic programming techniques.[2] The main difference between classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process, and they target large Markov decision processes where exact methods become infeasible.[3].mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}Principles[edit]Due to its generality, reinforcement learning is studied in many disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, and statistics. In the operations research and control literature, RL is called approximate dynamic programming, or neuro-dynamic programming. The problems of interest in RL have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation (particularly in the absence of a mathematical model of the environment).\nBasic reinforcement learning is modeled as a Markov decision process:\nA set of environment and agent states (the state space), \n  \n    \n      \n        \n          \n            S\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {S}}}\n  ;A set of actions (the action space), \n  \n    \n      \n        \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {A}}}\n  , of the agent;\n  \n    \n      \n        \n          P\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n        =\n        Pr\n        (\n        \n          S\n          \n            t\n            +\n            1\n          \n        \n        \n          =\n        \n        \n          s\n          \u2032\n        \n        \u2223\n        \n          S\n          \n            t\n          \n        \n        \n          =\n        \n        s\n        ,\n        \n          A\n          \n            t\n          \n        \n        \n          =\n        \n        a\n        )\n      \n    \n    {\\displaystyle P_{a}(s,s')=\\Pr(S_{t+1}{=}s'\\mid S_{t}{=}s,A_{t}{=}a)}\n  , the transition probability (at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ) from state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to state \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   under action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .\n  \n    \n      \n        \n          R\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle R_{a}(s,s')}\n  , the immediate reward after transition from \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   under action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .The purpose of reinforcement learning is for the agent to learn an optimal (or near-optimal) policy that maximizes the reward function or other user-provided reinforcement signal that accumulates from immediate rewards. This is similar to processes that appear to occur in animal psychology. For example, biological brains are hardwired to interpret signals such as pain and hunger as negative reinforcements, and interpret pleasure and food intake as positive reinforcements. In some circumstances, animals learn to adopt behaviors that optimize these rewards. This suggests that animals are capable of reinforcement learning.[4][5]A basic reinforcement learning agent interacts with its environment in discrete time steps. At each time step t, the agent receives the current state \n  \n    \n      \n        \n          S\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle S_{t}}\n   and reward \n  \n    \n      \n        \n          R\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle R_{t}}\n  . It then chooses an action \n  \n    \n      \n        \n          A\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle A_{t}}\n   from the set of available actions, which is subsequently sent to the environment. The environment moves to a new state \n  \n    \n      \n        \n          S\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle S_{t+1}}\n   and the reward \n  \n    \n      \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle R_{t+1}}\n   associated with the transition\n  \n    \n      \n        (\n        \n          S\n          \n            t\n          \n        \n        ,\n        \n          A\n          \n            t\n          \n        \n        ,\n        \n          S\n          \n            t\n            +\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (S_{t},A_{t},S_{t+1})}\n   is determined. The goal of a reinforcement learning agent is to learn a policy:\n\n  \n    \n      \n        \n          \n            \n              \n              \n                \u03c0\n                :\n                \n                  \n                    S\n                  \n                \n                \u00d7\n                \n                  \n                    A\n                  \n                \n                \u2192\n                [\n                0\n                ,\n                1\n                ]\n              \n            \n            \n              \n              \n                \u03c0\n                (\n                s\n                ,\n                a\n                )\n                =\n                Pr\n                (\n                \n                  A\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                a\n                \u2223\n                \n                  S\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                s\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {S}}\\times {\\mathcal {A}}\\to [0,1]\\\\&\\pi (s,a)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\n  that maximizes the expected cumulative reward.\nFormulating the problem as a Markov decision process assumes the agent directly observes the current environmental state; in this case, the problem is said to have full observability. If the agent only has access to a subset of states, or if the observed states are corrupted by noise, the agent is said to have partial observability, and formally the problem must be formulated as a partially observable Markov decision process. In both cases, the set of actions available to the agent can be restricted. For example, the state of an account balance could be restricted to be positive; if the current value of the state is 3 and the state transition attempts to reduce the value by 4, the transition will not be allowed.\nWhen the agent's performance is compared to that of an agent that acts optimally, the difference in performance yields the notion of regret. In order to act near optimally, the agent must reason about long-term consequences of its actions (i.e., maximize future rewards), although the immediate reward associated with this might be negative.\nThus, reinforcement learning is particularly well-suited to problems that include a long-term versus short-term reward trade-off. It has been applied successfully to various problems, including energy storage,[6]robot control,[7]photovoltaic generators,[8]backgammon, checkers,[9]Go (AlphaGo), and autonomous driving systems.[10]Two elements make reinforcement learning powerful: the use of samples to optimize performance, and the use of function approximation to deal with large environments. Thanks to these two key components, RL can be used in large environments in the following situations:\nA model of the environment is known, but an analytic solution is not available;Only a simulation model of the environment is given (the subject of simulation-based optimization);[11]The only way to collect information about the environment is to interact with it.The first two of these problems could be considered planning problems (since some form of model is available), while the last one could be considered to be a genuine learning problem. However, reinforcement learning converts both planning problems to machine learning problems.\nExploration[edit]The trade-off between exploration and exploitation has been most thoroughly studied through the multi-armed bandit problem and for finite state space Markov decision processes in Burnetas and Katehakis (1997).[12]Reinforcement learning requires clever exploration mechanisms; randomly selecting actions, without reference to an estimated probability distribution, shows poor performance. The case of (small) finite Markov decision processes is relatively well understood. However, due to the lack of algorithms that scale well with the number of states (or scale to problems with infinite state spaces), simple exploration methods are the most practical.\nOne such method is \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  -greedy, where \n  \n    \n      \n        0\n        <\n        \u03b5\n        <\n        1\n      \n    \n    {\\displaystyle 0<\\varepsilon <1}\n   is a parameter controlling the amount of exploration vs. exploitation. With probability \n  \n    \n      \n        1\n        \u2212\n        \u03b5\n      \n    \n    {\\displaystyle 1-\\varepsilon }\n  , exploitation is chosen, and the agent chooses the action that it believes has the best long-term effect (ties between actions are broken uniformly at random). Alternatively, with probability \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  , exploration is chosen, and the action is chosen uniformly at random. \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n   is usually a fixed parameter but can be adjusted either according to a schedule (making the agent explore progressively less), or adaptively based on heuristics.[13]Algorithms for control learning[edit]Even if the issue of exploration is disregarded and even if the state was observable (assumed hereafter), the problem remains to use past experience to find out which actions lead to higher cumulative rewards.\nCriterion of optimality[edit]Policy[edit]The agent's action selection is modeled as a map called policy:\n\n  \n    \n      \n        \n          \n            \n              \n              \n                \u03c0\n                :\n                \n                  \n                    A\n                  \n                \n                \u00d7\n                \n                  \n                    S\n                  \n                \n                \u2192\n                [\n                0\n                ,\n                1\n                ]\n              \n            \n            \n              \n              \n                \u03c0\n                (\n                a\n                ,\n                s\n                )\n                =\n                Pr\n                (\n                \n                  A\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                a\n                \u2223\n                \n                  S\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                s\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {A}}\\times {\\mathcal {S}}\\to [0,1]\\\\&\\pi (a,s)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\n  The policy map gives the probability of taking action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   when in state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  .[14]:\u200a61\u200a There are also deterministic policies  \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   for which \n  \n    \n      \n        \u03c0\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\pi (s)}\n   denotes the action that should be played at state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  .\nState-value function[edit]The state-value function \n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V_{\\pi }(s)}\n   is defined as, expected discounted return starting with state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  , i.e. \n  \n    \n      \n        \n          S\n          \n            0\n          \n        \n        =\n        s\n      \n    \n    {\\displaystyle S_{0}=s}\n  , and successively following policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  . Hence, roughly speaking, the value function estimates \"how good\" it is to be in a given state.[14]:\u200a60\u200a\n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        \n          S\n          \n            0\n          \n        \n        \n          =\n        \n        s\n        ]\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        \n          [\n          \n            \n              \u2211\n              \n                t\n                =\n                0\n              \n              \n                \u221e\n              \n            \n            \n              \u03b3\n              \n                t\n              \n            \n            \n              R\n              \n                t\n                +\n                1\n              \n            \n            \u2223\n            \n              S\n              \n                0\n              \n            \n            \n              =\n            \n            s\n          \n          ]\n        \n        ,\n      \n    \n    {\\displaystyle V_{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid S_{0}{=}s]=\\operatorname {\\mathbb {E} } \\left[\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}\\mid S_{0}{=}s\\right],}\n  where the random variable \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   denotes the discounted return, and is defined as the sum of future discounted rewards:\n\n  \n    \n      \n        G\n        =\n        \n          \u2211\n          \n            t\n            =\n            0\n          \n          \n            \u221e\n          \n        \n        \n          \u03b3\n          \n            t\n          \n        \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n        =\n        \n          R\n          \n            1\n          \n        \n        +\n        \u03b3\n        \n          R\n          \n            2\n          \n        \n        +\n        \n          \u03b3\n          \n            2\n          \n        \n        \n          R\n          \n            3\n          \n        \n        +\n        \u22ef\n        ,\n      \n    \n    {\\displaystyle G=\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}=R_{1}+\\gamma R_{2}+\\gamma ^{2}R_{3}+\\cdots ,}\n  where \n  \n    \n      \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle R_{t+1}}\n   is the reward for transitioning from state \n  \n    \n      \n        \n          S\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle S_{t}}\n   to \n  \n    \n      \n        \n          S\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle S_{t+1}}\n  ,\n  \n    \n      \n        0\n        \u2264\n        \u03b3\n        <\n        1\n      \n    \n    {\\displaystyle 0\\leq \\gamma <1}\n   is the discount rate. \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is less than 1, so rewards in the distant future are weighted less than rewards in the immediate future.\nThe algorithm must find a policy with maximum expected discounted return. From the theory of Markov decision processes it is known that, without loss of generality, the search can be restricted to the set of so-called stationary policies. A policy is stationary if the action-distribution returned by it depends only on the last state visited (from the observation agent's history). The search can be further restricted to deterministic stationary policies. A deterministic stationary policy deterministically selects actions based on the current state. Since any such policy can be identified with a mapping from the set of states to the set of actions, these policies can be identified with such mappings with no loss of generality.\nBrute force[edit]The brute force approach entails two steps:\nFor each possible policy, sample returns while following itChoose the policy with the largest expected discounted returnOne problem with this is that the number of policies can be large, or even infinite. Another is that the variance of the returns may be large, which requires many samples to accurately estimate the discounted return of each policy.\nThese problems can be ameliorated if we assume some structure and allow samples generated from one policy to influence the estimates made for others. The two main approaches for achieving this are value function estimation and direct policy search.\nValue function[edit]See also: Value functionValue function approaches attempt to find a policy that maximizes the discounted return by maintaining a set of estimates of expected discounted returns \n  \n    \n      \n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        ]\n      \n    \n    {\\displaystyle \\operatorname {\\mathbb {E} } [G]}\n   for some policy (usually either the \"current\" [on-policy] or the optimal [off-policy] one).\nThese methods rely on the theory of Markov decision processes, where optimality is defined in a sense stronger than the one above: A policy is optimal if it achieves the best-expected discounted return from any initial state (i.e., initial distributions play no role in this definition). Again, an optimal policy can always be found among stationary policies.\nTo define optimality in a formal manner, define the state-value of a policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   by\n\n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        s\n        ,\n        \u03c0\n        ]\n        ,\n      \n    \n    {\\displaystyle V^{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid s,\\pi ],}\n  where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   stands for the discounted return associated with following \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   from the initial state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  . Defining \n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V^{*}(s)}\n   as the maximum possible state-value of \n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V^{\\pi }(s)}\n  , where \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   is allowed to change,\n\n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n        =\n        \n          max\n          \n            \u03c0\n          \n        \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        .\n      \n    \n    {\\displaystyle V^{*}(s)=\\max _{\\pi }V^{\\pi }(s).}\n  A policy that achieves these optimal state-values in each state is called optimal. Clearly, a policy that is optimal in this sense is also optimal in the sense that it maximizes the expected discounted return, since \n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n        =\n        \n          max\n          \n            \u03c0\n          \n        \n        \n          E\n        \n        [\n        G\n        \u2223\n        s\n        ,\n        \u03c0\n        ]\n      \n    \n    {\\displaystyle V^{*}(s)=\\max _{\\pi }\\mathbb {E} [G\\mid s,\\pi ]}\n  , where \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is a state randomly sampled from the distribution \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   of initial states (so \n  \n    \n      \n        \u03bc\n        (\n        s\n        )\n        =\n        Pr\n        (\n        \n          S\n          \n            0\n          \n        \n        =\n        s\n        )\n      \n    \n    {\\displaystyle \\mu (s)=\\Pr(S_{0}=s)}\n  ).Although state-values suffice to define optimality, it is useful to define action-values. Given a state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  , an action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   and a policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  , the action-value of the pair \n  \n    \n      \n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle (s,a)}\n   under \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   is defined by\n\n  \n    \n      \n        \n          Q\n          \n            \u03c0\n          \n        \n        (\n        s\n        ,\n        a\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        s\n        ,\n        a\n        ,\n        \u03c0\n        ]\n        ,\n      \n    \n    {\\displaystyle Q^{\\pi }(s,a)=\\operatorname {\\mathbb {E} } [G\\mid s,a,\\pi ],}\n  where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   now stands for the random discounted return associated with first taking action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   in state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   and following \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  , thereafter.\nThe theory of Markov decision processes states that if \n  \n    \n      \n        \n          \u03c0\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\pi ^{*}}\n   is an optimal policy, we act optimally (take the optimal action) by choosing the action from \n  \n    \n      \n        \n          Q\n          \n            \n              \u03c0\n              \n                \u2217\n              \n            \n          \n        \n        (\n        s\n        ,\n        \u22c5\n        )\n      \n    \n    {\\displaystyle Q^{\\pi ^{*}}(s,\\cdot )}\n   with the highest action-value at each state, \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  . The action-value function of such an optimal policy (\n  \n    \n      \n        \n          Q\n          \n            \n              \u03c0\n              \n                \u2217\n              \n            \n          \n        \n      \n    \n    {\\displaystyle Q^{\\pi ^{*}}}\n  ) is called the optimal action-value function and is commonly denoted by \n  \n    \n      \n        \n          Q\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle Q^{*}}\n  . In summary, the knowledge of the optimal action-value function alone suffices to know how to act optimally.\nAssuming full knowledge of the Markov decision process, the two basic approaches to compute the optimal action-value function are value iteration and policy iteration. Both algorithms compute a sequence of functions \n  \n    \n      \n        \n          Q\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle Q_{k}}\n   (\n  \n    \n      \n        k\n        =\n        0\n        ,\n        1\n        ,\n        2\n        ,\n        \u2026\n      \n    \n    {\\displaystyle k=0,1,2,\\ldots }\n  ) that converge to \n  \n    \n      \n        \n          Q\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle Q^{*}}\n  . Computing these functions involves computing expectations over the whole state-space, which is impractical for all but the smallest (finite) Markov decision processes. In reinforcement learning methods, expectations are approximated by averaging over samples and using function approximation techniques to cope with the need to represent value functions over large state-action spaces.\nMonte Carlo methods[edit]Monte Carlo methods[15] are used to solve reinforcement learning problems by averaging sample returns. Unlike methods that require full knowledge of the environment's dynamics, Monte Carlo methods rely solely on actual or simulated experience\u2014sequences of states, actions, and rewards obtained from interaction with an environment. This makes them applicable in situations where the complete dynamics are unknown. Learning from actual experience does not require prior knowledge of the environment and can still lead to optimal behavior. When using simulated experience, only a model capable of generating sample transitions is required, rather than a full specification of transition probabilities, which is necessary for dynamic programming methods.\nMonte Carlo methods apply to episodic tasks, where experience is divided into episodes that eventually terminate. Policy and value function updates occur only after the completion of an episode, making these methods incremental on an episode-by-episode basis, though not on a step-by-step (online) basis. The term \"Monte Carlo\" generally refers to any method involving random sampling; however, in this context, it specifically refers to methods that compute averages from complete returns, rather than partial returns.\nThese methods function similarly to the bandit algorithms, in which returns are averaged for each state-action pair. The key difference is that actions taken in one state affect the returns of subsequent states within the same episode, making the problem non-stationary. To address this non-stationarity, Monte Carlo methods use the framework of general policy iteration (GPI). While dynamic programming computes value functions using full knowledge of the Markov decision process, Monte Carlo methods learn these functions through sample returns. The value functions and policies interact similarly to dynamic programming to achieve optimality, first addressing the prediction problem and then extending to policy improvement and control, all based on sampled experience.[14]Temporal difference methods[edit]Main article: Temporal difference learningThe first problem is corrected by allowing the procedure to change the policy (at some or all states) before the values settle. This too may be problematic as it might prevent convergence. Most current algorithms do this, giving rise to the class of generalized policy iteration algorithms. Many actor-critic methods belong to this category.\nThe second issue can be corrected by allowing trajectories to contribute to any state-action pair in them. This may also help to some extent with the third problem, although a better solution when returns have high variance is Sutton's temporal difference (TD) methods that are based on the recursive Bellman equation.[16][17] The computation in TD methods can be incremental (when after each transition the memory is changed and the transition is thrown away), or batch (when the transitions are batched and the estimates are computed once based on the batch). Batch methods, such as the least-squares temporal difference method,[18] may use the information in the samples better, while incremental methods are the only choice when batch methods are infeasible due to their high computational or memory complexity. Some methods try to combine the two approaches. Methods based on temporal differences also overcome the fourth issue.\nAnother problem specific to TD comes from their reliance on the recursive Bellman equation. Most TD methods have a so-called \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   parameter \n  \n    \n      \n        (\n        0\n        \u2264\n        \u03bb\n        \u2264\n        1\n        )\n      \n    \n    {\\displaystyle (0\\leq \\lambda \\leq 1)}\n   that can continuously interpolate between Monte Carlo methods that do not rely on the Bellman equations and the basic TD methods that rely entirely on the Bellman equations. This can be effective in palliating this issue.\nFunction approximation methods[edit]In order to address the fifth issue, function approximation methods are used. Linear function approximation starts with a mapping \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   that assigns a finite-dimensional vector to each state-action pair. Then, the action values of a state-action pair \n  \n    \n      \n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle (s,a)}\n   are obtained by linearly combining the components of \n  \n    \n      \n        \u03d5\n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle \\phi (s,a)}\n   with some weights\n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  :\n  \n    \n      \n        Q\n        (\n        s\n        ,\n        a\n        )\n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            d\n          \n        \n        \n          \u03b8\n          \n            i\n          \n        \n        \n          \u03d5\n          \n            i\n          \n        \n        (\n        s\n        ,\n        a\n        )\n        .\n      \n    \n    {\\displaystyle Q(s,a)=\\sum _{i=1}^{d}\\theta _{i}\\phi _{i}(s,a).}\n  The algorithms then adjust the weights, instead of adjusting the values associated with the individual state-action pairs. Methods based on ideas from nonparametric statistics (which can be seen to construct their own features) have been explored.\nValue iteration can also be used as a starting point, giving rise to the Q-learning algorithm and its many variants.[19] Including Deep Q-learning methods when a neural network is used to represent Q, with various applications in stochastic search problems.[20]The problem with using action-values is that they may need highly precise estimates of the competing action values that can be hard to obtain when the returns are noisy, though this problem is mitigated to some extent by temporal difference methods. Using the so-called compatible function approximation method compromises generality and efficiency.\nDirect policy search[edit]An alternative method is to search directly in (some subset of) the policy space, in which case the problem becomes a case of stochastic optimization. The two approaches available are gradient-based and gradient-free methods.\nGradient-based methods (policy gradient methods) start with a mapping from a finite-dimensional (parameter) space to the space of policies: given the parameter vector \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  , let \n  \n    \n      \n        \n          \u03c0\n          \n            \u03b8\n          \n        \n      \n    \n    {\\displaystyle \\pi _{\\theta }}\n   denote the policy associated to \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  . Defining the performance function by \n  \n    \n      \n        \u03c1\n        (\n        \u03b8\n        )\n        =\n        \n          \u03c1\n          \n            \n              \u03c0\n              \n                \u03b8\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho (\\theta )=\\rho ^{\\pi _{\\theta }}}\n   under mild conditions this function will be differentiable as a function of the parameter vector \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  . If the gradient of \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   was known, one could use gradient ascent. Since an analytic expression for the gradient is not available, only a noisy estimate is available. Such an estimate can be constructed in many ways, giving rise to algorithms such as Williams's REINFORCE method[21] (which is known as the likelihood ratio method in the simulation-based optimization literature).[22]A large class of methods avoids relying on gradient information. These include simulated annealing, cross-entropy search or methods of evolutionary computation. Many gradient-free methods can achieve (in theory and in the limit) a global optimum.\nPolicy search methods may converge slowly given noisy data. For example, this happens in episodic problems when the trajectories are long and the variance of the returns is large. Value-function based methods that rely on temporal differences might help in this case. In recent years, actor\u2013critic methods have been proposed and performed well on various problems.[23]Policy search methods have been used in the robotics context.[24] Many policy search methods may get stuck in local optima (as they are based on local search).\nModel-based algorithms[edit]Finally, all of the above methods can be combined with algorithms that first learn a model of the Markov decision process, the probability of each next state given an action taken from an existing state. For instance, the Dyna algorithm learns a model from experience, and uses that to provide more modelled transitions for a value function, in addition to the real transitions.[25] Such methods can sometimes be extended to use of non-parametric models, such as when the transitions are simply stored and \"replayed\" to the learning algorithm.[26]Model-based methods can be more computationally intensive than model-free approaches, and their utility can be limited by the extent to which the Markov decision process can be learnt.[27]There are other ways to use models than to update a value function.[28] For instance, in model predictive control the model is used to update the behavior directly.\nTheory[edit]Both the asymptotic and finite-sample behaviors of most algorithms are well understood. Algorithms with provably good online performance (addressing the exploration issue) are known.\nEfficient exploration of Markov decision processes is given in Burnetas and Katehakis (1997).[12] Finite-time performance bounds have also appeared for many algorithms, but these bounds are expected to be rather loose and thus more work is needed to better understand the relative advantages and limitations.\nFor incremental algorithms, asymptotic convergence issues have been settled.[clarification needed] Temporal-difference-based algorithms converge under a wider set of conditions than was previously possible (for example, when used with arbitrary, smooth function approximation).\nResearch[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  (October 2022) (Learn how and when to remove this message)Research topics include:\nactor-critic architecture[29]actor-critic-scenery architecture[3]adaptive methods that work with fewer (or no) parameters under a large number of conditionsbug detection in software projects[30]continuous learningcombinations with logic-based frameworks (e.g., temporal-logic specifications,[31] reward machines,[32] and probabilistic argumentation).[33]exploration in large Markov decision processesentity-based reinforcement learning[34][35][36]human feedback[37]interaction between implicit and explicit learning in skill acquisitionintrinsic motivation which differentiates information-seeking, curiosity-type behaviours from task-dependent goal-directed behaviours large-scale empirical evaluationslarge (or continuous) action spacesmodular and hierarchical reinforcement learning[38]multiagent/distributed reinforcement learning is a topic of interest. Applications are expanding.[39]occupant-centric controloptimization of computing resources[40][41][42]partial information (e.g., using predictive state representation)reward function based on maximising novel information[43][44][45]sample-based planning (e.g., based on Monte Carlo tree search).securities trading[46]transfer learning[47]TD learning modeling dopamine-based learning in the brain. Dopaminergic projections from the substantia nigra to the basal ganglia function are the prediction error.value-function and policy search methodsComparison of key algorithms[edit]The following table lists the key algorithms for learning a policy depending on several criteria:\nThe algorithm can be on-policy (it performs policy updates using trajectories sampled via the current policy)[48] or off-policy.The action space may be discrete (e.g. the action space could be \"going up\", \"going left\", \"going right\", \"going down\", \"stay\") or continuous (e.g. moving the arm with a given angle).The state space may be discrete (e.g. the agent could be in a cell in a grid) or continuous (e.g. the agent could be located at a given position in the plane).\n\nAlgorithmDescriptionPolicyAction spaceState spaceOperator\nMonte CarloEvery visit to Monte CarloEitherDiscreteDiscreteSample-means of state-values or action-values\nTD learningState\u2013action\u2013reward\u2013stateOff-policyDiscreteDiscreteState-value\nQ-learningState\u2013action\u2013reward\u2013stateOff-policyDiscreteDiscreteAction-value\nSARSAState\u2013action\u2013reward\u2013state\u2013actionOn-policyDiscreteDiscreteAction-value\nDQNDeep Q NetworkOff-policyDiscreteContinuousAction-value\nDDPGDeep Deterministic Policy GradientOff-policyContinuousContinuousAction-value\nA3CAsynchronous Advantage Actor-Critic AlgorithmOn-policyDiscreteContinuousAdvantage (=action-value - state-value)\nTRPOTrust Region Policy OptimizationOn-policyContinuous or DiscreteContinuousAdvantage\nPPOProximal Policy OptimizationOn-policyContinuous or DiscreteContinuousAdvantage\nTD3\nTwin Delayed Deep Deterministic Policy Gradient\nOff-policy\nContinuous\nContinuous\nAction-value\nSAC\nSoft Actor-Critic\nOff-policy\nContinuous\nContinuous\nAdvantage\nDSAC[49][50][51]Distributional Soft Actor CriticOff-policyContinuousContinuousAction-value distribution\nAssociative reinforcement learning[edit]Associative reinforcement learning tasks combine facets of stochastic learning automata tasks and supervised learning pattern classification tasks. In associative reinforcement learning tasks, the learning system interacts in a closed loop with its environment.[52]Deep reinforcement learning[edit]This approach extends reinforcement learning by using a deep neural network and without explicitly designing the state space.[53] The work on learning ATARI games by Google DeepMind increased attention to deep reinforcement learning or end-to-end reinforcement learning.[54]Adversarial deep reinforcement learning[edit]Adversarial deep reinforcement learning is an active area of research in reinforcement learning focusing on vulnerabilities of learned policies. In this research area some studies initially showed that reinforcement learning policies are susceptible to imperceptible adversarial manipulations.[55][56][57] While some methods have been proposed to overcome these susceptibilities, in the most recent studies it has been shown that these proposed solutions are far from providing an accurate representation of current vulnerabilities of deep reinforcement learning policies.[58]Fuzzy reinforcement learning[edit]By introducing fuzzy inference in reinforcement learning,[59] approximating the state-action value function with fuzzy rules in continuous space becomes possible. The IF - THEN form of fuzzy rules make this approach suitable for expressing the results in a form close to natural language. Extending FRL with Fuzzy Rule Interpolation[60] allows the use of reduced size sparse fuzzy rule-bases to emphasize cardinal rules (most important state-action values).\nInverse reinforcement learning[edit]In inverse reinforcement learning (IRL), no reward function is given. Instead, the reward function is inferred given an observed behavior from an expert. The idea is to mimic observed behavior, which is often optimal or close to optimal.[61] One popular IRL paradigm is named maximum entropy inverse reinforcement learning (MaxEnt IRL).[62] MaxEnt IRL estimates the parameters of a linear model of the reward function by maximizing the entropy of the probability distribution of observed trajectories subject to constraints related to matching expected feature counts. Recently it has been shown that MaxEnt IRL is a particular case of a more general framework named random utility inverse reinforcement learning (RU-IRL).[63] RU-IRL is based on random utility theory and Markov decision processes. While prior IRL approaches assume that the apparent random behavior of an observed agent is due to it following a random policy, RU-IRL assumes that the observed agent follows a deterministic policy but randomness in observed behavior is due to the fact that an observer only has partial access to the features the observed agent uses in decision making. The utility function is modeled as a random variable to account for the ignorance of the observer regarding the features the observed agent actually considers in its utility function.\nMulti-objective reinforcement learning[edit]Multi-objective reinforcement learning (MORL) is a form of reinforcement learning concerned with conflicting alternatives. It is distinct from multi-objective optimization in that it is concerned with agents acting in environments.[64][65]Safe reinforcement learning[edit]Safe reinforcement learning (SRL) can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes.[66] An alternative approach is risk-averse reinforcement learning, where instead of the expected return, a risk-measure of the return is optimized, such as the conditional value at risk (CVaR).[67] In addition to mitigating risk, the CVaR objective increases robustness to model uncertainties.[68][69] However, CVaR optimization in risk-averse RL requires special care, to prevent gradient bias[70] and blindness to success.[71]Self-reinforcement learning[edit]Self-reinforcement learning (or self-learning), is a learning paradigm which does not use the concept of immediate reward \n  \n    \n      \n        \n          R\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle R_{a}(s,s')}\n   after transition from \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   with action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  . It does not use an external reinforcement, it only uses the agent internal self-reinforcement. The internal self-reinforcement is provided by mechanism of feelings and emotions. In the learning process emotions are backpropagated by a mechanism of secondary reinforcement. The learning equation does not include the immediate reward, it only includes the state evaluation.\nThe self-reinforcement algorithm updates a memory matrix \n  \n    \n      \n        W\n        =\n        \u2016\n        w\n        (\n        a\n        ,\n        s\n        )\n        \u2016\n      \n    \n    {\\displaystyle W=\\|w(a,s)\\|}\n   such that in each iteration executes the following machine learning routine:\nIn situation \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   perform action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .Receive a consequence situation \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n  .Compute state evaluation \n  \n    \n      \n        v\n        (\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle v(s')}\n   of how good is to be in the consequence situation \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n  .Update crossbar memory \n  \n    \n      \n        \n          w\n          \u2032\n        \n        (\n        a\n        ,\n        s\n        )\n        =\n        w\n        (\n        a\n        ,\n        s\n        )\n        +\n        v\n        (\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle w'(a,s)=w(a,s)+v(s')}\n  .Initial conditions of the memory are received as input from the genetic environment. It is a system with only one input (situation), and only one output (action, or behavior).\nSelf-reinforcement (self-learning) was introduced in 1982 along with a neural network capable of self-reinforcement learning, named Crossbar Adaptive Array (CAA).[72][73] The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence states. The system is driven by the interaction between cognition and emotion.[74]Reinforcement Learning in Natural Language Processing[edit]In recent years, reinforcement learning has become a significant concept in natural language processing (NLP), where tasks are often sequential decision-making rather than static classification. Reinforcement learning is where an agent take actions in an environment to maximize the accumulation of rewards. This framework is best fit for many NLP tasks, including dialogue generation, text summarization, and machine translation, where the quality of the output depends on optimizing long-term or human-centered goals rather than the prediction of single correct label.\nEarly application of RL in NLP emerged in dialogue systems, where conversation was determined as a series of actions optimized for fluency and coherence. These early attempts, including policy gradient and sequence-level training techniques, laid a foundation for the broader application of reinforcement learning to other areas of NLP.\nA major breakthrough happened with the introduction of reinforcement learning from human feedback (RLHF), a method in which human feedback ratings are used to train a reward model that guides the RL agent. Unlike traditional rule-based or supervised systems, RLHF allows models to align their behavior with human judgments on complex and subjective tasks. This technique was initially used in the development of InstructGPT, an effective language model trained to follow human instructions and later in ChatGPT which incorporates RLHF for improving output responses and ensuring safety.\nMore recently, researchers have explored the use of offline RL in NLP to improve dialogue systems without the need of live human interaction. These methods optimize for user engagement, coherence, and diversity based on past conversation logs and pre-trained reward models.\nStatistical comparison of reinforcement learning algorithms[edit]Efficient comparison of RL algorithms is essential for research, deployment and monitoring of RL systems. To compare different algorithms on a given environment, an agent can be trained for each algorithm. Since the performance is sensitive to implementation details, all algorithms should be implemented as closely as possible to each other.[75] After the training is finished, the agents can be run on a sample of test episodes, and their scores (returns) can be compared. Since episodes are typically assumed to be i.i.d, standard statistical tools can be used for hypothesis testing, such as T-test and permutation test.[76] This requires to accumulate all the rewards within an episode into a single number\u2014the episodic return. However, this causes a loss of information, as different time-steps are averaged together, possibly with different levels of noise. Whenever the noise level varies across the episode, the statistical power can be improved significantly, by weighting the rewards according to their estimated noise.[77]Challenges and Limitations[edit]Despite significant advancements, reinforcement learning (RL) continues to face several challenges and limitations that hinder its widespread application in real-world scenarios.\nSample Inefficiency[edit]RL algorithms often require a large number of interactions with the environment to learn effective policies, leading to high computational costs and time-intensive to train the agent. For instance, OpenAI's Dota-playing bot utilized thousands of years of simulated gameplay to achieve human-level performance. Techniques like experience replay and curriculum learning have been proposed to deprive sample inefficiency, but these techniques add more complexity and are not always sufficient for real-world applications.\nStability and Convergence Issues[edit]Training RL models, particularly for deep neural network-based models, can be unstable and prone to divergence. A small change in the policy or environment can lead to extreme fluctuations in performance, making it difficult to achieve consistent results. This instability is further enhanced in the case of the continuous or high-dimensional action space, where the learning step becomes more complex and less predictable.\nGeneralization and Transferability[edit]The RL agents trained in specific environments often struggle to generalize their learned policies to new, unseen scenarios. This is the major setback preventing the application of RL to dynamic real-world environments where adaptability is crucial. The challenge is to develop such algorithms that can transfer knowledge across tasks and environments without extensive retraining.\nBias and Reward Function Issues[edit]Designing appropriate reward functions is critical in RL because poorly designed reward functions can lead to unintended behaviors. In addition, RL systems trained on biased data may perpetuate existing biases and lead to discriminatory or unfair outcomes. Both of these issues requires careful consideration of reward structures and data sources to ensure fairness and desired behaviors.\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Active learning (machine learning)Apprenticeship learningError-driven learningModel-free (reinforcement learning)Multi-agent reinforcement learningOptimal controlQ-learningReinforcement learning from human feedbackState\u2013action\u2013reward\u2013state\u2013action (SARSA)Temporal difference learningReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Kaelbling, Leslie P.; Littman, Michael L.; Moore, Andrew W. (1996). \"Reinforcement Learning: A Survey\". Journal of Artificial Intelligence Research. 4: 237\u2013285. arXiv:cs/9605103. doi:10.1613/jair.301. S2CID\u00a01708582. Archived from the original on 2001-11-20.^van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol.\u00a012. pp.\u00a03\u201342. doi:10.1007/978-3-642-27645-3_1. ISBN\u00a0978-3-642-27644-6.^ abLi, Shengbo (2023). Reinforcement Learning for Sequential Decision and Optimal Control (First\u00a0ed.). Springer Verlag, Singapore. pp.\u00a01\u2013460. doi:10.1007/978-981-19-7784-8. ISBN\u00a0978-9-811-97783-1. S2CID\u00a0257928563.{{cite book}}:  CS1 maint: location missing publisher (link)^Russell, Stuart J.; Norvig, Peter (2010). Artificial intelligence: a modern approach (Third\u00a0ed.). Upper Saddle River, New Jersey: Prentice Hall. pp.\u00a0830, 831. ISBN\u00a0978-0-13-604259-4.^Lee, Daeyeol; Seo, Hyojung; Jung, Min Whan (21 July 2012). \"Neural Basis of Reinforcement Learning and Decision Making\". Annual Review of Neuroscience. 35 (1): 287\u2013308. doi:10.1146/annurev-neuro-062111-150512. PMC\u00a03490621. PMID\u00a022462543.^Salazar Duque, Edgar Mauricio; Giraldo, Juan S.; Vergara, Pedro P.; Nguyen, Phuong; Van Der Molen, Anne; Slootweg, Han (2022). \"Community energy storage operation via reinforcement learning with eligibility traces\". Electric Power Systems Research. 212 108515. Bibcode:2022EPSR..21208515S. doi:10.1016/j.epsr.2022.108515. S2CID\u00a0250635151.^Xie, Zhaoming; Hung Yu Ling; Nam Hee Kim; Michiel van de Panne (2020). \"ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills\". arXiv:2005.04323 [cs.GR].^Vergara, Pedro P.; Salazar, Mauricio; Giraldo, Juan S.; Palensky, Peter (2022). \"Optimal dispatch of PV inverters in unbalanced distribution systems using Reinforcement Learning\". International Journal of Electrical Power & Energy Systems. 136 107628. Bibcode:2022IJEPE.13607628V. doi:10.1016/j.ijepes.2021.107628. S2CID\u00a0244099841.^Sutton & Barto 2018, Chapter 11.^Ren, Yangang; Jiang, Jianhua; Zhan, Guojian; Li, Shengbo Eben; Chen, Chen; Li, Keqiang; Duan, Jingliang (2022). \"Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections\". IEEE Transactions on Intelligent Transportation Systems. 23 (12): 24145\u201324156. arXiv:2110.12359. Bibcode:2022ITITr..2324145R. doi:10.1109/TITS.2022.3196167.^Gosavi, Abhijit (2003). Simulation-based Optimization: Parametric Optimization Techniques and Reinforcement. Operations Research/Computer Science Interfaces Series. Springer. ISBN\u00a0978-1-4020-7454-7.^ abBurnetas, Apostolos N.; Katehakis, Michael N. (1997), \"Optimal adaptive policies for Markov Decision Processes\", Mathematics of Operations Research, 22 (1): 222\u2013255, doi:10.1287/moor.22.1.222, JSTOR\u00a03690147^Tokic, Michel; Palm, G\u00fcnther (2011), \"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax\"(PDF), KI 2011: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol.\u00a07006, Springer, pp.\u00a0335\u2013346, ISBN\u00a0978-3-642-24455-1^ abc\"Reinforcement learning: An introduction\"(PDF). Archived from the original(PDF) on 2017-07-12. Retrieved 2017-07-23.^Singh, Satinder P.; Sutton, Richard S. (1996-03-01). \"Reinforcement learning with replacing eligibility traces\". Machine Learning. 22 (1): 123\u2013158. doi:10.1007/BF00114726. ISSN\u00a01573-0565.^Sutton, Richard S. (1984). Temporal Credit Assignment in Reinforcement Learning (PhD thesis). University of Massachusetts, Amherst, MA. Archived from the original on 2017-03-30. Retrieved 2017-03-29.^Sutton & Barto 2018, \u00a76. Temporal-Difference Learning.^Bradtke, Steven J.; Barto, Andrew G. (1996). \"Learning to predict by the method of temporal differences\". Machine Learning. 22: 33\u201357. CiteSeerX\u00a010.1.1.143.857. doi:10.1023/A:1018056104778. S2CID\u00a020327856.^Watkins, Christopher J.C.H. (1989). Learning from Delayed Rewards(PDF) (PhD thesis). King's College, Cambridge, UK.^Matzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022). \"Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities\". Entropy. 24 (8): 1168. Bibcode:2022Entrp..24.1168M. doi:10.3390/e24081168. PMC\u00a09407070. PMID\u00a036010832.^Williams, Ronald J. (1987). \"A class of gradient-estimating algorithms for reinforcement learning in neural networks\". Proceedings of the IEEE First International Conference on Neural Networks. CiteSeerX\u00a010.1.1.129.8871.^Peters, Jan; Vijayakumar, Sethu; Schaal, Stefan (2003). Reinforcement Learning for Humanoid Robotics(PDF). IEEE-RAS International Conference on Humanoid Robots. Archived from the original(PDF) on 2013-05-12. Retrieved 2006-05-08.^Juliani, Arthur (2016-12-17). \"Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)\". Medium. Retrieved 2018-02-22.^Deisenroth, Marc Peter; Neumann, Gerhard; Peters, Jan (2013). A Survey on Policy Search for Robotics(PDF). Foundations and Trends in Robotics. Vol.\u00a02. NOW Publishers. pp.\u00a01\u2013142. doi:10.1561/2300000021. hdl:10044/1/12051.^Sutton, Richard (1990). \"Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming\". Machine Learning: Proceedings of the Seventh International Workshop.^Lin, Long-Ji (1992). \"Self-improving reactive agents based on reinforcement learning, planning and teaching\"(PDF). Machine Learning. Vol.\u00a08. doi:10.1007/BF00992699.^Zou, Lan (2023-01-01), Zou, Lan (ed.), \"Chapter 7 - Meta-reinforcement learning\", Meta-Learning, Academic Press, pp.\u00a0267\u2013297, doi:10.1016/b978-0-323-89931-4.00011-0, ISBN\u00a0978-0-323-89931-4, retrieved 2023-11-08^van Hasselt, Hado; Hessel, Matteo; Aslanides, John (2019). \"When to use parametric models in reinforcement learning?\"(PDF). Advances in Neural Information Processing Systems. Vol.\u00a032.^Grondman, Ivo; Vaandrager, Maarten; Busoniu, Lucian; Babuska, Robert; Schuitema, Erik (2012-06-01). \"Efficient Model Learning Methods for Actor\u2013Critic Control\". IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics. 42 (3): 591\u2013602. Bibcode:2012ITSMC..42..591G. doi:10.1109/TSMCB.2011.2170565. ISSN\u00a01083-4419. PMID\u00a022156998.^\"On the Use of Reinforcement Learning for Testing Game Mechanics: ACM - Computers in Entertainment\". cie.acm.org. Retrieved 2018-11-27.^Li, Xiao; Vasile, Cristian-Ioan; Belta, Calin (2017). \"Reinforcement Learning with Temporal Logic Rewards\". 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). pp.\u00a03834\u20133839. doi:10.1109/IROS.2017.8206234.^Toro Icarte, Rodrigo; Klassen, Toryn Q.; Valenzano, Richard; McIlraith, Sheila A. (2022). \"Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning\". Journal of Artificial Intelligence Research. 73: 173\u2013208. arXiv:2010.03950. doi:10.1613/jair.1.12440.^Riveret, R\u00e9gis; Gao, Yang; Governatori, Guido; Rotolo, Antonino; Pitt, Jeremy; Sartor, Giovanni (2019). \"A probabilistic argumentation framework for reinforcement learning agents\". Autonomous Agents and Multi-Agent Systems. 33 (1\u20132): 216\u2013274. doi:10.1007/s10458-019-09404-2.^Haramati, Dan; Daniel, Tal; Tamar, Aviv (2024). \"Entity-Centric Reinforcement Learning for Object Manipulation from Pixels\". arXiv:2404.01220 [cs.RO].^Thompson, Isaac Symes; Caron, Alberto; Hicks, Chris; Mavroudis, Vasilios (2024-11-07). \"Entity-based Reinforcement Learning for Autonomous Cyber Defence\". Proceedings of the Workshop on Autonomous Cybersecurity (AutonomousCyber '24). ACM. pp.\u00a056\u201367. arXiv:2410.17647. doi:10.1145/3689933.3690835.^Winter, Clemens (2023-04-14). \"Entity-Based Reinforcement Learning\". Clemens Winter's Blog.^Yamagata, Taku; McConville, Ryan; Santos-Rodriguez, Raul (2021-11-16). \"Reinforcement Learning with Feedback from Multiple Humans with Diverse Skills\". arXiv:2111.08596 [cs.LG].^Kulkarni, Tejas D.; Narasimhan, Karthik R.; Saeedi, Ardavan; Tenenbaum, Joshua B. (2016). \"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\". Proceedings of the 30th International Conference on Neural Information Processing Systems. NIPS'16. USA: Curran Associates Inc.: 3682\u20133690. arXiv:1604.06057. Bibcode:2016arXiv160406057K. ISBN\u00a0978-1-5108-3881-9.^\"Reinforcement Learning / Successes of Reinforcement Learning\". umichrl.pbworks.com. Retrieved 2017-08-06.^Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (March 2020). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)(PDF). pp.\u00a01728\u20131733. doi:10.23919/DATE48585.2020.9116294. ISBN\u00a0978-3-9819263-4-7. S2CID\u00a0219858480.^Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Retrieved 2021-06-17.^Williams, Rhiannon (2020-07-21). \"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\". i. Retrieved 2021-06-17.^Kaplan, F.; Oudeyer, P. (2004). \"Maximizing Learning Progress: An Internal Reward System for Development\". In Iida, F.; Pfeifer, R.; Steels, L.; Kuniyoshi, Y. (eds.). Embodied Artificial Intelligence. Lecture Notes in Computer Science. Vol.\u00a03139. Berlin; Heidelberg: Springer. pp.\u00a0259\u2013270. doi:10.1007/978-3-540-27833-7_19. ISBN\u00a0978-3-540-22484-6. S2CID\u00a09781221.^Klyubin, A.; Polani, D.; Nehaniv, C. (2008). \"Keep your options open: an information-based driving principle for sensorimotor systems\". PLOS ONE. 3 (12) e4018. Bibcode:2008PLoSO...3.4018K. doi:10.1371/journal.pone.0004018. PMC\u00a02607028. PMID\u00a019107219.^Barto, A. G. (2013). \"Intrinsic motivation and reinforcement learning\". Intrinsically Motivated Learning in Natural and Artificial Systems(PDF). Berlin; Heidelberg: Springer. pp.\u00a017\u201347.^Dab\u00e9rius, Kevin; Granat, Elvin; Karlsson, Patrik (2020). \"Deep Execution - Value and Policy Based Reinforcement Learning for Trading and Beating Market Benchmarks\". The Journal of Machine Learning in Finance. 1. SSRN\u00a03374766.^George Karimpanal, Thommen; Bouffanais, Roland (2019). \"Self-organizing maps for storage and transfer of knowledge in reinforcement learning\". Adaptive Behavior. 27 (2): 111\u2013126. arXiv:1811.08318. doi:10.1177/1059712318818568. ISSN\u00a01059-7123. S2CID\u00a053774629.^cf. Sutton & Barto 2018, Section 5.4, p. 100^J Duan; Y Guan; S Li (2021). \"Distributional Soft Actor-Critic: Off-policy reinforcement learning for addressing value estimation errors\". IEEE Transactions on Neural Networks and Learning Systems. 33 (11): 6584\u20136598. arXiv:2001.02811. doi:10.1109/TNNLS.2021.3082568. PMID\u00a034101599. S2CID\u00a0211259373.^Y Ren; J Duan; S Li (2020). \"Improving Generalization of Reinforcement Learning with Minimax Distributional Soft Actor-Critic\". 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC). pp.\u00a01\u20136. arXiv:2002.05502. doi:10.1109/ITSC45102.2020.9294300. ISBN\u00a0978-1-7281-4149-7. S2CID\u00a0211096594.^Duan, J; Wang, W; Xiao, L (2025). \"Distributional Soft Actor-Critic with Three Refinements\". IEEE Transactions on Pattern Analysis and Machine Intelligence. PP (5): 3935\u20133946. arXiv:2310.05858. Bibcode:2025ITPAM..47.3935D. doi:10.1109/TPAMI.2025.3537087. PMID\u00a040031258.^Soucek, Branko (6 May 1992). Dynamic, Genetic and Chaotic Programming: The Sixth-Generation Computer Technology Series. John Wiley & Sons, Inc. p.\u00a038. ISBN\u00a00-471-55717-X.^Francois-Lavet, Vincent; et\u00a0al. (2018). \"An Introduction to Deep Reinforcement Learning\". Foundations and Trends in Machine Learning. 11 (3\u20134): 219\u2013354. arXiv:1811.12560. Bibcode:2018arXiv181112560F. doi:10.1561/2200000071. S2CID\u00a054434537.^Mnih, Volodymyr; et\u00a0al. (2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529\u2013533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID\u00a025719670. S2CID\u00a0205242740.^Goodfellow, Ian; Shlens, Jonathan; Szegedy, Christian (2015). \"Explaining and Harnessing Adversarial Examples\". International Conference on Learning Representations. arXiv:1412.6572.^Behzadan, Vahid; Munir, Arslan (2017). \"Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks\". Machine Learning and Data Mining in Pattern Recognition. Lecture Notes in Computer Science. Vol.\u00a010358. pp.\u00a0262\u2013275. arXiv:1701.04143. doi:10.1007/978-3-319-62416-7_19. ISBN\u00a0978-3-319-62415-0. S2CID\u00a01562290.^Huang, Sandy; Papernot, Nicolas; Goodfellow, Ian; Duan, Yan; Abbeel, Pieter (2017-02-07). Adversarial Attacks on Neural Network Policies. OCLC\u00a01106256905.^Korkmaz, Ezgi (2022). \"Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs\". Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22). 36 (7): 7229\u20137238. arXiv:2112.09025. doi:10.1609/aaai.v36i7.20684. S2CID\u00a0245219157.^Berenji, H.R. (1994). \"Fuzzy Q-learning: A new approach for fuzzy dynamic programming\". Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference. Orlando, FL, USA: IEEE. pp.\u00a0486\u2013491. doi:10.1109/FUZZY.1994.343737. ISBN\u00a00-7803-1896-X. S2CID\u00a056694947.^Vincze, David (2017). \"Fuzzy rule interpolation and reinforcement learning\"(PDF). 2017 IEEE 15th International Symposium on Applied Machine Intelligence and Informatics (SAMI). IEEE. pp.\u00a0173\u2013178. doi:10.1109/SAMI.2017.7880298. ISBN\u00a0978-1-5090-5655-2. S2CID\u00a017590120.^Ng, A. Y.; Russell, S. J. (2000). \"Algorithms for Inverse Reinforcement Learning\"(PDF). Proceeding ICML '00 Proceedings of the Seventeenth International Conference on Machine Learning. Morgan Kaufmann Publishers. pp.\u00a0663\u2013670. ISBN\u00a01-55860-707-2.^Ziebart, Brian D.; Maas, Andrew; Bagnell, J. Andrew; Dey, Anind K. (2008-07-13). \"Maximum entropy inverse reinforcement learning\". Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3. AAAI'08. Chicago, Illinois: AAAI Press: 1433\u20131438. ISBN\u00a0978-1-57735-368-3. S2CID\u00a0336219.^Pitombeira-Neto, Anselmo R.; Santos, Helano P.; Coelho da Silva, Ticiana L.; de Macedo, Jos\u00e9 Antonio F. (March 2024). \"Trajectory modeling via random utility inverse reinforcement learning\". Information Sciences. 660 120128. arXiv:2105.12092. doi:10.1016/j.ins.2024.120128. ISSN\u00a00020-0255. S2CID\u00a0235187141.^Hayes C, Radulescu R, Bargiacchi E, et\u00a0al. (2022). \"A practical guide to multi-objective reinforcement learning and planning\". Autonomous Agents and Multi-Agent Systems. 36 26. arXiv:2103.09568. doi:10.1007/s10458-022-09552-y. S2CID\u00a0254235920.,^Tzeng, Gwo-Hshiung; Huang, Jih-Jeng (2011). Multiple Attribute Decision Making: Methods and Applications (1st\u00a0ed.). CRC Press. ISBN\u00a0978-1-4398-6157-8.^Garc\u00eda, Javier; Fern\u00e1ndez, Fernando (1 January 2015). \"A comprehensive survey on safe reinforcement learning\"(PDF). The Journal of Machine Learning Research. 16 (1): 1437\u20131480.^Dabney, Will; Ostrovski, Georg; Silver, David; Munos, Remi (2018-07-03). \"Implicit Quantile Networks for Distributional Reinforcement Learning\". Proceedings of the 35th International Conference on Machine Learning. PMLR: 1096\u20131105. arXiv:1806.06923.^Chow, Yinlam; Tamar, Aviv; Mannor, Shie; Pavone, Marco (2015). \"Risk-Sensitive and Robust Decision-Making: a CVaR Optimization Approach\". Advances in Neural Information Processing Systems. 28. Curran Associates, Inc. arXiv:1506.02188.^\"Train Hard, Fight Easy: Robust Meta Reinforcement Learning\". scholar.google.com. Retrieved 2024-06-21.^Tamar, Aviv; Glassner, Yonatan; Mannor, Shie (2015-02-21). \"Optimizing the CVaR via Sampling\". Proceedings of the AAAI Conference on Artificial Intelligence. 29 (1). arXiv:1404.3862. doi:10.1609/aaai.v29i1.9561. ISSN\u00a02374-3468.^Greenberg, Ido; Chow, Yinlam; Ghavamzadeh, Mohammad; Mannor, Shie (2022-12-06). \"Efficient Risk-Averse Reinforcement Learning\". Advances in Neural Information Processing Systems. 35: 32639\u201332652. arXiv:2205.05138.^Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397\u2013402. ISBN 978-0-444-86488-8^Bozinovski S. (1995) \"Neuro genetic agents and structural theory of self-reinforcement learning systems\". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst [1]^Bozinovski, S. (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255\u2013263^Engstrom, Logan; Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Janoos, Firdaus; Rudolph, Larry; Madry, Aleksander (2019-09-25). \"Implementation Matters in Deep RL: A Case Study on PPO and TRPO\". ICLR.^Colas, C\u00e9dric (2019-03-06). \"A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms\". International Conference on Learning Representations. arXiv:1904.06979.^Greenberg, Ido; Mannor, Shie (2021-07-01). \"Detecting Rewards Deterioration in Episodic Reinforcement Learning\". Proceedings of the 38th International Conference on Machine Learning. PMLR: 3842\u20133853. arXiv:2010.11660.Further reading[edit]Annaswamy, Anuradha M. (3 May 2023). \"Adaptive Control and Intersections with Reinforcement Learning\". Annual Review of Control, Robotics, and Autonomous Systems. 6 (1): 65\u201393. doi:10.1146/annurev-control-062922-090153. ISSN\u00a02573-5144. S2CID\u00a0255702873.Auer, Peter; Jaksch, Thomas; Ortner, Ronald (2010). \"Near-optimal regret bounds for reinforcement learning\". Journal of Machine Learning Research. 11: 1563\u20131600.Bertsekas, Dimitri P. (2023) [2019]. Reinforcement Learning and Optimal Control (1st\u00a0ed.). Athena Scientific. ISBN\u00a0978-1-886-52939-7.Busoniu, Lucian; Babuska, Robert; De Schutter, Bart; Ernst, Damien (2010). Reinforcement Learning and Dynamic Programming using Function Approximators. Taylor & Francis CRC Press. ISBN\u00a0978-1-4398-2108-4.Fran\u00e7ois-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle (2018). \"An Introduction to Deep Reinforcement Learning\". Foundations and Trends in Machine Learning. 11 (3\u20134): 219\u2013354. arXiv:1811.12560. Bibcode:2018arXiv181112560F. doi:10.1561/2200000071. S2CID\u00a054434537.Li, Shengbo Eben (2023). Reinforcement Learning for Sequential Decision and Optimal Control (1st\u00a0ed.). Springer Verlag, Singapore. doi:10.1007/978-981-19-7784-8. ISBN\u00a0978-9-811-97783-1.Powell, Warren (2011). Approximate dynamic programming: solving the curses of dimensionality. Wiley-Interscience. Archived from the original on 2016-07-31. Retrieved 2010-09-08.Sutton, Richard S. (1988). \"Learning to predict by the method of temporal differences\". Machine Learning. 3: 9\u201344. doi:10.1007/BF00115009.Sutton, Richard S.; Barto, Andrew G. (2018) [1998]. Reinforcement Learning: An Introduction (2nd\u00a0ed.). MIT Press. ISBN\u00a0978-0-262-03924-6.Szita, Istvan; Szepesvari, Csaba (2010). \"Model-based Reinforcement Learning with Nearly Tight Exploration Complexity Bounds\"(PDF). ICML 2010. Omnipress. pp.\u00a01031\u20131038. Archived from the original(PDF) on 2010-07-14.External links[edit]Dissecting Reinforcement Learning Series of blog post on reinforcement learning with Python codeA (Long) Peek into Reinforcement Learning.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteArtificial intelligence (AI)HistorytimelineGlossaryCompaniesProjectsConceptsParameterHyperparameterLoss functionsRegressionBias\u2013variance tradeoffDouble descentOverfittingClusteringGradient descentSGDQuasi-Newton methodConjugate gradient methodBackpropagationAttentionConvolutionNormalizationBatchnormActivationSoftmaxSigmoidRectifierGatingWeight initializationRegularizationDatasetsAugmentationPrompt engineeringReinforcement learningQ-learningSARSAImitationPolicy gradientDiffusionLatent diffusion modelAutoregressionAdversaryRAGUncanny valleyRLHFSelf-supervised learningReflectionRecursive self-improvementHallucinationWord embeddingVibe codingSafety (Alignment)ApplicationsMachine learningIn-context learningArtificial neural networkDeep learningLanguage modelLargeNMTReasoningModel Context ProtocolIntelligent agentArtificial human companionHumanity's Last ExamArtificial general intelligence (AGI)ImplementationsAudio\u2013visualAlexNetWaveNetHuman image synthesisHWROCRComputer visionSpeech synthesis15.aiElevenLabsSpeech recognitionWhisperFacial recognitionAlphaFoldText-to-image modelsAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyRecraftStable DiffusionText-to-video modelsDream MachineRunway GenHailuo AIKlingSoraVeoMusic generationRiffusionSuno AIUdioTextWord2vecSeq2seqGloVeBERTT5LlamaChinchilla AIPaLMGPT123JChatGPT44oo1o34.54.1o4-mini5ClaudeGeminiGemini (language model)GemmaGrokLaMDABLOOMDBRXProject DebaterIBM WatsonIBM WatsonxGranitePanGu-\u03a3DeepSeekQwenDecisionalAlphaGoAlphaZeroOpenAI FiveSelf-driving carMuZeroAction selectionAutoGPTRobot controlPeopleAlan TuringWarren Sturgis McCullochWalter PittsJohn von NeumannChristopher D. ManningClaude ShannonShun'ichi AmariKunihiko FukushimaTakeo KanadeMarvin MinskyJohn McCarthyNathaniel RochesterAllen NewellCliff ShawHerbert A. SimonOliver SelfridgeFrank RosenblattBernard WidrowJoseph WeizenbaumSeymour PapertSeppo LinnainmaaPaul WerbosGeoffrey HintonJohn HopfieldJ\u00fcrgen SchmidhuberYann LeCunYoshua BengioLotfi A. ZadehStephen GrossbergAlex GravesJames GoodnightAndrew NgFei-Fei LiAlex KrizhevskyIlya SutskeverOriol VinyalsQuoc V. LeIan GoodfellowDemis HassabisDavid SilverAndrej KarpathyAshish VaswaniNoam ShazeerAidan GomezJohn SchulmanMustafa SuleymanJan LeikeDaniel KokotajloFran\u00e7ois CholletArchitecturesNeural Turing machineDifferentiable neural computerTransformerVision transformer (ViT)Recurrent neural network (RNN)Long short-term memory (LSTM)Gated recurrent unit (GRU)Echo state networkMultilayer perceptron (MLP)Convolutional neural network (CNN)Residual neural network (RNN)Highway networkMambaAutoencoderVariational autoencoder (VAE)Generative adversarial network (GAN)Graph neural network (GNN)CategoryvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.HardwarePrinted circuit boardPeripheralIntegrated circuitVery-large-scale integrationSystem on a chip (SoC)Energy consumption (green computing)Electronic design automationHardware accelerationProcessorSize / FormComputer systems organizationComputer architectureComputational complexityDependabilityEmbedded systemReal-time computingCyber-physical systemFault toleranceWireless sensor networkNetworksNetwork architectureNetwork protocolNetwork componentsNetwork schedulerNetwork performance evaluationNetwork serviceSoftware organizationInterpreterMiddlewareVirtual machineOperating systemSoftware qualitySoftware notations and toolsProgramming paradigmProgramming languageCompilerDomain-specific languageModeling languageSoftware frameworkIntegrated development environmentSoftware configuration managementSoftware librarySoftware repositorySoftware developmentControl variableSoftware development processRequirements analysisSoftware designSoftware constructionSoftware deploymentSoftware engineeringSoftware maintenanceProgramming teamOpen-source modelTheory of computationModel of computationStochasticFormal languageAutomata theoryComputability theoryComputational complexity theoryLogicSemanticsAlgorithmsAlgorithm designAnalysis of algorithmsAlgorithmic efficiencyRandomized algorithmComputational geometryMathematics of computingDiscrete mathematicsProbabilityStatisticsMathematical softwareInformation theoryMathematical analysisNumerical analysisTheoretical computer scienceComputational problemInformation systemsDatabase management systemInformation storage systemsEnterprise information systemSocial information systemsGeographic information systemDecision support systemProcess control systemMultimedia information systemData miningDigital libraryComputing platformDigital marketingWorld Wide WebInformation retrievalSecurityCryptographyFormal methodsSecurity hackerSecurity servicesIntrusion detection systemHardware securityNetwork securityInformation securityApplication securityHuman-centered computingInteraction designAugmented realityVirtual realitySocial computingUbiquitous computingVisualizationAccessibilityHuman\u2013computer interactionMobile computingConcurrencyConcurrent computingParallel computingDistributed computingMultithreadingMultiprocessingArtificial intelligenceNatural language processingKnowledge representation and reasoningComputer visionAutomated planning and schedulingSearch methodologyControl methodPhilosophy of artificial intelligenceDistributed artificial intelligenceMachine learningSupervised learningUnsupervised learningReinforcement learningMulti-task learningCross-validationGraphicsAnimationRenderingPhotograph manipulationGraphics processing unitImage compressionSolid modelingApplied computingQuantum computingE-commerceEnterprise softwareComputational mathematicsComputational physicsComputational chemistryComputational biologyComputational social scienceComputational engineeringDifferentiable computingComputational healthcareDigital artElectronic publishingCyberwarfareElectronic votingVideo gamesWord processingOperations researchEducational technologyDocument managementIn developmentThermodynamic computingCategoryOutlineGlossaries\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Reinforcement_learning&oldid=1319501801\"", "tags": ["en.wikipedia.org", "wiki", "reinforcement", "learning"]}
{"url": "https://en.wikipedia.org/wiki/Robot_Operating_System", "title": null, "text": "Set of software frameworks for robot software development.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}Robot Operating SystemCart pushing simulation in RVIZOriginal authorsWillow GarageStanford Artificial Intelligence LaboratoryOpen RoboticsInitial release2007; 18\u00a0years ago\u00a0(2007)Stable releaseJazzy Jalisco [1]\n   / 27\u00a0May 2024; 16 months ago\u00a0(2024-05-27)Preview releaseKilted Kaiju (ROS 2)[2]\n   Repository.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}github.com/ros2Written inC++, Python, and LispOperating systemLinux, macOS (experimental), Windows 10 (experimental)TypeRobotics suite, OS, libraryLicenseApache 2.0Websiteros.org\u00a0As ofFebruary 2025 \nRobot Operating System (ROS or ros) is an open-sourcerobotics middleware suite. Although ROS is not an operating system (OS) but a set of software frameworks for robot software development, it provides services designed for a heterogeneous computer cluster such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management. Running sets of ROS-based processes are represented in a graph architecture where processing takes place in nodes that may receive, post, and multiplex sensor data, control, state, planning, actuator, and other messages. Despite the importance of reactivity and low latency in robot control, ROS is not a real-time operating system (RTOS). However, it is possible to integrate ROS with real-time computing code.[3] The lack of support for real-time systems has been addressed in the creation of ROS 2,[4][5][6] a major revision of the ROS API which will take advantage of modern libraries and technologies for core ROS functions and add support for real-time code and embedded system hardware.\nSoftware in the ROS Ecosystem[7] can be separated into three groups:\nlanguage- and platform-independent tools used for building and distributing ROS-based software;ROS client library implementations such as roscpp,[8] rospy,[9] and roslisp;[10]packages containing application-related code that uses one or more ROS client libraries.[11]Both the language-independent tools and the main client libraries (C++, Python, and Lisp) are released under the terms of the BSD license, and as such are open-source software and free for both commercial and research use. The majority of other packages are licensed under a variety of open-source licenses. These other packages implement commonly used functionality and applications such as hardware drivers, robot models, datatypes, planning, perception, simultaneous localization and mapping (SLAM), simulation tools, and other algorithms.\nThe main ROS client libraries are geared toward a Unix-like system, mostly because of their dependence on large sets of open-source software dependencies. For these client libraries, Ubuntu Linux is listed as \"Supported\" while other variants such as Fedora Linux, macOS, and Microsoft Windows are designated \"experimental\" and are supported by the community.[12] The native Java ROS client library, rosjava,[13] however, does not share these limitations and has enabled ROS-based software to be written for the Android OS.[14] rosjava has also enabled ROS to be integrated into an officially supported MATLAB toolbox which can be used on Linux, macOS, and Microsoft Windows.[15] A JavaScript client library, roslibjs[16] has also been developed which enables integration of software into a ROS system via any standards-compliant web browser.\nHistory[edit]Early days at Stanford (2007 and earlier)[edit]Sometime before 2007, the first pieces of what eventually would become ROS began coalescing at Stanford University.[17][18] Eric Berger and Keenan Wyrobek, PhD students working in Kenneth Salisbury's[19] The Robotics laboratory at Stanford, was leading the Personal Robotics Program.[20] While working on robots to do manipulation tasks in human environments, the two students noticed that many of their colleagues were held back by the diverse nature of robotics: an excellent software developer might not have the hardware knowledge required, someone developing state of the art path planning might not know how to do the computer vision required. In an attempt to remedy this situation, the two students set out to make a baseline system that would provide a starting place for others in academia to build upon. In the words of Eric Berger, \"something that didn\u2019t suck, in all of those different dimensions\".[17]In their first steps towards this unifying system, the two built the PR1 as a hardware prototype and began to work on software from it, borrowing the best practices from other early open-source robotic software frameworks, particularly switchyard, a system that Morgan Quigley, another Stanford PhD student, had been working on in support of the STanford Artificial Intelligence Robot (STAIR)[21][22][23][24] by the Stanford Artificial Intelligence Laboratory. Early funding of US$50,000 was provided by Joanna Hoffman and Alain Rossmann, which supported the development of the PR1. While seeking funding for further development,[25] Eric Berger and Keenan Wyrobek met Scott Hassan, the founder of Willow Garage, a technology incubator which was working on an autonomous SUV and a solar autonomous boat. Hassan shared Berger and Wyrobek's vision of a \"Linux for robotics\", and invited them to come and work at Willow Garage. Willow Garage was started in January 2007, and the first commit of ROS code was made to SourceForge on 7 November 2007.[26]Willow Garage (2007\u20132013)[edit]Willow Garage began developing the PR2 robot as a follow-up to the PR1, and ROS as the software to run it. Groups from more than twenty institutions made contributions to ROS, both the core software and the growing number of packages that worked with ROS to form a greater software ecosystem.[27][28] That people outside of Willow were contributing to ROS (especially from Stanford's STAIR project) meant that ROS was a multi-robot platform from the start. While Willow Garage had originally had other projects in progress, they were scrapped in favor of the Personal Robotics Program: which focused on producing the PR2 as a research platform for academia and ROS as the open-source robotics stack that would underlie both academic research and tech startups, much like the LAMP stack did for web-based startups.\nIn December 2008, Willow Garage met the first of its three internal milestones: continuous navigation for the PR2 over two days and a distance of pi kilometers.[29] Soon after, an early version of ROS (0.4 Mango Tango)[30] was released, followed by the first RVIZ documentation and the first paper on ROS.[28] In early summer, the second internal milestone: having the PR2 navigate the office, open doors, and plug itself it in, was reached.[31] This was followed in August by the initiation of the ROS.org website.[32] Early tutorials on ROS were posted in December,[33] preparing for the release of ROS 1.0, in January 2010.[34] This was Milestone 3: producing tons of documentation and tutorials for the enormous abilities that Willow Garage's engineers had developed over the preceding 3 years.\nFollowing this, Willow Garage achieved one of its longest-held goals: giving away 10 PR2 robots to worthy academic institutions. This had long been a goal of the founders, as they felt that the PR2 could kick-start robotics research around the world. They ended up awarding eleven PR2s to different institutions, including University of Freiburg (Germany), Robert Bosch GmbH, Georgia Institute of Technology, KU Leuven (Belgium), Massachusetts Institute of Technology (MIT), Stanford University, Technical University of Munich (Germany), University of California, Berkeley, University of Pennsylvania, University of Southern California (USC), and University of Tokyo (Japan).[35] This, combined with Willow Garage's highly successful internship program[36] (run from 2008 to 2010 by Melonee Wise), helped to spread the word about ROS throughout the robotics world. The first official ROS distribution release: ROS Box Turtle, was released on 2 March 2010, marking the first time that ROS was officially distributed with a set of versioned packages for public use. These developments led to the first drone running ROS,[37] the first autonomous car running ROS,[38] and the adaption of ROS for Lego Mindstorms.[39] With the PR2 Beta program well underway, the PR2 robot was officially released for commercial purchase on 9 September 2010.[40]An image of Robot Operating System (ROS) running in Antarctica2011 was a banner year for ROS with the launch of ROS Answers, a Q/A forum for ROS users, on 15 February;[41] the introduction of the highly successful TurtleBot robot kit on 18 April;[42] and the total number of ROS repositories passing 100 on 5 May.[43] Willow Garage began 2012 by creating the Open Source Robotics Foundation (OSRF)[44] in April. The OSRF was immediately awarded a software contract by the Defense Advanced Research Projects Agency (DARPA).[45] Later that year, the first ROSCon was held in St. Paul, Minnesota,[46] the first book on ROS, ROS By Example,[47] was published, and Baxter, the first commercial robot to run ROS, was announced by Rethink Robotics.[48] Soon after passing its fifth anniversary in November, ROS began running on every continent on 3 December 2012.[49]In February 2013, the OSRF became the primary software maintainers for ROS,[50] foreshadowing the announcement in August that Willow Garage would be absorbed by its founders, Suitable Technologies.[51] At this point, ROS had released seven major versions (up to ROS Groovy),[52] and had users all over the globe. This chapter of ROS development would be finalized when Clearpath Robotics took over support responsibilities for PR2 in early 2014.[53]OSRF and Open Robotics (2013\u2013present)[edit]In the years since OSRF took over the primary development of ROS, a new version has been released every year,[52] while interest in ROS continues to grow. ROSCons have occurred every year since 2012, co-located with either ICRA or IROS, two flagship robotics conferences. Meetups of ROS developers have been organized in a variety of countries,[54][55][56] a number of ROS books have been published,[57] and many educational programs initiated.[58][59] On 1 September 2014, NASA announced the first robot to run ROS in space: Robotnaut 2, on the International Space Station.[60] In 2017, the OSRF changed its name to Open Robotics. Tech giants Amazon and Microsoft began to take an interest in ROS during this time, with Microsoft porting core ROS to Windows in September 2018,[61] followed by Amazon Web Services releasing RoboMaker in November 2018.[62]Perhaps the most important development of the OSRF/Open Robotics years thus far (not to discount the explosion of robot platforms that began to support ROS or the enormous improvements in each ROS version) was the proposal of ROS 2, a significant API change to ROS which is intended to support real-time programming, a wider variety of computing environments, and more modern technology.[63] ROS 2 was announced at ROSCon 2014,[64] the first commits to the ros2 repository were made in February 2015, followed by alpha releases in August 2015.[65] The first distribution release of ROS 2, Ardent Apalone, was released on 8 December 2017,[65] ushering in a new era of next-generation ROS development.\nDesign[edit]Philosophy[edit]An image depicting the ROS equation: Plumbing + Tools + Capabilities + Ecosystem = ROS!ROS was designed to be open source, intending that users would be able to choose the configuration of tools and libraries that interacted with the core of ROS so that users could shift their software stacks to fit their robot and application area. As such, there is very little which is core to ROS, beyond the general structure within which programs must exist and communicate. In one sense, ROS is the underlying plumbing behind nodes and message passing. However, in reality, ROS is not only plumbing, but a rich and mature set of tools, a wide-ranging set of robot-agnostic abilities provided by packages, and a greater ecosystem of additions to ROS.\nComputation graph model[edit]ROS processes are represented as nodes in a graph structure, connected by edges called topics.[66] ROS nodes can pass messages to one another through topics, make service calls to other nodes, provide a service for other nodes, or set or retrieve shared data from a communal database called the parameter server. A process called the ROS1 Master[66] makes all of this possible by registering nodes to themselves, setting up node-to-node communication for topics, and controlling parameter server updates. Messages and service calls do not pass through the master, rather the master sets up peer-to-peer communication between all node processes after they register themselves with the master. This decentralized architecture lends itself well to robots, which often consist of a subset of networked computer hardware, and may communicate with off-board computers for heavy computing or commands.\nNodes[edit]A node represents one process running the ROS graph. Every node has a name, which registers with the ROS1 master before it can take any other actions. Multiple nodes with different names can exist under different namespaces, or a node can be defined as anonymous, in which case it will randomly generate an additional identifier to add to its given name. Nodes are at the center of ROS programming, as most ROS client code is in the form of a ROS node which takes actions based on information received from other nodes, sends information to other nodes, or sends and receives requests for actions to and from other nodes.\nTopics[edit]Topics are named buses over which nodes send and receive messages.[67] Topic names must be unique within their namespace as well. To send messages to a topic, a node must publish to said topic, while to receive messages it must subscribe. The publish/subscribe model is anonymous: no node knows which nodes are sending or receiving on a topic, only that it is sending/receiving on that topic. The types of messages passed on a topic vary widely and can be user-defined. The content of these messages can be sensor data, motor control commands, state information, actuator commands, or anything else.\nServices[edit]A node may also advertise services.[68] A service represents an action that a node can take which will have a single result. As such, services are often used for actions that have a defined start and end, such as capturing a one-frame image, rather than processing velocity commands to a wheel motor or odometer data from a wheel encoder. Nodes advertise services and call services from one another.\nParameter server[edit]The parameter server[68] is a database shared between nodes which allows for communal access to static or semi-static information. Data that does not change frequently and as such will be infrequently accessed, such as the distance between two fixed points in the environment, or the weight of the robot, are good candidates for storage in the parameter server.\nTools[edit]ROS's core functionality is augmented by a variety of tools that allow developers to visualize and record data, easily navigate the ROS package structures, and create scripts automating complex configuration and setup processes. The addition of these tools greatly increases the abilities of systems using ROS by simplifying and providing solutions to several common robotics development problems. These tools are provided in packages like any other algorithm, but rather than providing implementations of hardware drivers or algorithms for various robotic tasks, these packages provide task and robot-agnostic tools that come with the core of most modern ROS installations.\nrviz[edit]rviz[69] (Robot Visualization tool) is a three-dimensional visualizer used to visualize robots, the environments they work in, and sensor data. It is a highly configurable tool, with many different types of visualizations and plugins. Unified Robot Description Format (URDF) is an XML file format for robot model description.\nrosbag[edit]rosbag[70] is a command line tool used to record and playback ROS message data. rosbag uses a file format called bags,[71] which log ROS messages by listening to topics and recording messages as they come in. Playing messages back from a bag is largely the same as having the original nodes that produced the data in the ROS computation graph, making bags a useful tool for recording data to be used in later development. While rosbag is a command line only tool, rqt_bag[72] provides a GUI interface to rosbag.\ncatkin[edit]catkin[73] is the ROS1 build system, having replaced rosbuild[74] as of ROS Groovy. catkin is based on CMake and is similarly cross-platform, open-source, and language-independent. As of ROS2 catkin is no longer in use, but still maintained for legacy support.[75]rosbash[edit]The rosbash[76] package provides a suite of tools which augment the functionality of the bash shell. These tools include rosls, roscd, and roscp, which replicate the functionalities of ls, cd, and cp respectively. The ROS versions of these tools allow users to use ros package names in place of the file path where the package is located. The package also adds tab-completion to most ROS utilities and includes rosed, which edits a given file with the chosen default text editor, as well rosrun, which runs executables in ROS packages. rosbash supports the same functionalities for zsh and tcsh, to a lesser extent.\nroslaunch[edit]roslaunch[77] is a tool used to launch multiple ROS nodes both locally and remotely, as well as setting parameters on the ROS parameter server. roslaunch configuration files, which are written using XML can easily automate a complex startup and configuration process into a single command. roslaunch scripts can include other roslaunch scripts, launch nodes on specific machines, and even restart processes that die during execution.\nPackages of note[edit]ROS contains many open-source implementations of common robotics functionality and algorithms. These open-source implementations are organized into packages. Many packages are included as part of ROS distributions, while others may be developed by individuals and distributed through code-sharing sites such as github. Some packages of note include:\nSystems and tools[edit]actionlib[78] provides a standardized interface for interfacing with preemptable tasks.nodelet[79] provides a way to run multiple algorithms in a single process.rosbridge[80] provides a JSON API to ROS functionalities for non-ROS programs.Mapping and localization[edit]slam toolbox[81] provides full 2D SLAM and localization system.gmapping[82] provides a wrapper for OpenSlam'sGmapping algorithm for simultaneous localization and mapping.cartographer[83] provides real time 2D and 3D SLAM algorithms developed at Google.amcl[84] provides an implementation of adaptive Monte-Carlo localization.Navigation[edit]navigation[85] provides the capability of navigating a mobile robot in a planar environment.Manipulation[edit]MoveIt![86] provides motion planning capabilities for robot manipulators. Its default planning library is the Open Motion Planning Library (OMPL).[87]Perception[edit]vision_opencv[88] is a meta-package which provides packages for integrating ROS with OpenCV.Coordinate frame representation[edit]tf[89] provided a system for representing, tracking and transforming coordinate frames until ROS Hydro, when it was deprecated in favor of tf2.tf2[90] is the second generation of the tf library, and provides the same abilities for ROS versions after Hydro.Simulation[edit]gazebo_ros_pkgs[91] is a meta-package which provides packages for integrating ROS with the Gazebo simulator.stage[92] provides an interface for the 2D Stage simulator.Versions and releases[edit]ROS releases may be incompatible with other releases and are often referred to by code name rather than version number. ROS 2 currently releases a version every year in May, following the release of Ubuntu LTS versions.[93][94] These releases are alternating supported for 5 years (even years/LTS Ubuntu version release) and 1.5 years (uneven years/no LTS Ubuntu version release). ROS 1 does not see any new version. Aside from this, there has been the ROS-Industrial or ROS-I derivate project since at least 2012.\nROS 2[edit]ROS 2 Distribution Releases[65][95]Distribution\nRelease date\nPoster\nEOL date\nSupport duration\nRolling Ridley[96][97](rolling release with latest features)\nprogressing sinceJune 2020\nN/A\nN/A\nLyrical Luth[98]May 2026\nN/A\nN/A\nN/A\nKilted Kaiju\n23 May 2025\nLatest version:November 2026.mw-parser-output .version-legend{display:flex;flex-wrap:wrap;column-gap:12px}.mw-parser-output .version-legend-vertical{display:flex;flex-wrap:wrap;column-gap:4px;flex-direction:column}.mw-parser-output .version-legend .legend-item,.mw-parser-output .version-legend-vertical .legend-item{page-break-inside:avoid;break-inside:avoid-column;gap:4px}.mw-parser-output .version-legend .legend-item .swatch,.mw-parser-output .version-legend-vertical .legend-item .swatch{display:inline-block;width:1.25em;height:1.25em;border:1px solid #aaa;margin-top:1px}.mw-parser-output .swatch-unsupported{background-color:#fdb3ab}.mw-parser-output .swatch-maintained{background-color:#f8eaba}.mw-parser-output .swatch-latest{background-color:#d4f4b4}.mw-parser-output .swatch-preview{background-color:#c1e6f5}.mw-parser-output .swatch-future{background-color:#f2e2fc}@media screen{html.skin-theme-clientpref-night .mw-parser-output .version-legend .legend-item .swatch,html.skin-theme-clientpref-night .mw-parser-output .version-legend-vertical .legend-item .swatch{border-color:#72777d}html.skin-theme-clientpref-night .mw-parser-output .swatch-unsupported{background-color:#421511}html.skin-theme-clientpref-night .mw-parser-output .swatch-maintained{background-color:#433500}html.skin-theme-clientpref-night .mw-parser-output .swatch-latest{background-color:#334423}html.skin-theme-clientpref-night .mw-parser-output .swatch-preview{background-color:#154467}html.skin-theme-clientpref-night .mw-parser-output .swatch-future{background-color:#3C2e69}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .version-legend .legend-item .swatch,html.skin-theme-clientpref-os .mw-parser-output .version-legend-vertical .legend-item .swatch{border-color:#72777d}html.skin-theme-clientpref-os .mw-parser-output .swatch-unsupported{background-color:#421511}html.skin-theme-clientpref-os .mw-parser-output .swatch-maintained{background-color:#433500}html.skin-theme-clientpref-os .mw-parser-output .swatch-latest{background-color:#334423}html.skin-theme-clientpref-os .mw-parser-output .swatch-preview{background-color:#154467}html.skin-theme-clientpref-os .mw-parser-output .swatch-future{background-color:#3C2e69}}1.5 years\nJazzy Jalisco\n23 May 2024[99]Supported: May 20295 years\nIron Irwini\n23 May 2023[100]Unsupported: November 20241.5 years\nHumble Hawksbill\n23 May 2022[101]Supported: May 20275 years\nGalactic Geochelone\n23 May 2021[102]Unsupported: December 20221.5 years\nFoxy Fitzroy\n5 June 2020[103]Unsupported: June 20233 years\nEloquent Elusor\n22 November 2019\nUnsupported: November 20201 year\nDashing Diademata\n31 May 2019\nUnsupported: May 20212 years\nCrystal Clemmys\n14 December 2018\nUnsupported: December 20191 year\nBouncy Bolson\n2 July 2018\nUnsupported: July 20191 year\nArdent Apalone\n8 December 2017\nUnsupported: December 20181 year\nbeta3\n13 September 2017\nN/A\nUnsupported: December 20174 months\nbeta2\n5 July 2017\nN/A\nUnsupported: September 20172 months\nbeta1\n19 December 2016\nN/A\nUnsupported: July 20177 months\n(ROS 2 real-time proposal)\n7 January 2016[104]N/A\nN/A\nN/A\nalpha1 (Anchor) -alpha8 (Hook-and-Loop)[105]31 August 2015 -5 October 2016[106]N/A\nUnsupported: December 2016total: 16 months\n(\"Why ROS 2?\")\n20 July 2015[107]N/A\nN/A\nN/A\n(batch CI jobs for ROS 2and http://design.ros2.org)\nreferenced in Q&A6 May 2015[108]N/A\nN/A\nN/A\n(first commits toROS 2 repository)\nFebruary 2015\nN/A\nN/A\nN/A\nROSCon 2014:[109][110]\"Next-generation ROS: Building on DDS\",\"ROS 2.0: Developer preview\"\n12 September 2014\nN/A\nN/A\nN/A\nLegend:UnsupportedSupportedLatest versionPreview versionFuture versionROS 1[edit]ROS 1 Distribution Releases[52]Distribution\nRelease date\nPoster\nEOL date\nSupport duration\nNoetic Ninjemys(last ROS 1 release)\n23 May 2020\nUnsupported: May 20255 years\nMelodic Morenia\n23 May 2018\nUnsupported: 2023-05-305 years\nLunar Loggerhead\n23 May 2017\nUnsupported: 2019-05-302 years\nKinetic Kame\n23 May 2016\nUnsupported: 2021-05-305 years\nJade Turtle\n23 May 2015\nUnsupported: 2017-05-302 years\nIndigo Igloo\n22 July 2014\nUnsupported: 2019-04-305 years\nHydro Medusa\n4 September 2013\nUnsupported: 2014-05-310.5 years\nGroovy Galapagos\n31 December 2012\nUnsupported: 2014-07-312 years\nFuerte Turtle\n23 April 2012\nUnsupported: --\u2014\nElectric Emys\n30 August 2011\nUnsupported: --\u2014\nDiamondback\n2 March 2011\nUnsupported: --\u2014\nC Turtle\n2 August 2010\nUnsupported: --\u2014\nBox Turtle\n2 March 2010\nUnsupported: --\u2014\n(Initial Release)\n2007\nn/a\nUnsupported: --\u2014\nLegend:UnsupportedSupportedLatest versionPreview versionFuture versionROS-Industrial[edit]ROS-Industrial[111] is an open-source project (BSD (legacy)/Apache 2.0 (preferred) license) that extends the advanced abilities of ROS to manufacturing automation and robotics. In the industrial environment, there are two different approaches to programming a robot: either through an external proprietary controller, typically implemented using ROS, or via the respective native programming language of the robot. ROS can therefore be seen as the software-based approach to programming industrial robots instead of the classic robot controller-based approach.\nThe ROS-Industrial repository includes interfaces for common industrial manipulators, grippers, sensors, and device networks. It also provides software libraries for automatic 2D/3D sensor calibration, process path/motion planning, applications like Scan-N-Plan, developer tools like the Qt Creator ROS Plugin, and training curricula that are specific to the needs of manufacturers. ROS-I is supported by an international Consortium of industry and research members. The project began as a collaborative endeavor between Yaskawa Motoman Robotics, Southwest Research Institute, and Willow Garage to support the use of ROS for manufacturing automation, with the GitHub repository being founded in January 2012 by Shaun Edwards (SwRI). Currently, the Consortium is divided into three groups; the ROS-Industrial Consortium Americas (led by SwRI and located in San Antonio, Texas), the ROS-Industrial Consortium Europe (led by Fraunhofer IPA and located in Stuttgart, Germany), and the ROS-Industrial Consortium Asia Pacific (led by Advanced Remanufacturing and Technology Centre (ARTC) and Nanyang Technological University (NTU) and located in Singapore).\nThe Consortia supports the global ROS-Industrial community by conducting ROS-I training, providing technical support and setting the future roadmap for ROS-I, as well as conducting pre-competitive joint industry projects to develop new ROS-I abilities.[112]Space ROS[edit]In November 2020, NASA announced Blue Origin had been selected through the Space Technology Mission Directorate\u2019s Announcement of Collaboration Opportunity (ACO) to co-develop Space Robot Operating System (Space ROS) together with three NASA centers.[113]  The purpose of Space ROS is to provide a reusable and modular software framework for robotic and autonomous space systems predicated on ROS 2 that is compliant to aerospace mission and safety assurance requirements (such as NPR 7150.2 and DO-178C). The project was formulated and led by Will Chambers,[114] Blue Origin's principal technologist of robotics at the time. In 2021, Blue Origin subcontracted software development workload to Open Robotics who remained on the team until the program ended in 2022. Space ROS is currently an open community project.[115][116]PickNik Robotics and Open Source Robotics Foundation currently lead the Space ROS effort.[117]ROS-compatible robots and hardware[edit]Robots[edit]ABB, Adept, Fanuc, Motoman, and Universal Robots are supported by ROS-Industrial.[118]Baxter[119] at Rethink Robotics, Inc.CK-9: robotics development kit by Centauri Robotics, supports ROS.[120]GoPiGo3: Raspberry Pi-based educational robot, supports ROS.[121]HERB[122] developed at Carnegie Mellon University in Intel's personal robotics programHusky A200: robot developed (and integrated into ROS) by Clearpath Robotics[123]Nao[124] humanoid: University of Freiburg's Humanoid Robots Lab[125] developed a ROS integration for the Nao humanoid based on an initial port by Brown University[126][127]PR1: personal robot developed in Ken Salisbury's lab at Stanford[128]PR2: personal robot being developed at Willow Garage[129]Raven II Surgical Robotic Research Platform[130][131]ROSbot: autonomous robot platform by Husarion[132]Shadow Robot Hand:[133] a fully dexterous humanoid hand.STAIR I and II:[134] robots developed in Andrew Ng's lab at StanfordStretch: an integrated mobile manipulator by Hello Robot targeting assistive applications.[135][136]SummitXL:[137] mobile robot developed by Robotnik, an engineering company specialized in mobile robots, robotic arms, and industrial solutions with ROS architecture.UBR1:[138][139] developed by Unbounded Robotics, a spin-off of Willow Garage.Webots: robot simulator integrating a complete ROS programming interface.[140]SBCs and hardware[edit]BeagleBoard: the robotics lab of the Katholieke Universiteit Leuven, Belgium[141] has ported ROS to the Beagleboard.Raspberry Pi: image of Ubuntu Mate with ROS[142] by Ubiquity Robotics; installation guide for Raspbian;[143] Installation guide for ROS2 to Raspberry Pi.[144]Sitara ARM Processors have support for the ROS package as part of the official Linux SDK.[145]See also[edit].mw-parser-output .portalbox{padding:0;margin:0.5em 0;display:table;box-sizing:border-box;max-width:175px;list-style:none}.mw-parser-output .portalborder{border:1px solid var(--border-color-base,#a2a9b1);padding:0.1em;background:var(--background-color-neutral-subtle,#f8f9fa)}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;height:1.9em;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}Free and open-source software portalOpen-source hardwareOpen-source softwareRobotics middlewareList of free and open-source software packagesReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"ROS 2 Jazzy Jalisco\". ROS.org. Open Robotics. Retrieved 25 February 2025.^\"ROS 2 Kilted Kaiju\". ROS.org. Open Robotics. May 2025. Retrieved 25 February 2025.^\"ROS/Introduction \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 30 July 2021.^Kay, Jackie (January 2016). \"Proposal for Implementation of Real-time Systems in ROS 2\". ROS.org. Open Robotics. Retrieved 23 January 2023.^Kay, Jackie (January 2016). \"Realtime Design Guidelines For ROS 2\". ROS.org. Open Robotics. Retrieved 23 January 2023.^\"ROS 2 For Realtime Applications\". ROS.org. Open Robotics. 17 October 2018. Retrieved 22 November 2018.^\"Browsing packages for melodic\". ROS.org. Open Robotics. Archived from the original on 24 September 2015. Retrieved 21 February 2016.^\"Package Summary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"Package SUmmary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"Package Summary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"client libraries\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS/Installation \u2013 ROS Wiki\". ROS.org. Open Robotics. 29 September 2013. Retrieved 12 July 2014.^\"rosjava \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"android \u2013 ROS Wiki\". ROS.org. Open Robotics. 12 April 2014. Retrieved 12 July 2014.^\"Robot Operating System (ROS) Support from MATLAB \u2013 Hardware Support\". Mathworks.com. Retrieved 12 July 2014.^\"roslibjs \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^ abGuizzo, Evan Ackerman and Erico (7 November 2017). \"Wizards of ROS: Willow Garage and the Making of the Robot Operating System\". IEEE Spectrum: Technology, Engineering, and Science News. Retrieved 29 April 2019.^Wyrobek, Keenan (31 October 2017). \"The Origin Story of ROS, the Linux of Robotics\". IEEE Spectrum: Technology, Engineering, and Science News. Retrieved 29 April 2019.^\"J. Kenneth Salisbury, Ph.D. | Salisbury Robotics Lab\". Retrieved 29 April 2019.^\"Stanford Personal Robotics Program\". personalrobotics.stanford.edu. Retrieved 29 April 2019.^\"Stanford's Robot Makers\". 16 January 2019.^Ng, Andrew; Gould, Stephen; Quigley, Morgan; Saxena, Ashutosh; Berger, Eric (2008). \"STAIR: The STanford Artificial Intelligence Robot project\". Snowbird Workshop.^\"STAIR\". stair.Stanford.edu. Retrieved 12 December 2017.^Quigley, Morgan; Berger, Eric; Ng, Andrew Y. (2007), STAIR: Hardware and Software Architecture(PDF), AAAI 2007 Robotics Workshop^Keenan Wyrobek (3 July 2017). \"Personal Robotics Program Fund Fundraising Deck from 2006\".^\"Repository: code\". Sourceforge.net. Retrieved 12 December 2017.^\"Repositories\". ROS.org. Retrieved 7 June 2011.^ abQuigley, Morgan; Gerkey, Brian; Conley, Ken; Faust, Josh; Foote, Tully; Leibs, Jeremy; Berger, Eric; Wheeler, Rob; Ng, Andrew. \"ROS: an open-source Robot Operating System\"(PDF). Retrieved 3 April 2010.^WillowGaragevideo (19 December 2008), Milestone 1, retrieved 29 April 2019^\"ROS 0.4 Release \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 29 April 2019.^WillowGaragevideo (2 July 2009), Milestone 2 Explained, retrieved 29 April 2019^\"Welcome to ros.org \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS Tutorials and Turtles \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS 1.0 \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"The Results Are In: PR2 Beta Program Recipients!\". Willow Garage. Archived from the original on 13 July 2018. Retrieved 29 April 2019.^\"Interns and Visiting Scholars\". Willow Garage. Retrieved 29 April 2019.^\"Robots Using ROS: Penn Quadrotors \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Robots Using ROS: Marvin autonomous car (Austin Robot Technology/UT Austin) \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Robots Using ROS: Lego NXT \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"PR2 Robots Available for Purchase\".^\"Announcing ROS Answers \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS on the Move: TurtleBots available for preorder\". Willow Garage. Retrieved 12 December 2017.^\"100 Repositories \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Willow Garage Spins Out OSRF\". Archived from the original on 6 November 2017. Retrieved 13 October 2017.^\"DARPA Awards Simulation Software Contract to Open Source Robotics Foundation\".^\"Thanks for a great ROSCon 2012! \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"New Book: ROS by Example \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"Rethink ROS \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"ROS: Five Years \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"Osrf \u2013 Ros @ Osrf\". Osrfoundation.org. 11 February 2013. Retrieved 12 July 2014.^\"employees join Suitable Technologies\". Willow Garage. Archived from the original on 8 October 2017. Retrieved 12 July 2014.^ abc\"Distributions \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"Clearpath Welcomes PR2 to the Family\". 15 January 2014.^\"Notes from the first Korean ROS Users Meetup \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"First Danish ROS Meetup\".^\"First Ukrainian ROS Meetup\".^\"Programming Robots with ROS: A Practical Introduction to the Robot Operating System\". OReilly.com. Retrieved 12 December 2017.^\"Report from first ROS Summer School in China \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"ROS Robot Ignite Academy\".^\"ROS running on ISS \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Summary\". ros-win.visualstudio.com. Retrieved 29 April 2019.^\"Announcing AWS RoboMaker\". Amazon Web Services, Inc. Retrieved 29 April 2019.^\"Why ROS 2?\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS 2 Overview\". ROS.org. Open Robotics. Retrieved 21 September 2021.^ abc\"ROS 2 Distributions\". ROS.org. Open Robotics. Retrieved 21 September 2021.^ ab\"ROS/Tutorials/UnderstandingNodes \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS/Tutorials/UnderstandingTopics \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^ ab\"ROS/Tutorials/UnderstandingServicesParams \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rviz \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"rosbag \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"Bags \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"rqt_bag \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"catkin \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rosbuild \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"Migrating a C++ Package Example \u2014 ROS 2 Documentation: Humble documentation\". docs.ros.org. Retrieved 7 October 2025.^\"rosbash \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"roslaunch \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"actionlib \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"nodelet \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rosbridge_suite \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"slam_toolbox \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 11 February 2020.^\"gmapping \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"cartographer \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"amcl \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"navigation \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"MoveIt Motion Planning Framework\". ROS MoveIt!.^\"MoveIt Documentation: Rolling\".^\"vision_opencv \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"tf \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"tf2 \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"gazebo_ros_pkgs \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"stage \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS Release Schedule Changes\". 9 May 2018.^\"REP 2000 -- ROS 2 Releases and Target Platforms (ROS.org)\". www.ros.org. Retrieved 25 February 2025.^\"REP 2000 \u2013 ROS 2 Releases and Target Platforms\". ROS.org. Open Robotics. Retrieved 20 February 2021.^\"ROS 2 Rolling Ridley (codename 'rolling'; June 2020) \u2013 ROS 2 Documentation: Foxy documentation\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"ROS 2 rolling distribution name brainstorming\". ROS.org. Open Robotics. 15 June 2020. Retrieved 30 July 2021.^\":kilted: ROS 2 Kilted Kaiju Release!\". Open Robotics Discourse. 23 May 2025. Retrieved 8 October 2025.^\"ROS 2 Jazzy Jalisco Released!\". 23 May 2024.^\"ROS 2 Iron Irwini Released!\". 23 May 2023.^\"ROS 2 Humble Hawksbill Released!\". 23 May 2022.^\"ROS Galactic Geochelone Released\". 23 May 2021. Retrieved 10 July 2021.^\"ROS Foxy Fitzroy Released\". 5 June 2020. Retrieved 24 June 2020.^\"ROS 2 design\". GitHub. 29 January 2022.^\"ROS 2 alpha releases (Aug 2015 \u2013 Oct 2016) \u2013 ROS 2 Documentation: Foxy documentation\".^\"ROS 2 alpha8\". 5 October 2016.^\"Why ROS 2?\".^\"Is there a release date of ros 2 or more pieces of information about it? \u2013 ROS Answers: Open Source Q&A Forum\".^\"Program | ROSCon 2014\".^\"Home \u00b7 ros2-wiki\".^\"ROS-Industrial About\". rosindustrial.org. Retrieved 12 December 2017.^\"Brief History\". ROS-Industrial. Retrieved 11 July 2018.^\"2020 NASA Announcement of Collaboration Opportunity (ACO) Selections - NASA\". 9 November 2020. Retrieved 31 October 2024.^The Construct (13 March 2023). RDP120: Space ROS. Retrieved 31 October 2024 \u2013 via YouTube.^\"Home\". space.ros.org. Retrieved 31 October 2024.^\"Space ROS\". GitHub. Retrieved 31 October 2024.^\"Space ROS | Space Robotics Operating System\". PickNik. Retrieved 31 October 2024.^\"Home\". ROS-Industrial. Retrieved 12 December 2017.^\"Baxter Research Robots Q&A | Rethink Robotics\". 24 July 2014. Archived from the original on 24 July 2014. Retrieved 30 July 2021.^\"CK-9 | Centauri Robotics\". centaurirobotics.in. Retrieved 30 July 2021.^\"Robots/gopigo3 \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"CMU Personal Robotics Lab\". personalrobotics.Intel-Research.net. Retrieved 12 December 2017.^\"Husky UGV \u2013 Outdoor Field Research Robot by Clearpath\". ClearPathRobotics.com. Retrieved 12 December 2017.^\"nao \u2013 ROS Wiki\". ROS.org. Open Robotics. 28 October 2013. Retrieved 12 July 2014.^\"Welcome to the Humanoid Robots Lab at the University of Bonn!\". Humanoid Robots Lab \u2013 University of Bonn. Retrieved 30 July 2021.^\"Brown University Robotics\". 28 January 2013. Archived from the original on 28 January 2013. Retrieved 30 July 2021.^\"[ros-users] ROS NAO Driver\". 29 October 2013. Archived from the original on 29 October 2013. Retrieved 30 July 2021.^\"Stanford Personal Robotics Program\". personalrobotics.Stanford.edu. Retrieved 12 December 2017.^\"Featured\". Willow Garage. 20 June 2010. Archived from the original on 20 June 2010. Retrieved 30 July 2021.^B. Hannaford, J. Rosen, Diana CW Friedman, H. King, P. Roan, L. Cheng, D. Glozman, J. Ma, S.N. Kosari, L. White, 'Raven-II: AN Open Platform for Surgical Robotics Research,' IEEE Transactions on Biomedical Engineering, vol. 60, pp. 954-959, April 2013.^\"BioRobotics Laboratory | Biorobotics Laboratory \u2013 University of Washington\". Brl.ee.washington.edu. Archived from the original on 14 July 2014. Retrieved 12 July 2014.^\"ROSbot 2.0 & ROSbot 2.0 PRO \u00b7 Husarion Docs\". husarion.com. Retrieved 30 July 2021.^\"Dexterous Hand Series \u2013 Shadow Robot Company\". Retrieved 30 July 2021.^\"STAIR\". stair.stanford.edu. Retrieved 30 July 2021.^\"Hello Robot\".^\"This Robot Could Be The Key To Empowering People With Disabilities\".^\"Summit XL \u2013 Robotnik\". Robotnik.es. Retrieved 12 July 2014.^\"Specification\". Unbounded Robotics. Archived from the original on 28 April 2015. Retrieved 12 July 2014.^Ackerman, Evan (21 October 2013). \"UBR-1 Robot From Unbounded Robotics Revolutionizes Affordable Mobile Manipulation\". IEEE Spectrum. Retrieved 12 July 2014.^\"Using ROS with Webots\". Retrieved 18 May 2018.^\"Koen Buys\". 29 October 2013. Archived from the original on 29 October 2013. Retrieved 30 July 2021.^\"Ubiquity Robotics Downloads\". Retrieved 29 January 2018.^\"ROSberryPi/Installing ROS Kinetic on the Raspberry Pi\". Retrieved 29 January 2018.^\"ROS 2 on Raspberry Pi\". Retrieved 17 October 2025.^\"5.3.6. ROS and Radar \u2013 Processor SDK Linux Documentation\". software-dl.ti.com. Retrieved 1 May 2020.Notes.mw-parser-output .refbegin{margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}@media screen{.mw-parser-output .refbegin{font-size:90%}}STAIR: The STanford Artificial Intelligence Robot project, Andrew Y. Ng, Stephen Gould, Morgan Quigley, Ashutosh Saxena, Eric Berger. Snowbird, 2008.Related projects[edit]RT middleware \u2013 Robot middleware standard/implementations. RT-component is discussed/defined by the Object Management Group.External links[edit]Official website.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteReal-time operating systems (RTOS)OperatingsystemsPOSIX supportUnix-likeDNIXJunos OSLynxOSMulti-Environment Real-Time^ (MERT \u2013 Unix-RT)OS2000QNX^Real-Time Linux\u00b0RTLinux\u00b0UNOSLiteOSLiteOS\u00b0PartialChorusOS^Integrity^Nucleus RTOS^NuttX^\u00b0Operating System Embedded^ (OSE)PX5 RTOS^RIOT^\u00b0RTEMS\u00b0TRON supportITRON projectT-KernelMicro T-KernelT-Engine Forum (organization)T-LicensePartialeCos\u00b0RTEMS\u00b0Capability-basedEROS^\u00b0seL4^\u00b0Java virtual machineChorus/Jazz^ (JavaOS + ChorusOS^)DOSMultiuser DOSConcurrent DOSFlexOSREAL/32L4 kernelL4Linux^\u00b0PikeOS^REX OS^Wombat^\u00b0PsionEKA2^\u00b0 kernel \u2192 Symbian OS^\u00b0MicrosoftThreadX^Windows Embedded CompactIBM4680 OS4690 OSTransaction Processing Facility (TPF)Texas InstrumentsDSOSTI-RTOS Kernel^\u00b0DECPDP-11 & VAXRSX-11RT-11VAXELNLow resourceChibiOS/RT^\u00b0Contiki\u00b0ERIKA Enterprise\u00b0FunkOS\u00b0Mynewt\u00b0Nano-RK\u00b0OpenComRTOS^PX5 RTOS^RT-Thread\u00b0 NanoRIOT\u00b0RTEMS\u00b0ThreadX^Zephyr^\u00b0BeRTOS^\u00b0DioneOSembOSFreeRTOS^\u00b0\u00b5C/OS^\u00b0\u00b5-velOSity^MQX^OS-9 (Microware)Phantom OS^\u00b0pSOSRMXRT-Thread\u00b0 StandardScreenOSSintran IIITHEOSThoth^ \u2192 Harmony^VRTX^VxWorksUniProtonFrameworks, kitsRobot Operating System\u00b0 2RTAI\u00b0TI-RTOS^\u00b0Xenomai\u00b0DevelopersGordon BellDavid CheritonDave CutlerDan DodgeAdam DunkelsKen SakamuraItalics= discontinued^ = Microkernel\u00b0 = Open-source softwareComparisonCategory\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robot_Operating_System&oldid=1317312908\"", "tags": ["en.wikipedia.org", "wiki", "robot", "operating", "system"]}
{"url": "https://en.wikipedia.org/wiki/Intelligent_agent", "title": null, "text": "Software agent which acts autonomously.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For the term in intelligent design, see Intelligent designer.Not to be confused with Embodied agent..mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}It has been suggested that Agentic AI be merged into this article. (Discuss) Proposed since May 2025.Simple reflex agent diagramIn artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. AI textbooks[which?] define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\nA specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods.\nIntelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria\u2014such as a firm, a state, or a biome.[1]Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[2] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[3] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[4]Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinarysocio-cognitivemodeling and computer social simulations.\nIntelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents\u2014autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[1]Intelligent agents as the foundation of AI[edit]This section possibly contains original research. Relevant discussion may be found on Talk:Intelligent agent. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed.  (February 2023) (Learn how and when to remove this message)The concept of intelligent agents provides a foundational lens through which to define and understand artificial intelligence. For instance, the influential textbook Artificial Intelligence: A Modern Approach (Russell & Norvig) describes:\nAgent: Anything that perceives its environment (using sensors) and acts upon it (using actuators). E.g., a robot with cameras and wheels, or a software program that reads data and makes recommendations.Rational Agent: An agent that strives to achieve the *best possible outcome* based on its knowledge and past experiences. \"Best\" is defined by a performance measure \u2013 a way of evaluating how well the agent is doing.Artificial Intelligence (as a field): The study and creation of these rational agents.Other researchers and definitions build upon this foundation. Padgham & Winikoff emphasize that intelligent agents should react to changes in their environment in a timely way, proactively pursue goals, and be flexible and robust (able to handle unexpected situations). Some also suggest that ideal agents should be \"rational\" in the economic sense (making optimal choices) and capable of complex reasoning, like having beliefs, desires, and intentions (BDI model). Kaplan and Haenlein offer a similar definition, focusing on a system's ability to understand external data, learn from that data, and use what is learned to achieve goals through flexible adaptation.\nDefining AI in terms of intelligent agents offers several key advantages:\nAvoids Philosophical Debates: It sidesteps arguments about whether AI is \"truly\" intelligent or conscious, like those raised by the Turing test or Searle's Chinese Room. It focuses on behavior and goal achievement, not on replicating human thought.Objective Testing: It provides a clear, scientific way to evaluate AI systems. Researchers can compare different approaches by measuring how well they maximize a specific \"goal function\" (or objective function). This allows for direct comparison and combination of techniques.Interdisciplinary Communication: It creates a common language for AI researchers to collaborate with other fields like mathematical optimization and economics, which also use concepts like \"goals\" and \"rational agents.\"Objective function[edit]Further information: utility function (economics) and loss function (mathematics)An objective function (or goal function) specifies the goals of an intelligent agent. An agent is deemed more intelligent if it consistently selects actions that yield outcomes better aligned with its objective function. In effect, the objective function serves as a measure of success.\nThe objective function may be:\nSimple: For example, in a game of Go, the objective function might assign a value of 1 for a win and 0 for a loss.Complex: It might require the agent to evaluate and learn from past actions, adapting its behavior based on patterns that have proven effective.The objective function encapsulates all of the goals the agent is designed to achieve. For rational agents, it also incorporates the trade-offs between potentially conflicting goals. For instance, a self-driving car's objective function might balance factors such as safety, speed, and passenger comfort.\nDifferent terms are used to describe this concept, depending on the context.  These include:\nUtility function:  Often used in economics and decision theory, representing the desirability of a state.Objective function: A general term used in optimization.Loss function:  Typically used in machine learning, where the goal is to minimize the loss (error).Reward Function: Used in reinforcement learning.Fitness Function: Used in evolutionary systems.Goals, and therefore the objective function, can be:\nExplicitly defined: Programmed directly into the agent.Induced: Learned or evolved over time.\nIn reinforcement learning, a \"reward function\" provides feedback, encouraging desired behaviors and discouraging undesirable ones. The agent learns to maximize its cumulative reward.In evolutionary systems, a \"fitness function\" determines which agents are more likely to reproduce. This is analogous to natural selection, where organisms evolve to maximize their chances of survival and reproduction.[5]Some AI systems, such as nearest-neighbor, reason by analogy rather than being explicitly goal-driven. However, even these systems can have goals implicitly defined within their training data.[6] Such systems can still be benchmarked by framing the non-goal system as one whose \"goal\" is to accomplish its narrow classification task.[7]Systems not traditionally considered agents, like knowledge-representation systems, are sometimes included in the paradigm by framing them as agents with a goal of, for example, answering questions accurately. Here, the concept of an \"action\" is extended to encompass the \"act\" of providing an answer. As a further extension, mimicry-driven systems can be framed as agents optimizing a \"goal function\" based on how closely the IA mimics the desired behavior.[2] In generative adversarial networks (GANs) of the 2010s, an \"encoder\"/\"generator\" component attempts to mimic and improvise human text composition. The generator tries to maximize a function representing how well it can fool an antagonistic \"predictor\"/\"discriminator\" component.[8]While symbolic AI systems often use an explicit goal function, the paradigm also applies to neural networks and evolutionary computing. Reinforcement learning can generate intelligent agents that appear to act in ways intended to maximize a \"reward function\".[9] Sometimes, instead of setting the reward function directly equal to the desired benchmark evaluation function, machine learning programmers use reward shaping to initially give the machine rewards for incremental progress.[10]Yann LeCun stated in 2018, \"Most of the learning algorithms that people have come up with essentially consist of minimizing some objective function.\"[11]AlphaZero chess had a simple objective function: +1 point for each win, and -1 point for each loss. A self-driving car's objective function would be more complex.[12] Evolutionary computing can evolve intelligent agents that appear to act in ways intended to maximize a \"fitness function\" influencing how many descendants each agent is allowed to leave.[4]The mathematical formalism of AIXI was proposed as a maximally intelligent agent in this paradigm.[13] However, AIXI is uncomputable. In the real world, an IA is constrained by finite time and hardware resources, and scientists compete to produce algorithms that achieve progressively higher scores on benchmark tests with existing hardware.[14]Agent function[edit]An intelligent agent's behavior can be described mathematically by an agent function. This function determines what the agent does based on what it has seen.\nA percept refers to the agent's sensory inputs at a single point in time. For example, a self-driving car's percepts might include camera images, lidar data, GPS coordinates, and speed readings at a specific instant. The agent uses these percepts, and potentially its history of percepts, to decide on its next action (e.g., accelerate, brake, turn).\nThe agent function, often denoted as f, maps the agent's entire history of percepts to an action.[15]Mathematically, this can be represented as\n\n  \n    \n      \n        f\n        :\n        \n          P\n          \n            \u2217\n          \n        \n        \u2192\n        A\n        ,\n      \n    \n    {\\displaystyle f\\colon P^{*}\\rightarrow A,}\n  where:\n\n  \n    \n      \n        \n          \n            P\n            \n              \u2217\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {P^{*}}}}\n   represents the set of all possible percept sequences (the agent's entire perceptual history). The asterisk (*) indicates a sequence of zero or more percepts.\n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {A}}}\n   represents the set of all possible actions the agent can take.\n  \n    \n      \n        \n          f\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {f}}}\n   is the agent function that maps a percept sequence to an action.It's crucial to distinguish between the agent function (an abstract mathematical concept) and the agent program (the concrete implementation of that function).\nThe agent function is a theoretical description.The agent program is the actual code that runs on the agent. The agent program takes the current percept as input and produces an action as output.The agent function can incorporate a wide range of decision-making approaches, including:[16]Calculating the utility (desirability) of different actions.Using logical rules and deduction.Employing fuzzy logic.Other methods.Classes of intelligent agents[edit]Russell and Norvig's classification[edit]Russell & Norvig (2003) group agents into five classes based on their degree of perceived intelligence and capability:[17]Simple reflex agents[edit]Simple reflex agentSimple reflex agents act only on the basis of the current percept, ignoring the rest of the percept history. The agent function is based on the condition-action rule: \"if condition, then action\".\nThis agent function only succeeds when the environment is fully observable. Some reflex agents can also contain information on their current state which allows them to disregard conditions whose actuators are already triggered.\nInfinite loops are often unavoidable for simple reflex agents operating in partially observable environments. If the agent can randomize its actions, it may be possible to escape from infinite loops.\nA home thermostat, which turns on or off when the temperature drops below a certain point, is an example of a simple reflex agent.[18][19]Model-based reflex agents[edit]Model-based reflex agentA model-based agent can handle partially observable environments. Its current state is stored inside the agent, maintaining a structure that describes the part of the world which cannot be seen. This knowledge about \"how the world works\" is referred to as a model of the world, hence the name \"model-based agent\".\nA model-based reflex agent should maintain some sort of internal model that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. Percept history and impact of action on the environment can be determined by using the internal model. It then chooses an action in the same way as reflex agent.\nAn agent may also use models to describe and predict the behaviors of other agents in the environment.[20]Goal-based agents[edit]Model-based, goal-based agentGoal-based agents further expand on the capabilities of the model-based agents, by using \"goal\" information. Goal information describes situations that are desirable. This provides the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. Search and planning are the subfields of artificial intelligence devoted to finding action sequences that achieve the agent's goals.\nChatGPT and the Roomba vacuum are examples of goal-based agents.[21]Utility-based agents[edit]Model-based, utility-based agentGoal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is.\nA rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning.\nLearning agents[edit]A general learning agentLearning lets agents begin in unknown environments and gradually surpass the bounds of their initial knowledge. A key distinction in such agents is the separation between a \"learning element,\" responsible for improving performance, and a \"performance element,\" responsible for choosing external actions.\nThe learning element gathers feedback from a \"critic\" to assess the agent's performance and decides how the performance element\u2014also called the \"actor\"\u2014can be adjusted to yield better outcomes. The performance element, once considered the entire agent, interprets percepts and takes actions.\nThe final component, the \"problem generator,\" suggests new and informative experiences that encourage exploration and further improvement.\nWeiss's classification[edit]According to Weiss (2013), agents can be categorized into four classes:\nLogic-based agents, where decisions about actions are derived through logical deduction.Reactive agents, where decisions occur through a direct mapping from situation to action.Belief\u2013desire\u2013intention agents, where decisions depend on manipulating data structures that represent the agent's beliefs, desires, and intentions.Layered architectures, where decision-making takes place across multiple software layers, each of which reasons about the environment at a different level of abstraction.Other[edit]In 2013, Alexander Wissner-Gross published a theory exploring the relationship between Freedom and Intelligence in intelligent agents.[22][23]Hierarchies of agents[edit]Main article: Multi-agent systemIntelligent agents can be organized hierarchically into multiple \"sub-agents.\" These sub-agents handle lower-level functions, and together with the main agent, they form a complete system capable of executing complex tasks and achieving challenging goals.\nTypically, an agent is structured by dividing it into sensors and actuators. The perception system gathers input from the environment via the sensors and feeds this information to a central controller, which then issues commands to the actuators. Often, a multilayered hierarchy of controllers is necessary to balance the rapid responses required for low-level tasks with the more deliberative reasoning needed for high-level objectives.[24]Alternative definitions and uses[edit]\"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\".[25] Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user.[26] These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\".\nAccording to Nikola Kasabov in 1998, IA systems should exhibit the following characteristics:[27]Accommodate new problem solving rules incrementally.Adapt online and in real time.Are able to analyze themselves in terms of behavior, error and success.Learn and improve through interaction with the environment (embodiment).Learn quickly from large amounts of data.Have memory-based exemplar storage and retrieval capacities.Have parameters to represent short- and long-term memory, age, forgetting, etc.Agentic AI[edit]Main article: Agentic AIIn the context of generative artificial intelligence, AI agents (also referred to as compound AI systems) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.[28]They possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs).[29]Researchers and commentators have noted that AI agents do not have a standard definition.[29][30][31][32]A common application of AI agents is the automation of tasks\u2014for example, booking travel plans based on a user's prompted request.[33][34] Prominent examples include Devin AI, AutoGPT, and SIMA.[35] Further examples of agents released since 2025 include OpenAI Operator,[36]ChatGPT Deep Research,[37]Manus,[38] Quark (based on Qwen),[39]AutoGLM Rumination,[39] and Coze (by ByteDance).[39] Frameworks for building AI agents include LangChain,[40] as well as tools such as CAMEL,[41][42] Microsoft AutoGen,[43] and OpenAI Swarm.[44]Companies such as Google, Microsoft and Amazon Web Services have offered platforms for deploying pre-built AI agents.[45]Proposed protocols for standardizing inter-agent communication include the Agent Protocol (by LangChain), the Model Context Protocol (by Anthropic), AGNTCY,[46]Gibberlink,[47] the Internet of Agents,[48] Agent2Agent (by Google),[49] and the Agent Network Protocol.[50] Software frameworks for addressing agent reliability include AgentSpec, ToolEmu, GuardAgent, Agentic Evaluations, and predictive models from H2O.ai.[51]In February 2025, Hugging Face released Open Deep Research, an open source version of OpenAI Deep Research.[52] Hugging Face also released a free web browser agent, similar to OpenAI Operator.[53] Galileo AI published on Hugging Face a leadership board for agents, which ranks their performance based on their underlying LLMs.[54]Autonomous capabilities[edit]The Financial Times compared the autonomy of AI agents to the SAE classification of self-driving cars, comparing most applications to level 2 or level 3, with some achieving level 4 in highly specialized circumstances, and level 5 being theoretical.[55]Multimodal AI agents[edit]In addition to large language models (LLMs), vision language models (VLMs) and multimodalfoundation models can be used as the basis for agents. In September 2024, Allen Institute for AI released an open source vision language model, which Wired noted could give AI agents the ability to perform complex computer tasks, including the possibility of automated computer hacking.[56]Nvidia released a framework for developers to use VLMs, LLMs and retrieval-augmented generation for building AI agents that can analyze images and videos, including video search and video summarization.[57][58] Microsoft released a multimodal agent model - trained on images, video, software user interface interactions, and robotics data - that the company claimed can manipulate software and robots.[59]Applications[edit]As of April 2025, per the Associated Press, there are few real world applications of AI agents.[60] As of June 2025, per Fortune, many companies are primarily experimenting with AI agents.[61]A recruiter for the Department of Government Efficiency proposed in April 2025 to use AI agents to automate the work of about 70,000 United States federal government employees, as part of a startup with funding from OpenAI and a partnership agreement with Palantir. This proposal was criticized by experts for its impracticality, if not impossibility, and the lack of corresponding widespread adoption by businesses.[62]Proposed benefits[edit]Proponents argue that AI agents can increase personal and economic productivity,[34][63] foster greater innovation,[64] and liberate users from monotonous tasks.[64][65] A Bloomberg opinion piece by Parmy Olson argued that agents are best suited for narrow, repetitive tasks with low risk.[66] Conversely, researchers suggest that agents could be applied to web accessibility for people who have disabilities,[67][68] and researchers at Hugging Face propose that agents could be used for coordinating resources such as during disaster response.[69] The R&D Advisory Team of the BBC views AI agents as being most useful when their assigned goal is uncertain.[70]Concerns[edit]Concerns include potential issues of liability,[63][70] an increased risk of cybercrime,[33][63]ethical challenges,[63] as well as problems related to AI safety[63] and AI alignment.[33][65] Other issues involve data privacy,[33][71] weakened human oversight,[33][63][69] a lack of guaranteed repeatability,[70]reward hacking,[72]algorithmic bias,[71][73] compounding software errors,[33][35] lack of explainability of agents' decisions,[33][74]security vulnerabilities,[33][75] problems with underemployment,[73]job displacement,[34][73] and the potential for user manipulation,[74][76]misinformation[69] or malinformation.[69] They may also complicate legal frameworks and risk assessments, foster hallucinations, hinder countermeasures against rogue agents, and suffer from the lack of standardized evaluation methods.[65][77][78] They have also been criticized for being expensive[29][77] and having a negative impact on internet traffic,[77] and potentially on the environment due to high energy usage.[70][79][80] There is also the risk of increased concentration of power by political leaders, as AI agents may not question instructions in the same way that humans would.[72]Journalists have described AI agents as part of a push by Big Tech companies to \"automate everything\".[81] Several CEOs of those companies have stated in early 2025 that they expect AI agents to eventually \"join the workforce\".[82][83] However, in a non-peer-reviewed study, Carnegie Mellon University researchers tested the behavior of agents in a simulated software company and found that none of the agents could complete a majority of the assigned tasks.[82][84] Other researchers had similar findings with Devin AI.[85]Yoshua Bengio warned at the 2025 World Economic Forum that \"all of the catastrophic scenarios with AGI or superintelligence happen if we have agents\".[86]In March 2025, Scale AI signed a contract with the United States Department of Defense to work with them, in collaboration with Anduril Industries and Microsoft, to develop and deploy AI agents for the purpose of assisting the military with \"operational decision-making\".[87] Researchers have expressed concerns that agents and the large language models they are based on could be biased towards aggressive foreign policy decisions.[88][89]Research-focused agents have the risk of consensus bias and coverage bias due to collecting information available on the public Internet.[90]NY Mag unfavorably compared the user workflow of agent-based web browsers to Amazon Alexa, which was \"software talking to software, not humans talking to software pretending to be humans to use software.\"[91]Agents have been linked to the dead Internet theory due to their ability to both publish and engage with online content.[92]Agents may get stuck in infinite loops.[36][93]Since many inter-agent protocols are being developed by large technology companies, there are concerns that those companies could use these protocols for self-benefit.[50]Possible mitigation[edit]Zico Kolter noted the possibility of emergent behavior as a result of interactions between agents, and proposed research in game theory to model the risks of these interactions.[94]Guardrails, defined by Business Insider as \"filters, rules, and tools that can be used to identify and remove inaccurate content\" have been suggested to help reduce errors.[95]To address security vulnerabilities related to data access, language models could be redesigned to separate instructions and data, or agentic applications could be required to include guardrails. These ideas were proposed in response to a zero-click exploit that affected Microsoft 365 Copilot.[61]Applications[edit]This section may lend undue weight to certain ideas, incidents, or controversies. Please help improve it by rewriting it to create a more balanced presentation. Discuss and resolve this issue before removing this message.  (September 2023)The concept of agent-based modeling for self-driving cars was discussed as early as 2003.[96]Hallerbach et al. explored the use of agent-based approaches for developing and validating automated driving systems. Their method involved a digital twin of the vehicle under test and microscopic traffic simulations using independent agents.[97]Waymo developed a multi-agent simulation environment called Carcraft, to test algorithms for self-driving cars.[98][99] This system simulates interactions between human drivers, pedestrians, and automated vehicles. Artificial agents replicate human behavior using real-world data.\nSalesforce's Agentforce is an agentic AI platform that allows for the building of autonomous agents to perform tasks.[100][101]The Transport Security Administration is integrating agentic AI into new technologies, including machines to authenticate passenger identities using biometrics and photos, and also for incident response.[102]See also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Ambient intelligenceArtificial conversational entityArtificial intelligence systems integrationAutonomous agentCognitive architecturesCognitive radio \u2013 a practical field for implementationCyberneticsDAYDREAMEREmbodied agentFederated search \u2013 the ability for agents to search heterogeneous data sources using a single vocabularyFriendly artificial intelligenceFuzzy agents \u2013 IA implemented with adaptive fuzzy logicGOAL agent programming languageHybrid intelligent systemIntelligent controlIntelligent systemJACK Intelligent AgentsMulti-agent system and multiple-agent system \u2013 multiple interactive agentsReinforcement learningSemantic Web \u2013 making data on the Web available for automated processing by agentsSocial simulationSoftware agentSoftware botReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^ abRussell & Norvig 2003, chpt. 2.^ ab.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Bringsjord, Selmer; Govindarajulu, Naveen Sundar (12 July 2018). \"Artificial Intelligence\". In Edward N. Zalta (ed.). The Stanford Encyclopedia of Philosophy (Summer 2020 Edition).^Wolchover, Natalie (30 January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 21 June 2020.^ abBull, Larry (1999). \"On model-based evolutionary computation\". Soft Computing. 3 (2): 76\u201382. doi:10.1007/s005000050055. S2CID\u00a09699920.^Domingos 2015, Chapter 5.^Domingos 2015, Chapter 7.^Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling for nearest neighbor classifiers. Machine learning, 54(2), 125\u2013152.^\"Generative adversarial networks: What GANs are and how they've evolved\". VentureBeat. 26 December 2019. Retrieved 18 June 2020.^Wolchover, Natalie (January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 18 June 2020.^Andrew Y. Ng, Daishi Harada, and Stuart Russell. \"Policy invariance under reward transformations: Theory and application to reward shaping.\" In ICML, vol. 99, pp. 278-287. 1999.^Martin Ford. Architects of Intelligence: The truth about AI from the people building it. Packt Publishing Ltd, 2018.^\"Why AlphaZero's Artificial Intelligence Has Trouble With the Real World\". Quanta Magazine. 2018. Retrieved 18 June 2020.^Adams, Sam; Arel, Itmar; Bach, Joscha; Coop, Robert; Furlan, Rod; Goertzel, Ben; Hall, J. Storrs; Samsonovich, Alexei; Scheutz, Matthias; Schlesinger, Matthew; Shapiro, Stuart C.; Sowa, John (15 March 2012). \"Mapping the Landscape of Human-Level Artificial General Intelligence\". AI Magazine. 33 (1): 25. doi:10.1609/aimag.v33i1.2322.^Hutson, Matthew (27 May 2020). \"Eye-catching advances in some AI fields are not real\". Science | AAAS. Retrieved 18 June 2020.^Russell & Norvig 2003, p.\u00a033^Salamon, Tomas (2011). Design of Agent-Based Models. Repin: Bruckner Publishing. pp.\u00a042\u201359. ISBN\u00a0978-80-904661-1-1.^Russell & Norvig 2003, pp.\u00a046\u201354^Thakur, Shreeya. \"AI Agents: 5 Key Types Explained With Examples // Unstop\". unstop.com. Retrieved 2025-04-24.^\"Types of AI Agents | IBM\". www.ibm.com. 2025-03-17. Retrieved 2025-04-24.^Stefano Albrecht and Peter Stone (2018). Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems.\nArtificial Intelligence, Vol. 258, pp. 66-95. https://doi.org/10.1016/j.artint.2018.01.002^\"What is an AI agent? A computer scientist explains the next wave of artificial intelligence tools\". Inverse. 2024-12-24. Retrieved 2025-04-24.^Box, Geeks out of the (2019-12-04). \"A Universal Formula for Intelligence\". Geeks out of the box. Retrieved 2022-10-11.^Wissner-Gross, A. D.; Freer, C. E. (2013-04-19). \"Causal Entropic Forces\". Physical Review Letters. 110 (16) 168702. Bibcode:2013PhRvL.110p8702W. doi:10.1103/PhysRevLett.110.168702. hdl:1721.1/79750. PMID\u00a023679649.^Poole, David; Mackworth, Alan. \"1.3 Agents Situated in Environments\u2023 Chapter 2 Agent Architectures and Hierarchical Control\u2023 Artificial Intelligence: Foundations of Computational Agents, 2nd Edition\". artint.info. Retrieved 28 November 2018.^Fingar, Peter (2018). \"Competing For The Future With Intelligent Agents... And A Confession\". Forbes Sites. Retrieved 18 June 2020.^Burgin, Mark; Dodig-Crnkovic, Gordana (2009). \"A Systematic Approach to Artificial Agents\". arXiv:0902.3513 [cs.AI].^Kasabov 1998.^Purdy, Mark (2024-12-12). \"What Is Agentic AI, and How Will It Change Work?\". Harvard Business Review. ISSN\u00a00017-8012. Retrieved 2025-04-24.^ abcKapoor, Sayash; Stroebl, Benedikt; Siegel, Zachary S.; Nadgir, Nitya; Narayanan, Arvind (2024). \"AI Agents That Matter\". arXiv:2407.01502 [cs.LG].^Zeff, Maxwell; Wiggers, Kyle (2025-03-14). \"No one knows what the hell an AI agent is\". TechCrunch. Archived from the original on 2025-03-18. Retrieved 2025-05-15.^Varanasi, Lakshmi. \"AI agents are all the rage. But no one can agree on what they do\". Business Insider. Archived from the original on 2025-04-11. Retrieved 2025-05-15.^Bort, Julie (2025-05-12). \"Even a16z VCs say no one really knows what an AI agent is\". TechCrunch. Archived from the original on 2025-05-12. Retrieved 2025-05-15.^ abcdefgh\"AI Agents: The Next Generation of Artificial Intelligence\". The National Law Review. 2024-12-30. Archived from the original on 2025-01-11. Retrieved 2025-01-14.^ abc\"What are the risks and benefits of 'AI agents'?\". World Economic Forum. 2024-12-16. Archived from the original on 2024-12-28. Retrieved 2025-01-14.^ abKnight, Will (2024-03-14). \"Forget Chatbots. AI Agents Are the Future\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-01-05. Retrieved 2025-01-14.^ abMarshall, Matt (2025-02-22). \"The rise of browser-use agents: Why Convergence's Proxy is beating OpenAI's Operator\". VentureBeat. Archived from the original on 2025-02-22. Retrieved 2025-04-02.^Milmo, Dan (2025-02-03). \"OpenAI launches 'deep research' tool that it says can match research analyst\". The Guardian. ISSN\u00a00261-3077. Archived from the original on 2025-02-03. Retrieved 2025-04-02.^Chen, Caiwei (2025-03-11). \"Everyone in AI is talking about Manus. We put it to the test\". MIT Technology Review. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^ abc\"China is gaining ground in the global race to develop AI agents\". Rest of World. 2025-06-02. Archived from the original on 2025-06-02. Retrieved 2025-06-12.^David, Emilia (2024-12-30). \"Why 2025 will be the year of AI orchestration\". VentureBeat. Archived from the original on 2024-12-30. Retrieved 2025-01-14.^\"CAMEL: Finding the Scaling Law of Agents. The first and the best multi-agent framework\". GitHub.^Li, Guohao (2023). \"Camel: Communicative agents for \"mind\" exploration of large language model society\"(PDF). Advances in Neural Information Processing Systems. 36: 51991\u201352008. arXiv:2303.17760. S2CID\u00a0257900712.^Dickson, Ben (2023-10-03). \"Microsoft's AutoGen framework allows multiple AI agents to talk to each other and complete your tasks\". VentureBeat. Archived from the original on 2024-12-27. Retrieved 2025-01-14.^\"The next AI wave \u2014 agents \u2014 should come with warning labels\". Computerworld. 2025-01-13. Archived from the original on 2025-01-14. Retrieved 2025-01-14.^David, Emilia (2025-04-15). \"Moveworks joins AI agent library craze\". VentureBeat. Archived from the original on 2025-04-15. Retrieved 2025-05-14.^David, Emilia (2025-03-06). \"A standard, open framework for building AI agents is coming from Cisco, LangChain and Galileo\". VentureBeat. Archived from the original on 2025-03-09. Retrieved 2025-04-02.^Zeff, Maxwell (2025-03-05). \"GibberLink lets AI agents call each other in robo-language\". TechCrunch. Archived from the original on 2025-03-05. Retrieved 2025-04-02.^Cooney, Michael (2025-01-30). \"Cisco touts 'Internet of Agents' for secure AI agent collaboration\". Network World. Archived from the original on 2025-01-31. Retrieved 2025-04-02.^Clark, Lindsay (2025-04-10). \"Did someone say AI agents, Google asks, bursting in\". The Register. Archived from the original on 2025-04-10. Retrieved 2025-05-14.^ abStokel-Walker, Chris (2025-06-11). \"Can we stop big tech from controlling the internet with AI agents?\". New Scientist. Archived from the original on 2025-06-11. Retrieved 2025-06-12.^David, Emilia (2025-03-28). \"New approach to agent reliability, AgentSpec, forces agents to follow rules\". VentureBeat. Archived from the original on 2025-04-12. Retrieved 2025-05-14.^Edwards, Benj (2025-02-05). \"Hugging Face clones OpenAI's Deep Research in 24 hours\". Ars Technica. Archived from the original on 2025-02-06. Retrieved 2025-04-02.^Wiggers, Kyle (2025-05-06). \"Hugging Face releases a free Operator-like agentic AI tool\". TechCrunch. Archived from the original on 2025-05-06. Retrieved 2025-05-14.^Ortiz, Sabrina (2025-02-14). \"Which AI agent is the best? This new leaderboard can tell you\". ZDNET. Archived from the original on 2025-03-30. Retrieved 2025-04-02.^Colback, Lucy (2025-05-07). \"AI agents: from co-pilot to autopilot\". Financial Times. Archived from the original on 2025-05-07. Retrieved 2025-05-14.^Knight, Will (2024-09-25). \"The Most Capable Open Source AI Model Yet Could Supercharge AI Agents\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-03-28. Retrieved 2025-06-12.^Takahashi, Dean (2024-11-04). \"Nvidia AI Blueprint makes it easy for any devs to build automated agents that analyze video\". VentureBeat. Archived from the original on 2024-12-05. Retrieved 2025-06-12.^Takahashi, Dean (2025-01-07). \"Nvidia launches blueprint for AI agents that can analyze video\". VentureBeat. Archived from the original on 2025-04-04. Retrieved 2025-06-12.^Edwards, Benj (2025-02-20). \"Microsoft's new AI agent can control software and robots\". Ars Technica. Archived from the original on 2025-05-20. Retrieved 2025-06-12.^\"Visa wants to give artificial intelligence 'agents' your credit card\". Associated Press. 2025-04-30. Archived from the original on 2025-05-01. Retrieved 2025-05-14.^ abGoldman, Sharon (2025-06-11). \"Microsoft Copilot flaw raises urgent questions for any business deploying AI agents\". Fortune. Archived from the original on 2025-06-11. Retrieved 2025-06-12.^Haskins, Caroline (2025-05-02). \"A DOGE Recruiter Is Staffing a Project to Deploy AI Agents Across the US Government\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-05-03. Retrieved 2025-05-14.^ abcdefPiper, Kelsey (2024-03-29). \"AI \"agents\" could do real work in the real world. That might not be a good thing\". Vox. Archived from the original on 2024-12-19. Retrieved 2025-01-14.^ abPurdy, Mark (2024-12-12). \"What Is Agentic AI, and How Will It Change Work?\". Harvard Business Review. ISSN\u00a00017-8012. Archived from the original on 2024-12-30. Retrieved 2025-01-20.^ abcWright, Webb (2024-12-12). \"AI Agents with More Autonomy Than Chatbots Are Coming. Some Safety Experts Are Worried\". Scientific American. Archived from the original on 2024-12-23. Retrieved 2025-01-14.^Olson, Parmy (2025-01-27). \"Skip the Hype, Here's How AI 'Agents' Can Really Help\". Bloomberg News. Archived from the original on 2025-01-27. Retrieved 2025-04-02.^Deng, Xiang; Gu, Yu; Zheng, Boyuan; Chen, Shijie; Stevens, Samuel; Wang, Boshi; Sun, Huan; Su, Yu (2023). \"Mind2Web: Towards a Generalist Agent for the Web\". arXiv:2306.06070 [cs.CL].^Woodall, Tatyana (2024-01-09). \"Researchers developing AI to make the internet more accessible\". Ohio State News. Archived from the original on 2025-03-28. Retrieved 2025-04-02.^ abcdMitchell, Margaret; Ghosh, Avijit; Luccioni, Sasha; Pistilli, Giada (2025-03-24). \"Why handing over total control to AI agents would be a huge mistake\". MIT Technology Review. Archived from the original on 2025-03-24. Retrieved 2025-04-02.^ abcd\"AI agents: Exploring the potential and the problems\". BBC Online. 2025-05-30. Archived from the original on 2025-06-10. Retrieved 2025-06-12.^ abO'Neill, Brian (2024-12-18). \"What is an AI agent? A computer scientist explains the next wave of artificial intelligence tools\". The Conversation. Archived from the original on 2025-01-04. Retrieved 2025-01-14.^ abHuckins, Grace (2025-06-12). \"Are we ready to hand AI agents the keys?\". MIT Technology Review. Archived from the original on 2025-06-12. Retrieved 2025-06-15.^ abcLin, Belle (2025-01-06). \"How Are Companies Using AI Agents? Here's a Look at Five Early Users of the Bots\". The Wall Street Journal. ISSN\u00a00099-9660. Archived from the original on 2025-01-06. Retrieved 2025-01-20.^ abZittrain, Jonathan L. (2024-07-02). \"We Need to Control AI Agents Now\". The Atlantic. Archived from the original on 2024-12-31. Retrieved 2025-01-20.^Kerner, Sean Michael (2025-01-16). \"Nvidia tackles agentic AI safety and security with new NeMo Guardrails NIMs\". VentureBeat. Archived from the original on 2025-01-16. Retrieved 2025-01-20.^Crawford, Kate (2024-12-23). \"AI Agents Will Be Manipulation Engines\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-01-03. Retrieved 2025-01-14.^ abc\"The argument against AI agents and unnecessary automation\". The Register. 2025-01-27. Archived from the original on 2025-01-27. Retrieved 2025-01-30.^Blackman, Reid (2025-06-13). \"Organizations Aren't Ready for the Risks of Agentic AI\". Harvard Business Review. ISSN\u00a00017-8012. Archived from the original on 2025-06-13. Retrieved 2025-06-15.^\"We did the math on AI's energy footprint. Here's the story you haven't heard\". MIT Technology Review. 2025-05-20. Archived from the original on 2025-05-20. Retrieved 2025-06-12. We started small, as the question of how much a single query costs is vitally important to understanding the bigger picture. That's because those queries are being built into ever more applications beyond standalone chatbots: from search, to agents, to the mundane daily apps we use to track our fitness, shop online, or book a flight. The energy resources required to power this artificial-intelligence revolution are staggering, and the world's biggest tech companies have made it a top priority to harness ever more of that energy, aiming to reshape our energy grids in the process.^\"Inside the effort to tally AI's energy appetite\". MIT Technology Review. 2025-06-03. Archived from the original on 2025-06-03. Retrieved 2025-06-12. Lots of AI companies are building reasoning models, which \"think\" for longer and use more energy. They're building hardware devices, perhaps like the one Jony Ive has been working on (which OpenAI just acquired for $6.5 billion), that have AI constantly humming along in the background of our conversations. They're designing agents and digital clones of us to act on our behalf. All these trends point to a more energy-intensive future (which, again, helps explain why OpenAI and others are spending such inconceivable amounts of money on energy).^Wong, Matteo (2025-03-14). \"Was Sam Altman Right About the Job Market?\". The Atlantic. Archived from the original on 2025-03-17. Retrieved 2025-04-02. In other words, flawed products won't stop tech companies' push to automate everything\u2014the AI-saturated future will be imperfect at best, but it is coming anyway.^ abAgarwal, Shubham. \"Carnegie Mellon staffed a fake company with AI agents. It was a total disaster\". Business Insider. Archived from the original on 2025-04-28. Retrieved 2025-05-15.^Sabin, Sam (2025-04-22). \"Exclusive: Anthropic warns fully AI employees are a year away\". Axios. Archived from the original on 2025-04-23. Retrieved 2025-05-15.^Xu, Frank F.; Song, Yufan; Li, Boxuan; Tang, Yuxuan; Jain, Kritanjali; Bao, Mengxue; Wang, Zora Z.; Zhou, Xuhui; Guo, Zhitong; Cao, Murong; Yang, Mingyang; Hao Yang Lu; Martin, Amaad; Su, Zhe; Maben, Leander; Mehta, Raj; Chi, Wayne; Jang, Lawrence; Xie, Yiqing; Zhou, Shuyan; Neubig, Graham (2024). \"TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks\". arXiv:2412.14161 [cs.CL].^Claburn, Thomas (2025-01-23). \"Tool touted as 'first AI software engineer' is bad at its job, testers claim\". The Register. Archived from the original on 2025-03-30. Retrieved 2025-06-15.^Balevic, Katie. \"Signal president warns the hyped agentic AI bots threaten user privacy\". Business Insider. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^Hornstein, Julia. \"AI agents are coming to the military. VCs love it, but researchers are a bit wary\". Business Insider. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^Tangermann, Victor (2025-03-06). \"Pentagon Signs Deal to \"Deploy AI Agents for Military Use\"\". Futurism. Archived from the original on 2025-03-08. Retrieved 2025-04-02.^Jensen, Benjamin (2025-03-04). \"The Troubling Truth About How AI Agents Act in a Crisis\". Foreign Policy. Archived from the original on 2025-03-04. Retrieved 2025-04-02.^Nu\u00f1ez, Michael (2025-02-25). \"OpenAI expands Deep Research access to Plus users, heating up AI agent wars with DeepSeek and Claude\". VentureBeat. Archived from the original on 2025-03-11. Retrieved 2025-04-02.^Herrman, John (2025-01-25). \"What Are AI 'Agents' For?\". Intelligencer. Archived from the original on 2025-01-25. Retrieved 2025-04-02.^Caramela, Sammi (2025-02-01). \"'Dead Internet Theory' Is Back Thanks to All of That AI Slop\". VICE. Archived from the original on 2025-02-01. Retrieved 2025-04-02.^Metz, Cade; Weise, Karen (2023-10-16). \"How 'A.I. Agents' That Roam the Internet Could One Day Replace Workers\". The New York Times. ISSN\u00a00362-4331. Archived from the original on 2023-12-19. Retrieved 2025-04-02.^Knight, Will (2025-04-09). \"The AI Agent Era Requires a New Kind of Game Theory\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-04-09. Retrieved 2025-05-15.^Varanasi, Lakshmi. \"Don't get too excited about AI agents yet. They make a lot of mistakes\". Business Insider. Archived from the original on 2025-04-18. Retrieved 2025-05-15.^Yang, Guoqing; Wu, Zhaohui; Li, Xiumei; Chen, Wei (2003). \"SVE: embedded agent-based smart vehicle environment\". Proceedings of the 2003 IEEE International Conference on Intelligent Transportation Systems. Vol.\u00a02. pp.\u00a01745\u20131749. doi:10.1109/ITSC.2003.1252782. ISBN\u00a00-7803-8125-4. S2CID\u00a0110177067.^Hallerbach, S.; Xia, Y.; Eberle, U.; Koester, F. (2018). \"Simulation-Based Identification of Critical Scenarios for Cooperative and Automated Vehicles\". SAE International Journal of Connected and Automated Vehicles. 1 (2). SAE International: 93. doi:10.4271/2018-01-1066.^Madrigal, Story by Alexis C. \"Inside Waymo's Secret World for Training Self-Driving Cars\". The Atlantic. Retrieved 14 August 2020.^Connors, J.; Graham, S.; Mailloux, L. (2018). \"Cyber Synthetic Modeling for Vehicle-to-Vehicle Applications\". In International Conference on Cyber Warfare and Security. Academic Conferences International Limited: 594-XI.^Nu\u00f1ez, Michael (2025-03-05). \"Salesforce launches Agentforce 2dx, letting AI run autonomously across enterprise systems\". VentureBeat. Retrieved 2025-04-24.^\"Salesforce unveils Agentforce to help create autonomous AI bots\". CIO. Retrieved 2025-04-24.^\"TSA Showcase Biometric AI-powered Airport Immigration Security\". techinformed.com. 2025-01-23. Retrieved 2025-04-24.Sources[edit]Domingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\u00a0978-0-465-06570-7.Russell, Stuart J.; Norvig, Peter (2003). Artificial Intelligence: A Modern Approach (2nd\u00a0ed.). Upper Saddle River, New Jersey: Prentice Hall. Chapter 2. ISBN\u00a00-13-790395-2.Kasabov, N. (1998). \"Introduction: Hybrid intelligent adaptive systems\". International Journal of Intelligent Systems. 13 (6): 453\u2013454. doi:10.1002/(SICI)1098-111X(199806)13:6<453::AID-INT1>3.0.CO;2-K. S2CID\u00a0120318478.Weiss, G. (2013). Multiagent systems (2nd\u00a0ed.). Cambridge, MA: MIT Press. ISBN\u00a0978-0-262-01889-0..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteArtificial intelligence (AI)HistorytimelineGlossaryCompaniesProjectsConceptsParameterHyperparameterLoss functionsRegressionBias\u2013variance tradeoffDouble descentOverfittingClusteringGradient descentSGDQuasi-Newton methodConjugate gradient methodBackpropagationAttentionConvolutionNormalizationBatchnormActivationSoftmaxSigmoidRectifierGatingWeight initializationRegularizationDatasetsAugmentationPrompt engineeringReinforcement learningQ-learningSARSAImitationPolicy gradientDiffusionLatent diffusion modelAutoregressionAdversaryRAGUncanny valleyRLHFSelf-supervised learningReflectionRecursive self-improvementHallucinationWord embeddingVibe codingSafety (Alignment)ApplicationsMachine learningIn-context learningArtificial neural networkDeep learningLanguage modelLargeNMTReasoningModel Context ProtocolIntelligent agentArtificial human companionHumanity's Last ExamArtificial general intelligence (AGI)ImplementationsAudio\u2013visualAlexNetWaveNetHuman image synthesisHWROCRComputer visionSpeech synthesis15.aiElevenLabsSpeech recognitionWhisperFacial recognitionAlphaFoldText-to-image modelsAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyRecraftStable DiffusionText-to-video modelsDream MachineRunway GenHailuo AIKlingSoraVeoMusic generationRiffusionSuno AIUdioTextWord2vecSeq2seqGloVeBERTT5LlamaChinchilla AIPaLMGPT123JChatGPT44oo1o34.54.1o4-mini5ClaudeGeminiGemini (language model)GemmaGrokLaMDABLOOMDBRXProject DebaterIBM WatsonIBM WatsonxGranitePanGu-\u03a3DeepSeekQwenDecisionalAlphaGoAlphaZeroOpenAI FiveSelf-driving carMuZeroAction selectionAutoGPTRobot controlPeopleAlan TuringWarren Sturgis McCullochWalter PittsJohn von NeumannChristopher D. ManningClaude ShannonShun'ichi AmariKunihiko FukushimaTakeo KanadeMarvin MinskyJohn McCarthyNathaniel RochesterAllen NewellCliff ShawHerbert A. SimonOliver SelfridgeFrank RosenblattBernard WidrowJoseph WeizenbaumSeymour PapertSeppo LinnainmaaPaul WerbosGeoffrey HintonJohn HopfieldJ\u00fcrgen SchmidhuberYann LeCunYoshua BengioLotfi A. ZadehStephen GrossbergAlex GravesJames GoodnightAndrew NgFei-Fei LiAlex KrizhevskyIlya SutskeverOriol VinyalsQuoc V. LeIan GoodfellowDemis HassabisDavid SilverAndrej KarpathyAshish VaswaniNoam ShazeerAidan GomezJohn SchulmanMustafa SuleymanJan LeikeDaniel KokotajloFran\u00e7ois CholletArchitecturesNeural Turing machineDifferentiable neural computerTransformerVision transformer (ViT)Recurrent neural network (RNN)Long short-term memory (LSTM)Gated recurrent unit (GRU)Echo state networkMultilayer perceptron (MLP)Convolutional neural network (CNN)Residual neural network (RNN)Highway networkMambaAutoencoderVariational autoencoder (VAE)Generative adversarial network (GAN)Graph neural network (GNN)Category.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesNationalUnited StatesFranceBnF dataIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Intelligent_agent&oldid=1319453939\"", "tags": ["en.wikipedia.org", "wiki", "intelligent", "agent"]}
{"url": "https://en.wikipedia.org/wiki/Software_agent", "title": null, "text": "Computer program acting for a user.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onMulti-agent systemsMulti-agent simulationIn computational economicsIn biologyIn social simulationModeling softwareAgent-oriented programmingAuto-GPTBotnetsFIPAPlatforms for software agentsJADEJACKGORITESoftware agent\nRelatedDistributed artificial intelligenceMulti-agent pathfindingMulti-agent planningMulti-agent reinforcement learningSelf-propelled particlesSwarm robotics.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteIn computer science, a software agent is a computer program that acts for a user or another program in a relationship of agency.\nThe term agent is derived from the Latinagere (to do): an agreement to act on one's behalf. Such \"action on behalf of\" implies the authority to decide which, if any, action is appropriate.[1][2] Some agents are colloquially known as bots, from robot. They may be embodied, as when execution is paired with a robot body, or as software such as a chatbot executing on a computer, such as a mobile device, e.g. Siri. Software agents may be autonomous or work together with other agents or people. Software agents interacting with people (e.g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo).\nRelated and derived concepts include intelligent agents (in particular exhibiting some aspects of artificial intelligence, such as reasoning), autonomous agents (capable of modifying the methods of achieving their objectives), distributed agents (being executed on physically distinct computers), multi-agent systems (distributed agents that work together to achieve an objective that could not be accomplished by a single agent acting alone), and mobile agents (agents that can relocate their execution onto different processors).\nConcepts[edit]The basic attributes of an autonomous software agent are that agents:\nare not strictly invoked for a task, but activate themselves,may reside in wait status on a host, perceiving context,may get to run status on a host upon starting conditions,do not require interaction of user,may invoke other tasks including communication.Nwana's Category of Software AgentThe concept of an agent provides a convenient and powerful way to describe a complex software entity that is capable of acting with a certain degree of autonomy in order to accomplish tasks on behalf of its host. But unlike objects, which are defined in terms of methods and attributes, an agent is defined in terms of its behavior.[3]Various authors have proposed different definitions of agents, these commonly include concepts such as:\npersistence: code is not executed on demand but runs continuously and decides for itself when it should perform some activity;autonomy: agents have capabilities of task selection, prioritization, goal-directed behavior, decision-making without human intervention;social ability: agents are able to engage other components through some sort of communication and coordination, they may collaborate on a task;reactivity: agents perceive the context in which they operate and react to it appropriately.Distinguishing agents from programs[edit]All agents are programs, but not all programs are agents. Contrasting the term with related concepts may help clarify its meaning. Franklin & Graesser (1997)[4] discuss four key notions that distinguish agents from arbitrary programs: reaction to the environment, autonomy, goal-orientation and persistence.\nIntuitive distinguishing agents from objects[edit]Agents are more autonomous than objects.Agents have flexible behavior: reactive, proactive, social.Agents have at least one thread of control but may have more.[5]Distinguishing agents from expert systems[edit]Expert systems are not coupled to their environment.Expert systems are not designed for reactive, proactive behavior.Expert systems do not consider social ability.[5]Distinguishing intelligent software agents from intelligent agents in AI[edit]Intelligent agents (also known as rational agents) are not just computer programs: they may also be machines, human beings, communities of human beings (such as firms) or anything that is capable of goal-directed behavior.(Russell & Norvig 2003) harv error: no target: CITEREFRussellNorvig2003 (help)Impact of software agents[edit]Software agents may offer various benefits to their end users by automating complex or repetitive tasks.[6] However, there are organizational and cultural impacts of this technology that need to be considered prior to implementing software agents.\nOrganizational impact[edit]Work contentment and job satisfaction impact[edit]People like to perform easy tasks providing the sensation of success unless the repetition of the simple tasking is affecting the overall output. In general implementing software agents to perform administrative requirements provides a substantial increase in work contentment, as administering their own work does never please the worker. The effort freed up serves for a higher degree of engagement in the substantial tasks of individual work. Hence, software agents may provide the basics to implement self-controlled work, relieved from hierarchical controls and interference.[7] Such conditions may be secured by application of software agents for required formal support.\nCultural impact[edit]The cultural effects of the implementation of software agents include trust affliction, skills erosion, privacy attrition and social detachment. Some users may not feel entirely comfortable fully delegating important tasks to software applications. Those who start relying solely on intelligent agents may lose important skills, for example, relating to information literacy. In order to act on a user's behalf, a software agent needs to have a complete understanding of a user's profile, including his/her personal preferences. This, in turn, may lead to unpredictable privacy issues. When users start relying on their software agents more, especially for communication activities, they may lose contact with other human users and look at the world with the eyes of their agents. These consequences are what agent researchers and users must consider when dealing with intelligent agent technologies.[8]History[edit]The concept of an agent can be traced back to Hewitt's Actor Model (Hewitt, 1977) - \"A self-contained, interactive and concurrently-executing object, possessing internal state and communication capability.\"[citation needed]To be more academic, software agent systems are a direct evolution of Multi-Agent Systems (MAS). MAS evolved from Distributed Artificial Intelligence (DAI), Distributed Problem Solving (DPS) and Parallel AI (PAI), thus inheriting all characteristics (good and bad) from DAI and AI.\nJohn Sculley's 1987 \"Knowledge Navigator\" video portrayed an image of a relationship between end-users and agents. Being an ideal first, this field experienced a series of unsuccessful top-down implementations, instead of a piece-by-piece, bottom-up approach. The range of agent types is now (from 1990) broad: WWW, search engines, etc.\nExamples  of intelligent software agents[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Intelligent agentBuyer agents (shopping bots)[edit]Buyer agents[9] travel around a network (e.g. the internet) retrieving information about goods and services. These agents, also known as 'shopping bots', work very efficiently for commodity products such as CDs, books, electronic components, and other one-size-fits-all products. Buyer agents are typically optimized to allow for digital payment services used in e-commerce and traditional businesses.[10]User agents (personal agents)[edit]User agents, or personal agents, are intelligent agents that take action on your behalf. In this category belong those intelligent agents that already perform, or will shortly perform, the following tasks:\nCheck your e-mail, sort it according to the user's order of preference, and alert you when important emails arrive.Play computer games as your opponent or patrol game areas for you.Assemble customized news reports for you. There are several versions of these, including CNN.Find information for you on the subject of your choice.Fill out forms on the Web automatically for you, storing your information for future referenceScan Web pages looking for and highlighting text that constitutes the \"important\" part of the information thereDiscuss topics with you ranging from your deepest fears to sportsFacilitate with online job search duties by scanning known job boards and sending the resume to opportunities who meet the desired criteriaProfile synchronization across heterogeneous social networksMonitoring-and-surveillance (predictive) agents[edit]Monitoring and surveillance agents are used to observe and report on equipment, usually computer systems. The agents may keep track of company inventory levels, observe competitors' prices and relay them back to the company, watch stock manipulation by insider trading and rumors, etc.\nService monitoringFor example, NASA's Jet Propulsion Laboratory has an agent that monitors inventory, planning, schedules equipment orders to keep costs down, and manages food storage facilities. These agents usually monitor complex computer networks that can keep track of the configuration of each computer connected to the network.\nA special case of monitoring-and-surveillance agents are organizations of agents used to automate decision-making process during tactical operations. The agents monitor the status of assets (ammunition, weapons available, platforms for transport, etc.) and receive goals from higher level agents. The agents then pursue the goals with the assets at hand, minimizing expenditure of the assets while maximizing goal attainment.\nData-mining agents[edit]This agent uses information technology to find trends and patterns in an abundance of information from many different sources. The user can sort through this information in order to find whatever information they are seeking.\nA data mining agent operates in a data warehouse discovering information. A 'data warehouse' brings together information from many different sources. \"Data mining\" is the process of looking through the data warehouse to find information that you can use to take action, such as ways to increase sales or keep customers who are considering defecting.\n'Classification' is one of the most common types of data mining, which finds patterns in information and categorizes them into different classes. Data mining agents can also detect major shifts in trends or a key indicator and can detect the presence of new information and alert you to it. For example, the agent may detect a decline in the construction industry for an economy; based on this relayed information construction companies will be able to make intelligent decisions regarding the hiring/firing of employees or the purchase/lease of equipment in order to best suit their firm.\nNetworking and communicating agents[edit]Some other examples of current intelligent agents include some spam filters, game bots, and server monitoring tools. Search engine indexing bots also qualify as intelligent agents.\nUser agent - for browsing the World Wide WebBuyer Agent [11]- As of 2025, advanced AI agents enable agentic commerce, autonomously handling product discovery, price comparison, and transactions in platforms like OpenAI integrations[12].Mail transfer agent - For serving E-mail, such as Microsoft Outlook. Why? It communicates with the POP3 mail server, without users having to understand POP3 command protocols. It even has rule sets that filter mail for the user, thus sparing them the trouble of having to do it themselves.SNMP agentIn Unix-style networking servers, httpd is an HTTP daemon that implements the Hypertext Transfer Protocol at the root of the World Wide WebManagement agents used to manage telecom devicesCrowd simulation for safety planning or 3D computer graphics,Wireless beaconing agent is a simple process hosted single tasking entity for implementing wireless lock or electronic leash in conjunction with more complex software agents hosted e.g. on wireless receivers.Use of autonomous agents (deliberately equipped with noise) to optimize coordination in groups online.[13]Software development agents (aka software bots)[edit]Main article: Software botSoftware bots are becoming important in software engineering.[14]Security agents[edit]Agents are also used in software security application to intercept, examine and act on various types of content.  Example include: \nData Loss Prevention (DLP) Agents[15] - examine user operations on a computer or network, compare with policies specifying allowed actions, and take appropriate action (e.g. allow, alert, block).  The more comprehensive DLP agents can also be used to perform EDR functions.Endpoint Detection and Response (EDR) Agents - monitor all activity on an endpoint computer in order to detect and respond to malicious activitiesCloud Access Security Broker (CASB) Agents - similar to DLP Agents, however examining traffic going to cloud applicationsDesign issues[edit]Issues to consider in the development of agent-based systems include \nhow tasks are scheduled and how synchronization of tasks is achievedhow tasks are prioritized by agentshow agents can collaborate, or recruit resources,how agents can be re-instantiated in different environments, and how their internal state can be stored,how the environment will be probed and how a change of environment leads to behavioral changes of the agentshow messaging and communication can be achieved,what hierarchies of agents are useful (e.g. task execution agents, scheduling agents, resource providers ...).For software agents to work together efficiently they must share semantics of their data elements. This can be done by having computer systems publish their metadata.\nThe definition of agent processing can be approached from two interrelated directions:\ninternal state processing and ontologies for representing knowledgeinteraction protocols \u2013 standards for specifying communication of tasksAgent systems are used to model real-world systems with concurrency or parallel processing.\nAgent Machinery \u2013 Engines of various kinds, which support the varying degrees of intelligenceAgent Content \u2013 Data employed by the machinery in Reasoning and LearningAgent Access \u2013 Methods to enable the machinery to perceive content and perform actions as outcomes of ReasoningAgent Security \u2013 Concerns related to distributed computing, augmented by a few special concerns related to agentsThe agent uses its access methods to go out into local and remote databases to forage for content. These access methods may include setting up news stream delivery to the agent, or retrieval from bulletin boards, or using a spider to walk the Web. The content that is retrieved in this way is probably already partially filtered\u00a0\u2013 by the selection of the newsfeed or the databases that are searched. The agent next may use its detailed searching or language-processing machinery to extract keywords or signatures from the body of the content that has been received or retrieved. This abstracted content (or event) is then passed to the agent's Reasoning or inferencing machinery in order to decide what to do with the new content. This process combines the event content with the rule-based or knowledge content provided by the user. If this process finds a good hit or match in the new content, the agent may use another piece of its machinery to do a more detailed search on the content. Finally, the agent may decide to take an action based on the new content; for example, to notify the user that an important event has occurred. This action is verified by a security function and then given the authority of the user. The agent makes use of a user-access method to deliver that message to the user. If the user confirms that the event is important by acting quickly on the notification, the agent may also employ its learning machinery to increase its weighting for this kind of event.\nBots can act on behalf of their creators to do good as well as bad. There are a few ways which bots can be created to demonstrate that they are designed with the best intention and are not built to do harm. This is first done by having a bot identify itself in the user-agent HTTP header when communicating with a site. The source IP address must also be validated to establish itself as legitimate. Next, the bot must also always respect a site's robots.txt file since it has become the standard across most of the web. And like respecting the robots.txt file, bots should shy away from being too aggressive and respect any crawl delay instructions.[16]Notions and frameworks for agents[edit]DAML (DARPA Agent Markup Language)3APL (Artificial Autonomous Agents Programming Language)GOAL agent programming languageOpen Agent Architecture (OAA)Web Ontology Language (OWL)daemons in Unix-like systems.Java Agent Template (JAT)Java Agent Development Framework (JADE)SARL agent programming language (arguably an Actor and not Agent oriented paradigm)See also[edit]Agent architectureChatbotData loss preventionEndpoint detection and responseSoftware botReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Nwana, H.\u00a0S. (1996). \"Software Agents: An Overview\". Knowledge Engineering Review. 21 (3): 205\u2013244. CiteSeerX\u00a010.1.1.50.660. doi:10.1017/s026988890000789x. S2CID\u00a07839197.^Schermer, B.\u00a0W. (2007). Software agents, surveillance, and the right to privacy: A legislative framework for agent-enabled surveillance(paperback). Vol.\u00a021. Leiden University Press. pp.\u00a0140, 205\u2013244. hdl:1887/11951. ISBN\u00a0978-0-596-00712-6. Retrieved October 30, 2012.^Wooldridge, M.; Jennings, N. R. (1995). \"Intelligent agents: theory and practice\". Knowledge Engineering Review. 10 (2): 115\u2013152. doi:10.1017/S0269888900008122. hdl:10044/1/35975.^Franklin, S.; Graesser, A. (1996). \"Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents\". Intelligent Agents III Agent Theories, Architectures, and Languages. Lecture Notes in Computer Science. Vol.\u00a01193. University of Memphis, Institute for Intelligent Systems. pp.\u00a021\u201335. doi:10.1007/BFb0013570. ISBN\u00a0978-3-540-62507-0.^ abWooldridge, Michael J. (2002). An Introduction to Multiagent Systems. New York: John Wiley & Sons. p.\u00a027. ISBN\u00a0978-0-471-49691-5.^Serenko, A.; Detlor, B. (2004). \"Intelligent agents as innovations\"(PDF). Artificial Intelligence & Society. 18 (4): 364\u2013381.^Adonisi, M. (2003). \"The relationship between Corporate Entrepreneurship, Market Orientation, Organisational Flexibility and Job satisfaction\"(PDF) (Diss.). Fac.of Econ.and Mgmt.Sci., Univ.of Pretoria.^Serenko, A.; Ruhi, U.; Cocosila, M. (2007). \"Unplanned effects of intelligent agents on Internet use: Social Informatics approach\"(PDF). Artificial Intelligence & Society. 21 (1\u20132): 141\u2013166.^Haag, Stephen; Cummings, Maeve; Dawkins, James (2006). Management Information Systems for the Information Age. pp.\u00a0224\u2013228.^\"Maximize Your Business Impact | How to Use Facebook Chatbots\". Keystone Click. August 26, 2016. Retrieved September 7, 2017.^\"Introducing AgentKit\". openai.com. October 29, 2025. Retrieved October 31, 2025.^\"Introducing AgentKit\". openai.com. October 29, 2025. Retrieved October 31, 2025.^Shirado, Hirokazu; Christakis, Nicholas A (2017). \"Locally noisy autonomous agents improve global human coordination in network experiments\". Nature. 545 (7654): 370\u2013374. Bibcode:2017Natur.545..370S. doi:10.1038/nature22332. PMC\u00a05912653. PMID\u00a028516927.^Lebeuf, Carlene; Storey, Margaret-Anne; Zagalsky, Alexey (2018). \"Software Bots\". IEEE Software. 35: 18\u201323. doi:10.1109/MS.2017.4541027. S2CID\u00a031931036.^\"Enterprise IP and DLP Software | Digital Guardian\"(PDF). info.digitalguardian.com. Retrieved December 25, 2024.^\"How to Live by the Code of Good Bots\". DARKReading from Information World. September 27, 2017. Retrieved November 14, 2017.External links[edit]Software Agents: An OverviewArchived July 17, 2011, at the Wayback Machine, Hyacinth S. Nwana. Knowledge Engineering Review, 11(3):1\u201340, September 1996. Cambridge University Press.FIPA The Foundation for Intelligent Physical AgentsJADE Java Agent Developing Framework, an Open Source framework developed by Telecom Italia LabsEuropean Software-Agent Research CenterArchived 2017-09-14 at the Wayback MachineJAFIMA JAFIMA: A Java based Agent Framework for Intelligent and Mobile AgentsSemanticAgent An Open Source framework to develop SWRL based Agents on top of JADEMobile-C A Multi-Agent Platform for Mobile C/C++ Agents.HLL High-Level Logic (HLL) Open Source Project.Open source project KATO for PHP and Java developers to write software agents\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Software_agent&oldid=1319667475\"", "tags": ["en.wikipedia.org", "wiki", "software", "agent"]}
{"url": "https://en.wikipedia.org/wiki/Robotic_process_automation", "title": null, "text": "Form of business process automation technology.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This article may require cleanup to meet Wikipedia's quality standards. The specific problem is: It's disorganized, with pieces thrown together in random places and content placed in sections that is unrelated to the sections' headings; also, lack of clarity and repetitiveness. Please help improve this article if you can.  (February 2025) (Learn how and when to remove this message).mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onAutomationAutomation in generalBankingBuildingHomeHighway systemLaboratoryLibraryBroadcastMixPool cleanerPop musicReasoningSemi-automationTelephone\nAttendantSwitchboardTeller machineVehicularVending machineRobotics and robotsDomesticVacuum cleanerRoombaLawn mowerGuided vehicleIndustrialPaintODD\nImpact of automationManumationOOLBiasSelf-driving carsTechnological unemploymentJobless recoveryPost-work societyThreat\nTrade shows and awardsASP-DACDACDATEIEEE Robotics and Automation AwardICCAD.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteRobotic process automation (RPA) is a form of business process automation that is based on software robots (bots) or artificial intelligence (AI) agents.[1] RPA should not be confused with artificial intelligence as it is based on automation technology following a predefined workflow.[2]  It is sometimes referred to as software robotics (not to be confused with robot software).\nIn traditional workflowautomation tools, a software developer produces a list of actions to automate a task and interface to the back end system using internal application programming interfaces (APIs) or dedicated scripting language. In contrast, RPA systems develop the action list by watching the user perform that task in the application's graphical user interface (GUI) and then perform the automation by repeating those tasks directly in the GUI. This can lower the barrier to the use of automation in products that might not otherwise feature APIs for this purpose.\nRPA tools have strong technical similarities to graphical user interface testing tools. These tools also automate interactions with the GUI, and often do so by repeating a set of demonstration actions performed by a user. RPA tools differ from such systems in that they allow data to be handled in and between multiple applications, for instance, receiving email containing an invoice, extracting the data, and then typing that into a bookkeeping system.\nHistoric evolution[edit]The typical benefits of robotic automation include reduced cost; increased speed, accuracy, and consistency; improved quality and scalability of production. Automation can also provide extra security, especially for sensitive data and financial services.\nAs a form of automation, the concept has been around for a long time in the form of screen scraping, so long that to early PC users the reminder of it often blurs with the idea of malware infection.[3] Yet compared to screen scraping, RPA is much more extensible, consisting of API integration into other enterprise applications, connectors into ITSM systems, terminal services and even some types of AI (e.g. machine learning) services such as image recognition. It is considered to be a significant technological evolution in the sense that new software platforms are emerging which are sufficiently mature, resilient, scalable and reliable to make this approach viable for use in large enterprises[4] (who would otherwise be reluctant due to perceived risks to quality and reputation).\nA principal barrier to the adoption of self-service is often technological: it may not always be feasible or economically viable to retrofit new interfaces onto existing systems. Moreover, organisations may wish to layer a variable and configurable set of process rules on top of the system interfaces which may vary according to market offerings and the type of customer. This only adds to the cost and complexity of the technological implementation. Robotic automation software provides a pragmatic means of deploying new services in this situation, where the robots simply mimic the behaviour of humans to perform the back-end transcription or processing. The relative affordability of this approach arises from the fact that no new IT transformation or investment is required; instead the software robots simply leverage greater use out of existing IT assets.\nUse[edit]The hosting of RPA services also aligns with the metaphor of a software robot, with each robotic instance having its own virtual workstation, much like a human worker. The robot uses keyboard and mouse controls to take actions and execute automations. Normally, all of these actions take place in a virtual environment and not on screen; the robot does not need a physical screen to operate, rather it interprets the screen display electronically. The scalability of modern solutions based on architectures such as these owes much to the advent of virtualization technology, without which the scalability of large deployments would be limited by the available capacity to manage physical hardware and by the associated costs. The implementation of RPA in business enterprises has shown dramatic cost savings when compared to traditional non-RPA solutions.[5]There are however several risks with RPA. Criticism includes risks of stifling innovation and creating a more complex maintenance environment of existing software that now needs to consider the use of graphical user interfaces in a way they weren't intended to be used.[6]Impact on employment[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Technological unemployment and AutomationAccording to Harvard Business Review, most operations groups adopting RPA have promised their employees that automation would not result in layoffs.[7] Instead, workers have been redeployed to do more interesting work. One academic study highlighted that knowledge workers did not feel threatened by automation: they embraced it and viewed the robots as team-mates.[8] The same study highlighted that, rather than resulting in a lower \"headcount\", the technology was deployed in such a way as to achieve more work and greater productivity with the same number of people.\nConversely, however, some analysts proffer that RPA represents a threat to the business process outsourcing (BPO) industry.[9] The thesis behind this notion is that RPA will enable enterprises to \"repatriate\" processes from offshore locations into local data centers, with the benefit of this new technology. The effect, if true, will be to create high-value jobs for skilled process designers in onshore locations (and within the associated supply chain of IT hardware, data center management, etc.) but to decrease the available opportunity to low-skilled workers offshore. On the other hand, this discussion appears to be healthy ground for debate as another academic study was at pains to counter the so-called \"myth\" that RPA will bring back many jobs from offshore.[8]RPA actual use[edit]Banking and finance process automationMortgage and lending processesCustomer care automationeCommerce merchandising operationsSocial media marketingOptical character recognition applicationsData extraction processFixed automation process[clarification needed]Manual and Repetative tasks automationImpact on society[edit]Academic studies[10][11] project that RPA, among other technological trends, is expected to drive a new wave of productivity and efficiency gains in the global labour market. Although not directly attributable to RPA alone, Oxford University conjectures that up to 35% of all jobs might be automated by 2035.[10]There are geographic implications to the trend in robotic automation. In the example above where an offshored process is \"repatriated\" under the control of the client organization (or even displaced by a business process outsourcer) from an offshore location to a data centre, the impact will be a deficit in economic activity to the offshore location and an economic benefit to the originating economy. On this basis, developed economies \u2013 with skills and technological infrastructure to develop and support a robotic automation capability \u2013 can be expected to achieve a net benefit from the trend.\nIn a TEDx talk[12] hosted by University College London (UCL), entrepreneur David Moss explains that digital labour in the form of RPA is likely to revolutionize the cost model of the services industry by driving the price of products and services down, while simultaneously improving the quality of outcomes and creating increased opportunity for the personalization of services.\nIn a separate TEDx in 2019 talk,[13] Japanese business executive, and former CIO of Barclays bank, Koichi Hasegawa noted that digital robots can be a positive effect on society if we start using a robot with empathy to help every person. He provides a case study of the Japanese insurance companies \u2013 Sompo Japan and Aioi \u2013 both of whom introduced bots to speed up the process of insurance pay-outs in past massive disaster incidents.\nMeanwhile, Professor Willcocks, author of the LSE paper[11] cited above, speaks of increased job satisfaction and intellectual stimulation, characterising the technology as having the ability to \"take the robot out of the human\",[14] a reference to the notion that robots will take over the mundane and repetitive portions of people's daily workload, leaving them to be used in more interpersonal roles or to concentrate on the remaining, more meaningful, portions of their day.\nIt was also found in a 2021 study observing the effects of robotization in Europe that, the gender pay gap increased at a rate of .18% for every 1% increase in robotization of a given industry.[15]Unassisted RPA[edit]Unassisted RPA, or RPAAI,[16][17] is the next generation of RPA related technologies. Technological advancements around artificial intelligence allow a process to be run on a computer without needing input from a user.\nHyperautomation[edit]Hyperautomation is the application of advanced technologies like RPA, artificial intelligence, machine learning (ML) and process mining to augment workers and automate processes in ways that are significantly more impactful than traditional automation capabilities.[18][19][20] Hyperautomation is the combination of technologies that allow faster application authorship (like low-code and no-code) with automation technologies that coordinate different worker types (i.e. human and artificial) for intelligent and strategic workflow optimization.[21][22]Gartner's report notes that this trend was kicked off with robotic process automation (RPA). The report notes that, \"RPA alone is not hyperautomation. Hyperautomation requires a combination of tools to help support replicating pieces of where the human is involved in a task.\"[23]Outsourcing[edit]Back office clerical processes outsourced by large organisations - particularly those sent offshore - tend to be simple and transactional in nature, requiring little (if any) analysis or subjective judgement. This would seem to make an ideal starting point for organizations beginning to adopt robotic automation for the back office. Whether client organisations choose to take outsourced processes back \"in house\" from their business process outsourcing (BPO) providers, thus representing a threat to the future of the BPO business,[24] or whether the BPOs implement such automations on their clients' behalf may well depend on a number of factors.\nConversely however, a BPO provider may seek to effect some form of client lock-in by means of automation. By removing cost from a business operation, where the BPO provider is considered to be the owner of the intellectual property and physical implementation of a robotic automation solution (perhaps in terms of hardware, ownership of software licences, etc.), the provider can make it very difficult for the client to take a process back \"in house\" or elect a new BPO provider. This effect occurs as the associated cost savings made through automation would - temporarily at least - have to be reintroduced to the business whilst the technical solution is reimplemented in the new operational context.\nThe geographically agnostic nature of software means that new business opportunities may arise for those organisations that have a political or regulatory impediment to offshoring or outsourcing. A robotised automation can be hosted in a data centre in any jurisdiction and this has two major consequences for BPO providers. Firstly, for example, a sovereign government may not be willing or legally able to outsource the processing of tax affairs and security administration. On this basis, if robots are compared to a human workforce, this creates a genuinely new opportunity for a \"third sourcing\" option, after the choices of onshore vs. offshore. Secondly, and conversely, BPO providers have previously relocated outsourced operations to different political and geographic territories in response to changing wage inflation and new labour arbitrage opportunities elsewhere. By contrast, a data centre solution would seem to offer a fixed and predictable cost base that, if sufficiently low in cost on a robot vs. human basis,  would seem to eliminate any potential need or desire to continually relocate operational bases.\nLimitations of robotic process automation[edit]While robotic process automation has many benefits including cost efficiency and consistency in performance, it also has some limitations. Current RPA solutions demand continual technical support to handle system changes, therefore it lacks the ability to autonomously adapt to new conditions. Because of this limitation, the system sometimes needs manual reconfiguration, which in turn has an effect on efficiency.[25]Difference between RPA and AI[edit]RPA is based on automation technology following a predefined workflow, and artificial intelligence is data-driven and focuses on processing information to make predictions. Therefore, there is a distinct difference between how the two systems operate. AI aims to mimic human intelligence, whereas RPA is focused on reproducing tasks that are typically human-directed.[26] Moreover, RPA could also be explained as virtual robots that take over routinized human work, it can identify data by interpreting the underlying tags. RPA, therefore, is based on machine learning, whereas AI utilizes self-learning technologies.[27]Examples[edit]Voice recognition and digital dictation software linked to join up business processes for straight through processing without manual interventionSpecialised remote infrastructure management software featuring automated investigation and resolution of problems, using robots for the first line IT supportChatbots used by internet retailers and service providers to service customer requests for information. Also used by companies to service employee requests for information from internal databasesPresentation layer automation software, increasingly used by business process outsourcers to displace human labourInteractive voice response (IVR) systems incorporating intelligent interaction with callersSee also[edit]AutomationBusiness process automationReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}AI interns:Software already taking jobs from humans, New Scientist^\"What is Robotic Process Automation (RPA)? | IBM\". www.ibm.com. IBM. 27 March 2024. Retrieved 25 April 2024.^\"what-is-screen-scraping-malware\". www.logixconsulting.com. Retrieved 31 March 2025.^Robotic Automation Emerges as a Threat to Traditional Low-Cost Outsourcing, HfS Research, archived from the original on 2015-09-21^\"10 Facts About The Big Four & Secret Tips To Be Recruited | LiveWell\"(PDF). www.kpmg-institutes.com. 16 November 2019. Retrieved 2025-02-24.^DeBrusk, Chris (24 October 2017). \"Five Robotic Process Automation Risks to Avoid\". MIT Sloan Management Review. Retrieved 28 June 2018.^Lacity, Mary C.; Willcocks, Leslie (19 June 2015), \"What knowledge workers stand to gain from automation\", Harvard Business Review^ abRobotic Process Automation at Xchanging(PDF), London School of Economics^Gartner Predicts 2014: Business and IT Services Are Facing the End of Outsourcing as We Know It, Gartner^ abTHE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION?, archived from the original on 2016-02-05^ abVieira, Helena (29 September 2015). \"Nine likely scenarios arising from the growing use of robots\". LSE Business Review.^White Collar Robots: The Virtual Workforce, TEDx Talks, 28 January 2016^RPA Live, BTOPEX^Jee, Charlotte, \"Technology is not about to steal your job\", Techworld, www.techworld.com^Aksoy, Cevat Giray; \u00d6zcan, Berkay; Philipp, Julia (May 2021). \"Robots and the gender pay gap in Europe\"(PDF). European Economic Review. 134 103693. doi:10.1016/j.euroecorev.2021.103693. S2CID\u00a0233835919.^Technologies, AIMDek (2018-08-29). \"Evolution of Robotic Process Automation (RPA): The Path to Cognitive RPA\". Medium. Retrieved 2019-01-28.^\"RPAAI - Robotic Process Automation\". rpaai.com (in Dutch). Archived from the original on 2020-08-15. Retrieved 2020-05-06.^\"Gartner Top 10 Strategic Technology Trends for 2020\". Gartner.^\"Gartner Tech Trends 2020\". Gigabit Magazine. Archived from the original on 2019-12-03. Retrieved 2019-10-30.^\"Hyperautomation among top 10 technology trends for 2020\". Tech Republic. 21 October 2019.^Lindsay James (2020-03-18). \"What is hyperautomation and how will it transform business?\". ITPro. Retrieved 2024-09-16.^Calkins, Matt (2020). Hyperautomation.^\"Gartner Announces Top 10 Strategic Technology Trends For 2020\". Forbes.^IT Robots May Mean the End of Offshore Outsourcing, CIO Magazine, archived from the original on 2014-02-16, retrieved 2020-05-02^Yatskiv, Nataliya; Yatskiv, Solomiya; Vasylyk, Anatoliy (2020). \"Method of Robotic Process Automation in Software Testing Using Artificial Intelligence\". 2020 10th International Conference on Advanced Computer Information Technologies (ACIT). pp.\u00a0501\u2013504. doi:10.1109/ACIT49673.2020.9208806. ISBN\u00a0978-1-7281-6759-6.^\"What is robotic process automation (RPA)?\". www.IBM.com. IBM. 27 March 2024. Retrieved 25 April 2024.^Andersson, Christoffer; Hallin, Anette; Ivory, Chris (January 2022). \"Unpacking the digitalisation of public services: Configuring work during automation in local government\". Government Information Quarterly. 39 (1) 101662. doi:10.1016/j.giq.2021.101662.Further reading[edit].mw-parser-output .refbegin{margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}@media screen{.mw-parser-output .refbegin{font-size:90%}}  \nvan der Aalst, Wil M. P.; Bichler, Martin; Heinzl, Armin (August 2018). \"Robotic Process Automation\". Business & Information Systems Engineering. 60 (4): 269\u2013272. doi:10.1007/s12599-018-0542-4.Syed, Rehan; Suriadi, Suriadi; Adams, Michael; Bandara, Wasana; Leemans, Sander J.J.; Ouyang, Chun; ter Hofstede, Arthur H.M.; van de Weerd, Inge; Wynn, Moe Thandar; Reijers, Hajo A. (February 2020). \"Robotic Process Automation: Contemporary themes and challenges\"(PDF). Computers in Industry. 115 103162. doi:10.1016/j.compind.2019.103162. hdl:1874/395182.Aguirre, Santiago; Rodriguez, Alejandro (2017). \"Automation of a Business Process Using Robotic Process Automation (RPA): A Case Study\". Applied Computer Sciences in Engineering. Communications in Computer and Information Science. Vol.\u00a0742. pp.\u00a065\u201371. doi:10.1007/978-3-319-66963-2_7. ISBN\u00a0978-3-319-66962-5.Agostinelli, Simone; Marrella, Andrea; Mecella, Massimo (2020). Towards Intelligent Robotic Process Automation for BPMers (Preprint). arXiv:2001.00804.Willcocks, Leslie; Lacity, Mary; Craig, Andrew (May 2017). \"Robotic Process Automation: Strategic Transformation Lever for Global Business Services?\"(PDF). Journal of Information Technology Teaching Cases. 7 (1): 17\u201328. doi:10.1057/s41266-016-0016-9.Leshob, Abderrahmane; Bourgouin, Audrey; Renard, Laurent (2018). \"Towards a Process Analysis Approach to Adopt Robotic Process Automation\". 2018 IEEE 15th International Conference on e-Business Engineering (ICEBE). pp.\u00a046\u201353. doi:10.1109/ICEBE.2018.00018. ISBN\u00a0978-1-5386-7992-0.Santos, Filipa; Pereira, R\u00faben; Vasconcelos, Jos\u00e9 Braga (20 September 2019). \"Toward robotic process automation implementation: an end-to-end perspective\". Business Process Management Journal. 26 (2): 405\u2013420. doi:10.1108/BPMJ-12-2018-0380. hdl:10071/20913.Chakraborti, Tathagata; Isahagian, Vatche; Khalaf, Rania; Khazaeni, Yasaman; Muthusamy, Vinod; Rizk, Yara; Unuvar, Merve (2020). \"From Robotic Process Automation to Intelligent Process Automation: \u2013 Emerging Trends \u2013\". Business Process Management: Blockchain and Robotic Process Automation Forum. Lecture Notes in Business Information Processing. Vol.\u00a0393. pp.\u00a0215\u2013228. doi:10.1007/978-3-030-58779-6_15. ISBN\u00a0978-3-030-58778-9.Enriquez, J. G.; Jimenez-Ramirez, A.; Dominguez-Mayo, F. J.; Garcia-Garcia, J. A. (2020). \"Robotic Process Automation: A Scientific and Industrial Systematic Mapping Study\". IEEE Access. 8: 39113\u201339129. Bibcode:2020IEEEA...839113E. doi:10.1109/ACCESS.2020.2974934.Agostinelli, Simone; Marrella, Andrea; Mecella, Massimo (2019). \"Research Challenges for Intelligent Robotic Process Automation\". Business Process Management Workshops. Lecture Notes in Business Information Processing. Vol.\u00a0362. pp.\u00a012\u201318. doi:10.1007/978-3-030-37453-2_2. ISBN\u00a0978-3-030-37452-5.Ratia, M.; Myll\u00e4rniemi, J.; Helander, N. (2018). \"Robotic Process Automation - Creating Value by Digitalizing Work in the Private Healthcare?\". Proceedings of the 22nd International Academic Mindtrek Conference. pp.\u00a0222\u2013227. doi:10.1145/3275116.3275129. ISBN\u00a0978-1-4503-6589-5.Vincent, Nishani Edirisinghe; Igou, Amy; Burns, Mary B. (September 2020). \"Preparing for the Robots: A Proposed Course in Robotic Process Automation\". Journal of Emerging Technologies in Accounting. 17 (2): 75\u201391. doi:10.2308/JETA-2020-020.Chacon Montero, Jesus; Jimenez Ramirez, Andres; Gonzalez Enriquez, Jose (2019). \"Towards a Method for Automated Testing in Robotic Process Automation Projects\". 2019 IEEE/ACM 14th International Workshop on Automation of Software Test (AST). pp.\u00a042\u201347. doi:10.1109/AST.2019.00012. hdl:11441/134243. ISBN\u00a0978-1-7281-2237-3.Kobayashi, Toru; Arai, Kenichi; Imai, Tetsuo; Tanimoto, Shigeaki; Sato, Hiroyuki; Kanai, Atsushi (2019). \"Communication Robot for Elderly Based on Robotic Process Automation\". 2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC). pp.\u00a0251\u2013256. doi:10.1109/COMPSAC.2019.10215. ISBN\u00a0978-1-7281-2607-4.Herm, Lukas-Valentin; Janiesch, Christian; Helm, Alexander; Imgrund, Florian; Fuchs, Kevin; Hofmann, Adrian; Winkelmann, Axel (2020). \"A Consolidated Framework for Implementing Robotic Process Automation Projects\". Business Process Management. Lecture Notes in Computer Science. Vol.\u00a012168. pp.\u00a0471\u2013488. doi:10.1007/978-3-030-58666-9_27. ISBN\u00a0978-3-030-58665-2.External links[edit]Jobs, productivity and the great decoupling, by Professor McAfee, Principal Research Scientist at MIT's Center for Digital Business.Rise of the software machines, Economist Magazine.London School of Economics Releases First in a Series of RPA Case Studies, ReutersHumans and Machines: The role of people in technology-driven organisationsArchived 2013-03-19 at the Wayback Machine, Economist Magazine.Robotic Automation as Threat to Traditional Low-Cost Outsourcing, HFS Research.\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robotic_process_automation&oldid=1314554087\"", "tags": ["en.wikipedia.org", "wiki", "robotic", "process", "automation"]}
{"url": "https://en.wikipedia.org/wiki/Chatbot", "title": null, "text": "Program that simulates conversation.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For the bot-creation software, see ChatBot. For bots on Internet Relay Chat, see IRC bot.A virtual assistant chatbotThe 1966 ELIZA chatbot.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}.mw-parser-output .nobold{font-weight:normal}Part of a series onMachine learningand data miningParadigmsSupervised learningUnsupervised learningSemi-supervised learningSelf-supervised learningReinforcement learningMeta-learningOnline learningBatch learningCurriculum learningRule-based learningNeuro-symbolic AINeuromorphic engineeringQuantum machine learningProblemsClassificationGenerative modelingRegressionClusteringDimensionality reductionDensity estimationAnomaly detectionData cleaningAutoMLAssociation rulesSemantic analysisStructured predictionFeature engineeringFeature learningLearning to rankGrammar inductionOntology learningMultimodal learningSupervised learning(classification\u00a0\u2022 regression)Apprenticeship learningDecision treesEnsemblesBaggingBoostingRandom forestk-NNLinear regressionNaive BayesArtificial neural networksLogistic regressionPerceptronRelevance vector machine (RVM)Support vector machine (SVM)ClusteringBIRCHCUREHierarchicalk-meansFuzzyExpectation\u2013maximization (EM)DBSCANOPTICSMean shiftDimensionality reductionFactor analysisCCAICALDANMFPCAPGDt-SNESDLStructured predictionGraphical modelsBayes netConditional random fieldHidden MarkovAnomaly detectionRANSACk-NNLocal outlier factorIsolation forestNeural networksAutoencoderDeep learningFeedforward neural networkRecurrent neural networkLSTMGRUESNreservoir computingBoltzmann machineRestrictedGANDiffusion modelSOMConvolutional neural networkU-NetLeNetAlexNetDeepDreamNeural fieldNeural radiance fieldPhysics-informed neural networksTransformerVisionMambaSpiking neural networkMemtransistorElectrochemical RAM (ECRAM)Reinforcement learningQ-learningPolicy gradientSARSATemporal difference (TD)Multi-agentSelf-playLearning with humansActive learningCrowdsourcingHuman-in-the-loopMechanistic interpretabilityRLHFModel diagnosticsCoefficient of determinationConfusion matrixLearning curveROC curveMathematical foundationsKernel machinesBias\u2013variance tradeoffComputational learning theoryEmpirical risk minimizationOccam learningPAC learningStatistical learningVC theoryTopological deep learningJournals and conferencesAAAIECML PKDDNeurIPSICMLICLRIJCAIMLJMLRRelated articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteA chatbot (originally chatterbot)[1] is a software application or web interface designed to have textual or spoken conversations.[2][3][4] Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\nChatbots have increased in popularity as part of the AI boom of the 2020s, and the popularity of ChatGPT, followed by competitors such as Gemini, Claude and later Grok.  AI chatbots typically use a foundationallarge language model, such as GPT-4 or the Gemini language model, which is fine-tuned for specific uses. \nA major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants.[5]History[edit]Turing test[edit]In 1950, Alan Turing's article \"Computing Machinery and Intelligence\" proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge to the extent that the judge is unable to distinguish reliably\u2014on the basis of the conversational content alone\u2014between the program and a real human.[6]Early chatbots[edit]Joseph Weizenbaum's program ELIZA was first published in 1966. Weizenbaum did not claim that ELIZA was genuinely intelligent, and the introduction to his paper presented it more as a debunking exercise:In artificial intelligence, machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained, its magic crumbles away; it stands revealed as a mere collection of procedures. The observer says to himself \"I could have written that\". With that thought, he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios. The object of this paper is to cause just such a re-evaluation of the program about to be \"explained\". Few programs ever needed it more.[7] ELIZA's key method of operation involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g. by responding to any input that contains the word 'MOTHER' with 'TELL ME MORE ABOUT YOUR FAMILY').[7] Thus an illusion of understanding is generated, even though the processing involved has been merely superficial. ELIZA showed that such an illusion is surprisingly easy to generate because human judges are ready to give the benefit of the doubt when conversational responses are capable of being interpreted as \"intelligent\".\nFollowing ELIZA, psychiatrist Kenneth Colby developed PARRY in 1972.[8][9][10][11]From 1978[12] to some time after 1983,[13] the CYRUS project led by Janet Kolodner constructed a chatbot simulating Cyrus Vance (57th United States Secretary of State). It used case-based reasoning, and updated its database daily by parsing wire news from United Press International. The program was unable to process the news items subsequent to the surprise resignation of Cyrus Vance in April 1980, and the team constructed another chatbot simulating his successor, Edmund Muskie.[14][13]In 1984, an interactive version of the program Racter was released which acted as a chatbot.[15]A.L.I.C.E. was released in 1995. This uses a markup language called AIML,[3] which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so-called, Alicebots. A.L.I.C.E. is a weak AI without any reasoning capabilities. It is based on a similar pattern matching technique as ELIZA in 1966. This is not strong AI, which would require sapience and logical reasoning abilities.\nJabberwacky, released in 1997, learns new responses and context based on real-timeuser interactions, rather than being driven from a static database.\nChatbot competitions focus on the Turing test or more specific goals. Two such annual contests are the Loebner Prize and The Chatterbox Challenge (the latter has been offline since 2015, however, materials can still be found from web archives).[16]DBpedia created a chatbot during the GSoC of 2017.[17] It can communicate through Facebook Messenger.\nModern chatbots based on large language models[edit]A Character.ai conversation with a Wittgenstein chatbotModern chatbots like ChatGPT are often based on large language models called generative pre-trained transformers (GPT). They are based on a deep learning architecture called the transformer, which contains artificial neural networks. They generate text after being trained on a large text corpus.\nApplication[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs to be updated. Please help update this article to reflect recent events or newly available information.  (December 2024)See also: Virtual assistantMessaging apps[edit]Many companies' chatbots run on messaging apps or simply via SMS. They are used for B2C customer service, sales and marketing.[18]In 2016, Facebook Messenger allowed developers to place chatbots on their platform. There were 30,000 bots created for Messenger in the first six months, rising to 100,000 by September 2017.[19]Since September 2017, this has also been as part of a pilot program on WhatsApp. Airlines KLM and Aerom\u00e9xico both announced their participation in the testing;[20][21][22][23] both airlines had previously launched customer services on the Facebook Messenger platform. The Nigerian event platform Demfati, for example, uses its Deeva chatbot on WhatsApp for dedicated B2C functions like ticket purchasing and event voting.[24]The bots usually appear as one of the user's contacts, but can sometimes act as participants in a group chat.\nMany banks, insurers, media companies, e-commerce companies, airlines, hotel chains, retailers, health care providers, government entities, and restaurant chains have used chatbots to answer simple questions, increase customer engagement,[25] for promotion, and to offer additional ways to order from them.[26] Chatbots are also used in market research to collect short survey responses.[27]A 2017 study showed 4% of companies used chatbots.[28] In a 2016 study, 80% of businesses said they intended to have one by 2020.[29]As part of company apps and websites[edit]Previous generations of chatbots were present on company websites, e.g. Ask Jenn from Alaska Airlines which debuted in 2008[30] or Expedia's virtual customer service agent which launched in 2011.[30][31] The newer generation of chatbots includes IBM Watson-powered \"Rocky\", introduced in February 2017 by the New York City-based e-commerce company Rare Carat to provide information to prospective diamond buyers.[32][33]Chatbot sequences[edit]Used by marketers to script sequences of messages, very similar to an autoresponder sequence. Such sequences can be triggered by user opt-in or the use of keywords within user interactions. After a trigger occurs a sequence of messages is delivered until the next anticipated user response. Each user response is used in the decision tree to help the chatbot navigate the response sequences to deliver the correct response message.\nCompany internal platforms[edit]Companies have used chatbots for customer support, human resources, or in Internet-of-Things (IoT) projects. Overstock.com, for one, has reportedly launched a chatbot named Mila to attempt to automate certain processes when customer service employees request sick leave.[34] Other large companies such as Lloyds Banking Group, Royal Bank of Scotland, Renault and Citro\u00ebn are now using chatbots instead of call centres with humans to provide a first point of contact.[citation needed] In large companies, like in hospitals and aviation organizations, chatbots are also used to share information within organizations, and to assist and replace service desks.[citation needed]Customer service[edit]Chatbots have been proposed as a replacement for customer service departments.[35]In 2016, Russia-based Tochka Bank launched a chatbot on Facebook for a range of financial services, including a possibility of making payments.[36] In July 2016, Barclays Africa also launched a Facebook chatbot.[37]Healthcare[edit]See also: Artificial intelligence in healthcareChatbots are also appearing in the healthcare industry.[38][39] A study suggested that physicians in the United States believed that chatbots would be most beneficial for scheduling doctor appointments, locating health clinics, or providing medication information.[40]In 2020, WhatsApp worked with the World Health Organization and the Government of India to make chatbots to answers users' questions on COVID-19.[41][42][43][44]In 2023, US-based National Eating Disorders Association replaced its human helpline staff with a chatbot but had to take it offline after users reported receiving harmful advice from it.[45][46][47]Politics[edit]See also: Government by algorithm \u00a7\u00a0AI politiciansIn New Zealand, the chatbot SAM \u2013 short for Semantic Analysis Machine[48] \u2013 has been developed by Nick Gerritsen of Touchtech.[49] It is designed to share its political thoughts, for example on topics such as climate change, healthcare and education, etc. It talks to people through Facebook Messenger.[50][51][52][53]In 2022, the chatbot \"Leader Lars\" or \"Leder Lars\" was nominated for The Synthetic Party to run in the Danish parliamentary election,[54] and was built by the artist collective Computer Lars.[55] Leader Lars differed from earlier virtual politicians by leading a political party and by not pretending to be an objective candidate.[56] This chatbot engaged in critical discussions on politics with users from around the world.[57]In India, the state government has launched a chatbot for its Aaple Sarkar platform,[58] which provides conversational access to information regarding public services managed.[59][60]Toys[edit]Chatbots have also been incorporated into devices not primarily meant for computing, such as toys.[61]Hello Barbie is an Internet-connected version of the doll that uses a chatbot provided by the company ToyTalk,[62] which previously used the chatbot for a range of smartphone-based characters for children.[63] These characters' behaviors are constrained by a set of rules that in effect emulate a particular character and produce a storyline.[64]The My Friend Cayla doll was marketed as a line of 18-inch (46\u00a0cm) dolls which uses speech recognition technology in conjunction with an Android or iOS mobile app to recognize the child's speech and have a conversation. Like the Hello Barbie doll, it attracted controversy due to vulnerabilities with the doll's Bluetooth stack and its use of data collected from the child's speech.\nIBM's Watson computer has been used as the basis for chatbot-based educational toys for companies such as CogniToys,[61] intended to interact with children for educational purposes.[65]Malicious use[edit]Malicious chatbots are frequently used to fill chat rooms with spam and advertisements by mimicking human behavior and conversations or to entice people into revealing personal information, such as bank account numbers. They were commonly found on Yahoo! Messenger, Windows Live Messenger, AOL Instant Messenger and other instant messaging protocols. There has also been a published report of a chatbot used in a fake personal ad on a dating service's website.[66]Tay, an AI chatbot designed to learn from previous interactions, caused major controversy after being targeted by internet trolls on Twitter. Soon after its launch, the bot was exploited, and with its \"repeat after me\" capability, it started releasing racist, sexist, and controversial responses to Twitter users.[67] This suggests that although the bot learned effectively from experience, adequate protection was not put in place to prevent misuse.[68]If a text-sending algorithm can pass itself off as a human instead of a chatbot, its message would be more credible. Therefore, human-seeming chatbots with well-crafted online identities could start scattering fake news that seems plausible, for instance making false claims during an election. With enough chatbots, it might be even possible to achieve artificial social proof.[69][70]Data security[edit]Data security is one of the major concerns of chatbot technologies. Security threats and system vulnerabilities are weaknesses that are often exploited by malicious users. Storage of user data and past communication, that is highly valuable for training and development of chatbots, can also give rise to security threats.[71] Chatbots operating on third-party networks may be subject to various security issues if owners of the third-party applications have policies regarding user data that differ from those of the chatbot.[71] Security threats can be reduced or prevented by incorporating protective mechanisms. User authentication, chat End-to-end encryption, and self-destructing messages are some effective solutions to resist potential security threats.[71]Mental health[edit]Chatbots have shown to be an emerging technology used in the field of mental health. Its usage may encourage users to seek advice on matters of mental health as a means to avoid the stigmatization that may come from sharing such matters with other people.[72] This is because chatbots can give a sense of privacy and anonymity when sharing sensitive information, as well as providing a space that allows for the user to be free of judgment.[72] An example of this can be seen in a study which found that with social media and AI chatbots both being possible outlets to express mental health online, users were more willing to share their darker and more depressive emotions to the chatbot.[72]Findings prove that chatbots have great potential in scenarios in which it is difficult for users to reach out to family or friends for support.[72] It has been noted that it demonstrates the ability to give young people \"various types of social support such as appraisal, informational, emotional, and instrumental support\".[72] Studies have found that chatbots are able to assist users in managing things such as depression and anxiety.[72] Some examples of chatbots that serve this function are \"Woebot, Wysa, Vivibot, and Tess\".[72]Evidence indicates that when mental health chatbots interact with users, they tend to follow certain conversation flows.[73] These being guided conversation, semi guided conversation, and open ended conversation.[73] The most popular, guided conversation, \"only allows the users to communicate with the chatbot with predefined responses from the chatbot. It does not allow any form of open input from the users\".[73] It has also been noted in a study looking at the methods employed by various mental health chatbots, that most of them employed a form of cognitive behavior therapy with the user.[73]Adverse effects[edit]Further information: Chatbot psychosisResearch has identified potential barriers to entry that come with the usage of chatbots for mental health.[74] There are ongoing privacy concerns with sharing user's personal data in chat logs with chatbots.[74] There is a lack of willingness from those in lower socioeconomic statuses to adopt interactions with chatbots as a meaningful way to improve upon mental health.[74] Though chatbots may be capable of detecting simple human emotions in interactions with users, they are incapable of replicating the level of empathy that human therapists do.[74] \nDue to the nature of chatbots being language-learning models trained on numerous datasets, the issue of algorithmic bias exists.[74] Chatbots with built in biases from their training can have them brought out against individuals of certain backgrounds and may result in incorrect information being conveyed.[74]There is a lack of research about how exactly these interactions help with a user's real life.[73] There are concerns regarding the safety of users when interacting with such chatbots.[73] When improvements and advancements are made to such technologies, how that may affect humans is not a priority.[73] It is possible that this can lead to \"unintended negative consequences, such as biases, inadequate and failed responses, and privacy issues\".[73]A risk in the usage of chatbots to deal with mental health is increased isolation, as well as a lack of support in times of crisis.[73] Another notable risk is a general lack of a strong understanding of mental health.[73] Studies have indicated that mental-health-oriented chatbots have been prone to recommending users medical solutions and to rely upon themselves heavily.[73] \nObsessive use of chatbots has been linked to chatbot psychosis[75] in people already prone to delusional and conspiratorial thinking. This is caused in part by chatbots \"hallucinating\" information,[76] as they are designed for engagement, and to keep people talking.[77]Limitations[edit]Traditional chatbots particularly lacked understanding of user requests, leading to clunky, repetitive conversations. Their pre-programmed responses would often fail to satisfy unexpected user queries, causing frustration. These chatbots were particularly unhelpful for users who lacked a clear understanding of their problem or the service they needed.[78]Chatbots based on large language models are much more versatile, but require a large amount of conversational data to train. These models generate new responses word by word based on user input, and are usually trained on a large dataset of natural-language phrases.[3] They sometimes provide plausible-sounding but incorrect or nonsensical answers, referred to as \"hallucinations\". They can for example make up names, dates, or historical events.[79] When humans use and apply chatbot content contaminated with hallucinations, this results in \"botshit\".[80] Given the increasing adoption and use of chatbots for generating content, there are concerns that this technology will significantly reduce the cost it takes humans to generate misinformation.[81]Impact on jobs[edit]Chatbots and technology in general used to automate repetitive tasks. But advanced chatbots like ChatGPT are also targeting high-paying, creative, and knowledge-based jobs, raising concerns about workforce disruption and quality trade-offs in favor of cost-cutting.[82]Chatbots are increasingly used by small and medium enterprises, to handle customer interactions efficiently, reducing reliance on large call centers and lowering operational costs.[83]Prompt engineering, the task of designing and refining prompts (inputs) leading to desired AI-generated responses has quickly gained significant demand with the advent of large language models,[84] although the viability of this job is questioned due to new techniques for automating prompt engineering.[85]Impact on the environment[edit]See also: Environmental impacts of artificial intelligence and Data_center \u00a7\u00a0Energy_useGenerative AI uses a high amount of electric power. Due to reliance on fossil fuels in its generation, this increases air pollution, water pollution, and greenhouse gas emissions. In 2023, a question to ChatGPT consumed on average 10 times as much energy as a Google search.[86] Data centres in general, and those used for AI tasks specifically, use significant amounts of water for cooling.[87][88]See also[edit].mw-parser-output .portalbox{padding:0;margin:0.5em 0;display:table;box-sizing:border-box;max-width:175px;list-style:none}.mw-parser-output .portalborder{border:1px solid var(--border-color-base,#a2a9b1);padding:0.1em;background:var(--background-color-neutral-subtle,#f8f9fa)}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;height:1.9em;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}Linguistics portalProgramming portal.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Applications of artificial intelligenceArtificial human companionArtificial intelligence and electionsAutonomous agentConversational user interfaceDeadbotDead Internet theoryDeaths linked to chatbotsFriendly artificial intelligenceHybrid intelligent systemIntelligent agentInternet botList of chatbotsMulti-agent systemSocial botSoftware agentSoftware botStochastic parrotTechnological unemploymentTwitterbotReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Mauldin, Michael (1994), \"ChatterBots, TinyMuds, and the Turing Test: Entering the Loebner Prize Competition\", Proceedings of the Eleventh National Conference on Artificial Intelligence, AAAI Press, archived from the original on 13 December 2007, retrieved 5 March 2008^\"What is a chatbot?\". techtarget.com. Archived from the original on 2 November 2010. Retrieved 30 January 2017.^ abcCaldarini, Guendalina; Jaf, Sardar; McGarry, Kenneth (2022). \"A Literature Survey of Recent Advances in Chatbots\". Information. 13 (1) 41. MDPI. arXiv:2201.06657. doi:10.3390/info13010041.^Adamopoulou, Eleni; Moussiades, Lefteris (2020). \"Chatbots: History, technology, and applications\". Machine Learning with Applications. 2 100006. doi:10.1016/j.mlwa.2020.100006.^\"2017 Messenger Bot Landscape, a Public Spreadsheet Gathering 1000+ Messenger Bots\". 3 May 2017. Archived from the original on 2 February 2019. Retrieved 1 February 2019.^Turing, Alan (1950), \"Computing Machinery and Intelligence\", Mind, 59 (236): 433\u2013460, doi:10.1093/mind/lix.236.433^ abWeizenbaum, Joseph (January 1966), \"ELIZA \u2013 A Computer Program For the Study of Natural Language Communication Between Man And Machine\", Communications of the ACM, 9 (1): 36\u201345, doi:10.1145/365153.365168, S2CID\u00a01896290^G\u00fczeldere, G\u00fcven; Franchi, Stefano (24 July 1995), \"Constructions of the Mind\", Stanford Humanities Review, SEHR, 4 (2), Stanford University, archived from the original on 11 July 2007, retrieved 5 March 2008^Computer History Museum (2006), \"Internet History \u2013 1970's\", Exhibits, Computer History Museum, archived from the original on 21 February 2008, retrieved 5 March 2008^Sondheim, Alan J (1997), <nettime> Important Documents from the Early Internet (1972), nettime.org, archived from the original on 13 June 2008, retrieved 5 March 2008^Network Working Group (1973). \"PARRY Encounters the DOCTOR\". Internet Engineering Task Force. Internet Society. doi:10.17487/RFC0439. RFC439. \u2013 Transcript of a session between Parry and Eliza. (This is not the dialogue from the ICCC, which took place 24\u201326 October 1972, whereas this session is from 18 September 1972.)^Kolodner, Janet L. Memory organization for natural language data-base inquiry. Advanced Research Projects Agency, 1978.^ abKolodner, Janet L. (1 October 1983). \"Maintaining organization in a dynamic long-term memory\". Cognitive Science. 7 (4): 243\u2013280. doi:10.1016/S0364-0213(83)80001-9 (inactive 30 August 2025). ISSN\u00a00364-0213.{{cite journal}}:  CS1 maint: DOI inactive as of August 2025 (link)^Dennett, Daniel C. (2004), Teuscher, Christof (ed.), \"Can Machines Think?\", Alan Turing: Life and Legacy of a Great Thinker, Berlin, Heidelberg: Springer, pp.\u00a0295\u2013316, doi:10.1007/978-3-662-05642-4_12, ISBN\u00a0978-3-662-05642-4^The Policeman's Beard is Half ConstructedArchived 4 February 2010 at the Wayback Machine. everything2.com. 13 November 1999^\"Chat Robots Simiulate People\". 11 October 2015.^\"Meet the DBpedia Chatbot | DBpedia\". wiki.dbpedia.org. 22 August 2018. Archived from the original on 2 September 2019. Retrieved 2 September 2019.^Beaver, Laurie (July 2016). \"The Chatbots Explainer\". Business Insider. BI Intelligence. Archived from the original on 3 May 2019. Retrieved 4 November 2019.^\"Facebook Messenger Hits 100,000 bots\". 18 April 2017. Archived from the original on 22 September 2017. Retrieved 22 September 2017.^\"KLM claims airline first with WhatsApp Business Platform\". www.phocuswire.com. Archived from the original on 5 February 2020. Retrieved 12 December 2021.^Forbes Staff (26 October 2017). \"Aerom\u00e9xico te atender\u00e1 por WhatsApp durante 2018\". Archived from the original on 2 July 2018. Retrieved 2 July 2018.^\"Podr\u00e1s hacer 'check in' y consultar tu vuelo con Aerom\u00e9xico a trav\u00e9s de WhatsApp\". Huffington Post. 27 October 2017. Archived from the original on 10 March 2018. Retrieved 2 July 2018.^\"Building for People, and Now Businesses\". WhatsApp.com. Archived from the original on 9 February 2018. Retrieved 2 July 2018.^\"How a Google deranking issue in 2017 gave birth to an e-ticketing platform\". 18 July 2025. Retrieved 16 October 2025.^\"She is the company's most effective employee\". Nordea News. September 2017. Archived from the original on 23 March 2023. Retrieved 23 March 2023.^\"Better believe the bot boom is blowing up big for B2B, B2C businesses\". VentureBeat. 24 July 2016. Archived from the original on 3 August 2017. Retrieved 30 August 2017.^Dandapani, Arundati (30 April 2020). \"Redesigning Conversations with Artificial Intelligence (Chapter 11)\". In Sha, Mandy (ed.). The Essential Role of Language in Survey Research. RTI Press. pp.\u00a0221\u2013230. doi:10.3768/rtipress.bk.0023.2004. ISBN\u00a0978-1-934831-24-3.^Capan, Faruk (18 October 2017). \"The AI Revolution is Underway!\". www.PM360online.com. Archived from the original on 8 March 2018. Retrieved 7 March 2018.^\"80% of businesses want chatbots by 2020\". Business Insider. 15 December 2016. Archived from the original on 8 March 2018. Retrieved 7 March 2018.^ ab\"A Virtual Travel Agent With All the Answers\". The New York Times. 4 March 2008. Archived from the original on 15 June 2017. Retrieved 3 August 2017.^\"Chatbot vendor directory released\". www.hypergridbusiness.com. October 2011. Archived from the original on 23 April 2017. Retrieved 23 April 2017.^\"Rare Carat's Watson-powered chatbot will help you put a diamond ring on it\". TechCrunch. 15 February 2017. Archived from the original on 22 August 2017. Retrieved 22 August 2017.^\"10 ways you may have already used IBM Watson\". VentureBeat. 10 March 2017. Archived from the original on 22 August 2017. Retrieved 22 August 2017.^Greenfield, Rebecca (5 May 2016). \"Chatbots Are Your Newest, Dumbest Co-Workers\". Bloomberg.com. Archived from the original on 6 April 2017. Retrieved 6 March 2017.^F\u00f8lstad, Asbj\u00f8rn; Nordheim, Cecilie Bertinussen; Bj\u00f8rkli, Cato Alexander (2018). \"What Makes Users Trust a Chatbot for Customer Service? An Exploratory Interview Study\". In Bodrunova, Svetlana S. (ed.). Internet Science. Lecture Notes in Computer Science. Vol.\u00a011193. Cham: Springer International Publishing. pp.\u00a0194\u2013208. doi:10.1007/978-3-030-01437-7_16. hdl:11250/2571164. ISBN\u00a0978-3-030-01437-7.^\"\u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u0438\u0439 \u0431\u0430\u043d\u043a \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u043b \u0447\u0430\u0442-\u0431\u043e\u0442\u0430 \u0432 Facebook\". Vedomosti.ru. 13 July 2016. Archived from the original on 1 April 2019. Retrieved 1 April 2019.^\"Absa launches 'world-first' Facebook Messenger banking\". 19 July 2016. Archived from the original on 1 April 2019. Retrieved 1 April 2019.^Larson, Selena (11 October 2016). \"Baidu is bringing AI chatbots to healthcare\". CNN Money. Archived from the original on 3 January 2020. Retrieved 3 January 2020.^\"AI chatbots have a future in healthcare, with caveats\". AI in Healthcare. Archived from the original on 23 March 2023. Retrieved 17 September 2019.^Palanica, Adam; Flaschner, Peter; Thommandram, Anirudh; Li, Michael; Fossat, Yan (3 January 2019). \"Physicians' Perceptions of Chatbots in Health Care: Cross-Sectional Web-Based Survey\". Journal of Medical Internet Research. 21 (4) e12887. doi:10.2196/12887. PMC\u00a06473203. PMID\u00a030950796.^Ahaskar, Abhijit (27 March 2020). \"How WhatsApp chatbots are helping in the fight against Covid-19\". Mint. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"India's Coronavirus Chatbot on WhatsApp Crosses 1.7 Crore Users in 10 Days\". NDTV Gadgets 360. April 2020. Archived from the original on 21 June 2020. Retrieved 23 July 2020.^Kurup, Rajesh (21 March 2020). \"COVID-19: Govt of India launches a WhatsApp chatbot\". Business Line. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"In focus: Mumbai-based Haptik which developed India's official WhatsApp chatbot for Covid-19\". Hindustan Times. 7 April 2020. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^Crimmins, Tricia (30 May 2023). \"'This robot causes harm': National Eating Disorders Association's new chatbot advises people with disordering eating to lose weight\". The Daily Dot. Retrieved 2 June 2023.^Knight, Taylor (31 May 2023). \"Eating disorder helpline fires AI for harmful advice after sacking humans\".^Aratani, Lauren (31 May 2023). \"US eating disorder helpline takes down AI chatbot over harmful advice\". The Guardian. ISSN\u00a00261-3077. Retrieved 1 June 2023.^\"Sam, the virtual politician\". Tuia Innovation. Archived from the original on 1 September 2019. Retrieved 9 September 2019.^Wellington, Victoria University of (15 December 2017). \"Meet the world's first virtual politician\". Victoria University of Wellington. Archived from the original on 3 January 2020. Retrieved 3 January 2020.^Wagner, Meg (23 November 2017). \"This virtual politician wants to run for office\". CNN. Archived from the original on 1 September 2019. Retrieved 9 September 2019.^\"Talk with the first-ever robot politician on Facebook Messenger\". Engadget. 25 November 2017. Archived from the original on 4 August 2019. Retrieved 9 September 2019.^Prakash, Abishur (8 August 2018). \"AI-Politicians: A Revolution In Politics\". Medium. Archived from the original on 10 August 2019. Retrieved 1 September 2019.^\"SAM website\". Archived from the original on 11 May 2021. Retrieved 23 May 2021.^Sternberg, Sarah (20 June 2022). \"Danskere vil ind p\u00e5 den politiske scene med kunstig intelligens\" [Danes want to enter the political scene with artificial intelligence]. Jyllands-Posten. Archived from the original on 20 June 2022. Retrieved 20 June 2022.^Diwakar, Amar (22 August 2022). \"Can an AI-led Danish party usher in an age of algorithmic politics?\". TRT World. Archived from the original on 22 August 2022. Retrieved 22 August 2022.^Xiang, Chloe (13 October 2022). \"This Danish Political Party Is Led by an AI\". Vice: Motherboard. Archived from the original on 13 October 2022. Retrieved 13 October 2022.^Hearing, Alice (14 October 2022). \"A.I. chatbot is leading a Danish political party and setting its policies. Now users are grilling it for its stance on political landmines\". Fortune. Archived from the original on 22 December 2022. Retrieved 8 December 2022.^\"Maharashtra government launches Aaple Sarkar chatbot to provide info on 1,400 public services\". CNBC TV18. 5 March 2019. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"Government of Maharashtra launches Aaple Sarkar chatbot with Haptik\". The Economic Times. Archived from the original on 16 December 2020. Retrieved 23 July 2020.^Aggarwal, Varun (5 March 2019). \"Maharashtra launches Aaple Sarkar chatbot\". Business Line. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^ abAmy (23 February 2015). \"Conversational Toys \u2013 The Latest Trend in Speech Technology\". Virtual Agent Chat. Archived from the original on 21 February 2018. Retrieved 11 August 2016.^Nagy, Evie (13 February 2015). \"Using Toy-talk Technology, New Hello Barbie Will Have Real Conversations With Kids\". Fast Company. Archived from the original on 15 March 2015. Retrieved 18 March 2015.^Oren Jacob, the co-founder and CEO of ToyTalk interviewed on the TV show Triangulation on the TWiT.tv network^\"Artificial intelligence script tool\". Archived from the original on 12 December 2021. Retrieved 12 December 2021.^Takahashi, Dean (23 February 2015). \"Elemental's smart connected toy taps IBM's Watson supercomputer for its brains\". Venture Beat. Archived from the original on 20 May 2015. Retrieved 15 May 2015.^Epstein, Robert (October 2007). \"From Russia With Love: How I got fooled (and somewhat humiliated) by a computer\"(PDF). Scientific American: Mind. pp.\u00a016\u201317. Archived(PDF) from the original on 19 October 2010. Retrieved 9 December 2007.\nPsychologist Robert Epstein reports how he was initially fooled by a chatterbot posing as an attractive girl in a personal ad he answered on a dating website. In the ad, the girl portrayed herself as being in Southern California and then soon revealed, in poor English, that she was actually in Russia. He became suspicious after a couple of months of email exchanges, sent her an email test of gibberish, and she still replied in general terms. The dating website is not named.^Neff, Gina; Nagy, Peter (12 October 2016). \"Automation, Algorithms, and Politics| Talking to Bots: Symbiotic Agency and the Case of Tay\". International Journal of Communication. 10: 17. ISSN\u00a01932-8036.^Bird, Jordan J.; Ekart, Aniko; Faria, Diego R. (June 2018). \"Learning from Interaction: An Intelligent Networked-Based Human-Bot and Bot-Bot Chatbot System\". Advances in Computational Intelligence Systems. Advances in Intelligent Systems and Computing. Vol.\u00a0840 (1st\u00a0ed.). Nottingham, UK: Springer. pp.\u00a0179\u2013190. doi:10.1007/978-3-319-97982-3_15. ISBN\u00a0978-3-319-97982-3. S2CID\u00a052069140.^Temming, Maria (20 November 2018). \"How Twitter bots get people to spread fake news\". Science News. Archived from the original on 27 November 2018. Retrieved 20 November 2018.^Epp, Len (11 May 2016). \"Five Potential Malicious Uses For Chatbots\". Archived from the original on 24 February 2023. Retrieved 24 February 2023.^ abcHasal, Martin; Nowakov\u00e1, Jana; Ahmed Saghair, Khalifa; Abdulla, Hussam; Sn\u00e1\u0161el, V\u00e1clav; Ogiela, Lidia (10 October 2021). \"Chatbots: Security, privacy, data protection, and social aspects\". Concurrency and Computation: Practice and Experience. 33 (19) e6426. doi:10.1002/cpe.6426. hdl:10084/145153. ISSN\u00a01532-0626.^ abcdefgChin, Hyojin; Song, Hyeonho; Baek, Gumhee; Shin, Mingi; Jung, Chani; Cha, Meeyoung; Choi, Junghoi; Cha, Chiyoung (20 October 2023). \"The Potential of Chatbots for Emotional Support and Promoting Mental Well-Being in Different Cultures: Mixed Methods Study\". Journal of Medical Internet Research. 25 e51712. doi:10.2196/51712. ISSN\u00a01438-8871. PMC\u00a010625083. PMID\u00a037862063.^ abcdefghijkHaque, M D Romael; Rubya, Sabirat (22 May 2023). \"An Overview of Chatbot-Based Mobile Mental Health Apps: Insights From App Description and User Reviews\". JMIR mHealth and uHealth. 11 e44838. doi:10.2196/44838. ISSN\u00a02291-5222. PMC\u00a010242473. PMID\u00a037213181.^ abcdefCoghlan, Simon; Leins, Kobi; Sheldrick, Susie; Cheong, Marc; Gooding, Piers; D'Alfonso, Simon (January 2023). \"To chat or bot to chat: Ethical issues with using chatbots in mental health\". Digital Health. 9 20552076231183542. doi:10.1177/20552076231183542. ISSN\u00a02055-2076. PMC\u00a010291862. PMID\u00a037377565.^Harrison Dupr\u00e9, Maggie (28 June 2025). \"People Are Being Involuntarily Committed, Jailed After Spiraling Into \"ChatGPT Psychosis\"\". Futurism. Retrieved 29 June 2025.^Klee, Miles (4 May 2025). \"People Are Losing Loved Ones to AI-Fueled Spiritual Fantasies\". Rolling Stone. Retrieved 29 June 2025.^Hill, Kashmir (13 June 2025). \"They Asked an A.I. Chatbot Questions. The Answers Sent Them Spiraling\". The New York Times. Archived from the original on 28 June 2025. Retrieved 29 June 2025.^Navaluri, Vijay (9 April 2024). \"Chatbots are dead: How generative AI & automation is transforming the way we interact with technology\". The Economic Times. ISSN\u00a00013-0389. Retrieved 25 May 2025.^Stover, Dawn (3 September 2023). \"Will AI make us crazy?\". Bulletin of the Atomic Scientists. 79 (5): 299\u2013303. Bibcode:2023BuAtS..79e.299S. doi:10.1080/00963402.2023.2245247. ISSN\u00a00096-3402.^Hannigan, Timothy R.; McCarthy, Ian P.; Spicer, Andr\u00e9 (20 March 2024). \"Beware of botshit: How to manage the epistemic risks of generative chatbots\". Business Horizons. 67 (5): 471\u2013486. doi:10.1016/j.bushor.2024.03.001. ISSN\u00a00007-6813.^\"Transcript: Ezra Klein Interviews Gary Marcus\". The New York Times. 6 January 2023. ISSN\u00a00362-4331. Retrieved 21 April 2024.^\"ChatGPT took their jobs. Now they walk dogs and fix air conditioners\". The Washington Post. 2 June 2023.^Haugeland, Isabel Kathleen Fornell; F\u00f8lstad, Asbj\u00f8rn; Taylor, Cameron; Bj\u00f8rkli, Cato Alexander (1 May 2022). \"Understanding the user experience of customer service chatbots: An experimental study of chatbot interaction design\". International Journal of Human-Computer Studies. 161 102788. doi:10.1016/j.ijhcs.2022.102788. hdl:10852/104483. ISSN\u00a01071-5819.^\"The Future Belongs to Prompt Engineers\". Inc. 12 March 2024.^\"Is The End of Prompt Engineering Here?\". The Information. 19 November 2024. Retrieved 14 December 2024.^\"AI is poised to drive 160% increase in data center power demand\". Goldman Sachs. 14 May 2024. Retrieved 2 December 2024.^Sreedhar, Nitin (22 October 2023). \"AI and its carbon footprint: How much water does ChatGPT consume?\". Mint Lounge.^Crownhart, Casey. \"AI is an energy hog. This is what it means for climate change\". MIT Technology Review.Further reading[edit]Gertner, Jon. (2023) \"Wikipedia's Moment of Truth: Can the online encyclopedia help teach A.I. chatbots to get their facts right \u2014 without destroying itself in the process?\" New York Times Magazine (18 July 2023) onlineSearle, John (1980), \"Minds, Brains and Programs\", Behavioral and Brain Sciences, 3 (3): 417\u2013457, doi:10.1017/S0140525X00005756, S2CID\u00a055303721Vincent, James, \"Horny Robot Baby Voice: James Vincent on AI chatbots\", London Review of Books, vol. 46, no. 19 (10 October 2024), pp.\u00a029\u201332. \"[AI chatbot] programs are made possible by new technologies but rely on the timelelss human tendency to anthropomorphise.\" (p.\u00a029.)Adamopoulou, Eleni; Moussiades, Lefteris (2020). Maglogiannis, Ilias; Iliadis, Lazaros; Pimenidis, Elias (eds.). \"An Overview of Chatbot Technology\". Artificial Intelligence Applications and Innovations. 584. Cham: Springer: 373\u2013383. doi:10.1007/978-3-030-49186-4_31. PMC\u00a07256567.Ciesla, Robert (2024). The Book of Chatbots: From ELIZA to ChatGPT. Springer Cham. doi:10.1007/978-3-031-51004-5. ISBN\u00a0978-3-031-51004-5.External links[edit]@media screen{html.skin-theme-clientpref-night .mw-parser-output .sister-inline-image img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sister-inline-image img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}} Media related to Chatbots at Wikimedia Commons.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteNatural language processingGeneral termsAI-completeBag-of-wordsn-gramBigramTrigramComputational linguisticsNatural language understandingStop wordsText processingText analysisArgument miningCollocation extractionConcept miningCoreference resolutionDeep linguistic processingDistant readingInformation extractionNamed-entity recognitionOntology learningParsingsemanticsyntacticPart-of-speech taggingSemantic analysisSemantic role labelingSemantic decompositionSemantic similaritySentiment analysisTerminology extractionText miningTextual entailmentTruecasingWord-sense disambiguationWord-sense inductionText segmentationCompound-term processingLemmatisationLexical analysisText chunkingStemmingSentence segmentationWord segmentationAutomatic summarizationMulti-document summarizationSentence extractionText simplificationMachine translationComputer-assistedExample-basedRule-basedStatisticalTransfer-basedNeuralDistributional semantics modelsBERTDocument-term matrixExplicit semantic analysisfastTextGloVeLanguage modellargesmallLatent semantic analysisLong short-term memorySeq2seqTransformerWord embeddingWord2vecLanguage resources,datasets and corporaTypes andstandardsCorpus linguisticsLexical resourceLinguistic Linked Open DataMachine-readable dictionaryParallel textPropBankSemantic networkSimple Knowledge Organization SystemSpeech corpusText corpusThesaurus (information retrieval)TreebankUniversal DependenciesDataBabelNetBank of EnglishDBpediaFrameNetGoogle Ngram ViewerUBYWordNetWikidataAutomatic identificationand data captureSpeech recognitionSpeech segmentationSpeech synthesisNatural language generationOptical character recognitionTopic modelDocument classificationLatent Dirichlet allocationPachinko allocationComputer-assistedreviewingAutomated essay scoringConcordancerGrammar checkerPredictive textPronunciation assessmentSpell checkerNatural languageuser interfaceChatbotInteractive fictionQuestion answeringVirtual assistantVoice user interfaceRelatedFormal semanticsHallucinationNatural Language ToolkitspaCy.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDNationalCzech RepublicLatviaIsrael\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Chatbot&oldid=1319634585\"", "tags": ["en.wikipedia.org", "wiki", "chatbot"]}
{"url": "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "title": null, "text": ".mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}.mw-parser-output .multiple-issues-text{width:95%;margin:0.2em 0}.mw-parser-output .multiple-issues-text>.mw-collapsible-content{margin-top:0.3em}.mw-parser-output .compact-ambox .ambox{border:none;border-collapse:collapse;background-color:transparent;margin:0 0 0 1.6em!important;padding:0!important;width:auto;display:block}body.mediawiki .mw-parser-output .compact-ambox .ambox.mbox-small-left{font-size:100%;width:auto;margin:0}.mw-parser-output .compact-ambox .ambox .mbox-text{padding:0!important;margin:0!important}.mw-parser-output .compact-ambox .ambox .mbox-text-span{display:list-item;line-height:1.5em;list-style-type:disc}body.skin-minerva .mw-parser-output .multiple-issues-text>.mw-collapsible-toggle,.mw-parser-output .compact-ambox .ambox .mbox-image,.mw-parser-output .compact-ambox .ambox .mbox-imageright,.mw-parser-output .compact-ambox .ambox .mbox-empty-cell,.mw-parser-output .compact-ambox .hide-when-compact{display:none}This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these messages)\n      This article's tone or style may not reflect the encyclopedic tone used on Wikipedia. See Wikipedia's guide to writing better articles for suggestions.  (April 2022) (Learn how and when to remove this message)This article may lend undue weight to very obscure AI projects of questionable importance. Please help improve it by rewriting it in a balanced fashion that contextualises different points of view.  (April 2022) (Learn how and when to remove this message)\n     (Learn how and when to remove this message).mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onArtificial intelligence (AI)Major goalsArtificial general intelligenceIntelligent agentRecursive self-improvementPlanningComputer visionGeneral game playingKnowledge representationNatural language processingRoboticsAI safetyApproachesMachine learningSymbolicDeep learningBayesian networksEvolutionary algorithmsHybrid intelligent systemsSystems integrationOpen-sourceApplicationsBioinformaticsDeepfakeEarth sciences Finance Generative AIArtAudioMusicGovernmentHealthcareMental healthIndustrySoftware developmentTranslation Military PhysicsProjectsPhilosophyAI alignmentArtificial consciousnessThe bitter lessonChinese roomFriendly AIEthicsExistential riskTuring testUncanny valleyHistoryTimelineProgressAI winterAI boomAI bubbleControversiesDeepfake pornographyTaylor Swift deepfake pornography controversyGoogle Gemini image generation controversyPause Giant AI ExperimentsRemoval of Sam Altman from OpenAIStatement on AI RiskTay (chatbot)Th\u00e9\u00e2tre D'op\u00e9ra SpatialVoiceverse NFT plagiarism scandalGlossaryGlossary.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteArtificial intelligence is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. Artificial intelligence (AI) has been used in applications throughout industry and academia. Within the field of Artificial Intelligence, there are multiple subfields. The subfield of Machine learning has been used for various scientific and commercial purposes[1] including language translation, image recognition, decision-making,[2][3]credit scoring, and e-commerce. In recent years, there have been massive advancements in the field of Generative Artificial Intelligence, which uses generative models to produce text, images, videos or other forms of data[4]. This article describes applications of AI in different sectors. \nAgriculture[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Precision agriculture and Digital agricultureIn agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency.[5] AI has been used to attempt to classify livestock pig call emotions,[6] automate greenhouses,[7] detect diseases and pests,[8] and optimize irrigation.[9]Architecture and design[edit].mw-parser-output .excerpt-hat .mw-editsection-like{font-style:normal}This section is an excerpt from Artificial intelligence in architecture.[edit]A sketch being converted via AI to a 3D mesh of a similar-looking buildingArtificial intelligence in architecture is the use of artificial intelligence in automation, design, and planning in the architectural process or in assisting human skills in the field of architecture.[10]\nAI has been used by some architects for design, and has been proposed as a way to automate planning and routine tasks in the field.[11][12]Business[edit]See also: \u00a7\u00a0ServicesA 2023 study found that generative AI increased productivity by 15% in contact centers.[13] Another 2023 study found it increased productivity by up to 40% in writing tasks.[14] An August 2025 review by MIT found that of surveyed companies, 95% did not report any improvement in revenue from the use of AI.[15] A September 2025 article by the Harvard Business Review describes how increased use of AI does not automatically lead to increases in revenue or actual productivity. Referring to \"AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task\" the article coins the term workslop. Per studies done in collaboration with the Stanford Social Media Lab, workslop does not improve productivity and undermines trust and collaboration among colleagues.[16]Computer science[edit]Programming assistance[edit]See also: Automatic programming and Programming environmentAI-assisted software development[edit]AI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. AI-assisted software development systems differ in functionality, quality, speed, and approach to privacy. Creating software primarily via AI is known as \"vibe coding\". Code created or suggested by AI can be incorrect or inefficient, and should be carefully reviewed by software developers before being accepted.[citation needed] The use of AI-assisted coding can potentially speed-up software development, but can also slow-down the process by creating more work when debugging and testing.[17][18] The rush to prematurely adopt AI technology can also incur additional technical debt.[17] AI also requires additional consideration and careful review for cybersecurity, since AI coding software is trained on a wide range of code of inconsistent quality and often replicates poor practices.[19][20]Neural network design[edit]An overview of AI agent and its core capabilities (memory, tools usage, actions, and ability to plan)AI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.[21]Quantum computing[edit]Further information: Quantum machine learningSee also: \u00a7\u00a0Chemistry and biologyResearch and development of quantum computers has been performed with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications.[22][23] The use of quantum machine learning  for quantum simulators has been proposed for solving physics and chemistry problems.[24][25][better\u00a0source\u00a0needed]Historical contributions[edit]AI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:[26]Time sharingInteractive interpretersGraphical user interfaces and the computer mouseRapid application development environmentsThe linked list data structureAutomatic storage managementSymbolic programmingFunctional programmingDynamic programmingObject-oriented programmingOptical character recognitionConstraint satisfactionCustomer service[edit]Human resources[edit]Main article: Artificial intelligence in hiringAnother application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.[citation needed]Online and telephone customer service[edit]An automated online assistant providing customer service on a web pageAI underlies avatars (automated online assistants) on web pages.[27] It can reduce operation and training costs.[27]Pypestream automated customer service for its mobile application to streamline communication with customers.[28]A Google app analyzes language and converts speech into text.[29] The platform can identify angry customers through their language and respond appropriately.[30] Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative.[31] Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.[32]Hospitality[edit]In the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs.[33] AI hotel services come in the form of a chatbot,[34] application, virtual voice assistant and service robots.\nEducation[edit]See also: AI in educationIn educational institutions, AI has been used to automate routine tasks like attendance tracking, grading and marking. AI tools have been used to attempt to monitor student progress and analyze learning behaviors, with the intention of facilitating interventions for students facing academic problems.[35]Energy and environment[edit]Energy system[edit]The U.S. Department of Energy wrote in an April 2024 report that AI may have applications in modeling power grids, reviewing federal permits with large language models, predicting levels of renewable energy production, and improving the planning process for electrical vehicle charging networks.[36] Other studies have suggested that machine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).[37][38][39][40][41]Environmental monitoring[edit]See also: Climate-smart agricultureAutonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics[42] or remote sensing and other applications of environmental monitoring make use of machine learning.[43][44][45][46]For example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution \u2013 primarily ocean pollution \u2013 by helping identify who and where mismanages plastic waste, dumping it into oceans.[47][48]Early-warning systems[edit]Machine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics,[49][50] earthquakes,[51][52][53] landslides,[54] heavy rainfall,[55] long-term water supply vulnerability,[56] tipping-points of ecosystem collapse,[57]cyanobacterial bloom outbreaks,[58] and droughts.[59][60][61]Economic and social challenges[edit]See also: \u00a7\u00a0Environmental monitoringAI for Good is a platform launched in 2017 by the International Telecommunication Union (ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN's Sustainable Development Goals.[citation needed]The University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.[62]Entertainment and media[edit]Media[edit]See also: \u00a7\u00a0Telecommunications, and Synthetic mediaImage restorationAI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision.\nTypical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement.\nMotion interpolation[63]Pixel-art scaling algorithms[64]Image scaling[65]Image restoration[66][67]Photo colorization[68]Film restoration and video upscaling[69]Photo tagging[70]Automated species identification (such as identifying plants, fungi and animals with an app)Text-to-image models such as DALL-E, Midjourney and Stable DiffusionImage to video[71]Text to video such as Make-A-Video from Meta, Imagen video and Phenaki from GoogleText to music with AI models such as MusicLM[72][73]Text to speech such as ElevenLabs and 15.aiMotion capture[74]Deep-fakes[edit]Deep-fakes can be used for comedic purposes but are better known for fake news and hoaxes.\nDeepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof.[75]In January 2016,[76] the Horizon 2020 program financed the InVID Project[77][78] to help journalists and researchers detect fake documents, made available as browser plugins.[79][80]In June 2016, the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face,[81] a program that animates photographs of faces, mimicking the facial expressions of another person. The technology has been demonstrated animating the faces of people including Barack Obama and Vladimir Putin. Other methods have been demonstrated based on deep neural networks, from which the name deep fake was taken.\nIn September 2018, U.S. Senator Mark Warner proposed to penalize social media companies that allow sharing of deep-fake documents on their platforms.[82]In 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames.[83]DARPA gave 68 million dollars to work on deep-fake detection.[83]Audio deepfakes[84][85] and AI software capable of detecting deep-fakes and cloning human voices have been developed.[86][87]Respeecher is a program that enables one person to speak with the voice of another.\nVideo surveillance analysis and manipulated media detection[edit]See also: Web scraping, Photograph manipulation, and Video manipulationThis section is an excerpt from Video content analysis \u00a7 Artificial Intelligence.[edit]\nArtificial intelligence for video surveillance utilizes computer software programs that analyze the audio and images from video surveillance cameras in order to recognize humans, vehicles, objects and events. Security contractors program is the software to define restricted areas within the camera's view (such as a fenced off area, a parking lot but not the sidewalk or public street outside the lot) and program for times of day (such as after the close of business) for the property being protected by the camera surveillance. The artificial intelligence (\"A.I.\") sends an alert if it detects a trespasser breaking the \"rule\" set that no person is allowed in that area during that time of day.AI algorithms have been used to detect deepfake videos.[88][89]Video production[edit]Artificial intelligence is also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.[90]  Way mark Studios utilized the tools offered by both DALL-E and Mid-journey to create a fully AI generated film called The Frost in the summer of 2023.[90] Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.[90]  Yves Bergquist, a director of the AI & Neuroscience in Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology.[91]Music[edit]Main article: Music and artificial intelligenceAI has been used to compose music of various genres.\nDavid Cope created an AI called Emily Howell that managed to become well known in the field of algorithmic computer music.[92] The algorithm behind Emily Howell is registered as a US patent.[93]In 2012, AI Iamus created the first complete classical album.[94]AIVA (Artificial Intelligence Virtual Artist), composes symphonic music, mainly classical music for film scores.[95] It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association.[96]Melomics creates computer-generated music for stress and pain relief.[97]At Sony CSL Research Laboratory, the Flow Machines software creates pop songs by learning music styles from a huge database of songs. It can compose in multiple styles.\nThe Watson Beat uses reinforcement learning and deep belief networks to compose music on a simple seed input melody and a select style. The software was open sourced[98] and musicians such as Taryn Southern[99] collaborated with the project to create music.\nSouth Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO.[100]Writing and reporting[edit]See also: \u00a7\u00a0Web feeds and postsNarrative Science sells computer-generated news and reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses.[101]Automated Insights generates personalized recaps and previews for Yahoo SportsFantasy Football.[102]Yseop, uses AI to turn structured data into natural language comments and recommendations. Yseop writes financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German.[103]TALESPIN made up stories similar to the fables of Aesop. The program started with a set of characters who wanted to achieve certain goals. The story narrated their attempts to satisfy these goals.[citation needed] Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\".[104]While AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such as Little Red Riding Hood.[105] In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.[106]South Korean company Hanteo Global uses a journalism bot to write articles.[107]Literary authors are also exploring uses of AI. An example is David Jhave Johnston's work ReRites (2017\u20132019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications.\nSports writing[edit]In 2010, artificial intelligence used baseball statistics to automatically generate news articles. This was launched by The Big Ten Network using software from Narrative Science.[108]After being unable to cover every Minor League Baseball game with a large team, Associated Press collaborated with Automated Insights in 2016 to create game recaps that were automated by artificial intelligence.[109]UOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words on Google.[109]El Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use the Perspective API to moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it.[109]A local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team.[109]Lede AI has been used in 2023 to take scores from high school football games to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company, Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment.[110]Wikipedia[edit]This section is an excerpt from Artificial intelligence in Wikimedia projects.[edit]AI-generated draft article getting nominated for speedy deletion under G15 criteriaArtificial intelligence is used in Wikimedia projects for the purpose of developing those projects.[111] \nVarious articles on Wikipedia have been created entirely with or with the help of artificial intelligence. AI-generated content can be detrimental to Wikipedia when unreliable or containing fake citations.\n\nTo address the issue of low-quality AI-generated content, the Wikipedia community created in 2023 a WikiProject named AI Cleanup. In August 2025, Wikipedia adopted a policy that allowed editors to nominate suspected AI-generated articles for speedy deletion. Millions of its articles have been edited by bots[112] which however are usually not artificial intelligence software. Many AI platforms use Wikipedia data,[113] mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences,[114]detecting covert vandalism[115] or recommending articles and tasks to new editors.\nMachine translation .mw-parser-output div.crossreference{padding-left:0}(see above) has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages.[116][117]Video games[edit]Main article: Artificial intelligence in video gamesSee also: Video game bot and Artificial intelligence in video gamesIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010).[118][119] AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.[120]Games have been a major application[relevant?] of AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson),[121]Go (AlphaGo),[122][123][124][125][126][127][128]poker (Pluribus[129] and Cepheus),[130]E-sports (StarCraft),[131][132] and general game playing (AlphaZero[133][134][135] and MuZero).[136][137][138][139]Kuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool.[140][141]Character.ai is another example of a chatbot being used for recreation.[citation needed]Visual images[edit]A \"cyborg elf\" generated by Stable DiffusionMain article: Artificial intelligence artThe first AI art program, called AARON, was developed by Harold Cohen in 1968[142] with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen.[143]AI platforms such as DALL-E,[144]Stable Diffusion,[144]Imagen,[145] and Midjourney[146] have been used for generating visual images from inputs such as text or other images.[147] Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches.\nAI has been used to generate quantitative analysis of existing digital art collections.[148]\nTwo computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art.[149] While distant viewing includes the analysis of large collections, close reading involves one piece of artwork.\nComputer animation[edit]Pixar began experimenting with a machine learning project called \"Genesis\" in the early 2000s. It was designed to learn algorithms and create 3D models for its characters and props.[citation needed] \nIn 2023, Netflix of Japan's usage of AI to generate background images for short The Dog & the Boy was met with backlash online.[150]Finance[edit]Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking began in 1987 when Security Pacific National Bank launched a fraud prevention task-force to counter the unauthorized use of debit cards.[151]Banks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours.[152]AI is used to combat fraud and financial crimes by monitoring behavioral patterns for any abnormal changes or anomalies.[153][154][155]The use of AI in applications such as online trading and decision-making has changed major economic theories.[156] For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualized pricing. AI systems reduce information asymmetry in the market and thus make markets more efficient.[157] The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises.[158]Trading and investment[edit]Algorithmic trading involves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Such high-frequency trading represents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios. Automated trading systems are typically used by large institutional investors but include smaller firms trading with their own AI systems.[159]Large financial institutions use AI to assist with their investment practices.[160]BlackRock's AI engine, Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use of natural language processing to analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them with wealth management products.[161]Underwriting[edit]Online lender Upstart uses machine learning for underwriting.[162]ZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting.[163] This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.[164]Audit[edit]AI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration.[165][quantify]Continuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making.[166]Anti\u2013money laundering[edit]AI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used for anti\u2013money laundering (AML).[167][168]Anti\u2013money laundering\nCollections and Account Receivables[edit]In recent years, the debt collection industry has begun to adopt AI-driven \"agents\" to automate routine outreach and negotiation tasks. Platforms use natural-language processing and machine learning to interact with consumers.\nProponents claim these systems can handle high volumes of standard enquiries, freeing human collectors to focus on more complex cases, while delivering more consistent, 24/7 service. However, critics warn of potential compliance pitfalls, such as the risk of unintended bias in algorithmic decision-making.[169]History[edit]In the 1980s, AI started to become prominent in finance as expert systems were commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year.[170] One of the first systems was the Pro-trader expert system that predicted the 87-point drop in the Dow Jones Industrial Average in 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\"[171]One of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people.[172]In the 1990s, AI was applied to fraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases of money laundering equal to $1 billion.[173] These expert systems were later replaced by machine learning systems.[174]Outside finance, the late 1980s and early 1990s also saw expert systems used in technical and environmental domains. For example, researchers built a fishway design advisor to recommend fish passage structures under varying hydraulic and biological conditions using the VP-Expert shell.[175] Transportation researchers applied the same shell to balance airport capacity with noise-mitigation plans.[176] In agriculture, a potato insect expert system (PIES) supported pest management decisions for Colorado potato beetle.[177] The U.S. Environmental Protection Agency\u2019s CORMIX system for modeling pollutant discharges combined rules with Fortran hydrodynamic models.[178]AI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI.[179]Regulatory developments in the EU[edit]In the European Union, the Artificial Intelligence Act (Regulation\u202f(EU)\u202f2024/1689) classifies several finance\u2011sector uses of AI as \"high\u2011risk\", including systems used to evaluate the creditworthiness of natural persons or to establish a credit score and AI used for risk assessment and pricing in life or health insurance.[180][181][182] These systems must meet requirements on risk management, data governance, technical documentation and logging, transparency, and human oversight.[181][183]The Act's obligations are phased in: prohibitions and AI\u2011literacy rules apply from 2\u202fFebruary\u202f2025, governance and most GPAI duties from 2\u202fAugust\u202f2025, the bulk of obligations from 2\u202fAugust\u202f2026, and certain safety\u2011component high\u2011risk obligations from 2\u202fAugust\u202f2027.[182]Health[edit]Healthcare[edit]Main article: Artificial intelligence in healthcareX-ray of a hand, with automatic calculation of bone age by a computer softwareA patient-side surgical arm of Da Vinci Surgical SystemAI in healthcare is often used for classification, to evaluate a CT scan or electrocardiogram or to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16\u00a0billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients.[184] Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry.[185]The early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem.[186] Microsoft's AI project Hanover helps doctors choose cancer treatments from among the more than 800 medicines and vaccines.[187][188] Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient. Myeloid leukemia is one target. Another study reported on an AI that was as good as doctors in identifying skin cancers.[189] Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions.[190] In one study done with transfer learning, an AI diagnosed eye conditions similar to an ophthalmologist and recommended treatment referrals.[191]Another study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon.[192]Artificial neural networks are used as clinical decision support systems for medical diagnosis,[193] such as in concept processing technology in EMR software.\nOther healthcare tasks thought suitable for an AI that are in development include:\nScreening[194]Companion robots for elder care[195]Drug creation[196] (e.g. by identifying candidate drugs[197] and by using existing drug screening data such as in life extension research)[198]Clinical training[199]Identifying genomic pathogen signatures of novel pathogens[200] or identifying pathogens via physics-based fingerprints[201] (including pandemic pathogens)Helping link genes to their functions,[202] otherwise analyzing genes[203] and identification of novel biological targets[204]Help development of biomarkers[204]Help tailor therapies to individuals in personalized medicine/precision medicine[204][205]Workplace health and safety[edit]Main article: Workplace impact of artificial intelligence \u00a7\u00a0Health and safety applicationsAI-enabled chatbots decrease the need for humans to perform basic call center tasks, and machine learning in sentiment analysis can spot fatigue in order to prevent overwork.[206]Decision support systems can potentially prevent industrial disasters and make disaster response more efficient.[207] For manual workers in material handling, predictive analytics has been proposed to reduce musculoskeletal injury.[208] \nAI can attempt to process workers' compensation claims.[209][210] AI has been proposed for detection of accident near misses, which are underreported.[211]Biochemistry[edit]Machine learning has been used for drug design,[41]drug discovery and development, drug repurposing, improving pharmaceutical productivity, and clinical trials.[212]Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\",[213] has been used in drug-syntheses, and developing routes for recycling 200 industrial waste chemicals into important drugs and agrochemicals (chemical synthesis design).[214] It has also been used to explore the origins of life on Earth.[215] \nDeep learning has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene, DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results.[216]The AI program AlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).[217][218][219][220]Language processing[edit]Language translation[edit]Main article: Machine translationSpeech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another.[221]AI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator.[222] Additionally, research and development are in progress to decode and conduct animal communication.[6][223]Meaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.[224]Law and government[edit]Government[edit]Main article: Artificial intelligence in governmentAI facial recognition systems are used for mass surveillance, notably in China.[225][226] In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.[227]Law[edit]Main article: Legal informatics \u00a7\u00a0Artificial intelligenceLegal analysis[edit]AI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers.[228] While its use is common, it is not expected to replace most work done by lawyers in the near future.[229]The electronic discovery industry uses machine learning to reduce manual searching.[230]Law enforcement and legal proceedings[edit]Law enforcement has begun using facial recognition systems (FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants.[231]COMPAS is a commercial system used by U.S. courts to assess the likelihood of recidivism.[232]One concern relates to algorithmic bias, AI programs may become biased after processing data that exhibits bias.[233]ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants.[232]In 2019, the city of Hangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-related intellectual property claims.[234]:\u200a124\u200a Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards.[234]:\u200a124\u200aManufacturing[edit]Main articles: Artificial intelligence in industry and Artificial intelligence in heavy industrySensors[edit]Artificial intelligence has been combined with digital spectrometry by IdeaCuria Inc.,[235][236] enable applications such as at-home water quality monitoring.\nToys and games[edit]In the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.[237]Oil and gas[edit]Oil and gas companies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output.[238][239]Military[edit]Main article: Military applications of artificial intelligenceVarious countries are deploying AI military applications.[240] The main applications enhance command and control, communications, sensors, integration and interoperability.[citation needed] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[240] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both piloted and autonomous.[citation needed]AI has been used in military operations in Iraq, Syria, Israel and Ukraine.[240][241][242][243]Internet and e-commerce[edit]Main article: Marketing and artificial intelligenceWeb feeds and posts[edit]Machine learning has been used for recommendation systems in determining which posts should show up in social media feeds.[244][245] Various types of social media analysis also make use of machine learning[246][247] and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.[248][249][250]AI has been used to customize shopping options and personalize offers.[251]Online gambling companies have used AI for targeting gamblers.[252]Virtual assistants and search[edit]Main article: Virtual assistantIntelligent personal assistants use AI to attempt to respond to natural language requests. Siri, released in 2010 for Apple smartphones, popularized the concept.[253]Bing Chat has used artificial intelligence as part of its search engine.[254]Spam filtering[edit]Main article: Spam filterMachine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements.[255] Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails.[256] These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.[257]Facial recognition and image labeling[edit]Main articles: Automatic image annotation and Artificial intelligence for video surveillanceAI has been used in facial recognition systems. Some examples are Apple's Face ID and Android's Face Unlock, which are used to secure mobile devices.[258] \nChina has used facial recognition and artificial intelligence technology in Xinjiang. In 2017, reporters visiting the region found surveillance cameras installed every hundred meters or so in several cities, as well as facial recognition checkpoints at areas like gas stations, shopping centers, and mosque entrances.[259][260] Human rights groups have criticized the Chinese government for using artificial intelligence facial recognition technology for use in political suppression.[261][262]The Netherlands has deployed facial recognition and artificial intelligence technology since 2016.[263] The database of the Dutch police currently contains over 2.2\u00a0million pictures of 1.3\u00a0million Dutch citizens. This accounts for about 8% of the population. In The Netherlands, face recognition is not used by the police on municipal CCTV.[264]Image labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people.[222] Facebook's DeepFace identifies human faces in digital images.[citation needed]Scientific research[edit]Evidence of general impacts[edit]In April 2024, the Scientific Advice Mechanism to the European Commission published advice[265] including a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research.\nAs benefits, the evidence review[266] highlighted:\nits role in accelerating research and innovationits capacity to automate workflowsenhancing dissemination of scientific workAs challenges:\nlimitations and risks around transparency, reproducibility and interpretabilitypoor performance (inaccuracy)risk of harm through misuse or unintended usesocietal concerns including the spread of misinformation and increasing inequalitiesArchaeology, history and imaging of sites[edit]See also: Digital archaeologyMachine learning can help to restore and attribute ancient texts.[267] It can help to index texts for example to enable better and easier searching and classification of fragments.[268]\nArtificial intelligence can also be used to investigate genomes to uncover genetic history, such as interbreeding between archaic and modern humans by which for example the past existence of a ghost population, not Neanderthal or Denisovan, was inferred.[269]Further information: Ancient DNA \u00a7\u00a0Human aDNA, and Genetic history of Europe\nIt can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\".[270]Further information: Remote sensing in archaeologyPhysics[edit]Main article: Machine learning in physicsA deep learning system was reported to learn intuitive physics from visual data (of virtual 3D environments) based on an unpublished approach inspired by studies of visual cognition in infants.[271][272] Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.[273][274] In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.[273]Materials science[edit]In November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that the AI system GNoME had documented over 2 million new materials. GNoME uses deep learning techniques to examine potential material structures, and identify stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, with a success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database.[275][276][277]Reverse engineering[edit]Machine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts,[278] and for quickly understanding the behavior of malware.[279][280][281] It can be used to reverse engineer artificial intelligence models.[282] It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality[283] or protein design for pre-specified functional sites.[284][285] Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.[286]Astronomy, space activities and ufology[edit]See also: \u00a7\u00a0Novel types of machine learningArtificial intelligence is used in astronomy to analyze increasing amounts of available data[287][288] and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy.[289] It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance,[290] and more autonomous operation.[291][292][46][288]In the search for extraterrestrial intelligence (SETI), machine learning has been used in attempts to identify artificially generated electromagnetic waves in available data[293][294] \u2013 such as real-time observations[295] \u2013 and other technosignatures, e.g. via anomaly detection.[296] In ufology, the SkyCAM-5 project headed by Prof. Hakan Kayal[297] and the Galileo Project headed by Avi Loeb use machine learning to attempt to detect and classify types of UFOs.[298][299][300][301][302] The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI: 'Oumuamua-like interstellar objects, and non-manmade artificial satellites.[303][304]Machine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals \u2013 such as phosphine possibly detected on Venus \u2013 which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets.[305]Chemistry and biology[edit]See also: \u00a7\u00a0Health, \u00a7\u00a0Quantum computing, and Computational chemistry \u00a7\u00a0ApplicationsThere is research about which types of computer-aided chemistry would benefit from machine learning.[306] \nA deep learning AI-based process has been developed that uses genome databases to design novel proteins based on evolutionary algorithms.[307][308]\nMachine learning has also been used for protein design with pre-specified functional sites,[284][285] predicting molecular properties, and exploring large chemical/reaction spaces.[309]Using drug discovery AI algorithms, researchers generated 40,000 potential chemical weapon candidates, helping in the regulation of such chemicals to prevent synthesizing them for real harm.[310][311][312]There are various types of applications for machine learning in decoding human biology, such as helping to map gene expression patterns to functional activation patterns[313] or identifying functional DNA motifs.[314] It is widely used in genetic research.[315]\nThere also is some use of machine learning in synthetic biology,[316][317] disease biology,[317] nanotechnology (e.g. nanostructured materials and bionanotechnology),[318][319] and materials science.[320][321][322]Security and surveillance[edit]Cyber security[edit]Cyber security companies are adopting neural networks, machine learning, and natural language processing to improve their systems.[323]Applications of AI in cyber security include:\nNetwork protection: Machine learning improves intrusion detection systems by broadening the search beyond previously identified threats.[324]Endpoint protection: Attacks such as ransomware can be thwarted by learning typical malware behaviors.\nAI-related cyber security application cases vary in both benefit and complexity. Security features such as Security Orchestration, Automation, and Response (SOAR) and Extended Endpoint Detection and Response (XDR) offer significant benefits for businesses, but require significant integration and adaptation efforts.[325]Application security: can help counterattacks such as server-side request forgery, SQL injection, cross-site scripting, and distributed denial-of-service.\nAI technology can also be utilized to improve system security and safeguard our privacy. Randrianasolo (2012) suggested a security system based on artificial intelligence that can recognize intrusions and adapt to perform better.[326] In order to improve cloud computing security, Sahil (2015) created a user profile system for the cloud environment with AI techniques.[327]Suspect user behavior: Machine learning can identify fraud or compromised applications as they occur.[328]Transportation and logistics[edit]Automotive and public transit[edit]Main articles: Vehicular automation, Self-driving car, and Smart traffic lightSide view of a Waymo-branded self-driving carTransportation's complexity means that in most cases, training an AI in a real-world driving environment is impractical, and is achieved through simulator-based testing.[329] AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.[330] AI-based fuzzy logic controllers operate gearboxes. AI-based driver-assist systems include features such as self-parking and adaptive cruise control.[citation needed]Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals).[331][332]There are prototypes of autonomous automotive public transport vehicles such as autonomous rail transport in operation,[333][334][335] electric mini-buses,[336][337][338] and autonomous delivery vehicles,[339][340][332] including delivery robots.[341][342]Autonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018.[343] A group of autonomous trucks follow closely behind each other. German corporation Daimler is testing its Freightliner Inspiration.[344]AI has been used to optimize traffic management, which can reduce wait times, energy use, and emissions.[345].mw-parser-output .tmulti .multiimageinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .tmulti .multiimageinner span:not(.skin-invert-image):not(.skin-invert):not(.bg-transparent) img{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .tmulti .multiimageinner span:not(.skin-invert-image):not(.skin-invert):not(.bg-transparent) img{background-color:white}}Cameras with radar and ultrasonic acoustic location sensors, while using predictive algorithms to have artificially intelligent traffic lights to make traffic flow betterMilitary[edit]Aircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated.\nAI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or in swarms.[346]AOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information from TF-30 documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the F-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers.\nSpeech recognition allows traffic controllers to give verbal directions to drones.\nArtificial intelligence supported design of aircraft,[347] or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective.\nNASA[edit]In 2003 a Dryden Flight Research Center project created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved.[348] The software compensated for damaged components by relying on the remaining undamaged components.[349]The 2016 Intelligent Autopilot System combined apprenticeship learning and behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions.[350]Maritime[edit]Neural networks are used by situational awareness systems in ships and boats.[351] There also are autonomous boats.\nSee also[edit]Applications of artificial intelligence to legal informaticsApplications of deep learningApplications of machine learningArtificial intelligence and electionsCollective intelligence \u00a7\u00a0ApplicationsList of artificial intelligence projectsList of datasets for machine-learning researchOpen dataProgress in artificial intelligenceTimeline of computing 2020\u2013presentFootnotes[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Brynjolfsson, Erik; Mitchell, Tom (22 December 2017). \"What can machine learning do? Workforce implications\". Science. 358 (6370): 1530\u20131534. Bibcode:2017Sci...358.1530B. doi:10.1126/science.aap8062. PMID\u00a029269459.^Shin, Minkyu; Kim, Jin; van Opheusden, Bas; Griffiths, Thomas L. (2023). \"Superhuman artificial intelligence can improve human decision-making by increasing novelty\". Proceedings of the National Academy of Sciences. 120 (12) e2214840120. arXiv:2303.07462. Bibcode:2023PNAS..12014840S. doi:10.1073/pnas.2214840120. PMC\u00a010041097. PMID\u00a036913582.^Chen, Yiting; Liu, Tracy Xiao; Shan, You; Zhong, Songfa (2023). \"The emergence of economic rationality of GPT\". Proceedings of the National Academy of Sciences. 120 (51) e2316205120. arXiv:2305.12763. Bibcode:2023PNAS..12016205C. doi:10.1073/pnas.2316205120. PMC\u00a010740389. PMID\u00a038085780.^\"What is Generative AI? | IBM\". www.ibm.com. 2024-03-22. Retrieved 2025-07-22.^Gambhire, Akshaya; Shaikh Mohammad, Bilal N. (8 April 2020). Use of Artificial Intelligence in Agriculture. Proceedings of the 3rd International Conference on Advances in Science & Technology (ICAST) 2020. SSRN\u00a03571733.^ abBriefer, Elodie F.; Sypherd, Ciara C.-R.; Linhart, Pavel; Leliveld, Lisette M. C.; Padilla de la Torre, Monica; Read, Eva R.; Gu\u00e9rin, Carole; Deiss, V\u00e9ronique; Monestier, Chlo\u00e9; Rasmussen, Jeppe H.; \u0160pinka, Marek; D\u00fcpjan, Sandra; Boissy, Alain; Janczak, Andrew M.; Hillmann, Edna; Tallet, C\u00e9line (7 March 2022). \"Classification of pig calls produced from birth to slaughter according to their emotional valence and context of production\". Scientific Reports. 12 (1): 3409. Bibcode:2022NatSR..12.3409B. doi:10.1038/s41598-022-07174-8. PMC\u00a08901661. PMID\u00a035256620.^Moreno Mill\u00e1n, M; Sevilla Guzm\u00e1n, E; Demyda, S E (2011). \"Population, Poverty, Production, Food Security, Food Sovereignty, Biotechnology and Sustainable Development: Challenges for the XXI Century\". Bulletin of University of Agricultural Sciences and Veterinary Medicine Cluj-Napoca. Veterinary Medicine. 1 (68).^Liundi, Nicholas; Darma, Aditya Wirya; Gunarso, Rivaldi; Warnars, Harco Leslie Hendric Spits (2019). \"Improving Rice Productivity in Indonesia with Artificial Intelligence\". 2019 7th International Conference on Cyber and IT Service Management (CITSM). pp.\u00a01\u20135. doi:10.1109/CITSM47753.2019.8965385. ISBN\u00a0978-1-7281-2909-9.^Talaviya, Tanha; Shah, Dhara; Patel, Nivedita; Yagnik, Hiteshri; Shah, Manan (2020). \"Implementation of artificial intelligence in agriculture for optimisation of irrigation and application of pesticides and herbicides\". Artificial Intelligence in Agriculture. 4: 58\u201373. doi:10.1016/j.aiia.2020.04.002.^Bernstein, Phillip (2022). Machine Learning: Architecture in the Age of Artificial Intelligence. London: RIBA Publishing. ISBN\u00a0978-1-914124-01-3.^Heathcote, Edwin (20 January 2024). \"AI is coming for architecture\". Financial Times. Retrieved 2024-02-07.^\"Will Artificial Intelligence Replace Architects?\". ArchDaily. 2023-10-18. Retrieved 2024-02-07.^Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey (2025-02-04). \"Generative AI at Work\". The Quarterly Journal of Economics. 140 (2): 889\u2013942. doi:10.1093/qje/qjae044. ISSN\u00a00033-5533. Archived from the original on 2025-06-05.^Noy, Shakked; Zhang, Whitney (2023-07-14). \"Experimental evidence on the productivity effects of generative artificial intelligence\". Science. 381 (6654): 187\u2013192. Bibcode:2023Sci...381..187N. doi:10.1126/science.adh2586. PMID\u00a037440646.^Estrada, Sheryl (18 August 2025). \"MIT report: 95% of generative AI pilots at companies are failing\". Fortune. Retrieved 15 October 2025.^Niederhoffer, Kate; Kellerman, Gabriella Rosen; Lee, Angela; Liebscher, Alex; Rapuano, Kristina; Hancock, Jeffrey T. (22 September 2025). \"AI-Generated \"Workslop\" Is Destroying Productivity\". Harvard Business Review. Retrieved 15 October 2025.^ abNickelsburg, Monica (1 October 2025). \"The human coders hired to mop up AI slop\". www.kuow.org. NPR. Retrieved 25 October 2025.^Davis, Dominic-Madori (14 September 2025). \"Vibe coding has turned senior devs into 'AI babysitters,' but they say it's worth it\". TechCrunch. Retrieved 25 October 2025.^Newman, Lily Hay. \"Vibe Coding Is the New Open Source\u2014in the Worst Way Possible\". Wired. Retrieved 25 October 2025.^Tangermann, Victor (31 May 2025). \"Companies Are Discovering a Grim Problem With \"Vibe Coding\"\". Futurism. Retrieved 25 October 2025.^\"Google AI creates its own \"child\" bot\". The Independent. 5 December 2017. Retrieved 5 February 2018.^Spagnolo, Michele; Morris, Joshua; Piacentini, Simone; Antesberger, Michael; Massa, Francesco; Crespi, Andrea; Ceccarelli, Francesco; Osellame, Roberto; Walther, Philip (April 2022). \"Experimental photonic quantum memristor\". Nature Photonics. 16 (4): 318\u2013323. arXiv:2105.04867. Bibcode:2022NaPho..16..318S. doi:10.1038/s41566-022-00973-5.^Ramanathan, Shriram (July 2018). \"Quantum materials for brain sciences and artificial intelligence\". MRS Bulletin. 43 (7): 534\u2013540. Bibcode:2018MRSBu..43..534R. doi:10.1557/mrs.2018.147.^\"Artificial intelligence makes accurate quantum chemical simulations more affordable\". Nature Portfolio Chemistry Community. 2 December 2021. Retrieved 30 May 2022.^Guan, Wen; Perdue, Gabriel; Pesah, Arthur; Schuld, Maria; Terashi, Koji; Vallecorsa, Sofia; Vlimant, Jean-Roch (March 2021). \"Quantum machine learning in high energy physics\". Machine Learning: Science and Technology. 2 (1): 011003. arXiv:2005.08582. doi:10.1088/2632-2153/abc17d.^Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\u00a0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\u00a00-13-790395-2^ abKongthon, Alisa; Sangkeettrakarn, Chatchawal; Kongyoung, Sarawoot; Haruechaiyasak, Choochart (2009). \"Implementing an online help desk system based on conversational agent\". Proceedings of the International Conference on Management of Emergent Digital EcoSystems. pp.\u00a0450\u2013451. doi:10.1145/1643823.1643908. ISBN\u00a0978-1-60558-829-2.^Sara Ashley O'Brien (12 January 2016). \"Is this app the call center of the future?\". CNN. Retrieved 26 September 2016.^\"Using Google AI to convert speech to text\". Google Cloud. Retrieved 2025-09-07.^Clark, Jack (20 July 2016). \"New Google AI Brings Automation to Customer Service\". Bloomberg.com.^\"Amazon.com tests customer service chatbots\". Amazon Science. 25 February 2020. Retrieved 23 April 2021.^Malatya Turgut Ozal University, Malatya, Turkey; Isguzar, Seda; Fendoglu, Eda; Malatya Turgut Ozal University, Malatya, Turkey; SimSek, Ahmed Ihsan (May 2024). \"Innovative Applications in Businesses: An Evaluation on Generative Artificial Intelligence\"(PDF). Amfiteatru Economic. 26 (66): 511. doi:10.24818/EA/2024/66/511. Retrieved 13 June 2024.{{cite journal}}:  CS1 maint: multiple names: authors list (link)^\"Advanced analytics in hospitality\". McKinsey & Company. 2017. Retrieved 14 January 2020.^Zlatanov, Sonja; Popesku, Jovan (2019). \"Current Applications of Artificial Intelligence in Tourism and Hospitality\". Proceedings of the International Scientific Conference - Sinteza 2019. pp.\u00a084\u201390. doi:10.15308/Sinteza-2019-84-90. ISBN\u00a0978-86-7912-703-7.^\"The promises and perils of new technologies to improve education and employment opportunities\". Brookings. Retrieved 2024-04-20.^\"Role of AI in Energy\". DOE.^Bourhnane, Safae; Abid, Mohamed Riduan; Lghoul, Rachid; Zine-Dine, Khalid; Elkamoun, Najib; Benhaddou, Driss (30 January 2020). \"Machine learning for energy consumption prediction and scheduling in smart buildings\". SN Applied Sciences. 2 (2): 297. doi:10.1007/s42452-020-2024-9.^Kanwal, Sidra; Khan, Bilal; Muhammad Ali, Sahibzada (February 2021). \"Machine learning based weighted scheduling scheme for active power control of hybrid microgrid\". International Journal of Electrical Power & Energy Systems. 125 106461. Bibcode:2021IJEPE.12506461K. doi:10.1016/j.ijepes.2020.106461.^Mohanty, Prasanta Kumar; Jena, Premalata; Padhy, Narayana Prasad (2020). \"Home Electric Vehicle Charge Scheduling Using Machine Learning Technique\". 2020 IEEE International Conference on Power Systems Technology (POWERCON). pp.\u00a01\u20135. doi:10.1109/POWERCON48463.2020.9230627. ISBN\u00a0978-1-7281-6350-5.^Foster, Isabella (15 March 2021). \"Making Smart Grids Smarter with Machine Learning\". EIT | Engineering Institute of Technology. Retrieved 3 July 2022.^ abCiaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. p.\u00a0211. ISBN\u00a0978-88-947876-0-3.^Williams, Ben; Lamont, Timothy A. C.; Chapuis, Lucille; Harding, Harry R.; May, Eleanor B.; Prasetya, Mochyudho E.; Seraphim, Marie J.; Jompa, Jamaluddin; Smith, David J.; Janetski, Noel; Radford, Andrew N.; Simpson, Stephen D. (July 2022). \"Enhancing automated analysis of marine soundscapes using ecoacoustic indices and machine learning\". Ecological Indicators. 140 108986. Bibcode:2022EcInd.14008986W. doi:10.1016/j.ecolind.2022.108986. hdl:10871/129693.^Hino, M.; Benami, E.; Brooks, N. (October 2018). \"Machine learning for environmental monitoring\". Nature Sustainability. 1 (10): 583\u2013588. Bibcode:2018NatSu...1..583H. doi:10.1038/s41893-018-0142-9.^\"How machine learning can help environmental regulators\". Stanford News. Stanford University. 8 April 2019. Retrieved 29 May 2022.^\"AI empowers environmental regulators\". Stanford News. Stanford University. 19 April 2021. Retrieved 29 May 2022.^ ab\"Artificial intelligence in space\". www.esa.int. Retrieved 30 May 2022.^Frost, Rosie (9 May 2022). \"Plastic waste can now be found and monitored from space\". euronews. Retrieved 24 June 2022.^\"Global Plastic Watch\". www.globalplasticwatch.org. Retrieved 24 June 2022.^\"AI may predict the next virus to jump from animals to humans\". Public Library of Science. Retrieved 19 October 2021.^Mollentze, Nardus; Babayan, Simon A.; Streicker, Daniel G. (28 September 2021). \"Identifying and prioritizing potential human-infecting viruses from their genome sequences\". PLOS Biology. 19 (9) e3001390. doi:10.1371/journal.pbio.3001390. PMC\u00a08478193. PMID\u00a034582436.^Li, Zefeng; Meier, Men-Andrin; Hauksson, Egill; Zhan, Zhongwen; Andrews, Jennifer (28 May 2018). \"Machine Learning Seismic Wave Discrimination: Application to Earthquake Early Warning\". Geophysical Research Letters. 45 (10): 4773\u20134779. Bibcode:2018GeoRL..45.4773L. doi:10.1029/2018GL077870.^\"Machine learning and gravity signals could rapidly detect big earthquakes\". Science News. 11 May 2022. Retrieved 3 July 2022.^Fauvel, Kevin; Balouek-Thomert, Daniel; Melgar, Diego; Silva, Pedro; Simonet, Anthony; Antoniu, Gabriel; Costan, Alexandru; Masson, V\u00e9ronique; Parashar, Manish; Rodero, Ivan; Termier, Alexandre (3 April 2020). \"A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning\". Proceedings of the AAAI Conference on Artificial Intelligence. 34 (1): 403\u2013411. doi:10.1609/aaai.v34i01.5376.^Thirugnanam, Hemalatha; Ramesh, Maneesha Vinodini; Rangan, Venkat P. (September 2020). \"Enhancing the reliability of landslide early warning systems by machine learning\". Landslides. 17 (9): 2231\u20132246. Bibcode:2020Lands..17.2231T. doi:10.1007/s10346-020-01453-z.^Moon, Seung-Hyun; Kim, Yong-Hyuk; Lee, Yong Hee; Moon, Byung-Ro (2019). \"Application of machine learning to an early warning system for very short-term heavy rainfall\". Journal of Hydrology. 568: 1042\u20131054. Bibcode:2019JHyd..568.1042M. doi:10.1016/j.jhydrol.2018.11.060.^Robinson, Bethany; Cohen, Jonathan S.; Herman, Jonathan D. (September 2020). \"Detecting early warning signals of long-term water supply vulnerability using machine learning\". Environmental Modelling & Software. 131 104781. Bibcode:2020EnvMS.13104781R. doi:10.1016/j.envsoft.2020.104781.^Bury, Thomas M.; Sujith, R. I.; Pavithran, Induja; Scheffer, Marten; Lenton, Timothy M.; Anand, Madhur; Bauch, Chris T. (28 September 2021). \"Deep learning for early warning signals of tipping points\". Proceedings of the National Academy of Sciences. 118 (39) e2106140118. Bibcode:2021PNAS..11806140B. doi:10.1073/pnas.2106140118. PMC\u00a08488604. PMID\u00a034544867.^Park, Yongeun; Lee, Han Kyu; Shin, Jae-Ki; Chon, Kangmin; Kim, SungHwan; Cho, Kyung Hwa; Kim, Jin Hwi; Baek, Sang-Soo (15 June 2021). \"A machine learning approach for early warning of cyanobacterial bloom outbreaks in a freshwater reservoir\". Journal of Environmental Management. 288 112415. Bibcode:2021JEnvM.28812415P. doi:10.1016/j.jenvman.2021.112415. PMID\u00a033774562.^Li, Jun; Wang, Zhaoli; Wu, Xushu; Xu, Chong-Yu; Guo, Shenglian; Chen, Xiaohong; Zhang, Zhenxing (August 2021). \"Robust Meteorological Drought Prediction Using Antecedent SST Fluctuations and Machine Learning\". Water Resources Research. 57 (8) e2020WR029413. Bibcode:2021WRR....5729413L. doi:10.1029/2020WR029413. hdl:10852/92935.^Khan, Najeebullah; Sachindra, D. A.; Shahid, Shamsuddin; Ahmed, Kamal; Shiru, Mohammed Sanusi; Nawaz, Nadeem (May 2020). \"Prediction of droughts over Pakistan using machine learning algorithms\". Advances in Water Resources. 139 103562. Bibcode:2020AdWR..13903562K. doi:10.1016/j.advwatres.2020.103562.^Kaur, Amandeep; Sood, Sandeep K. (May 2020). \"Deep learning based drought assessment and prediction framework\". Ecological Informatics. 57 101067. Bibcode:2020EcInf..5701067K. doi:10.1016/j.ecoinf.2020.101067.^Preparing for the future of artificial intelligence. National Science and Technology Council. p.\u00a014. OCLC\u00a0965620122. Retrieved 7 December 2024.^\"Research at NVIDIA: Transforming Standard Video Into Slow Motion with AI\". 18 June 2018. Archived from the original on 21 December 2021 \u2013 via YouTube.^\"Artificial intelligence is helping old video games look like new\". The Verge. 18 April 2019.^\"Review: Topaz Sharpen AI is Amazing\". petapixel.com. 4 March 2019.^Griffin, Matthew (26 April 2018). \"AI can now restore your corrupted photos to their original condition\".^\"NVIDIA's AI can fix bad photos by looking at other bad photos\". Engadget. 10 July 2018.^\"Using AI to Colorize and Upscale a 109-Year-Old Video of New York City to 4K and 60fps\". petapixel.com. 24 February 2020.^\"YouTubers are upscaling the past to 4K. Historians want them to stop\". Wired UK.^\"Facebook's image outage reveals how the company's AI tags your photos\". The Verge. 3 July 2019.^\"Google's DeepMind AI can 'transframe' a single image into a video\". 18 August 2022.^\"Google's new AI turns text into music\". 28 January 2023.^\"Google's new AI music generator can create - and hold - a tune\". 30 January 2023.^\"CSDL | IEEE Computer Society\".^Jodka, Sara (February 1, 2024). \"Manipulating reality: the intersection of deepfakes and the law\". Reuters.com. Retrieved December 8, 2024.^\"InVID kick-off meeting\". InVID project. 22 January 2016. Retrieved 23 December 2021. We are kicking-off the new H2020 InVID research project.^(In Video Veritas)^\"Consortium of the InVID project\". InVID project. Retrieved 23 December 2021. The InVID vision: The InVID innovation action develops a knowledge verification platform to detect emerging stories and assess the reliability of newsworthy video files and content spread via social media.^Teyssou, Denis (2019). \"Applying Design Thinking Methodology: The InVID Verification Plugin\". Video Verification in the Fake News Era. pp.\u00a0263\u2013279. doi:10.1007/978-3-030-26752-0_9. ISBN\u00a0978-3-030-26751-3.^\"Fake news debunker by InVID & WeVerify\". Retrieved 23 December 2021.^\"TUM Visual Computing & Artificial Intelligence: Prof. Matthias Nie\u00dfner\". niessnerlab.org.^\"Will \"Deepfakes\" Disrupt the Midterm Election?\". Wired. November 2018.^ abAfchar, Darius; Nozick, Vincent; Yamagishi, Junichi; Echizen, Isao (2018). \"MesoNet: A Compact Facial Video Forgery Detection Network\". 2018 IEEE International Workshop on Information Forensics and Security (WIFS). pp.\u00a01\u20137. arXiv:1809.00888. doi:10.1109/WIFS.2018.8630761. ISBN\u00a0978-1-5386-6536-7.^Lyons, Kim (29 January 2020). \"FTC says the tech behind audio deepfakes is getting better\". The Verge.^\"Audio samples from \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\"\". google.github.io.^Strickland, Eliza (11 December 2019). \"Facebook AI Launches Its Deepfake Detection Challenge\". IEEE Spectrum.^\"Contributing Data to Deepfake Detection Research\". ai.googleblog.com. 24 September 2019.^Ober, Holly. \"New method detects deepfake videos with up to 99% accuracy\". University of California-Riverside. Retrieved 3 July 2022.^\"AI algorithm detects deepfake videos with high accuracy\". techxplore.com. Retrieved 3 July 2022.^ abc\"Welcome to the new surreal. How AI-generated video is changing film\". MIT Technology Review. Retrieved 2023-12-05.^Bean, Thomas H. Davenport and Randy (2023-06-19). \"The Impact of Generative AI on Hollywood and Entertainment\". MIT Sloan Management Review. Retrieved 2023-12-05.^Cheng, Jacqui (30 September 2009). \"Virtual composer makes beautiful music\u2014and stirs controversy\". Ars Technica.^.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US patent 7696426\u00a0^\"Computer composer honours Turing's centenary\". New Scientist. 4 July 2012. Archived from the original on 2016-04-13. Retrieved 27 December 2021.^Hick, Thierry (11 October 2016). \"La musique classique recompos\u00e9e\". Luxemburger Wort.^\"R\u00e9sultats de recherche - La Sacem\". repertoire.sacem.fr.^Requena, Gloria; S\u00e1nchez, Carlos; Corzo-Higueras, Jos\u00e9 Luis; Reyes-Alvarado, Sirenia; Rivas-Ruiz, Francisco; Vico, Francisco; Raglio, Alfredo (2014). \"Melomics music medicine (M3) to lessen pain perception during pediatric prick test procedure\". Pediatric Allergy and Immunology. 25 (7): 721\u2013724. doi:10.1111/pai.12263. PMID\u00a025115240.^\"Watson Beat on GitHub\". GitHub. 10 October 2018.^\"Songs in the Key of AI\". Wired. 17 May 2018.^\"Hayeon, sister of Girls' Generation's Taeyeon, debuts with song made by AI\". koreajoongangdaily.joins.com. 7 October 2020. Retrieved 23 October 2020.^business intelligence solutionsArchived 3 November 2011 at the Wayback Machine. Narrative Science. Retrieved 21 July 2013.^Eule, Alexander. \"Big Data and Yahoo's Quest for Mass Personalization\". Barron's.^\"Artificial Intelligence Software that Writes like a Human Being\". Archived from the original on 12 April 2013. Retrieved 11 March 2013.^Riedl, Mark Owen; Bulitko, Vadim (6 December 2012). \"Interactive Narrative: An Intelligent Systems Approach\". AI Magazine. 34 (1): 67. doi:10.1609/aimag.v34i1.2449.^Callaway, Charles B.; Lester, James C. (August 2002). \"Narrative prose generation\". Artificial Intelligence. 139 (2): 213\u2013252. doi:10.1016/S0004-3702(02)00230-8.^\"A Japanese AI program just wrote a short novel, and it almost won a literary prize\". Digital Trends. 23 March 2016. Retrieved 18 November 2016.^\"Bot News\". Hanteo News. 20 October 2020. Retrieved 20 October 2020.^Canavilhas, Jo\u00e3o (September 2022). \"Artificial Intelligence and Journalism: Current Situation and Expectations in the Portuguese Sports Media\". Journalism and Media. 3 (3): 510\u2013520. doi:10.3390/journalmedia3030035. hdl:10400.6/12308.^ abcdGalily, Yair (August 2018). \"Artificial intelligence and sports journalism: Is it a sweeping change?\". Technology in Society. 54: 47\u201351. doi:10.1016/j.techsoc.2018.03.001.^Wu, Daniel (2023-08-31). \"Gannett halts AI-written sports recaps after readers mocked the stories\". Washington Post. Retrieved 2023-10-31.^Gertner, Jon (18 July 2023). \"Wikipedia's Moment of Truth - Can the online encyclopedia help teach A.I. chatbots to get their facts right \u2014 without destroying itself in the process? + comment\". The New York Times. Archived from the original on 18 July 2023. Retrieved 19 July 2023.{{cite news}}:  CS1 maint: bot: original URL status unknown (link)^\"Study reveals bot-on-bot editing wars raging on Wikipedia's pages\". The Guardian. 23 February 2017. Retrieved 10 January 2023.^Cole, K. C. \"The Shaky Ground Truths of Wikipedia\". Wired. Retrieved 10 January 2023.^\"AI can automatically rewrite outdated text in Wikipedia articles\". Engadget. Retrieved 10 January 2023.^Metz, Cade. \"Wikipedia Deploys AI to Expand Its Ranks of Human Editors\". Wired. Retrieved 10 January 2023.^\"Wikipedia taps Google to help editors translate articles\". VentureBeat. 9 January 2019. Retrieved 9 January 2023.^Wilson, Kyle (8 May 2019). \"Wikipedia has a Google Translate problem\". The Verge. Retrieved 9 January 2023.^\"Why AI researchers like video games\". The Economist. Archived from the original on 5 October 2017.^Yannakakis, Geogios N. (2012). \"Game AI revisited\". Proceedings of the 9th conference on Computing Frontiers - CF '12. p.\u00a0285. doi:10.1145/2212908.2212954. ISBN\u00a0978-1-4503-1215-8.^Maass, Laura E. Shummon (1 July 2019). \"Artificial Intelligence in Video Games\". Medium. Retrieved 23 April 2021.^Markoff, John (16 February 2011). \"Computer Wins on 'Jeopardy!': Trivial, It's Not\". The New York Times. Archived from the original on 22 October 2014. Retrieved 25 October 2014.^\"AlphaGo \u2013 Google DeepMind\". Archived from the original on 10 March 2016.^\"Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol\". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016.^Metz, Cade (27 May 2017). \"After Win in China, AlphaGo's Designers Explore New AI\". Wired. Archived from the original on 2 June 2017.^\"World's Go Player Ratings\". May 2017. Archived from the original on 1 April 2017.^\"\u67ef\u6d01\u8fce19\u5c81\u751f\u65e5 \u96c4\u8e1e\u4eba\u7c7b\u4e16\u754c\u6392\u540d\u7b2c\u4e00\u5df2\u4e24\u5e74\" (in Chinese). May 2017. Archived from the original on 11 August 2017.^\"MuZero: Mastering Go, chess, shogi and Atari without rules\". Deepmind. 23 December 2020. Retrieved 1 March 2021.^Steven Borowiec; Tracey Lien (12 March 2016). \"AlphaGo beats human Go champ in milestone for artificial intelligence\". Los Angeles Times. Retrieved 13 March 2016.^Solly, Meilan. \"This Poker-Playing A.I. Knows When to Hold 'Em and When to Fold 'Em\". Smithsonian. Pluribus has bested poker pros in a series of six-player no-limit Texas Hold'em games, reaching a milestone in artificial intelligence research. It is the first bot to beat humans in a complex multiplayer competition.^Bowling, Michael; Burch, Neil; Johanson, Michael; Tammelin, Oskari (9 January 2015). \"Heads-up limit hold'em poker is solved\". Science. 347 (6218): 145\u2013149. Bibcode:2015Sci...347..145B. doi:10.1126/science.1259433. PMID\u00a025574016.^Ontanon, Santiago; Synnaeve, Gabriel; Uriarte, Alberto; Richoux, Florian; Churchill, David; Preuss, Mike (December 2013). \"A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft\". IEEE Transactions on Computational Intelligence and AI in Games. 5 (4): 293\u2013311. doi:10.1109/TCIAIG.2013.2286295.^\"Facebook Quietly Enters StarCraft War for AI Bots, and Loses\". WIRED. 2017. Retrieved 7 May 2018.^Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (7 December 2018). \"A general reinforcement learning algorithm that masters chess, shogi, and go through self-play\". Science. 362 (6419): 1140\u20131144. Bibcode:2018Sci...362.1140S. doi:10.1126/science.aar6404. PMID\u00a030523106.^Sample, Ian (18 October 2017). \"'It's able to create knowledge itself': Google unveils AI that learns on its own\". The Guardian. Retrieved 7 May 2018.^Appenzeller, Tim (7 July 2017). \"The AI revolution in science\". Science. doi:10.1126/science.aan7064.^\"The superhero of artificial intelligence: can this genius keep it in check?\". The Guardian. 16 February 2016. Archived from the original on 23 April 2018. Retrieved 26 April 2018.^Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529\u2013533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID\u00a025719670.^Sample, Ian (14 March 2017). \"Google's DeepMind makes AI program that can learn like a human\". The Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018.^Schrittwieser, Julian; Antonoglou, Ioannis; Hubert, Thomas; Simonyan, Karen; Sifre, Laurent; Schmitt, Simon; Guez, Arthur; Lockhart, Edward; Hassabis, Demis; Graepel, Thore; Lillicrap, Timothy; Silver, David (24 December 2020). \"Mastering Atari, Go, chess and shogi by planning with a learned model\". Nature. 588 (7839): 604\u2013609. arXiv:1911.08265. Bibcode:2020Natur.588..604S. doi:10.1038/s41586-020-03051-4. PMID\u00a033361790.^Ortiz, Sabrina. \"You can now chat with a famous AI character on Viber. Here's how\". zdnet.com. ZDNET. Retrieved 5 December 2024. ICONIQ created Kuki, an AI character whose sole purpose is to entertain humans and has even been used as a brand ambassador for H&M, modeled for Vogue, and starred in its own Roblox game.^Lewis, Nell (19 August 2020). \"Robot friends: Why people talk to chatbots in times of trouble\". cnn.com. CNN. Retrieved 5 December 2024. Since 2016, when the bot landed on major messaging platforms, an estimated 5 million unique users hailing from all corners of the world have chatted with her.^Poltronieri, Fabrizio Augusto; H\u00e4nska, Max (2019). \"Technical Images and Visual Art in the Era of Artificial Intelligence: From GOFAI to GANs\". Proceedings of the 9th International Conference on Digital and Interactive Arts. pp.\u00a01\u20138. doi:10.1145/3359852.3359865. ISBN\u00a0978-1-4503-7250-3.^\"Fine art print - crypto art\". Kate Vass Galerie. Retrieved 2022-05-07.^ ab\"Analysis | Is That Trump Photo Real? Free AI Tools Come With Risks\". Washington Post. Retrieved 30 August 2022.^\"Google's image generator rivals DALL-E in shiba inu drawing\". TechCrunch. Retrieved 30 August 2022.^\"Midjourney's enthralling AI art generator goes live for everyone\". PCWorld.^\"After Photos, Here's How AI Made A Trippy Music Video Out Of Thin Air\". Fossbytes. 19 May 2022. Retrieved 30 May 2022.^Cetinic, Eva; She, James (2022-02-16). \"Understanding and Creating Art with AI: Review and Outlook\". ACM Transactions on Multimedia Computing, Communications, and Applications. 18 (2): 66:1\u201366:22. arXiv:2102.09109. doi:10.1145/3475799.^Lang, Sabine; Ommer, Bjorn (2018). \"Reflecting on How Artworks Are Processed and Analyzed by Computer Vision: Supplementary Material\". Proceedings of the European Conference on Computer Vision (ECCV) Workshops \u2013 via Computer Vision Foundation.^Cole, Samantha (2023-02-01). \"Netflix Made an Anime Using AI Due to a 'Labor Shortage,' and Fans Are Pissed\". Vice. Retrieved 2023-12-04.^Christy, Charles A. (17 January 1990). \"Impact of Artificial Intelligence on Banking\". Los Angeles Times. Retrieved 10 September 2019.^O'Neill, Eleanor (31 July 2016). \"Accounting, automation and AI\". icas.com. Archived from the original on 18 November 2016. Retrieved 18 November 2016.^\"CTO Corner: Artificial Intelligence Use in Financial Services \u2013 Financial Services Roundtable\". Financial Services Roundtable. 2 April 2015. Archived from the original on 18 November 2016. Retrieved 18 November 2016.^\"Artificial Intelligence Solutions, AI Solutions\". sas.com.^Chapman, Lizette (7 January 2019). \"Palantir once mocked the idea of salespeople. Now it's hiring them\". Los Angeles Times. Retrieved 28 February 2019.^Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. 2017. doi:10.1007/978-3-319-66104-9. ISBN\u00a0978-3-319-66103-2.[page\u00a0needed]^Marwala, Tshilidzi; Hurwitz, Evan (2017). \"Efficient Market Hypothesis\". Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. pp.\u00a0101\u2013110. doi:10.1007/978-3-319-66104-9_9. ISBN\u00a0978-3-319-66103-2.^Shao, Jun; Lou, Zhukun; Wang, Chong; Mao, Jinye; Ye, Ailin (16 May 2022). \"The impact of artificial intelligence (AI) finance on financing constraints of non-SOE firms in emerging markets\". International Journal of Emerging Markets. 17 (4): 930\u2013944. doi:10.1108/IJOEM-02-2021-0299.^\"Algorithmic Trading\". Investopedia. 18 May 2005.^\"The Financial Stability Implications of Artificial Intelligence\"(PDF). FSB. Retrieved 2025-09-07.^\"Beyond Robo-Advisers: How AI Could Rewire Wealth Management\". 5 January 2017.^Asatryan, Diana (3 April 2017). \"Machine Learning Is the Future of Underwriting, But Startups Won't be Driving It\". bankinnovation.net. Retrieved 15 April 2022.^Laura, Blattner; Jann, Spiess. \"Explainability & Fairness in Machine Learning for Credit Underwriting\"(PDF). FinRegLab. Retrieved 2025-09-07.^\"ZestFinance Introduces Machine Learning Platform to Underwrite Millennials and Other Consumers with Limited Credit History\" (Press release). 14 February 2017.^Chang, Hsihui; Kao, Yi-Ching; Mashruwala, Raj; Sorensen, Susan M. (10 April 2017). \"Technical Inefficiency, Allocative Inefficiency, and Audit Pricing\". Journal of Accounting, Auditing & Finance. 33 (4): 580\u2013600. doi:10.1177/0148558X17696760.^Munoko, Ivy; Brown-Liburd, Helen L.; Vasarhelyi, Miklos (November 2020). \"The Ethical Implications of Using Artificial Intelligence in Auditing\". Journal of Business Ethics. 167 (2): 209\u2013234. doi:10.1007/s10551-019-04407-1.^Fadelli, Ingrid. \"LaundroGraph: Using deep learning to support anti\u2013money laundering efforts\". techxplore.com. Retrieved 18 December 2022.^Cardoso, M\u00e1rio; Saleiro, Pedro; Bizarro, Pedro (2022). \"LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\". Proceedings of the Third ACM International Conference on AI in Finance. pp.\u00a0130\u2013138. arXiv:2210.14360. doi:10.1145/3533271.3561727. ISBN\u00a0978-1-4503-9376-8.^Sivamayilvelan, Keerthana; Rajasekar, Elakkiya; Vairavasundaram, Subramaniyaswamy; Balachandran, Santhi; Suresh, Vishnu (2025-11-01). \"Building explainable artificial intelligence for reinforcement learning based debt collection recommender system using large language models\". Engineering Applications of Artificial Intelligence. 159 111622. doi:10.1016/j.engappai.2025.111622. ISSN\u00a00952-1976.^Durkin, J. (2002). \"History and applications\". Expert Systems. Vol.\u00a01. pp.\u00a01\u201322. doi:10.1016/B978-012443880-4/50045-4. ISBN\u00a0978-0-12-443880-4.^Chen, K.C.; Liang, Ting-peng (May 1989). \"Protrader: An Expert System for Program Trading\". Managerial Finance. 15 (5): 1\u20136. doi:10.1108/eb013623.^Nielson, Norma; Brown, Carol E.; Phillips, Mary Ellen (July 1990). \"Expert Systems for Personal Financial Planning\". Journal of Financial Planning: 137\u2013143. doi:10.11575/PRISM/33995. hdl:1880/48295.^Senator, Ted E.; Goldberg, Henry G.; Wooton, Jerry; Cottini, Matthew A.; Khan, A.F. Umar; Kilinger, Christina D.; Llamas, Winston M.; Marrone, MichaeI P.; Wong, Raphael W.H. (1995). \"The FinCEN Artificial Intelligence System: Identifying Potential Money Laundering from Reports of Large Cash Transactions\"(PDF). IAAI-95 Proceedings. Archived from the original(PDF) on 2015-10-20. Retrieved 2019-01-14.^Sutton, Steve G.; Holt, Matthew; Arnold, Vicky (September 2016). \"'The reports of my death are greatly exaggerated'\u2014Artificial intelligence research in accounting\". International Journal of Accounting Information Systems. 22: 60\u201373. doi:10.1016/j.accinf.2016.07.005.^Bender, Michael J.; Katopodis, Chris; Simonovic, Slobodan P. (1992). \"A prototype expert system for fishway design\". Environmental Monitoring and Assessment. 23 (1\u20133): 115\u2013127. Bibcode:1992EMnAs..23..115B. doi:10.1007/BF00406956. PMID\u00a024227094.^Wayson, Roger L. (1989). \"Use of a Knowledge-Based Expert System to Maximize Airport Capacity in Harmony with Noise-Mitigation Plans\"(PDF). Transportation Research Record. 1218: 31\u201340.^Vencill, A. M.; Speese, J. (1995). \"Potato Insect Expert System: Computerized Approach to Colorado Potato Beetle Management\". Journal of Economic Entomology. 88 (4): 944\u2013954. doi:10.1093/jee/88.4.944.^Jirka, Gerhard H.; Akar, Paul J. (1996). User's Manual for CORMIX: A Hydrodynamic Mixing Zone Model and Decision Support System for Pollutant Discharges into Surface Waters(PDF) (Report). U.S. Environmental Protection Agency.^Chalmers, Dominic; MacKenzie, Niall G.; Carter, Sara (September 2021). \"Artificial Intelligence and Entrepreneurship: Implications for Venture Creation in the Fourth Industrial Revolution\". Entrepreneurship Theory and Practice. 45 (5): 1028\u20131053. doi:10.1177/1042258720934581.^Thompsett, Louis (2025-02-04). \"What EU AI Act Means for Governance in Financial Sector\". fintechmagazine.com. Retrieved 2025-09-20.^ abSzczytko, Jacek (2025-08-15). \"How will the AI Act alter the landscape for fintechs? Key requirements and penalties\". Dudkowiak & Putyra. Retrieved 2025-09-20.^ ab\"Regulation - EU - 2024/1689 - EN - EUR-Lex\". eur-lex.europa.eu. Retrieved 2025-09-20.^\"AI Credit Regulations Affecting Lending Business 2025\". hesfintech. 10 October 2025. Archived from the original on 12 October 2025. Retrieved 10 October 2025.^\"10 Promising AI Applications in Health Care\". Harvard Business Review. 10 May 2018. Archived from the original on 15 December 2018. Retrieved 28 August 2018.^Lareyre, Fabien; L\u00ea, Cong Duy; Ballaith, Ali; Adam, C\u00e9dric; Carrier, Marion; Amrani, Samantha; Caradu, Caroline; Raffort, Juliette (August 2022). \"Applications of Artificial Intelligence in Non-cardiac Vascular Diseases: A Bibliographic Analysis\". Angiology. 73 (7): 606\u2013614. doi:10.1177/00033197211062280. PMID\u00a034996315.^\"What is artificial intelligence in medicine?\". IBM. 28 March 2024. Retrieved 19 April 2024.^\"Microsoft Using AI to Accelerate Cancer Precision Medicine\". HealthITAnalytics. 29 October 2019. Retrieved 29 November 2020.^Dina Bass (20 September 2016). \"Microsoft Develops AI to Help Cancer Doctors Find the Right Treatments\". Bloomberg L.P. Archived from the original on 11 May 2017.^Gallagher, James (26 January 2017). \"Artificial intelligence 'as good as cancer doctors'\". BBC News. Archived from the original on 26 January 2017. Retrieved 26 January 2017.^Langen, Pauline A.; Katz, Jeffrey S.; Dempsey, Gayle, eds. (18 October 1994), Remote monitoring of high-risk patients using artificial intelligence, archived from the original on 28 February 2017, retrieved 27 February 2017^Kermany, Daniel S.; Goldbaum, Michael; Cai, Wenjia; Valentim, Carolina C.S.; Liang, Huiying; Baxter, Sally L.; McKeown, Alex; Yang, Ge; Wu, Xiaokang; Yan, Fangbing; Dong, Justin; Prasadha, Made K.; Pei, Jacqueline; Ting, Magdalene Y.L.; Zhu, Jie; Li, Christina; Hewett, Sierra; Dong, Jason; Ziyar, Ian; Shi, Alexander; Zhang, Runze; Zheng, Lianghong; Hou, Rui; Shi, William; Fu, Xin; Duan, Yaou; Huu, Viet A.N.; Wen, Cindy; Zhang, Edward D.; Zhang, Charlotte L.; Li, Oulan; Wang, Xiaobo; Singer, Michael A.; Sun, Xiaodong; Xu, Jie; Tafreshi, Ali; Lewis, M. Anthony; Xia, Huimin; Zhang, Kang (February 2018). \"Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\". Cell. 172 (5): 1122\u20131131.e9. doi:10.1016/j.cell.2018.02.010. PMID\u00a029474911.^Senthilingam, Meera (12 May 2016). \"Are Autonomous Robots Your next Surgeons?\". CNN. Archived from the original on 3 December 2016. Retrieved 4 December 2016.^Pumplun L, Fecho M, Wahl N, Peters F, Buxmann P (2021). \"Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\". Journal of Medical Internet Research. 23 (10) e29301. doi:10.2196/29301. PMC\u00a08556641. PMID\u00a034652275.^Inglese, Marianna; Patel, Neva; Linton-Reid, Kristofer; Loreto, Flavia; Win, Zarni; Perry, Richard J.; Carswell, Christopher; Grech-Sollars, Matthew; Crum, William R.; Lu, Haonan; Malhotra, Paresh A.; Aboagye, Eric O. (20 June 2022). \"A predictive model using the mesoscopic architecture of the living brain to detect Alzheimer's disease\". Communications Medicine. 2 (1): 70. doi:10.1038/s43856-022-00133-4. PMC\u00a09209493. PMID\u00a035759330.News report: \"Single MRI scan of the brain could detect Alzheimer's disease\". Physics World. 13 July 2022. Retrieved 19 July 2022.^Yorita, Akihiro; Kubota, Naoyuki (2011). \"Cognitive Development in Partner Robots for Information Support to Elderly People\". IEEE Transactions on Autonomous Mental Development. 3 (1): 64\u201373. Bibcode:2011ITAMD...3...64Y. doi:10.1109/TAMD.2011.2105868.^\"Artificial Intelligence Will Redesign Healthcare \u2013 The Medical Futurist\". The Medical Futurist. 4 August 2016. Retrieved 18 November 2016.^D\u00f6nerta\u015f, Handan Melike; Fuentealba, Mat\u00edas; Partridge, Linda; Thornton, Janet M. (February 2019). \"Identifying Potential Ageing-Modulating Drugs In Silico\". Trends in Endocrinology & Metabolism. 30 (2): 118\u2013131. doi:10.1016/j.tem.2018.11.005. PMC\u00a06362144. PMID\u00a030581056.^Smer-Barreto, Vanessa; Quintanilla, Andrea; Elliot, Richard J. R.; Dawson, John C.; Sun, Jiugeng; Carragher, Neil O.; Acosta, Juan Carlos; Oyarz\u00fan, Diego A. (27 April 2022). \"Discovery of new senolytics using machine learning\". bioRxiv. doi:10.1101/2022.04.26.489505. hdl:10261/269843.^Luxton, David D. (2014). \"Artificial intelligence in psychological practice: Current and future applications and implications\". Professional Psychology: Research and Practice. 45 (5): 332\u2013339. doi:10.1037/a0034559.^Randhawa, Gurjit S.; Soltysiak, Maximillian P. M.; Roz, Hadi El; Souza, Camila P. E. de; Hill, Kathleen A.; Kari, Lila (24 April 2020). \"Machine learning using intrinsic genomic signatures for rapid classification of novel pathogens: COVID-19 case study\". PLOS ONE. 15 (4) e0232391. Bibcode:2020PLoSO..1532391R. doi:10.1371/journal.pone.0232391. PMC\u00a07182198. PMID\u00a032330208.^Ye, Jiarong; Yeh, Yin-Ting; Xue, Yuan; Wang, Ziyang; Zhang, Na; Liu, He; Zhang, Kunyan; Ricker, RyeAnne; Yu, Zhuohang; Roder, Allison; Perea Lopez, Nestor; Organtini, Lindsey; Greene, Wallace; Hafenstein, Susan; Lu, Huaguang; Ghedin, Elodie; Terrones, Mauricio; Huang, Shengxi; Huang, Sharon Xiaolei (7 June 2022). \"Accurate virus identification with interpretable Raman signatures by machine learning\". Proceedings of the National Academy of Sciences. 119 (23) e2118836119. arXiv:2206.02788. Bibcode:2022PNAS..11918836Y. doi:10.1073/pnas.2118836119. PMC\u00a09191668. PMID\u00a035653572.^\"Artificial intelligence finds disease-related genes\". Link\u00f6ping University. Retrieved 3 July 2022.^\"Researchers use AI to detect new family of genes in gut bacteria\". UT Southwestern Medical Center. Retrieved 3 July 2022.^ abcZhavoronkov, Alex; Mamoshina, Polina; Vanhaelen, Quentin; Scheibye-Knudsen, Morten; Moskalev, Alexey; Aliper, Alex (2019). \"Artificial intelligence for aging and longevity research: Recent advances and perspectives\". Ageing Research Reviews. 49: 49\u201366. doi:10.1016/j.arr.2018.11.003. PMID\u00a030472217.^Adir, Omer; Poley, Maria; Chen, Gal; Froim, Sahar; Krinsky, Nitzan; Shklover, Jeny; Shainsky-Roitman, Janna; Lammers, Twan; Schroeder, Avi (April 2020). \"Integrating Artificial Intelligence and Nanotechnology for Precision Cancer Medicine\". Advanced Materials. 32 (13) 1901989. Bibcode:2020AdM....3201989A. doi:10.1002/adma.201901989. PMC\u00a07124889. PMID\u00a031286573.^Moore, Phoebe V. (7 May 2019). \"OSH and the Future of Work: benefits and risks of artificial intelligence tools in workplaces\". EU-OSHA. pp.\u00a03\u20137. Retrieved 30 July 2020.^Howard, John (November 2019). \"Artificial intelligence: Implications for the future of work\". American Journal of Industrial Medicine. 62 (11): 917\u2013926. doi:10.1002/ajim.23037. PMID\u00a031436850.^Gianatti, Toni-Louise (14 May 2020). \"How AI-Driven Algorithms Improve an Individual's Ergonomic Safety\". Occupational Health & Safety. Retrieved 30 July 2020.^Meyers, Alysha R. (1 May 2019). \"AI and Workers' Comp\". NIOSH Science Blog. Retrieved 3 August 2020.^Webb, Sydney; Siordia, Carlos; Bertke, Stephen; Bartlett, Diana; Reitz, Dan (26 February 2020). \"Artificial Intelligence Crowdsourcing Competition for Injury Surveillance\". NIOSH Science Blog. Retrieved 3 August 2020.^Ferguson, Murray (19 April 2016). \"Artificial Intelligence: What's To Come for EHS... And When?\". EHS Today. Retrieved 30 July 2020.^Paul, Debleena; Sanap, Gaurav; Shenoy, Snehal; Kalyane, Dnyaneshwar; Kalia, Kiran; Tekade, Rakesh K. (January 2021). \"Artificial intelligence in drug discovery and development\". Drug Discovery Today. 26 (1): 80\u201393. doi:10.1016/j.drudis.2020.10.010. PMC\u00a07577280. PMID\u00a033099022.^\"Allchemy \u2013 Resource-aware AI for drug discovery\". Retrieved 29 May 2022.^Wo\u0142os, Agnieszka; Koszelewski, Dominik; Roszak, Rafa\u0142; Szymku\u0107, Sara; Moskal, Martyna; Ostaszewski, Ryszard; Herrera, Brenden T.; Maier, Josef M.; Brezicki, Gordon; Samuel, Jonathon; Lummiss, Justin A. M.; McQuade, D. Tyler; Rogers, Luke; Grzybowski, Bartosz A. (April 2022). \"Computer-designed repurposing of chemical wastes into drugs\". Nature. 604 (7907): 668\u2013676. Bibcode:2022Natur.604..668W. doi:10.1038/s41586-022-04503-9. PMID\u00a035478240.^Wo\u0142os, Agnieszka; Roszak, Rafa\u0142; \u017b\u0105d\u0142o-Dobrowolska, Anna; Beker, Wiktor; Mikulak-Klucznik, Barbara; Sp\u00f3lnik, Grzegorz; Dygas, Miros\u0142aw; Szymku\u0107, Sara; Grzybowski, Bartosz A. (25 September 2020). \"Synthetic connectivity, emergence, and self-regeneration in the network of prebiotic chemistry\". Science. 369 (6511) eaaw1955. doi:10.1126/science.aaw1955. PMID\u00a032973002.^Zhavoronkov, Alex; Ivanenkov, Yan A.; Aliper, Alex; Veselov, Mark S.; Aladinskiy, Vladimir A.; Aladinskaya, Anastasiya V.; Terentiev, Victor A.; Polykovskiy, Daniil A.; Kuznetsov, Maksim D.; Asadulaev, Arip; Volkov, Yury; Zholus, Artem; Shayakhmetov, Rim R.; Zhebrak, Alexander; Minaeva, Lidiya I.; Zagribelnyy, Bogdan A.; Lee, Lennart H.; Soll, Richard; Madge, David; Xing, Li; Guo, Tao; Aspuru-Guzik, Al\u00e1n (September 2019). \"Deep learning enables rapid identification of potent DDR1 kinase inhibitors\". Nature Biotechnology. 37 (9): 1038\u20131040. doi:10.1038/s41587-019-0224-x. PMID\u00a031477924.^\"DeepMind is answering one of biology's biggest challenges\". The Economist. 30 November 2020. Retrieved 30 November 2020.^Jeremy Kahn, Lessons from DeepMind's breakthrough in protein-folding A.I., Fortune, 1 December 2020^\"DeepMind uncovers structure of 200m proteins in scientific leap forward\". The Guardian. 2022-07-28. Retrieved 2022-07-28.^\"AlphaFold reveals the structure of the protein universe\". DeepMind. 2022-07-28. Retrieved 2022-07-28.^Nakamura, Satoshi (2009). \"Overcoming the language barrier with speech translation technology\". Science & Technology Trends Quarterly Review (31): 35\u201348. CORE output ID\u00a0236667511.^ abClark, Jack (8 December 2015). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com.^\"Can artificial intelligence really help us talk to the animals?\". The Guardian. 31 July 2022. Retrieved 30 August 2022.^K. Mandal, G. S. Pradeep Ghantasala, Firoz Khan, R. Sathiyaraj, B. Balamurugan (2020). Natural Language Processing in Artificial Intelligence (1st\u00a0ed.). Apple Academic Press. pp.\u00a053\u201354. ISBN\u00a0978-0-367-80849-5.{{cite book}}:  CS1 maint: multiple names: authors list (link)^Buckley, Chris; Mozur, Paul (22 May 2019). \"How China Uses High-Tech Surveillance to Subdue Minorities\". The New York Times.^\"Security lapse exposed a Chinese smart city surveillance system\". 3 May 2019. Archived from the original on 7 March 2021. Retrieved 14 September 2020.^\"AI traffic signals to be installed in Bengaluru soon\". NextBigWhat. 24 September 2019. Retrieved 1 October 2019.^Ashley, Kevin D. (2017). Artificial Intelligence and Legal Analytics. doi:10.1017/9781316761380. ISBN\u00a0978-1-107-17150-3.[page\u00a0needed]^Lohr, Steve (19 March 2017). \"A.I. Is Doing Legal Work. But It Won't Replace Lawyers, Yet\". The New York Times.^Croft, Jane (2 May 2019). \"AI learns to read Korean, so you don't have to\". Financial Times. Retrieved 19 December 2019.^Kleider-Offutt, Heather; Stevens, Beth; Mickes, Laura; Boogert, Stewart (3 April 2024). \"Application of artificial intelligence to eyewitness identification\". Cognitive Research: Principles and Implications. 9 (1): 19. doi:10.1186/s41235-024-00542-0. PMC\u00a010991253. PMID\u00a038568356.^ abJeff Larson; Julia Angwin (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020.^\"Commentary: Bad news. Artificial intelligence is biased\". CNA. 12 January 2019. Archived from the original on 12 January 2019. Retrieved 19 June 2020.^ ab\u0160imal\u010d\u00edk, Matej (2023). \"Rule by Law\". In Kironska, Kristina; Turscanyi, Richard Q. (eds.). Contemporary China: a New Superpower?. Routledge. ISBN\u00a0978-1-03-239508-1.^\"Digital Spectrometry\". 8 October 2018.^US 9967696B2, \"Digital Spectrometry Patent\", published 2018-10-08\u00a0^\"How artificial intelligence is moving from the lab to your kid's playroom\". The Washington Post. Retrieved 18 November 2016.^\"Application of artificial intelligence in oil and gas industry: Exploring its impact\". 15 May 2019.^Salvaterra, Neanda (14 October 2019). \"Oil and Gas Companies Turn to AI to Cut Costs\". The Wall Street Journal.^ abcCongressional Research Service (2019). Artificial Intelligence and National Security(PDF). Washington, DC: Congressional Research Service.PD-notice^Iraqi, Amjad (2024-04-03). \"'Lavender': The AI machine directing Israel's bombing spree in Gaza\". +972 Magazine. Retrieved 2024-04-06.^Davies, Harry; McKernan, Bethan; Sabbagh, Dan (2023-12-01). \"'The Gospel': how Israel uses AI to select bombing targets in Gaza\". The Guardian. Retrieved 2023-12-04.^Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf St\u00f6rsender \u2013 deshalb sollen sie jetzt autonom operieren\". Neue Z\u00fcrcher Zeitung (in German). Retrieved 10 August 2024.^\"What are the security risks of open sourcing the Twitter algorithm?\". VentureBeat. 27 May 2022. Retrieved 29 May 2022.^\"Examining algorithmic amplification of political content on Twitter\". Retrieved 29 May 2022.^Park, SoHyun; Oh, Heung-Kwon; Park, Gibeom; Suh, Bongwon; Bae, Woo Kyung; Kim, Jin Won; Yoon, Hyuk; Kim, Duck-Woo; Kang, Sung-Bum (February 2016). \"The Source and Credibility of Colorectal Cancer Information on Twitter\". Medicine. 95 (7) e2775. doi:10.1097/MD.0000000000002775. PMC\u00a04998625. PMID\u00a026886625.^Efthimion, Phillip; Payne, Scott; Proferes, Nicholas (20 July 2018). \"Supervised Machine Learning Bot Detection Techniques to Identify Social Twitter Bots\". SMU Data Science Review. 1 (2).^\"The online information environment\"(PDF). Retrieved 21 February 2022.^Islam, Md Rafiqul; Liu, Shaowu; Wang, Xianzhi; Xu, Guandong (29 September 2020). \"Deep learning for misinformation detection on online social networks: a survey and new perspectives\". Social Network Analysis and Mining. 10 (1): 82. doi:10.1007/s13278-020-00696-x. PMC\u00a07524036. PMID\u00a033014173.^Mohseni, Sina; Ragan, Eric (4 December 2018). \"Combating Fake News with Interpretable News Feed Algorithms\". arXiv:1811.12349 [cs.SI].^\"How artificial intelligence may be making you buy things\". BBC News. 9 November 2020. Retrieved 9 November 2020.^Busby, Mattha (30 April 2018). \"Revealed: how bookies use AI to keep gamblers hooked\". The Guardian.^Rowinski, Dan (15 January 2013). \"Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]\". ReadWrite. Archived from the original on 22 December 2015.^Roose, Kevin (16 February 2023). \"Bing's A.I. Chat: 'I Want to Be Alive. \ud83d\ude08'\". The New York Times.^Galego Hernandes, Paulo R.; Floret, Camila P.; Cardozo De Almeida, Katia F.; Da Silva, Vinicius Camargo; Papa, Joso Paulo; Pontara Da Costa, Kelton A. (2021). \"Phishing Detection Using URL-based XAI Techniques\". 2021 IEEE Symposium Series on Computational Intelligence (SSCI). pp.\u00a001\u201306. doi:10.1109/SSCI50451.2021.9659981. ISBN\u00a0978-1-7281-9048-8.^J\u00e1\u00f1ez-Martino, Francisco; Alaiz-Rodr\u00edguez, Roc\u00edo; Gonz\u00e1lez-Castro, V\u00edctor; Fidalgo, Eduardo; Alegre, Enrique (2023-02-01). \"A review of spam email detection: analysis of spammer strategies and the dataset shift problem\". Artificial Intelligence Review. 56 (2): 1145\u20131173. doi:10.1007/s10462-022-10195-4. hdl:10612/14967.^Kapan, Sibel; Sora Gunal, Efnan (January 2023). \"Improved Phishing Attack Detection with Machine Learning: A Comprehensive Evaluation of Classifiers and Features\". Applied Sciences. 13 (24) 13269. doi:10.3390/app132413269.^Heath, Nick (11 December 2020). \"What is AI? Everything you need to know about Artificial Intelligence\". ZDNet. Retrieved 1 March 2021.^\"China's massive investment in artificial intelligence has an insidious downside\". Science AAAS. February 7, 2018. Retrieved February 23, 2018.^\"China bets on facial recognition in big drive for total surveillance\". The Washington Post. 2018. Retrieved February 23, 2018.^\"Facial recognition forced on 800 million Chinese internet users\". Radio France Internationale. 15 October 2019. Retrieved April 21, 2024.^\"Country policy and information note: Falun Gong, China, November 2023 (accessible)\". The United Kingdom Government. April 4, 2024. Retrieved April 21, 2024.^Techredacteur, Joost Schellevis (December 16, 2016). \"Politie gaat verdachten opsporen met gezichtsherkenning\". nos.nl (in Dutch). Retrieved September 22, 2019.^Boon, Lex (August 25, 2018). \"Meekijken met de 226 gemeentecamera's\". Het Parool (in Dutch). Retrieved September 22, 2019.^\"Successful and timely uptake of artificial intelligence in science in the EU \u2013 Scientific Advice Mechanism\". Retrieved 2024-04-16.^\"AI in science evidence review report \u2013 Scientific Advice Mechanism\". Retrieved 2024-04-16.^Assael, Yannis; Sommerschield, Thea; Shillingford, Brendan; Bordbar, Mahyar; Pavlopoulos, John; Chatzipanagiotou, Marita; Androutsopoulos, Ion; Prag, Jonathan; de Freitas, Nando (March 2022). \"Restoring and attributing ancient texts using deep neural networks\". Nature. 603 (7900): 280\u2013283. Bibcode:2022Natur.603..280A. doi:10.1038/s41586-022-04448-z. PMC\u00a08907065. PMID\u00a035264762.^Mantovan, Lorenzo; Nanni, Loris (September 2020). \"The Computerization of Archaeology: Survey on Artificial Intelligence Techniques\". SN Computer Science. 1 (5) 267. arXiv:2005.02863. doi:10.1007/s42979-020-00286-w.^Mondal, Mayukh; Bertranpetit, Jaume; Lao, Oscar (December 2019). \"Approximate Bayesian computation with deep learning supports a third archaic introgression in Asia and Oceania\". Nature Communications. 10 (1): 246. Bibcode:2019NatCo..10..246M. doi:10.1038/s41467-018-08089-7. PMC\u00a06335398. PMID\u00a030651539.^Tanti, Marc; Berruyer, Camille; Tafforeau, Paul; Muscat, Adrian; Farrugia, Reuben; Scerri, Kenneth; Valentino, Gianluca; Sol\u00e9, V. Armando; Briffa, Johann A. (15 December 2021). \"Automated segmentation of microtomography imaging of Egyptian mummies\". PLOS ONE. 16 (12) e0260707. arXiv:2105.06738. Bibcode:2021PLoSO..1660707T. doi:10.1371/journal.pone.0260707. PMC\u00a08673632. PMID\u00a034910736.^\"DeepMind AI learns physics by watching videos that don't make sense\". New Scientist. Retrieved 21 August 2022.^Piloto, Luis S.; Weinstein, Ari; Battaglia, Peter; Botvinick, Matthew (11 July 2022). \"Intuitive physics learning in a deep-learning model inspired by developmental psychology\". Nature Human Behaviour. 6 (9): 1257\u20131267. doi:10.1038/s41562-022-01394-8. PMC\u00a09489531. PMID\u00a035817932.^ abFeldman, Andrey (11 August 2022). \"Artificial physicist to unravel the laws of nature\". Advanced Science News. Retrieved 21 August 2022.^Chen, Boyuan; Huang, Kuang; Raghupathi, Sunand; Chandratreya, Ishaan; Du, Qiang; Lipson, Hod (July 2022). \"Automated discovery of fundamental variables hidden in experimental data\". Nature Computational Science. 2 (7): 433\u2013442. doi:10.1038/s43588-022-00281-6. PMID\u00a038177869.^Nu\u00f1ez, Michael (2023-11-29). \"Google DeepMind's materials AI has already discovered 2.2 million new crystals\". VentureBeat. Retrieved 2023-12-19.^Merchant, Amil; Batzner, Simon; Schoenholz, Samuel S.; Aykol, Muratahan; Cheon, Gowoon; Cubuk, Ekin Dogus (December 2023). \"Scaling deep learning for materials discovery\". Nature. 624 (7990): 80\u201385. Bibcode:2023Natur.624...80M. doi:10.1038/s41586-023-06735-9. PMC\u00a010700131. PMID\u00a038030720.^Peplow, Mark (29 November 2023). \"Google AI and robots join forces to build new materials\". Nature. doi:10.1038/d41586-023-03745-5. PMID\u00a038030771.^Yanamandra, Kaushik; Chen, Guan Lin; Xu, Xianbo; Mac, Gary; Gupta, Nikhil (29 September 2020). \"Reverse engineering of additive manufactured composite part by toolpath reconstruction using imaging and machine learning\". Composites Science and Technology. 198 108318. doi:10.1016/j.compscitech.2020.108318.^Anderson, Blake; Storlie, Curtis; Yates, Micah; McPhall, Aaron (2014). \"Automating Reverse Engineering with Machine Learning Techniques\". Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop. pp.\u00a0103\u2013112. doi:10.1145/2666652.2666665. ISBN\u00a0978-1-4503-3153-1.^Liu, Wenye; Chang, Chip-Hong; Wang, Xueyang; Liu, Chen; Fung, Jason M.; Ebrahimabadi, Mohammad; Karimi, Naghmeh; Meng, Xingyu; Basu, Kanad (June 2021). \"Two Sides of the Same Coin: Boons and Banes of Machine Learning in Hardware Security\". IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 11 (2): 228\u2013251. Bibcode:2021IJEST..11..228L. doi:10.1109/JETCAS.2021.3084400. hdl:10356/155876.^\"DARPA Taps GrammaTech for Artificial Intelligence Exploration (AIE) Program\". www.businesswire.com. 7 January 2021. Retrieved 10 January 2023.^Greenberg, Andy. \"How to Steal an AI\". Wired. Retrieved 10 January 2023.^Sanchez-Lengeling, Benjamin; Aspuru-Guzik, Al\u00e1n (27 July 2018). \"Inverse molecular design using machine learning: Generative models for matter engineering\". Science. 361 (6400): 360\u2013365. Bibcode:2018Sci...361..360S. doi:10.1126/science.aat2663. PMID\u00a030049875.^ ab\"Biologists train AI to generate medicines and vaccines\". University of Washington-Harborview Medical Center.^ abWang, Jue; Lisanza, Sidney; Juergens, David; Tischer, Doug; Watson, Joseph L.; Castro, Karla M.; Ragotte, Robert; Saragovi, Amijai; Milles, Lukas F.; Baek, Minkyung; Anishchenko, Ivan; Yang, Wei; Hicks, Derrick R.; Exp\u00f2sit, Marc; Schlichthaerle, Thomas; Chun, Jung-Ho; Dauparas, Justas; Bennett, Nathaniel; Wicky, Basile I. M.; Muenks, Andrew; DiMaio, Frank; Correia, Bruno; Ovchinnikov, Sergey; Baker, David (22 July 2022). \"Scaffolding protein functional sites using deep learning\". Science. 377 (6604): 387\u2013394. Bibcode:2022Sci...377..387W. doi:10.1126/science.abn2100. PMC\u00a09621694. PMID\u00a035862514.^Teemu, Rintala (17 June 2019). Using Boolean network extraction of trained neural networks to reverse-engineer gene-regulatory networks from time-series data (Master's in Life Science Technologies thesis). Aalto University.[page\u00a0needed]^Ball, Nicholas M.; Brunner, Robert J. (July 2010). \"Data mining and machine learning in astronomy\". International Journal of Modern Physics D. 19 (7): 1049\u20131106. arXiv:0906.2173. Bibcode:2010IJMPD..19.1049B. doi:10.1142/S0218271810017160.^ abShekhtman, Svetlana (15 November 2019). \"NASA Applying AI Technologies to Problems in Space Science\". NASA. Retrieved 30 May 2022.^Fluke, Christopher J.; Jacobs, Colin (March 2020). \"Surveying the reach and maturity of machine learning and artificial intelligence in astronomy\". WIREs Data Mining and Knowledge Discovery. 10 (2) e1349. arXiv:1912.02934. Bibcode:2020WDMKD..10.1349F. doi:10.1002/widm.1349.^Pultarova, Tereza (29 April 2021). \"Artificial intelligence is learning how to dodge space junk in orbit\". Space.com. Retrieved 3 July 2022.^Mohan, Jaya Preethi; Tejaswi, N. (2020). \"A Study on Embedding the Artificial Intelligence and Machine Learning into Space Exploration and Astronomy\". Emerging Trends in Computing and Expert Technology. Lecture Notes on Data Engineering and Communications Technologies. Vol.\u00a035. pp.\u00a01295\u20131302. doi:10.1007/978-3-030-32150-5_131. ISBN\u00a0978-3-030-32149-9.^Rees, Martin (30 April 2022). \"Could space-going billionaires be the vanguard of a cosmic revolution? | Martin Rees\". The Guardian. Retrieved 29 May 2022.^Gutowska, Ma\u0142gorzata; Scriney, Michael; McCarren, Andrew (December 2019). Identifying extra-terrestrial intelligence using machine learning. 27th AIAI Irish Conference on Artificial Intelligence and Cognitive Science.^Zhang, Yunfan Gerry; Gajjar, Vishal; Foster, Griffin; Siemion, Andrew; Cordes, James; Law, Casey; Wang, Yu (2018). \"Fast Radio Burst 121102 Pulse Detection and Periodicity: A Machine Learning Approach\". The Astrophysical Journal. 866 (2): 149. arXiv:1809.03043. Bibcode:2018ApJ...866..149Z. doi:10.3847/1538-4357/aadf31.^Nanda, Lakshay; V, Santhi (2019). \"SETI (Search for Extra Terrestrial Intelligence) Signal Classification using Machine Learning\". 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). pp.\u00a0499\u2013504. doi:10.1109/ICSSIT46314.2019.8987793. ISBN\u00a0978-1-7281-2119-2.^Gajjar, Vishal; Siemion, Andrew; Croft, Steve; Brzycki, Bryan; Burgay, Marta; Carozzi, Tobia; Concu, Raimondo; Czech, Daniel; DeBoer, David; DeMarines, Julia; Drew, Jamie; Enriquez, J. Emilio; Fawcett, James; Gallagher, Peter; Garrett, Michael; Gizani, Nectaria; Hellbourg, Greg; Holder, Jamie; Isaacson, Howard; Kudale, Sanjay; Lacki, Brian; Lebofsky, Matthew; Li, Di; MacMahon, David H. E.; McCauley, Joe; Melis, Andrea; Molinari, Emilio; Murphy, Pearse; Perrodin, Delphine; Pilia, Maura; Price, Danny C.; Webb, Claire; Werthimer, Dan; Williams, David; Worden, Pete; Zarka, Philippe; Zhang, Yunfan Gerry (2 August 2019). \"The Breakthrough Listen Search for Extraterrestrial Intelligence\". Bulletin of the American Astronomical Society. 51 (7): 223. arXiv:1907.05519. Bibcode:2019BAAS...51g.223G.^\"SkyCAM-5 - Chair of Computer Science VIII - Aerospace Information Technology\". University of W\u00fcrzburg. Retrieved 29 May 2022.^\"Project Galileo: The search for alien tech hiding in our Solar System\". BBC Science Focus Magazine. Retrieved 29 May 2022.^\"'Something's coming': is America finally ready to take UFOs seriously?\". The Guardian. 5 February 2022. Retrieved 29 May 2022.^David, Leonard (27 January 2022). \"2022 could be a turning point in the study of UFOs\". livescience.com. Retrieved 29 May 2022.^Gritz, Jennie Rothenberg. \"The Wonder of Avi Loeb\". Retrieved 29 May 2022.^Mann, Adam. \"Avi Loeb's Galileo Project Will Search for Evidence of Alien Visitation\". Scientific American. Retrieved 29 May 2022.^\"Galileo Project \u2013 Activities\". projects.iq.harvard.edu. Retrieved 29 May 2022.^\"The Galileo Project: Harvard researchers to search for signs of alien technology\". Sky News.^Zapata Trujillo, Juan C.; Syme, Anna-Maree; Rowell, Keiran N.; Burns, Brendan P.; Clark, Ebubekir S.; Gorman, Maire N.; Jacob, Lorrie S. D.; Kapodistrias, Panayioti; Kedziora, David J.; Lempriere, Felix A. R.; Medcraft, Chris; O'Sullivan, Jensen; Robertson, Evan G.; Soares, Georgia G.; Steller, Luke; Teece, Bronwyn L.; Tremblay, Chenoa D.; Sousa-Silva, Clara; McKemmish, Laura K. (2021). \"Computational Infrared Spectroscopy of 958 Phosphorus-Bearing Molecules\". Frontiers in Astronomy and Space Sciences. 8 639068: 43. arXiv:2105.08897. Bibcode:2021FrASS...8...43Z. doi:10.3389/fspas.2021.639068.^\"Chemists debate machine learning's future in synthesis planning and ask for open data\". cen.acs.org. Retrieved 29 May 2022.^\"Machine learning reveals recipe for building artificial proteins\". phys.org. Retrieved 17 August 2020.^Russ, William P.; Figliuzzi, Matteo; Stocker, Christian; Barrat-Charlaix, Pierre; Socolich, Michael; Kast, Peter; Hilvert, Donald; Monasson, Remi; Cocco, Simona; Weigt, Martin; Ranganathan, Rama (2020). \"An evolution-based model for designing chorismatemutase enzymes\". Science. 369 (6502): 440\u2013445. Bibcode:2020Sci...369..440R. doi:10.1126/science.aba3304. PMID\u00a032703877. S2CID\u00a0220714458.^Stocker, Sina; Cs\u00e1nyi, G\u00e1bor; Reuter, Karsten; Margraf, Johannes T. (30 October 2020). \"Machine learning in chemical reaction space\". Nature Communications. 11 (1): 5505. Bibcode:2020NatCo..11.5505S. doi:10.1038/s41467-020-19267-x. PMC\u00a07603480. PMID\u00a033127879.^Yirka, Bob. \"Repurposed drug-seeking AI system generates 40,000 possible chemical weapons in just six hours\". techxplore.com. Retrieved 19 April 2022.^Urbina, Fabio; Lentzos, Filippa; Invernizzi, C\u00e9dric; Ekins, Sean (March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189\u2013191. doi:10.1038/s42256-022-00465-9. ISSN\u00a02522-5839. PMC\u00a09544280. PMID\u00a036211133. S2CID\u00a0247302391.^\"AI drug algorithms can be flipped to generate bioweapons\". www.theregister.com. Retrieved 24 April 2022.^Hansen, Justine Y.; Markello, Ross D.; Vogel, Jacob W.; Seidlitz, Jakob; Bzdok, Danilo; Misic, Bratislav (September 2021). \"Mapping gene transcription and neurocognition across human neocortex\". Nature Human Behaviour. 5 (9): 1240\u20131250. doi:10.1038/s41562-021-01082-z. PMID\u00a033767429.^Vo ngoc, Long; Huang, Cassidy Yunjing; Cassidy, California Jack; Medrano, Claudia; Kadonaga, James T. (September 2020). \"Identification of the human DPR core promoter element using machine learning\". Nature. 585 (7825): 459\u2013463. Bibcode:2020Natur.585..459V. doi:10.1038/s41586-020-2689-7. PMC\u00a07501168. PMID\u00a032908305.^Bijun, Zhang; Ting, Fan (2022). \"Knowledge structure and emerging trends in the application of deep learning in genetics research: A bibliometric analysis [2000\u20132021]\". Frontiers in Genetics. 13 951939. doi:10.3389/fgene.2022.951939. PMC\u00a09445221. PMID\u00a036081985.^Radivojevi\u0107, Tijana; Costello, Zak; Workman, Kenneth; Garcia Martin, Hector (25 September 2020). \"A machine learning Automated Recommendation Tool for synthetic biology\". Nature Communications. 11 (1): 4879. arXiv:1911.11091. Bibcode:2020NatCo..11.4879R. doi:10.1038/s41467-020-18008-4. PMC\u00a07519645. PMID\u00a032978379.^ abPablo Carbonell; Tijana Radivojevic; H\u00e9ctor Garc\u00eda Mart\u00edn* (2019). \"Opportunities at the Intersection of Synthetic Biology, Machine Learning, and Automation\". ACS Synthetic Biology. 8 (7): 1474\u20131477. doi:10.1021/acssynbio.8b00540. hdl:20.500.11824/998. PMID\u00a031319671.^Gadzhimagomedova, Z. M.; Pashkov, D. M.; Kirsanova, D. Yu.; Soldatov, S. A.; Butakova, M. A.; Chernov, A. V.; Soldatov, A. V. (February 2022). \"Artificial Intelligence for Nanostructured Materials\". Nanobiotechnology Reports. 17 (1): 1\u20139. doi:10.1134/S2635167622010049.^Mirzaei, Mahsa; Furxhi, Irini; Murphy, Finbarr; Mullins, Martin (July 2021). \"A Machine Learning Tool to Predict the Antibacterial Capacity of Nanoparticles\". Nanomaterials. 11 (7): 1774. doi:10.3390/nano11071774. PMC\u00a08308172. PMID\u00a034361160.^Chen, Angela (25 April 2018). \"How AI is helping us discover materials faster than ever\". The Verge. Retrieved 30 May 2022.^Talapatra, Anjana; Boluki, S.; Duong, T.; Qian, X.; Dougherty, E.; Arr\u00f3yave, R. (26 November 2018). \"Autonomous efficient experiment design for materials discovery with Bayesian model averaging\". Physical Review Materials. 2 (11) 113803. arXiv:1803.05460. Bibcode:2018PhRvM...2k3803T. doi:10.1103/PhysRevMaterials.2.113803.^Zhao, Yicheng; Zhang, Jiyun; Xu, Zhengwei; Sun, Shijing; Langner, Stefan; Hartono, Noor Titan Putri; Heumueller, Thomas; Hou, Yi; Elia, Jack; Li, Ning; Matt, Gebhard J.; Du, Xiaoyan; Meng, Wei; Osvet, Andres; Zhang, Kaicheng; Stubhan, Tobias; Feng, Yexin; Hauch, Jens; Sargent, Edward H.; Buonassisi, Tonio; Brabec, Christoph J. (13 April 2021). \"Discovery of temperature-induced stability reversal in perovskites using high-throughput robotic learning\". Nature Communications. 12 (1): 2191. Bibcode:2021NatCo..12.2191Z. doi:10.1038/s41467-021-22472-x. PMC\u00a08044090. PMID\u00a033850155.^Anne Johnson; Emily Grumbling (2019). Implications of artificial intelligence for cybersecurity: proceedings of a workshop. Washington, DC: National Academies Press. pp.\u00a04\u20135. ISBN\u00a0978-0-309-49451-9. OCLC\u00a01134854973. Retrieved 2025-05-12.^Kocher, Geeta; Kumar, Gulshan (August 2021). \"Machine learning and deep learning methods for intrusion detection systems: recent developments and challenges\". Soft Computing. 25 (15): 9731\u20139763. doi:10.1007/s00500-021-05893-0.^Kant, Daniel; Johannsen, Andreas (16 January 2022). \"Evaluation of AI-based use cases for enhancing the cyber security defense of small and medium-sized companies (SMEs)\". Electronic Imaging. 34 (3): 387\u20131\u2013387\u20138. doi:10.2352/EI.2022.34.3.MOBMU-387.^Randrianasolo, Arisoa (2012). Artificial intelligence in computer security: Detection, temporary repair and defense (Thesis). p.\u00a0vii. hdl:2346/45196.^Sahil; Sood, Sandeep; Mehmi, Sandeep; Dogra, Shikha (2015). \"Artificial intelligence for designing user profiling system for cloud computing security: Experiment\". 2015 International Conference on Advances in Computer Engineering and Applications. pp.\u00a051\u201358. doi:10.1109/ICACEA.2015.7164645. ISBN\u00a0978-1-4673-6911-4.^Parisi, Alessandro (2019). Hands-On Artificial Intelligence for Cybersecurity: Implement smart AI systems for preventing cyber attacks and detecting threats and network anomalies. Packt Publishing Ltd. ISBN\u00a0978-1-78980-517-8. OCLC\u00a01111967955.[page\u00a0needed]^Hallerbach, Sven; Xia, Yiqun; Eberle, Ulrich; Koester, Frank (3 April 2018). \"Simulation-Based Identification of Critical Scenarios for Cooperative and Automated Vehicles\". SAE International Journal of Connected and Automated Vehicles. 1 (2): 93\u2013106. doi:10.4271/2018-01-1066.^West, Darrell M. (20 September 2016). \"Moving forward: Self-driving vehicles in China, Europe, Japan, Korea, and the United States\". Brookings.^\"Programming safety into self-driving cars\". National Science Foundation. 2 February 2015.^ ab\"Self-driving delivery van ditches \"human controls\"\". BBC News. 7 February 2020. Retrieved 28 April 2022.^\"Transportation Germany Unveils the World's First Fully Automated Train in Hamburg\". 12 October 2021. Retrieved 3 July 2022.^\"Railway digitalisation using drones\". www.euspa.europa.eu. 25 February 2021. Retrieved 3 July 2022.^\"World's fastest driverless bullet train launches in China\". The Guardian. 9 January 2020. Retrieved 3 July 2022.^Benson, Thor. \"Self-driving buses to appear on public roads for the first time\". Inverse. Retrieved 26 August 2021.^\"Europe's first full-sized self-driving urban electric bus has arrived\". World Economic Forum. Retrieved 26 August 2021.^Huber, Dominik; Viere, Tobias; Horschutz Nemoto, Eliane; Jaroudi, Ines; Korbee, Dorien; Fournier, Guy (2022). \"Climate and environmental impacts of automated minibuses in future public transportation\". Transportation Research Part D: Transport and Environment. 102 103160. Bibcode:2022TRPD..10203160H. doi:10.1016/j.trd.2021.103160.^Hawkins, Andrew J. (22 July 2020). \"Waymo is designing a self-driving Ram delivery van with FCA\". The Verge. Retrieved 28 April 2022.^Buss, Dale (31 Aug 2021). \"Walmart Presses Its Distribution Legacy To Lead In Automated Delivery\". Forbes. Retrieved 28 April 2022.^Rita Liao (25 May 2021). \"JD.com, Meituan and Neolix to test autonomous deliveries on Beijing public roads\". TechCrunch. Retrieved 28 April 2022.^Cooley, Patrick; Dispatch, The Columbus (1 September 2021). \"Grubhub testing delivery robots\". techxplore.com. Retrieved 28 April 2022.^Burgess, Matt (24 August 2017). \"The UK is about to Start Testing Self-Driving Truck Platoons\". Wired UK. Archived from the original on 22 September 2017. Retrieved 20 September 2017.^Davies, Alex (5 May 2015). \"World's First Self-Driving Semi-Truck Hits the Road\". Wired. Archived from the original on 28 October 2017. Retrieved 20 September 2017.^Preparing for the future of artificial intelligence. National Science and Technology Council. OCLC\u00a0965620122.^Jones, Randolph M.; Laird, John E.; Nielsen, Paul E.; Coulter, Karen J.; Kenny, Patrick; Koss, Frank V. (15 March 1999). \"Automated Intelligent Pilots for Combat Flight Simulation\". AI Magazine. 20 (1): 27. doi:10.1609/aimag.v20i1.1438.^AIDA Homepage. Kbs.twi.tudelft.nl (17 April 1997). Retrieved 21 July 2013.^The Story of Self-Repairing Flight Control Systems. NASA Dryden. (April 2003). Retrieved 25 August 2016.^Adams, Eric (28 March 2017). \"AI Wields the Power to Make Flying Safer\u2014and Maybe Even Pleasant\". Wired. Retrieved 7 October 2017.^Baomar, Haitham; Bentley, Peter J. (2016). \"An Intelligent Autopilot System that learns flight emergency procedures by imitating human pilots\". 2016 IEEE Symposium Series on Computational Intelligence (SSCI). pp.\u00a01\u20139. doi:10.1109/SSCI.2016.7849881. ISBN\u00a0978-1-5090-4240-1.^\"UB invests in student-founded startup\". buffalo.edu. Retrieved 24 December 2020.Further reading[edit]Kaplan, A.M.; Haenlein, M. (2018). \"Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence\". Business Horizons. 62 (1): 15\u201325. doi:10.1016/j.bushor.2018.08.004.Kurzweil, Ray (2005). The Singularity is Near: When Humans Transcend Biology. New York: Viking. ISBN\u00a0978-0-670-03384-3.National Research Council (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press. ISBN\u00a0978-0-309-06278-7. OCLC\u00a0246584055.Moghaddam, M. J.; Soleymani, M. R.; Farsi, M. A. (2015). \"Sequence planning for stamping operations in progressive dies\". Journal of Intelligent Manufacturing. 26 (2): 347\u2013357. doi:10.1007/s10845-013-0788-0.Felten, Ed (3 May 2016). \"Preparing for the Future of Artificial Intelligence\"..mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteEmerging technologiesFieldsInformation andcommunicationsAmbient intelligenceInternet of thingsArtificial intelligenceApplications of artificial intelligenceMachine translationMachine visionMobile translationProgress in artificial intelligenceSemantic WebSpeech recognitionAtomtronicsCarbon nanotube field-effect transistorCybermethodologyAugmented realityFourth-generation optical discs3D optical data storageHolographic data storageGPGPUMemory\nCBRAMECRAMFRAMMillipedeMRAMNRAMPRAMRacetrack memoryRRAMSONOSUltraRAMOptical computingRFIDChipless RFIDSoftware-defined radioThree-dimensional integrated circuitTopicsAutomationCollingridge dilemmaDifferential technological developmentDisruptive innovationEphemeralizationEthicsAIBioethicsCyberethicsNeuroethicsRobot ethicsExploratory engineeringProactionary principleTechnological changeTechnological unemploymentTechnological convergenceTechnological evolutionTechnological paradigmTechnology forecastingAccelerating changeFuture-oriented technology analysisHorizon scanningMoore's lawTechnological singularityTechnology scoutingTechnology in science fictionTechnology readiness levelTechnology roadmapTranshumanismList\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Applications_of_artificial_intelligence&oldid=1319003784\"", "tags": ["en.wikipedia.org", "wiki", "applications", "artificial", "intelligence"]}
{"url": "https://en.wikipedia.org/wiki/Android_(robot)", "title": null, "text": "Robot resembling a human.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}\"Mechanoid\" redirects here. For other uses, see Mechanoid (disambiguation).\"Androids\" redirects here. For other uses, see Androids (disambiguation).For the mascot, see Android (operating system) \u00a7\u00a0Mascot.Repliee Q2, an android, can mimic human functions such as blinking, breathing and speaking, with the ability to recognize and process speech and touch, and then respond in kind.\nAn android is a humanoid robot or other artificial being, often made from a flesh-like material.[1][2][3][4] Historically, androids existed only in the domain of science fiction and were frequently seen in film and television, but advances in robot technology have allowed the creation of similar robots in real life.[5][6]Terminology[edit]Early example of the term androides used to describe human-like mechanical devices, London Times, 22 December 1795The Oxford English Dictionary traces the earliest use (as \"Androides\") to Ephraim Chambers' 1728 Cyclopaedia, in reference to an automaton that St. Albertus Magnus allegedly created.[3][7] By the late 1700s, \"androides\", elaborate mechanical devices resembling humans performing human activities, were displayed in exhibit halls.[8]\nThe term \"android\" appears in US patents as early as 1863 in reference to miniature human-like toy automatons.[9] The term android was used in a more modern sense by the French author Auguste Villiers de l'Isle-Adam in his work Tomorrow's Eve (1886), featuring an artificial humanoid robot named Hadaly.[3] The term made an impact into English pulp science fiction starting from Jack Williamson's The Cometeers (1936) and the distinction between mechanical robots and fleshy androids was popularized by Edmond Hamilton's Captain Future stories (1940\u20131944).[3]Although Karel \u010capek's robots in R.U.R. (Rossum's Universal Robots) (1921)\u2014the play that introduced the word robot to the world\u2014were organic artificial humans, the word \"robot\" has come to primarily refer to mechanical humans, animals, and other beings.[3] The term \"android\" can mean either one of these,[3] while a cyborg (\"cybernetic organism\" or \"bionic man\") would be a creature that is a combination of organic and mechanical parts.\nThe term \"droid\", popularized by George Lucas in the original Star Wars film and now used widely within science fiction, originated as an abridgment of \"android\", but has been used by Lucas and others to mean any robot, including distinctly non-human form machines like R2-D2. The word \"android\" was used in Star Trek: The Original Series episode \"What Are Little Girls Made Of?\" The abbreviation \"andy\", coined as a pejorative by writer Philip K. Dick in his novel Do Androids Dream of Electric Sheep?, has seen some further usage, such as within the TV series Total Recall 2070.[10]While the term \"android\" is used in reference to human-looking robots in general (not necessarily male-looking humanoid robots), a robot with a female appearance can also be referred to as a gynoid. Besides one can refer to robots without alluding to their sexual appearance by calling them anthrobots (a portmanteau of anthr\u014dpos and robot; see anthrobotics) or anthropoids (short for anthropoid robots; the term humanoids is not appropriate because it is already commonly used to refer to human-like organic species in the context of science fiction, futurism and speculative astrobiology).[11]Authors have used the term android in more diverse ways than robot or cyborg. In some fictional works, the difference between a robot and android is only superficial, with androids being made to look like humans on the outside but with robot-like internal mechanics.[3] In other stories, authors have used the word \"android\" to mean a wholly organic, yet artificial, creation.[3] Other fictional depictions of androids fall somewhere in between.[3]Eric G. Wilson, who defines an android as a \"synthetic human being\", distinguishes between three types of android, based on their body's composition:\nthe mummy type \u2013 made of \"dead things\" or \"stiff, inanimate, natural material\", such as mummies, puppets, dolls and statuesthe golem type \u2013 made from flexible, possibly organic material, including golems and homunculithe automaton type \u2013 made from a mix of dead and living parts, including automatons and robots[4]Although human morphology is not necessarily the ideal form for working robots, the fascination in developing robots that can mimic it can be found historically in the assimilation of two concepts: simulacra (devices that exhibit likeness) and automata (devices that have independence).\nProjects[edit]Several projects aiming to create androids that look, and, to a certain degree, speak or act like a human being have been launched or are underway.\nJapan[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs expansion with: more recent examples and additional citations. You can help by adding to it.  (October 2018)Repliee Q2, a Japanese androidJapanese robotics have been leading the field since the 1970s.[12]Waseda University initiated the WABOT project in 1967, and in 1972 completed the WABOT-1, the first android, a full-scale humanoid intelligent robot.[13][14] Its limb control system allowed it to walk with the lower limbs, and to grip and transport objects with hands, using tactile sensors. Its vision system allowed it to measure distances and directions to objects using external receptors, artificial eyes and ears. And its conversation system allowed it to communicate with a person in Japanese, with an artificial mouth.[14][15][16]In 1984, WABOT-2 was revealed, and made a number of improvements. It was capable of playing the organ. Wabot-2 had ten fingers and two feet, and was able to read a score of music. It was also able to accompany a person.[17] In 1986, Honda began its humanoid research and development program, to create humanoid robots capable of interacting successfully with humans.[18]The Intelligent Robotics Lab, directed by Hiroshi Ishiguro at Osaka University, and the Kokoro company demonstrated the Actroid at Expo 2005 in Aichi Prefecture, Japan and released the Telenoid R1 in 2010. In 2006, Kokoro developed a new DER 2 android. The height of the human body part of DER2 is 165\u00a0cm. There are 47 mobile points. DER2 can not only change its expression but also move its hands and feet and twist its body. The \"air servosystem\" which Kokoro developed originally is used for the actuator. As a result of having an actuator controlled precisely with air pressure via a servosystem, the movement is very fluid and there is very little noise. DER2 realized a slimmer body than that of the former version by using a smaller cylinder. Outwardly DER2 has a more beautiful proportion. Compared to the previous model, DER2 has thinner arms and a wider repertoire of expressions. Once programmed, it is able to choreograph its motions and gestures with its voice.\nThe Intelligent Mechatronics Lab, directed by Hiroshi Kobayashi at the Tokyo University of Science, has developed an android head called Saya, which was exhibited at Robodex 2002 in Yokohama, Japan. There are several other initiatives around the world involving humanoid research and development at this time, which will hopefully introduce a broader spectrum of realized technology in the near future. Now Saya is working at the Science University of Tokyo as a guide.\nThe Waseda University (Japan) and NTT docomo's manufacturers have succeeded in creating a shape-shifting robot WD-2. It is capable of changing its face. At first, the creators decided the positions of the necessary points to express the outline, eyes, nose, and so on of a certain person. The robot expresses its face by moving all points to the decided positions, they say. The first version of the robot was first developed back in 2003. After that, a year later, they made a couple of major improvements to the design. The robot features an elastic mask made from the average head dummy. It uses a driving system with a 3DOF unit. The WD-2 robot can change its facial features by activating specific facial points on a mask, with each point possessing three degrees of freedom. This one has 17 facial points, for a total of 56 degrees of freedom. As for the materials they used, the WD-2's mask is fabricated with a highly elastic material called Septom, with bits of steel wool mixed in for added strength. Other technical features reveal a shaft driven behind the mask at the desired facial point, driven by a DC motor with a simple pulley and a slide screw. Apparently, the researchers can also modify the shape of the mask based on actual human faces. To \"copy\" a face, they need only a 3D scanner to determine the locations of an individual's 17 facial points. After that, they are then driven into position using a laptop and 56 motor control boards. In addition, the researchers also mention that the shifting robot can even display an individual's hair style and skin color if a photo of their face is projected onto the 3D Mask.\nSingapore[edit]Prof Nadia Thalmann, a Nanyang Technological University scientist, directed efforts of the Institute for Media Innovation along with the School of Computer Engineering in the development of a social robot, Nadine. Nadine is powered by software similar to Apple's Siri or Microsoft's Cortana. Nadine may become a personal assistant in offices and homes in future, or she may become a companion for the young and the elderly.\nAssoc Prof Gerald Seet from the School of Mechanical & Aerospace Engineering and the BeingThere Centre led a three-year R&D development in tele-presence robotics, creating EDGAR. A remote user can control EDGAR with the user's face and expressions displayed on the robot's face in real time. The robot also mimics their upper body movements.\n[19]South Korea[edit]EveR-2, the first android that can singKITECH researched and developed EveR-1, an android interpersonal communications model capable of emulating human emotional expression via facial \"musculature\" and capable of rudimentary conversation, having a vocabulary of around 400 words. She is 160 cm tall and weighs 50 kg, matching the average figure of a Korean woman in her twenties. EveR-1's name derives from the Biblical Eve, plus the letter r for robot. EveR-1's advanced computing processing power enables speech recognition and vocal synthesis, at the same time processing lip synchronization and visual recognition by 90-degree micro-CCD cameras with face recognition technology. An independent microchip inside her artificial brain handles gesture expression, body coordination, and emotion expression. Her whole body is made of highly advanced synthetic jelly silicon and with 60 artificial joints in her face, neck, and lower body; she is able to demonstrate realistic facial expressions and sing while simultaneously dancing. In South Korea, the Ministry of Information and Communication had an ambitious plan to put a robot in every household by 2020.[20] Several robot cities have been planned for the country: the first will be built in 2016 at a cost of 500 billion won (US$440 million), of which 50 billion is direct government investment.[21] The new robot city will feature research and development centers for manufacturers and part suppliers, as well as exhibition halls and a stadium for robot competitions. The country's new Robotics Ethics Charter will establish ground rules and laws for human interaction with robots in the future, setting standards for robotics users and manufacturers, as well as guidelines on ethical standards to be programmed into robots to prevent human abuse of robots and vice versa.[22]United States[edit]Walt Disney and a staff of Imagineers created Great Moments with Mr. Lincoln that debuted at the 1964 New York World's Fair.[23]Dr. William Barry, an Education Futurist and former visiting West Point Professor of Philosophy and Ethical Reasoning at the United States Military Academy, created an AI android character named \"Maria Bot\". This Interface AI android was named after the infamous fictional robot Maria in the 1927 film Metropolis, as a well-behaved distant relative. Maria Bot is the first AI Android Teaching Assistant at the university level.[24][25] Maria Bot has appeared as a keynote speaker as a duo with Barry for a TEDx talk in Everett, Washington in February 2020.[26]Resembling a human from the shoulders up, Maria Bot is a virtual being android that has complex facial expressions and head movement and engages in conversation about a variety of subjects. She uses AI to process and synthesize information to make her own decisions on how to talk and engage. She collects data through conversations, direct data inputs such as books or articles, and through internet sources.\nMaria Bot was built by an international high-tech company for Barry to help improve education quality and eliminate education poverty. Maria Bot is designed to create new ways for students to engage and discuss ethical issues raised by the increasing presence of robots and artificial intelligence. Barry also uses Maria Bot to demonstrate that programming a robot with life-affirming, ethical framework makes them more likely to help humans to do the same.[27]Maria Bot is an ambassador robot for good and ethical AI technology.[28]Hanson Robotics, Inc., of Texas and KAIST produced an android portrait of Albert Einstein, using Hanson's facial android technology mounted on KAIST's life-size walking bipedal robot body. This Einstein android, also called \"Albert Hubo\", thus represents the first full-body walking android in history.[29] Hanson Robotics, the FedEx Institute of Technology,[30] and the University of Texas at Arlington also developed the android portrait of sci-fi author Philip K. Dick (creator of Do Androids Dream of Electric Sheep?, the basis for the film Blade Runner), with full conversational capabilities that incorporated thousands of pages of the author's works.[31] In 2005, the PKD android won a first-place artificial intelligence award from AAAI.\nChina[edit]On April 19, 2025, 21 humanoid robots participated along with 12,000 human runners in a half-marathon in Beijing. While almost every robot fell down and had overheating problems, and the robots were continuously being controlled by human handlers accompanying them, six of the robots did reach the finish line. Two of them, Tiangong Ultra by Chinese robotics company UBTech, and N2 by Chinese company Noetix Robotics, which took first and second place respectively among robots in the race, stood out for their consistent (albeit slow) pace.[32]Use in fiction[edit]See also: List of fictional robots and androidsAndroids are a staple of science fiction. Isaac Asimov pioneered the fictionalization of the science of robotics and artificial intelligence, notably in his 1950s series I, Robot.[33] One thing common to most fictional androids is that the real-life technological challenges associated with creating thoroughly human-like robots \u2014 such as the creation of strong artificial intelligence\u2014are assumed to have been solved.[34] Fictional androids are often depicted as mentally and physically equal or superior to humans\u2014moving, thinking and speaking as fluidly as them.[3][34]The tension between the nonhuman substance and the human appearance\u2014or even human ambitions\u2014of androids is the dramatic impetus behind most of their fictional depictions.[4][34] Some android heroes seek, like Pinocchio, to become human, as in the film Bicentennial Man,[34] or Data in Star Trek: The Next Generation. Others, as in the film Westworld, rebel against abuse by careless humans.[34] Android hunter Deckard in Do Androids Dream of Electric Sheep? and its film adaptation Blade Runner discovers that his targets appear to be, in some ways, more \"human\" than he is.[34] The sequel Blade Runner 2049 involves android hunter K, himself an android, discovering the same thing. Android stories, therefore, are not essentially stories \"about\" androids; they are stories about the human condition and what it means to be human.[34] \nOne aspect of writing about the meaning of humanity is to use discrimination against androids as a mechanism for exploring racism in society, as in Blade Runner.[35] Perhaps the clearest example of this is John Brunner's 1968 novel Into the Slave Nebula, where the blue-skinned android slaves are explicitly shown to be fully human.[36] More recently, the androids Bishop and Annalee Call in the films Aliens and Alien Resurrection are used as vehicles for exploring how humans deal with the presence of an \"Other\".[37] The 2018 video game Detroit: Become Human also explores how androids are treated as second class citizens in a near future society.\nFemale androids, or \"gynoids\", are often seen in science fiction, and can be viewed as a continuation of the long tradition of men attempting to create the stereotypical \"perfect woman\".[38] Examples include the Greek myth of Pygmalion and the female robot Maria in Fritz Lang's Metropolis. Some gynoids, like Pris in Blade Runner, are designed as sex-objects, with the intent of \"pleasing men's violent sexual desires\",[39] or as submissive, servile companions, such as in The Stepford Wives. Fiction about gynoids has therefore been described as reinforcing \"essentialist ideas of femininity\",[40] although others have suggested that the treatment of androids is a way of exploring racism and misogyny in society.[41]The 2015 Japanese film Sayonara, starring Geminoid F, was promoted as \"the first movie to feature an android performing opposite a human actor\".[42]The 2023 Dutch film I'm Not a Robot won the Academy Award for Best Live Action Short Film in 2025.\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}ActroidAndroid scienceAnimatronicsAudio-AnimatronicsAutomatonCyborgDomestic robotGynoidHumanoid robotNeuroroboticsReplicantSynthoidUncanny valleyReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Van Riper, A. Bowdoin (2002). Science in popular culture: a reference guide. Westport: Greenwood Press. p.\u00a010. ISBN\u00a00-313-31822-0.^Prucher, Jeff (2007). \"android\". Brave New Words: The Oxford Dictionary of Science Fiction. Oxford University Press. pp.\u00a06\u20137. ISBN\u00a0978-0-19-530567-8.^ abcdefghijBrian M. Stableford (2006). Science fact and science fiction: an encyclopedia. CRC Press. pp.\u00a022\u201323. ISBN\u00a0978-0-415-97460-8.^ abcEric G. Wilson (2006). The melancholy android: on the psychology of sacred machines. SUNY Press. pp.\u00a027\u201328. ISBN\u00a0978-0-7914-6846-3.^McCaw, Caroline (2001). Http. [University of Otago?]. OCLC\u00a0225915408.^Ishiguro, Hiroshi. \"Android science.\", Cognitive Science Society, Osaka, 2005. Retrieved on 3 October 2013.^OED at \"android\" citing Ephraim Chambers, Cyclop\u00e6dia; or, a universal dictionary of arts and sciences. 1728.^\"At the Mechanical Theater\". London Times. 22 December 1795.^\"U.S. Patent and Trademark Office, Patent# 40891, Toy Automation\". Google Patents. Retrieved 7 January 2007.[dead link]^Levin, Drew S. (exec. prod.) (23 February 1999). \"Rough Whimper of Insanity\". Total Recall 2070. Season 1. Episode 7. Toronto.  2:10 minutes in. Channel Zero. CHCH-TV. Archived from the original on 5 February 2010.^\"Anthrobotics: Where The Human Ends and the Robot Begins\". Futurism. 7 March 2017. Archived from the original on 9 April 2024. Retrieved 19 February 2022.^Zeghloul, Sa\u00efd; Laribi, Med Amine; Gazeau, Jean-Pierre (21 September 2015). Robotics and Mechatronics: Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics. Springer. ISBN\u00a09783319223681.^\"Humanoid History -WABOT-\". www.humanoid.waseda.ac.jp. Archived from the original on 1 September 2017. Retrieved 6 May 2017.^ ab\"Historical Android Projects\". androidworld.com. Archived from the original on 25 November 2005. Retrieved 6 May 2017.^Robots: From Science Fiction to Technological Revolution, page 130^Duffy, Vincent G. (19 April 2016). Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering. CRC Press. ISBN\u00a09781420063523.^\"2history\". Archived from the original on 12 October 2007. Retrieved 31 August 2007.^\"P3\". Honda Worldwide. Archived from the original on 15 November 2018. Retrieved 1 September 2007.^\"NTU scientists unveil social and telepresence robots\". Archived from the original on 3 September 2019. Retrieved 31 December 2015.^\"A Robot in Every Home by 2020, South Korea Says\". News.nationalgeographic.com. 28 October 2010. Archived from the original on 14 November 2006. Retrieved 22 November 2011.^\"South Korea set to build \"Robot Land\"\". Engadget. 27 August 2007. Archived from the original on 13 January 2012. Retrieved 22 November 2011.^\"Robot Code of Ethics to Prevent Android Abuse, Protect Humans\". News.nationalgeographic.com. 28 October 2010. Archived from the original on 19 March 2007. Retrieved 22 November 2011.^\"Pavilions & Attractions \u2013 Illinois \u2013 Page Two\". Archived from the original on 2 September 2023. Retrieved 23 March 2011.^\"The Education of an Android Teacher \u2013 EdSurge News\". 9 March 2020. Archived from the original on 17 July 2024. Retrieved 15 March 2020.^\"First Android Teaching Assistant at NDNU | Media Center\". Archived from the original on 28 July 2020. Retrieved 15 March 2020.^\"William Barry | tedxeverettcom\". Archived from the original on 28 July 2020. Retrieved 15 March 2020.^\"Maria Bot\". Archived from the original on 12 August 2021. Retrieved 15 March 2020.^\"Mesh conference announces AI robot as keynote speaker\". 24 February 2020. Archived from the original on 7 November 2023. Retrieved 15 March 2020.^\"(no title)\". www.hansonrobotics.wordpress.com. Archived from the original on 16 July 2024. Retrieved 5 August 2010.{{cite web}}: Cite uses generic title (help)^\"FIT \u2013 FedEx Institute of Technology \u2013 The University of Memphis\". www.fedex.memphis.edu. Archived from the original on 10 December 2008. Retrieved 24 October 2006.^\"about \" PKD Android\". www.pkdandroid.org. Archived from the original on 14 August 2009. Retrieved 7 August 2009.^Yang, Zeyi (19 April 2025). \"Stumbling and Overheating, Most Humanoid Robots Fail to Finish Half-Marathon in Beijing\". Wired. Archived from the original on 21 April 2025. Retrieved 22 April 2025.^Jonathan Barra, Roger Caille; et\u00a0al. \"The Android Generation\". West Coast Midnight Run/Citadel Consulting Group LLC. Archived from the original on 24 February 2014. Retrieved 9 February 2013.^ abcdefgVan Riper, op.cit., p. 11.^Dinello, Daniel (2005). Technophobia!: Science Fiction Visions of Posthuman Technology. University of Texas Press. p.\u00a076. ISBN\u00a09780292709867.^D'Ammassa, Don (2005). Encyclopedia of Science Fiction. Facts on File. p.\u00a058. ISBN\u00a0978-0-8160-5924-9.^Nishime, LeiLani (Winter 2005). \"The Mulatto Cyborg: Imagining a Multiracial Future\". Cinema Journal. 44 (2). University of Texas Press: 34\u201349. doi:10.1353/cj.2005.0011.^Melzer, Patricia (2006). Alien Constructions: Science Fiction and Feminist Thought. University of Texas Press. p.\u00a0202. ISBN\u00a0978-0-292-71307-9.^Melzer, p. 204^Grebowicz, Margret; L. Timmel Duchamp; Nicola Griffith; Terry Bisson (2007). SciFi in the mind's eye: reading science through science fiction. Open Court. p.\u00a0xviii. ISBN\u00a0978-0-8126-9630-1.^Dinello, op. cit., p 77.^James Hadfield (24 October 2015). \"Tokyo: 'Sayonara' Filmmakers Debate Future of Robot Actors\". variety.com. Archived from the original on 7 November 2015. Retrieved 9 November 2015.Further reading[edit]Kerman, Judith B. (1991). Retrofitting Blade Runner: Issues in Ridley Scott's Blade Runner and Philip K. Dick's Do Androids Dream of Electric Sheep? Bowling Green, OH: Bowling Green State University Popular Press. ISBN\u00a00-87972-509-5.Perkowitz, Sidney (2004). Digital People: From Bionic Humans to Androids. Joseph Henry Press. ISBN\u00a00-309-09619-7.Shelde, Per (1993). Androids, Humanoids, and Other Science Fiction Monsters: Science and Soul in Science Fiction Films. New York: New York University Press. ISBN\u00a00-8147-7930-1.Ishiguro, Hiroshi. \"Android science.\" Cognitive Science Society. 2005.Glaser, Horst Albert and Rossbach, Sabine: The Artificial Human, Frankfurt/M., Bern, New York 2011 \"The Artificial Human\"TechCast Article Series, Jason Rupinski and Richard Mix, \"Public Attitudes to Androids: Robot Gender, Tasks, & Pricing\"Carpenter, J. (2009). Why send the Terminator to do R2D2s job?: Designing androids as rhetorical phenomena. Proceedings of HCI 2009: Beyond Gray Droids: Domestic Robot Design for the 21st Century. Cambridge, UK. 1 September.Telotte, J.P. Replications: A Robotic History of the Science Fiction Film. University of Illinois Press, 1995.External links[edit].mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}.mw-parser-output .sister-box .side-box-abovebelow{padding:0.75em 0;text-align:center}.mw-parser-output .sister-box .side-box-abovebelow>b{display:block}.mw-parser-output .sister-box .side-box-text>ul{border-top:1px solid #aaa;padding:0.75em 0;width:220px;margin:0 auto}.mw-parser-output .sister-box .side-box-text>ul>li{min-height:31px}.mw-parser-output .sister-logo{display:inline-block;width:31px;line-height:31px;vertical-align:middle;text-align:center}.mw-parser-output .sister-link{display:inline-block;margin-left:7px;width:182px;vertical-align:middle}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Android (robot)  at Wikipedia's sister projectsDefinitions from WiktionaryMedia from Commons.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteAndroidsGynoidsActroidAi-DaEveRHRP-4CMein\u00fc robotRepliee Q1ExpoMale (androids)Ibn Sina RobotGeminoidBabies and childreniCubSee alsoFictional robots and androidsFictional gynoidsAndroid scienceHumanoid robotsCyborgsCategoryvteHumanoid robotsLeggedMiniBioloidCocoFemiSapienRoboSapienRobosapien v2RopidRS MediaHOAPJO-ZEROKHR-1Kirobo and MirataManavNaoPINOPlenQRIOSmall,mediumArchieASIMOFlameGuRooHUBOiCubMurata Boy and Murata GirlREEMToyota Partner RobotXianxingzheHuman-sizedAi-DaAmecaAtlasE seriesEricFEDORGeorgeIsaacRobotKobianLeonardo's robotMAHRU & AHRAMusaOptimusP seriesPETMANRobot Man of SzegedSophiaSurenaTOPIOBigElektroLand WalkerWheeledGuRooEMIEWEnoni-SOBOTJustinPepperSanbotSeropiTOPIO DioWakamaruMitra RobotTrackedBattlefield Extraction-Assist Robot (BEAR)Upper torsoDomoGakutensokuGeoff PetersonMindarRobonautShaluTelenoid R1RelatedAndroidsCyborgsList of fictional robots and androidsRobot fetishismvteMobile robots and uncrewed vehiclesAerialUnmanned aerial vehicle (UAV)Unmanned combat air vehicle (UCAV)AerobotHelicamList of unmanned aerial vehicle applicationsOrnithopterGroundWalkingHumanoidAndroidHexapodlistOtherUnmanned ground vehicle (UGV)Automated guided vehicle (AGV)Self-driving carAutomatic train operation (ATO)listUnderwaterUnmanned underwater vehicle (UUV)Autonomous underwater vehicle (AUV)Intervention AUV (I-AUV)Remotely operated underwater vehicle (ROUV)Underwater gliderSurfaceUnmanned surface vehicle (USV)SpaceUncrewed spacecraftlist of probeslist by programlist of orbitersCargo spacecraftspaceflights to the ISSSpace telescopelistOtherDomesticMilitaryRescueMedicalDisabilityAgriculturalBEAM roboticsMicroboticsNanoroboticsRoboticsRobot locomotionAutonomous robotAutonomous logisticsRadio-controlled modelRemote control vehicleRemote control animalCategoriesRadio controlUnmanned vehiclesvteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutline.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesNationalUnited StatesFranceBnF dataCzech RepublicIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Android_(robot)&oldid=1319722735\"", "tags": ["en.wikipedia.org", "wiki", "android", "robot"]}
{"url": "https://en.wikipedia.org/wiki/Robotics", "title": null, "text": "Design, construction, use, and application of robots.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This article may relate to a different subject or has undue weight on an aspect of the subject.Specifically, the article goes in too much detail on specific types of robot and includes product placement. Please help relocate relevant information and remove irrelevant content.  (August 2024)Roboticists with three Mars rover robots. Front and center is the flight spare for the first Mars rover, Sojourner, which landed on Mars in 1997 as part of the Mars Pathfinder Project. On the left is a Mars Exploration Rover (MER) test vehicle that is a working sibling to Spirit and Opportunity, which landed on Mars in 2004. On the right is a test rover for the Mars Science Laboratory, which landed Curiosity on Mars in 2012.Robotics is the interdisciplinary study and practice of the design, construction, operation, and use of robots.[1]Within mechanical engineering, robotics is the design and construction of the physical structures of robots, while in computer science, robotics focuses on robotic automation algorithms. Other disciplines contributing to robotics include electrical, control, software, information, electronic, telecommunication, computer, mechatronic, and materials engineering.\nThe goal of most robotics is to design machines that can help and assist humans. Many robots are built to do jobs that are hazardous to people, such as finding survivors in unstable ruins, and exploring space, mines and shipwrecks. Others replace people in jobs that are boring, repetitive, or unpleasant, such as cleaning, monitoring, transporting, and assembling. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes.\nRobotics aspects[edit]Mechanical aspectElectrical aspectSoftware aspectRobotics usually combines three aspects of design work to create robot systems:\nMechanical construction: a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud might use caterpillar tracks. Origami inspired robots can sense and analyze in extreme environments.[2] The mechanical aspect of the robot is mostly the creator's solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function.Electrical components that power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol-powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol-powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status), and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations)Software. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not be able to go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly structured, its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence, and hybrid. A robot with remote control programming has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. A hybrid is a form of programming that incorporates both AI and RC functions in them.[3]Applied robotics[edit]As many robots are designed for specific tasks, this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".[4]Current and potential applications include:\nManufacturing. Robots have been increasingly used in manufacturing since the 1960s. According to the Robotic Industries Association US data, in 2016 the automotive industry was the main customer of industrial robots with 52% of total sales.[5] In the auto industry, they can amount for more than half of the \"labor\". There are even \"lights off\" factories such as an IBM keyboard manufacturing factory in Texas that was fully automated as early as 2003.[6]Autonomous transport including airplane autopilot and self-driving carsDomestic robots including robotic vacuum cleaners, robotic lawn mowers, dishwasher loading[7] and flatbread baking.[8]Construction robots. Construction robots can be separated into three types: traditional robots, robotic arm, and robotic exoskeleton.[9]Automated mining.Space exploration, including Mars rovers.Energy applications including cleanup of nuclear contaminated areas;[a] and cleaning solar panel arrays.Medical robots and Robot-assisted surgery designed and used in clinics.[11]Agricultural robots.[12] The use of robots in agriculture is closely linked to the concept of AI-assisted precision agriculture and drone usage.[13]Food processing. Commercial examples of kitchen automation are Flippy (burgers), Zume Pizza (pizza), Cafe X (coffee), Makr Shakr (cocktails), Frobot (frozen yogurts), Sally (salads),[14] salad or food bowl robots manufactured by Dexai (a Draper Laboratory spinoff, operating on military bases), and integrated food bowl assembly systems manufactured by Spyce Kitchen (acquired by Sweetgreen) and Silicon Valley startup Hyphen.[15] Other examples may include manufacturing technologies based on 3D Food Printing.Military robots.Robot sports for entertainment and education, including Robot combat, Autonomous racing, drone racing, and FIRST Robotics.Mechanical robotics areas[edit]Power source[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}Further information: Power supply and Energy storageThe InSight lander with solar panels deployed in a cleanroomAt present, mostly (lead\u2013acid) batteries are used as a power source. Many different types of batteries can be used as a power source for robots. They range from lead\u2013acid batteries, which are safe and have relatively long shelf lives but are rather heavy compared to silver\u2013cadmium batteries which are much smaller in volume and are currently much more expensive. Designing a battery-powered robot needs to take into account factors such as safety, cycle lifetime, and weight. Generators, often some type of internal combustion engine, can also be used. However, such designs are often mechanically complex and need fuel, require heat dissipation, and are relatively heavy. A tether connecting the robot to a power supply would remove the power supply from the robot entirely. This has the advantage of saving weight and space by moving all power generation and storage components elsewhere. However, this design does come with the drawback of constantly having a cable connected to the robot, which can be difficult to manage.[16] \nPotential power sources could be:\npneumatic (compressed gases)Solar power (using the sun's energy and converting it into electrical power)hydraulics (liquids)flywheel energy storageorganic garbage (through anaerobic digestion)nuclearActuation[edit]Main article: ActuatorA robotic leg powered by air musclesActuators are the \"muscles\" of a robot, the parts which convert stored energy into movement.[17] By far the most popular actuators are electric motors that rotate a wheel or gear, and linear actuators that control industrial robots in factories. There are some recent advances in alternative types of actuators, powered by electricity, chemicals, or compressed air.\nElectric motors[edit]Main article: Electric motorThe vast majority of robots use electric motors, often brushed and brushless DC motors in portable robots or AC motors in industrial robots and CNC machines. These motors are often preferred in systems with lighter loads, and where the predominant form of motion is rotational.\nLinear actuators[edit]Main article: Linear actuatorVarious types of linear actuators move in and out instead of by spinning, and often have quicker direction changes, particularly when very large forces are needed such as with industrial robotics. They are typically powered by compressed air (pneumatic actuator) or an oil (hydraulic actuator) Linear actuators can also be powered by electricity which usually consists of a motor and a leadscrew. Another common type is a mechanical linear actuator such as a rack and pinion on a car.\nSeries elastic actuators[edit]Series elastic actuation (SEA) relies on the idea of introducing intentional elasticity between the motor actuator and the load for robust force control. Due to the resultant lower reflected inertia, series elastic actuation improves safety when a robot interacts with the environment (e.g., humans or workpieces) or during collisions.[18] Furthermore, it also provides energy efficiency and shock absorption (mechanical filtering) while reducing excessive wear on the transmission and other mechanical components. This approach has successfully been employed in various robots, particularly advanced manufacturing robots[19] and walking humanoid robots.[20][21]The controller design of a series elastic actuator is most often performed within the passivity framework as it ensures the safety of interaction with unstructured environments.[22] Despite its remarkable stability and robustness, this framework suffers from the stringent limitations imposed on the controller which may trade-off performance. The reader is referred to the following survey which summarizes the common controller architectures for SEA along with the corresponding sufficient passivity conditions.[23] One recent study has derived the necessary and sufficient passivity conditions for one of the most common impedance control architectures, namely velocity-sourced SEA.[24] This work is of particular importance as it drives the non-conservative passivity bounds in an SEA scheme for the first time which allows a larger selection of control gains.\nAir muscles[edit]Main article: Pneumatic artificial musclesPneumatic artificial muscles also known as air muscles, are special tubes that expand (typically up to 42%) when air is forced inside them. They are used in some robot applications.[25][26][27]Wire muscles[edit]Main article: Shape memory alloyMuscle wire, also known as shape memory alloy, is a material that contracts (under 5%) when electricity is applied. They have been used for some small robot applications.[28][29]Electroactive polymers[edit]Main article: Electroactive polymersEAPs or EPAMs are a plastic material that can contract substantially (up to 380% activation strain) from electricity, and have been used in facial muscles and arms of humanoid robots,[30] and to enable new robots to float,[31] fly, swim or walk.[32]Piezo motors[edit]Main article: Piezoelectric motorRecent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line.[33] Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size.[34] These motors are already available commercially and being used on some robots.[35][36]Elastic nanotubes[edit]Further information: Carbon nanotubeElastic nanotubes are a promising artificial muscle technology in early-stage experimental development. The absence of defects in carbon nanotubes enables these filaments to deform elastically by several percent, with energy storage levels of perhaps 10\u00a0J/cm3 for metal nanotubes. Human biceps could be replaced with an 8\u00a0mm diameter wire of this material. Such compact \"muscle\" might allow future robots to outrun and outjump humans.[37]Sensing[edit]Main articles: Robotic sensing and Robotic sensorsSensors allow robots to receive information about a certain measurement of the environment, or internal components. This is essential for robots to perform their tasks, and act upon any changes in the environment to calculate the appropriate response. They are used for various forms of measurements, to give the robots warnings about safety or malfunctions, and to provide real-time information about the task it is performing.\nTouch[edit]Main article: Tactile sensorCurrent robotic and prosthetic hands receive far less tactile information than the human hand. Recent research has developed a tactile sensor array that mimics the mechanical properties and touch receptors of human fingertips.[38][39] The sensor array is constructed as a rigid core surrounded by conductive fluid contained by an elastomeric skin. Electrodes are mounted on the surface of the rigid core and are connected to an impedance-measuring device within the core. When the artificial skin touches an object the fluid path around the electrodes is deformed, producing impedance changes that map the forces received from the object. The researchers expect that an important function of such artificial fingertips will be adjusting the robotic grip on held objects.\nScientists from several European countries and Israel developed a prosthetic hand in 2009, called SmartHand, which functions like a real one \u2014allowing patients to write with it, type on a keyboard, play piano, and perform other fine movements. The prosthesis has sensors which enable the patient to sense real feelings in its fingertips.[40]Further information: Sensory-motor mapOther[edit]Other common forms of sensing in robotics use lidar, radar, and sonar.[41]Lidar measures the distance to a target by illuminating the target with laser light and measuring the reflected light with a sensor. Radar uses radio waves to determine the range, angle, or velocity of objects. Sonar uses sound propagation to navigate, communicate with or detect objects on or under the surface of the water.\nMechanical grippers[edit]One of the most common types of end-effectors are \"grippers\". In its simplest manifestation, it consists of just two fingers that can open and close to pick up and let go of a range of small objects. Fingers can, for example, be made of a chain with a metal wire running through it.[42] Hands that resemble and work more like a human hand include the Shadow Hand and the Robonaut hand.[43] Hands that are of a mid-level complexity include the Delft hand.[44][45] Mechanical grippers can come in various types, including friction and encompassing jaws. Friction jaws use all the force of the gripper to hold the object in place using friction. Encompassing jaws cradle the object in place, using less friction.\nSuction end-effectors[edit]Suction end-effectors, powered by vacuum generators, are very simple astrictive[46] devices that can hold very large loads provided the prehension surface is smooth enough to ensure suction.\nPick and place robots for electronic components and for large objects like car windscreens, often use very simple vacuum end-effectors.\nSuction is a highly used type of end-effector in industry, in part because the natural compliance of soft suction end-effectors can enable a robot to be more robust in the presence of imperfect robotic perception. As an example: consider the case of a robot vision system that estimates the position of a water bottle but has 1 centimeter of error. While this may cause a rigid mechanical gripper to puncture the water bottle, the soft suction end-effector may just bend slightly and conform to the shape of the water bottle surface.\nGeneral purpose effectors[edit]Some advanced robots are beginning to use fully humanoid hands, like the Shadow Hand, MANUS,[47] and the Schunk hand.[48] They have powerful Robot Dexterity Intelligence (RDI), with as many as 20 degrees of freedom and hundreds of tactile sensors.[49]Control robotics areas[edit]Puppet Magnus, a robot-manipulated marionette with complex control systemsExperimental planar robot arm and sensor-based, open-architecture robot controllerRuBot II can manually resolve Rubik's cubes.Further information: Control system and Principles of motion sensingThe mechanical structure of a robot must be controlled to perform tasks.[50] The control of a robot involves three distinct phases \u2013 perception, processing, and action (robotic paradigms).[51]Sensors give information about the environment or the robot itself (e.g. the position of its joints or its end effector). This information is then processed to be stored or transmitted and to calculate the appropriate signals to the actuators (motors), which move the mechanical structure to achieve the required co-ordinated motion or force actions.\nThe processing phase can range in complexity. At a reactive level, it may translate raw sensor information directly into actuator commands (e.g. firing motor power electronic gates based directly upon encoder feedback signals to achieve the required torque/velocity of the shaft). Sensor fusion and internal models may first be used to estimate parameters of interest (e.g. the position of the robot's gripper) from noisy sensor data. An immediate task (such as moving the gripper in a certain direction until an object is detected with a proximity sensor) is sometimes inferred from these estimates. Techniques from control theory are generally used to convert the higher-level tasks into individual commands that drive the actuators, most often using kinematic and dynamic models of the mechanical structure.[50][51][52]At longer time scales or with more sophisticated tasks, the robot may need to build and reason with a \"cognitive\" model. Cognitive models try to represent the robot, the world, and how the two interact. Pattern recognition and computer vision can be used to track objects.[50]Mapping techniques can be used to build maps of the world. Finally, motion planning and other artificial intelligence techniques may be used to figure out how to act. For example, a planner may figure out how to achieve a task without hitting obstacles, falling over, etc.\nModern commercial robotic control systems are highly complex, integrate multiple sensors and effectors, have many interacting degrees-of-freedom (DOF) and require operator interfaces, programming tools and real-time capabilities.[51] They are oftentimes interconnected to wider communication networks and in many cases are now both IoT-enabled and mobile.[53] Progress towards open architecture, layered, user-friendly and 'intelligent' sensor-based interconnected robots has emerged from earlier concepts related to Flexible Manufacturing Systems (FMS), and several 'open or 'hybrid' reference architectures exist which assist developers of robot control software and hardware to move beyond traditional, earlier notions of 'closed' robot control systems have been proposed.[52] Open architecture controllers are said to be better able to meet the growing requirements of a wide range of robot users, including system developers, end users and research scientists, and are better positioned to deliver the advanced robotic concepts related to Industry 4.0.[52] In addition to utilizing many established features of robot controllers, such as position, velocity and force control of end effectors, they also enable IoT interconnection and the implementation of more advanced sensor fusion and control techniques, including adaptive control, Fuzzy control and Artificial Neural Network (ANN)-based control.[52] When implemented in real-time, such techniques can potentially improve the stability and performance of robots operating in unknown or uncertain environments by enabling the control systems to learn and adapt to environmental changes.[54] There are several examples of reference architectures for robot controllers, and also examples of successful implementations of actual robot controllers developed from them. One example of a generic reference architecture and associated interconnected, open-architecture robot and controller implementation was used in a number of research and development studies, including prototype implementation of novel advanced and intelligent control and environment mapping methods in real-time.[54][55]Manipulation[edit]KUKAindustrial robot operating in a foundryPuma, one of the first industrial robotsBaxter, a modern and versatile industrial robot developed by Rodney BrooksLefty, first checker playing robotFurther information: Mobile manipulatorA definition of robotic manipulation has been provided by Matt Mason as: \"manipulation refers to an agent's control of its environment through selective contact\".[56]Robots need to manipulate objects; pick up, modify, destroy, move or otherwise have an effect. Thus the functional end of a robot arm intended to make the effect (whether a hand, or tool) are often referred to as end effectors,[57] while the \"arm\" is referred to as a manipulator.[58] Most robot arms have replaceable end-effectors, each allowing them to perform some small range of tasks. Some have a fixed manipulator that cannot be replaced, while a few have one very general-purpose manipulator, for example, a humanoid hand.[59]Locomotion[edit]Main articles: Robot locomotion and Mobile robotRolling robots[edit]Segway in the Robot museum in NagoyaFor simplicity, most mobile robots have four wheels or a number of continuous tracks. Some researchers have tried to create more complex wheeled robots with only one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to.\nTwo-wheeled balancing robots[edit]Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[60] Many different balancing robots have been designed.[61] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA's Robonaut that has been mounted on a Segway.[62]One-wheeled balancing robots[edit]Main article: Self-balancing unicycleA one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon University's \"Ballbot\" which is the approximate height and width of a person, and Tohoku Gakuin University's \"BallIP\".[63] Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people.[64]Spherical orb robots[edit]Main article: Spherical robotSeveral attempts have been made in robots that are completely inside a spherical ball, either by spinning a weight inside the ball,[65][66] or by rotating the outer shells of the sphere.[67][68] These have also been referred to as an orb bot[69] or a ball bot.[70][71]Six-wheeled robots[edit]Using six wheels instead of four wheels can give better traction or grip in outdoor terrain such as on rocky dirt or grass.\nTracked robots[edit]Tracks provide even more traction than a six-wheeled robot. Tracked wheels behave as if they were made of hundreds of wheels, therefore are very common for outdoor off-road robots, where the robot must drive on very rough terrain. However, they are difficult to use indoors such as on carpets and smooth floors. Examples include NASA's Urban Robot \"Urbie\".[72]Walking robots[edit]Further information: Mantis the spider robotWalking is a difficult and dynamic problem to solve. Several robots have been made which can walk reliably on two legs, however, none have yet been made which are as robust as a human. There has been much study on human-inspired walking, such as AMBER lab which was established in 2008 by the Mechanical Engineering Department at Texas A&M University.[73] Many other robots have been built that walk on more than two legs, due to these robots being significantly easier to construct.[74][75] Walking robots can be used for uneven terrains, which would provide better mobility and energy efficiency than other locomotion methods. Typically, robots on two legs can walk well on flat floors and can occasionally walk up stairs. None can walk over rocky, uneven terrain. Some of the methods which have been tried are:\nZMP technique[edit]Main article: Zero moment pointThe zero moment point (ZMP) is the algorithm used by robots such as Honda's ASIMO. The robot's onboard computer tries to keep the total inertial forces (the combination of Earth's gravity and the acceleration and deceleration of walking), exactly opposed by the floor reaction force (the force of the floor pushing back on the robot's foot). In this way, the two forces cancel out, leaving no moment (force causing the robot to rotate and fall over).[76] However, this is not exactly how a human walks, and the difference is obvious to human observers, some of whom have pointed out that ASIMO walks as if it needs the lavatory.[77][78][79] ASIMO's walking algorithm is not static, and some dynamic balancing is used (see below). However, it still requires a smooth surface to walk on.\nHopping[edit]Several robots, built in the 1980s by Marc Raibert at the MIT Leg Laboratory, successfully demonstrated very dynamic walking. Initially, a robot with only one leg, and a very small foot could stay upright simply by hopping. The movement is the same as that of a person on a pogo stick. As the robot falls to one side, it would jump slightly in that direction, in order to catch itself.[80] Soon, the algorithm was generalised to two and four legs. A bipedal robot was demonstrated running and even performing somersaults.[81] A quadruped was also demonstrated which could trot, run, pace, and bound.[82] For a full list of these robots, see the MIT Leg Lab Robots page.[83]Dynamic balancing (controlled falling)[edit]A more advanced way for a robot to walk is by using a dynamic balancing algorithm, which is potentially more robust than the Zero Moment Point technique, as it constantly monitors the robot's motion, and places the feet in order to maintain stability.[84] This technique was recently demonstrated by Anybots' Dexter Robot,[85] which is so stable, it can even jump.[86] Another example is the TU Delft Flame.\nPassive dynamics[edit]Main article: Passive dynamicsPerhaps the most promising approach uses passive dynamics where the momentum of swinging limbs is used for greater efficiency. It has been shown that totally unpowered humanoid mechanisms can walk down a gentle slope, using only gravity to propel themselves. Using this technique, a robot need only supply a small amount of motor power to walk along a flat surface or a little more to walk up a hill. This technique promises to make walking robots at least ten times more efficient than ZMP walkers, like ASIMO.[87][88]Flying[edit]A modern passenger airliner is essentially a flying robot, with two humans to manage it. The autopilot can control the plane for each stage of the journey, including takeoff, normal flight, and even landing.[89] Other flying robots are uninhabited and are known as unmanned aerial vehicles (UAVs). They can be smaller and lighter without a human pilot on board, and fly into dangerous territory for military surveillance missions. Some can even fire on targets under command. UAVs are also being developed which can fire on targets automatically, without the need for a command from a human. Other flying robots include cruise missiles, the Entomopter, and the Epson micro helicopter robot. Robots such as the Air Penguin, Air Ray, and Air Jelly have lighter-than-air bodies, are propelled by paddles, and are guided by sonar.\nBiomimetic flying robots (BFRs)[edit]A flapping wing BFR generating lift and thrustBFRs take inspiration from flying mammals, birds, or insects. BFRs can have flapping wings, which generate the lift and thrust, or they can be propeller actuated. BFRs with flapping wings have increased stroke efficiencies, increased maneuverability, and reduced energy consumption in comparison to propeller actuated BFRs.[90] Mammal and bird inspired BFRs share similar flight characteristics and design considerations. For instance, both mammal and bird inspired BFRs minimize edge fluttering and pressure-induced wingtip curl by increasing the rigidity of the wing edge and wingtips. Mammal and insect inspired BFRs can be impact resistant, making them useful in cluttered environments.\nMammal inspired BFRs typically take inspiration from bats, but the flying squirrel has also inspired a prototype.[91] Examples of bat inspired BFRs include Bat Bot[92] and the DALER.[93] Mammal inspired BFRs can be designed to be multi-modal; therefore, they're capable of both flight and terrestrial movement. To reduce the impact of landing, shock absorbers can be implemented along the wings.[93] Alternatively, the BFR can pitch up and increase the amount of drag it experiences.[91] By increasing the drag force, the BFR will decelerate and minimize the impact upon grounding. Different land gait patterns can also be implemented.[91]Dragonfly inspired BFR.Bird inspired BFRs can take inspiration from raptors, gulls, and everything in-between. Bird inspired BFRs can be feathered to increase the angle of attack range over which the prototype can operate before stalling.[94] The wings of bird inspired BFRs allow for in-plane deformation, and the in-plane wing deformation can be adjusted to maximize flight efficiency depending on the flight gait.[94] An example of a raptor inspired BFR is the prototype by Savastano et al.[95] The prototype has fully deformable flapping wings and is capable of carrying a payload of up to 0.8\u00a0kg while performing a parabolic climb, steep descent, and rapid recovery. The gull inspired prototype by Grant et al. accurately mimics the elbow and wrist rotation of gulls, and they find that lift generation is maximized when the elbow and wrist deformations are opposite but equal.[96]Insect inspired BFRs typically take inspiration from beetles or dragonflies. An example of a beetle inspired BFR is the prototype by Phan and Park,[97] and a dragonfly inspired BFR is the prototype by Hu et al.[98] The flapping frequency of insect inspired BFRs are much higher than those of other BFRs; this is because of the aerodynamics of insect flight.[99] Insect inspired BFRs are much smaller than those inspired by mammals or birds, so they are more suitable for dense environments.\nBiologically-inspired flying robots[edit]Visualization of entomopter flying on Mars (NASA)A class of robots that are biologically inspired, but which do not attempt to mimic biology, are creations such as the Entomopter. Funded by DARPA, NASA, the United States Air Force, and the Georgia Tech Research Institute and patented by Prof. Robert C. Michelson for covert terrestrial missions as well as flight in the lower Mars atmosphere, the Entomopter flight propulsion system uses low Reynolds number wings similar to those of the hawk moth (Manduca sexta), but flaps them in a non-traditional \"opposed x-wing fashion\" while \"blowing\" the surface to enhance lift based on the Coand\u0103 effect as well as to control vehicle attitude and direction. Waste gas from the propulsion system not only facilitates the blown wing aerodynamics, but also serves to create ultrasonic emissions like that of a Bat for obstacle avoidance. The Entomopter and other biologically-inspired robots leverage features of biological systems, but do not attempt to create mechanical analogs.\nSnaking[edit]Two robot snakes. The left one has 64 motors (with 2 degrees of freedom per segment), the right one 10.Several snake robots have been successfully developed. Mimicking the way real snakes move, these robots can navigate very confined spaces, meaning they may one day be used to search for people trapped in collapsed buildings.[100] The Japanese ACM-R5 snake robot[101] can even navigate both on land and in water.[102]Skating[edit]A small number of skating robots have been developed, one of which is a multi-mode walking and skating device. It has four legs, with unpowered wheels, which can either step or roll.[103] Another robot, Plen, can use a miniature skateboard or roller-skates, and skate across a desktop.[104]Capuchin, a climbing robotClimbing[edit]Several different approaches have been used to develop robots that have the ability to climb vertical surfaces. One approach mimics the movements of a human climber on a wall with protrusions; adjusting the center of mass and moving each limb in turn to gain leverage. An example of this is Capuchin,[105] built by Ruixiang Zhang at Stanford University, California. Another approach uses the specialized toe pad method of wall-climbing geckoes, which can run on smooth surfaces such as vertical glass. Examples of this approach include Wallbot[106] and Stickybot.[107]China's Technology Daily reported on 15 November 2008, that Li Hiu Yeung and his research group of New Concept Aircraft (Zhuhai) Co., Ltd. had successfully developed a bionic gecko robot named \"Speedy Freelander\". According to Yeung, the gecko robot could rapidly climb up and down a variety of building walls, navigate through ground and wall fissures, and walk upside-down on the ceiling. It was also able to adapt to the surfaces of smooth glass, rough, sticky or dusty walls as well as various types of metallic materials. It could also identify and circumvent obstacles automatically. Its flexibility and speed were comparable to a natural gecko. A third approach is to mimic the motion of a snake climbing a pole.[41]Swimming (Piscine)[edit]It is calculated that when swimming some fish can achieve a propulsive efficiency greater than 90%.[108] Furthermore, they can accelerate and maneuver far better than any man-made boat or submarine, and produce less noise and water disturbance. Therefore, many researchers studying underwater robots would like to copy this type of locomotion.[109] Notable examples are the Robotic Fish G9,[110] and Robot Tuna built to analyze and mathematically model thunniform motion.[111] The Aqua Penguin,[112] copies the streamlined shape and propulsion by front \"flippers\" of penguins. The Aqua Ray and Aqua Jelly emulate the locomotion of manta ray, and jellyfish, respectively.\nRobotic Fish: iSplash-IIIn 2014, iSplash-II was developed as the first robotic fish capable of outperforming real carangiform fish in terms of average maximum velocity (measured in body lengths/ second) and endurance, the duration that top speed is maintained.[113] This build attained swimming speeds of 11.6BL/s (i.e. 3.7\u00a0m/s).[114] The first build, iSplash-I (2014) was the first robotic platform to apply a full-body length carangiform swimming motion which was found to increase swimming speed by 27% over the traditional approach of a posterior confined waveform.[115]Sailing[edit]The autonomous sailboat robot VaimosSailboat robots have also been developed in order to make measurements at the surface of the ocean. A typical sailboat robot is Vaimos.[116] Since the propulsion of sailboat robots uses the wind, the energy of the batteries is only used for the computer, for the communication and for the actuators (to tune the rudder and the sail). If the robot is equipped with solar panels, the robot could theoretically navigate forever. The two main competitions of sailboat robots are WRSC, which takes place every year in Europe, and Sailbot.\nComputational robotics areas[edit]TOPIO, a humanoid robot, played ping pong at Tokyo IREX 2009.[117]Control systems may also have varying levels of autonomy.\nDirect interaction is used for haptic or teleoperated devices, and the human has nearly complete control over the robot's motion.Operator-assist modes have the operator commanding medium-to-high-level tasks, with the robot automatically figuring out how to achieve them.[118]An autonomous robot may go without human interaction for extended periods of time . Higher levels of autonomy do not necessarily require more complex cognitive capabilities. For example, robots in assembly plants are completely autonomous but operate in a fixed pattern.Another classification takes into account the interaction between human control and the machine motions.\nTeleoperation. A human controls each movement, each machine actuator change is specified by the operator.Supervisory. A human specifies general moves or position changes and the machine decides specific movements of its actuators.Task-level autonomy. The operator specifies only the task and the robot manages itself to complete it.Full autonomy. The machine will create and complete all its tasks without human interaction.Vision[edit]Main article: Computer visionComputer vision is the science and technology of machines that see. As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences and views from cameras.\nIn most practical computer vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common.\nComputer vision systems rely on image sensors that detect electromagnetic radiation which is typically in the form of either visible light or infra-red light. The sensors are designed using solid-state physics. The process by which light propagates and reflects off surfaces is explained using optics. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Robots can also be equipped with multiple vision sensors to be better able to compute the sense of depth in the environment. Like human eyes, robots' \"eyes\" must also be able to focus on a particular area of interest, and also adjust to variations in light intensities.\nThere is a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological system, at different levels of complexity. Also, some of the learning-based methods developed within computer vision have a background in biology.\nEnvironmental interaction and navigation[edit]Main articles: Robotic mapping and Robotic navigationRadar, GPS, and lidar, are all combined to provide proper navigation and obstacle avoidance (vehicle developed for 2007 DARPA Urban Challenge).This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.  (July 2009) (Learn how and when to remove this message)Though a significant percentage of robots in commission today are either human controlled or operate in a static environment, there is an increasing interest in robots that can operate autonomously in a dynamic environment. These robots require some combination of navigation hardware and software in order to traverse their environment. In particular, unforeseen events (e.g. people and other obstacles that are not stationary) can cause problems or collisions. Some highly advanced robots such as ASIMO and Mein\u00fc robot have particularly good robot navigation hardware and software. Also, self-controlled cars, Ernst Dickmanns' driverless car, and the entries in the DARPA Grand Challenge, are capable of sensing the environment well and subsequently making navigational decisions based on this information, including by a swarm of autonomous robots.[119] Most of these robots employ a GPS navigation device with waypoints, along with radar, sometimes combined with other sensory data such as lidar, video cameras, and inertial guidance systems for better navigation between waypoints.\nHuman-robot interaction[edit]Main article: Human-robot interactionKismet can produce a range of facial expressions.The state of the art in sensory intelligence for robots will have to progress through several orders of magnitude if we want the robots working in our homes to go beyond vacuum-cleaning the floors. If robots are to work effectively in homes and other non-industrial environments, the way they are instructed to perform their jobs, and especially how they will be told to stop will be of critical importance. The people who interact with them may have little or no training in robotics, and so any interface will need to be extremely intuitive. Science fiction authors also typically assume that robots will eventually be capable of communicating with humans through speech, gestures, and facial expressions, rather than a command-line interface. Although speech would be the most natural way for the human to communicate, it is unnatural for the robot. It will probably be a long time before robots interact as naturally as the fictional C-3PO, or Data of Star Trek, Next Generation. Even though the current state of robotics cannot meet the standards of these robots from science-fiction, robotic media characters (e.g., Wall-E, R2-D2) can elicit audience sympathies that increase people's willingness to accept actual robots in the future.[120] Acceptance of social robots is also likely to increase if people can meet a social robot under appropriate conditions. Studies have shown that interacting with a robot by looking at, touching, or even imagining interacting with the robot can reduce negative feelings that some people have about robots before interacting with them.[121] However, if pre-existing negative sentiments are especially strong, interacting with a robot can increase those negative feelings towards robots.[121]Speech recognition[edit]Main article: Speech recognitionInterpreting the continuous flow of sounds coming from a human, in real time, is a difficult task for a computer, mostly because of the great variability of speech.[122] The same word, spoken by the same person may sound different depending on local acoustics, volume, the previous word, whether or not the speaker has a cold, etc.. It becomes even harder when the speaker has a different accent.[123] Nevertheless, great strides have been made in the field since Davis, Biddulph, and Balashek designed the first \"voice input system\" which recognized \"ten digits spoken by a single user with 100% accuracy\" in 1952.[124] Currently, the best systems can recognize continuous, natural speech, up to 160 words per minute, with an accuracy of 95%.[125] With the help of artificial intelligence, machines nowadays can use people's voice to identify their emotions such as satisfied or angry.[126]Robotic voice[edit]Other hurdles exist when allowing the robot to use voice for interacting with humans. For social reasons, synthetic voice proves suboptimal as a communication medium,[127] making it necessary to develop the emotional component of robotic voice through various techniques.[128][129] An advantage of diphonic branching is the emotion that the robot is programmed to project, can be carried on the voice tape, or phoneme, already pre-programmed onto the voice media. One of the earliest examples is a teaching robot named Leachim developed in 1974 by Michael J. Freeman.[130][131] Leachim was able to convert digital memory to rudimentary verbal speech on pre-recorded computer discs.[132] It was programmed to teach students in The Bronx, New York.[132]Facial expression[edit]Further information: Emotion recognitionFacial expressions can provide rapid feedback on the progress of a dialog between two humans, and soon may be able to do the same for humans and robots. Robotic faces have been constructed by Hanson Robotics using their elastic polymer called Frubber, allowing a large number of facial expressions due to the elasticity of the rubber facial coating and embedded subsurface motors (servos).[133] The coating and servos are built on a metal skull. A robot should know how to approach a human, judging by their facial expression and body language. Whether the person is happy, frightened, or crazy-looking affects the type of interaction expected of the robot. Likewise, robots like Kismet and the more recent addition, Nexi[134] can produce a range of facial expressions, allowing it to have meaningful social exchanges with humans.[135]Gestures[edit]Further information: Gesture recognitionOne can imagine, in the future, explaining to a robot chef how to make a pastry, or asking directions from a robot police officer. In both of these cases, making hand gestures would aid the verbal descriptions. In the first case, the robot would be recognizing gestures made by the human, and perhaps repeating them for confirmation. In the second case, the robot police officer would gesture to indicate \"down the road, then turn right\". It is likely that gestures will make up a part of the interaction between humans and robots.[136] A great many systems have been developed to recognize human hand gestures.[137]Proxemics[edit]Proxemics is the study of personal space, and HRI systems may try to model and work with its concepts for human interactions.\nArtificial emotions[edit]Artificial emotions can also be generated, composed of a sequence of facial expressions or gestures. As can be seen from the movie Final Fantasy: The Spirits Within, the programming of these artificial emotions is complex and requires a large amount of human observation. To simplify this programming in the movie, presets were created together with a special software program. This decreased the amount of time needed to make the film. These presets could possibly be transferred for use in real-life robots. An example of a robot with artificial emotions is Robin the Robot\u00a0[hy] developed by an Armenian IT company Expper Technologies, which uses AI-based peer-to-peer interaction. Its main task is achieving emotional well-being, i.e. overcome stress and anxiety. Robin was trained to analyze facial expressions and use his face to display his emotions given the context. The robot has been tested by kids in US clinics, and observations show that Robin increased the appetite and cheerfulness of children after meeting and talking.[138]Personality[edit]Many of the robots of science fiction have a personality, something which may or may not be desirable in the commercial robots of the future.[139] Nevertheless, researchers are trying to create robots which appear to have a personality:[140][141] i.e. they use sounds, facial expressions, and body language to try to convey an internal state, which may be joy, sadness, or fear. One commercial example is Pleo, a toy robot dinosaur, which can exhibit several apparent emotions.[142]Research robotics[edit]Further information: Areas of roboticsMuch of the research in robotics focuses not on specific industrial tasks, but on investigations into new types of robots, alternative ways to think about or design robots, and new ways to manufacture them. Other investigations, such as MIT's cyberflora project, are almost wholly academic.\nTo describe the level of advancement of a robot, the term \"Generation Robots\" can be used. This term is coined by Professor Hans Moravec, Principal Research Scientist at the Carnegie Mellon UniversityRobotics Institute in describing the near future evolution of robot technology. First-generation robots, Moravec predicted in 1997, should have an intellectual capacity comparable to perhaps a lizard and should become available by 2010. Because the first generation robot would be incapable of learning, however, Moravec predicts that the second generation robot would be an improvement over the first and become available by 2020, with the intelligence maybe comparable to that of a mouse. The third generation robot should have intelligence comparable to that of a monkey. Though fourth generation robots, robots with human intelligence, professor Moravec predicts, would become possible, he does not predict this happening before around 2040 or 2050.[143]Dynamics and kinematics[edit]Main article: Robot kinematicsFurther information: Kinematics and Dynamics (mechanics).mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}External videosHow the BB-8 Sphero Toy WorksThe study of motion can be divided into kinematics and dynamics.[144] Direct kinematics or forward kinematics refers to the calculation of end effector position, orientation, velocity, and acceleration when the corresponding joint values are known. Inverse kinematics refers to the opposite case in which required joint values are calculated for given end effector values, as done in path planning. Some special aspects of kinematics include handling of redundancy (different possibilities of performing the same movement), collision avoidance, and singularity avoidance. Once all relevant positions, velocities, and accelerations have been calculated using kinematics, methods from the field of dynamics are used to study the effect of forces upon these movements. Direct dynamics refers to the calculation of accelerations in the robot once the applied forces are known. Direct dynamics is used in computer simulations of the robot. Inverse dynamics refers to the calculation of the actuator forces necessary to create a prescribed end-effector acceleration. This information can be used to improve the control algorithms of a robot.\nIn each area mentioned above, researchers strive to develop new concepts and strategies, improve existing ones, and improve the interaction between these areas. To do this, criteria for \"optimal\" performance and ways to optimize design, structure, and control of robots must be developed and implemented.\nOpen source robotics[edit]Further information: Open source robotics, List of open-source robotics hardware, and List of open-source robotics softwareOpen source robotics research seeks standards for defining, and methods for designing and building, robots so that they can easily be reproduced by anyone. Research includes legal and technical definitions; seeking out alternative tools and materials to reduce costs and simplify builds; and creating interfaces and standards for designs to work together. Human usability research also investigates how to best document builds through visual, text or video instructions.\nEvolutionary robotics[edit]Evolutionary robots is a methodology that uses evolutionary computation to help design robots, especially the body form, or motion and behavior controllers. In a similar way to natural evolution, a large population of robots is allowed to compete in some way, or their ability to perform a task is measured using a fitness function. Those that perform worst are removed from the population and replaced by a new set, which have new behaviors based on those of the winners. Over time the population improves, and eventually a satisfactory robot may appear. This happens without any direct programming of the robots by the researchers. Researchers use this method both to create better robots,[145] and to explore the nature of evolution.[146] Because the process often requires many generations of robots to be simulated,[147] this technique may be run entirely or mostly in simulation, using a robot simulator software package, then tested on real robots once the evolved algorithms are good enough.[148] According to the International Federation of Robotics (IFR) study World Robotics 2023, there were about 4,281,585 operational industrial robots by the end of 2023[149] \nBionics and biomimetics[edit]Bionics and biomimetics apply the physiology and methods of locomotion of animals to the design of robots. For example, the design of BionicKangaroo was based on the way kangaroos jump.\nSwarm robotics[edit]Swarm robotics is an approach to the coordination of multiple robots as a system which consist of large numbers of mostly simple physical robots. \u2033In a robot swarm, the collective behavior of the robots results from local interactions between the robots and between the robots and the environment in which they act.\u2033* [119]Quantum computing[edit]There has been some research into whether robotics algorithms can be run more quickly on quantum computers than they can be run on digital computers. This area has been referred to as quantum robotics.[150]Other research areas[edit]Nanorobots.Cobots (collaborative robots).[151]Autonomous drones.High temperature crucibles allow robotic systems to automate sample analysis.[152]The main venues for robotics research are the international conferences ICRA and IROS.\nHuman factors[edit]Education and training[edit]Main article: Educational roboticsThe SCORBOT-ER 4u educational robotRobotics engineers design robots, maintain them, develop new applications for them, and conduct research to expand the potential of robotics.[153] Robots have become a popular educational tool in some middle and high schools, particularly in parts of the USA,[154] as well as in numerous youth summer camps, raising interest in programming, artificial intelligence, and robotics among students.\nEmployment[edit]A robot technician builds small all-terrain robots (courtesy: MobileRobots, Inc.).Main article: Technological unemploymentRobotics is an essential component in many modern manufacturing environments. As factories increase their use of robots, the number of robotics\u2013related jobs grow and have been observed to be steadily rising.[155] The employment of robots in industries has increased productivity and efficiency savings and is typically seen as a long-term investment for benefactors. A study found that 47 percent of US jobs are at risk to automation \"over some unspecified number of years\".[156] These claims have been criticized on the ground that social policy, not AI, causes unemployment.[157] In a 2016 article in The Guardian, Stephen Hawking stated \"The automation of factories has already decimated jobs in traditional manufacturing, and the rise of artificial intelligence is likely to extend this job destruction deep into the middle classes, with only the most caring, creative or supervisory roles remaining\".[158]   The rise of robotics is thus often used as an argument for universal basic income.\nAccording to a GlobalData September 2021 report, the robotics industry was worth $45bn in 2020, and by 2030, it will have grown at a compound annual growth rate (CAGR) of 29% to $568bn, driving jobs in robotics and related industries.[159]Occupational safety and health implications[edit]Main article: Workplace robotics safetyA discussion paper drawn up by EU-OSHA highlights how the spread of robotics presents both opportunities and challenges for occupational safety and health (OSH).[160]The greatest OSH benefits stemming from the wider use of robotics should be substitution for people working in unhealthy or dangerous environments. In space, defense, security, or the nuclear industry, but also in logistics, maintenance, and inspection, autonomous robots are particularly useful in replacing human workers performing dirty, dull or unsafe tasks, thus avoiding workers' exposures to hazardous agents and conditions and reducing physical, ergonomic and psychosocial risks. For example, robots are already used to perform repetitive and monotonous tasks, to handle radioactive material or to work in explosive atmospheres. In the future, many other highly repetitive, risky or unpleasant tasks will be performed by robots in a variety of sectors like agriculture, construction, transport, healthcare, firefighting or cleaning services.[161]Moreover, there are certain skills to which humans will be better suited than machines for some time to come and the question is how to achieve the best combination of human and robot skills. The advantages of robotics include heavy-duty jobs with precision and repeatability, whereas the advantages of humans include creativity, decision-making, flexibility, and adaptability. This need to combine optimal skills has resulted in collaborative robots and humans sharing a common workspace more closely and led to the development of new approaches and standards to guarantee the safety of the \"man-robot merger\". Some European countries are including robotics in their national programs and trying to promote a safe and flexible cooperation between robots and operators to achieve better productivity. For example, the German Federal Institute for Occupational Safety and Health (BAuA) organises annual workshops on the topic \"human-robot collaboration\".\nIn the future, cooperation between robots and humans will be diversified, with robots increasing their autonomy and human-robot collaboration reaching completely new forms. Current approaches and technical standards[162][163] aiming to protect employees from the risk of working with collaborative robots will have to be revised.\nUser experience[edit]Great user experience predicts the needs, experiences, behaviors, language and cognitive abilities, and other factors of each user group. It then uses these insights to produce a product or solution that is ultimately useful and usable. For robots, user experience begins with an understanding of the robot's intended task and environment, while considering any possible social impact the robot may have on human operations and interactions with it.[164]It defines that communication as the transmission of information through signals, which are elements perceived through touch, sound, smell and sight.[165] The author states that the signal connects the sender to the receiver and consists of three parts: the signal itself, what it refers to, and the interpreter. Body postures and gestures, facial expressions, hand and head movements are all part of nonverbal behavior and communication. Robots are no exception when it comes to human-robot interaction. Therefore, humans use their verbal and nonverbal behaviors to communicate their defining characteristics. Similarly, social robots need this coordination to perform human-like behaviors.\nCareers[edit]Robotics is an interdisciplinary field, combining primarily mechanical engineering and computer science but also drawing on electronic engineering and other subjects. The usual way to build a career in robotics is to complete an undergraduate degree in one of these established subjects, followed by a graduate (masters') degree in Robotics. Graduate degrees are typically joined by students coming from all of the contributing disciplines, and include familiarization of relevant undergraduate level subject matter from each of them, followed by specialist study in pure robotics topics which build upon them. As an interdisciplinary subject, robotics graduate programmes tend to be especially reliant on students working and learning together and sharing their knowledge and skills from their home discipline first degrees.\nRobotics industry careers then follow the same pattern, with most roboticists working as part of interdisciplinary teams of specialists from these home disciplines followed by the robotics graduate degrees which enable them to work together. Workers typically continue to identify as members of their home disciplines who work in robotics, rather than as 'roboticists'. This structure is reinforced by the nature of some engineering professions, which grant chartered engineer status to members of home disciplines rather than to robotics as a whole.\nRobotics careers are widely predicted to grow in the 21st century, as robots replace more manual and intellectual human work. Some workers who lose their jobs to robotics may be well-placed to retrain to build and maintain these robots, using their domain-specific knowledge and skills.\nHistory[edit]See also: History of robots\n\nDate\nSignificance\nRobot name\nInventor\nc. 420 B.C.\nA wooden, steam-propelled bird, which was able to fly\nFlying pigeon\nArchytas of Tarentum\nThird century B.C. and earlier\nOne of the earliest descriptions of automata appears in the Lie Zi text, on a much earlier encounter between King Mu of Zhou (1023\u2013957 BC) and a mechanical engineer known as Yan Shi, an 'artificer'. The latter allegedly presented the king with a life-size, human-shaped figure of his mechanical handiwork.[166]Yan Shi (Chinese: \u5043\u5e08)\nFirst century A.D. and earlier\nDescriptions of more than 100 machines and automata, including a fire engine, a wind organ, a coin-operated machine, and a steam-powered engine, in Pneumatica and Automata by Heron of AlexandriaCtesibius, Philo of Byzantium, Heron of Alexandria, and others\n1206\nCreated early humanoid automata, programmable automaton band[167]Robot band, hand-washing automaton,[168] automated moving peacocks[169]Al-Jazari1495\nDesigns for a humanoid robot\nMechanical KnightLeonardo da Vinci1560s\nClockwork Prayer that had machinal feet built under its robes that imitated walking. The robot's eyes, lips, and head all move in lifelike gestures.\nClockwork Prayer[citation needed]Gianello della Torre1738\nMechanical duck that was able to eat, flap its wings, and excrete\nDigesting DuckJacques de Vaucanson1898\nNikola Tesla demonstrates the first radio-controlled vessel.\nTeleautomaton\nNikola Tesla\n\n1903\nLeonardo Torres Quevedo presented the Telekino at the Paris Academy of Science, a radio-based control system with different operational states, for testing airships without risking human lives.[170] He conduct the initial test controlling a tricycle almost 100 feet away, being the first example of a radio-controlled unmanned ground vehicle.[171][172]TelekinoLeonardo Torres Quevedo1912\nLeonardo Torres Quevedo builds the first truly autonomous machine capable of playing chess. As opposed to the human-operated The Turk and Ajeeb, El Ajedrecista had an integrated automaton built to play chess without human guidance. It only played an endgame with three chess pieces, automatically moving a white king and a rook to checkmate the black king moved by a human opponent.[173][174]El AjedrecistaLeonardo Torres Quevedo1914\nIn his paper Essays on Automatics published in 1914, Leonardo Torres Quevedo proposed a machine that makes \"judgments\" using sensors that capture information from the outside, parts that manipulate the outside world like arms, power sources such as batteries and air pressure, and most importantly, captured information and past information. It was defined as an organism that can control reactions in response to external information and adapt to changes in the environment to change its behavior.[175][176][177][178]Essays on Automatics\nLeonardo Torres Quevedo1921\nFirst fictional automatons called \"robots\" appear in the play R.U.R.Rossum's Universal RobotsKarel \u010capek1930s\nHumanoid robot exhibited at the 1939 and 1940 World's FairsElektroWestinghouse Electric Corporation1946\nFirst general-purpose digital computer\nWhirlwindMultiple people\n1948\nSimple robots exhibiting biological behaviors[179]Elsie and Elmer\nWilliam Grey Walter1948\nFormulation of principles of cyberneticscyberneticsNorbert Wiener1956\nFirst commercial robot, from the Unimation company founded by George Devol and Joseph Engelberger, based on Devol's patents[180]UnimateGeorge Devol1961\nFirst installed industrial robot.  The first digitally operated and programmable robot, Unimate, was installed in 1961 to lift hot pieces of metal from a die casting machine and stack them.\nUnimateGeorge Devol1967 to 1972\nFirst full-scale humanoid intelligent robot,[181][182] and first android. Its limb control system allowed it to walk with the lower limbs, and to grip and transport objects with its hands, using tactile sensors. Its vision system allowed it to measure distances and directions to objects using external receptors, artificial eyes, and ears. And its conversation system allowed it to communicate with a person in Japanese, with an artificial mouth.[183][184][185]WABOT-1\nWaseda University1973\nFirst industrial robot with six electromechanically driven axes[186][187]Famulus\nKUKA Robot Group1974\nThe world's first microcomputer controlled electric industrial robot, IRB 6 from ASEA, was delivered to a small mechanical engineering company in southern Sweden. The design of this robot had been patented in 1972.\nIRB 6\nABB Robot Group1975\nProgrammable universal manipulation arm, a Unimation product\nPUMAVictor Scheinman1978\nThe first object-level robot programming language, RAPT, allowing robots to handle variations in object position, shape, and sensor noise.[188]Freddy I and IIPatricia Ambler and Robin Popplestone1983\nFirst multitasking, the parallel programming language used for robot control. It was the Event Driven Language (EDL) on the IBM/Series/1 process computer, with the implementation of both inter-process communication (WAIT/POST) and mutual exclusion (ENQ/DEQ) mechanisms for robot control.[189]ADRIEL I\nStevo Bozinovski and Mihail Sestakov\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Artificial intelligenceAutonomous robotCloud roboticsCognitive roboticsEvolutionary roboticsFog roboticsGlossary of roboticsIndex of robotics articlesMechatronicsMulti-agent systemOutline of roboticsQuantum roboticsRoboethicsRobot rightsRobotic artRobotic governanceSelf-reconfiguring modular robotSoft roboticsTeleroboticsNotes[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^One database, developed by the United States Department of Energy, contains information on almost 500 existing robotic technologies.[10]References[edit]^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"German National Library\". International classification system of the German National Library (GND). Archived from the original on 2020-08-19.^\"Origami-Inspired Robots Can Sense, Analyze and Act in Challenging Environments\". UCLA. Retrieved 2023-04-10.^Raj, Aditi (26 August 2024). \"AI & Robotics: The Role of AI in Robots\". Retrieved 2024-08-29.^Hunt, V. Daniel (1985). \"Smart Robots\". Smart Robots: A Handbook of Intelligent Robotic Systems. Chapman and Hall. p.\u00a0141. ISBN\u00a0978-1-4613-2533-8. Archived from the original on 2023-03-15. Retrieved 2018-12-04.^\"Robot density rises globally\". Robotic Industries Association. 8 February 2018. Archived from the original on 2020-11-23. Retrieved 2018-12-03.^Pinto, Jim (1 October 2003). \"Fully automated factories approach reality\". Automation World. Archived from the original on 2011-10-01. Retrieved 2018-12-03.^Eyre, Michael (12 September 2014). \"'Boris' the robot can load up dishwasher\". BBC News. Archived from the original on 2020-12-21. Retrieved 2018-12-03.^Corner, Stuart (23 November 2017). \"AI-driven robot makes 'perfect' flatbread\". iothub.com.au. Archived from the original on 2020-11-24. Retrieved 2018-12-03.^Pollock, Emily (7 June 2018). \"Construction Robotics Industry Set to Double by 2023\". engineering.com. Archived from the original on 2020-08-07. Retrieved 2018-12-03.^\"Technology Advanced Search\". D&D Knowledge Management Information Tool. Archived from the original on 2020-08-06.^Ar\u00e1mbula Cos\u00edo, F.; Hibberd, R. D.; Davies, B. L. (July 1997). \"Electromagnetic compatibility aspects of active robotic systems for surgery: the robotic prostatectomy experience\". Medical and Biological Engineering and Computing. 35 (4): 436\u2013440. doi:10.1007/BF02534105. ISSN\u00a01741-0444. PMID\u00a09327627. S2CID\u00a021479700.^Grift, Tony E. (2004). \"Agricultural Robotics\". University of Illinois at Urbana\u2013Champaign. Archived from the original on 2007-05-04. Retrieved 2018-12-03.^Thomas, Jim (1 November 2017). \"How corporate giants are automating the farm\". New Internationalist. Archived from the original on 2021-01-10. Retrieved 2018-12-03.^Kolodny, Lora (4 July 2017). \"Robots are coming to a burger joint near you\". CNBC. Archived from the original on 2020-12-05. Retrieved 2018-12-03.^Scott Kirsner (27 January 2023). \"Robots in the kitchen? Local engineers are making it a reality\". The Boston Globe.^Dowling, Kevin. \"Power Sources for Small Robots\"(PDF). Carnegie Mellon University. Archived(PDF) from the original on 2020-11-25. Retrieved 2012-05-11.^Roozing, Wesley; Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2016). \"Design Optimisation and Control of Compliant Actuation Arrangements in Articulated Robots for Improved Energy Efficiency\". IEEE Robotics and Automation Letters. 1 (2): 1110\u20131117. Bibcode:2016IRAL....1.1110R. doi:10.1109/LRA.2016.2521926. S2CID\u00a01940410.^Pratt, G.A.; Williamson, M.M. (1995). \"Series elastic actuators\". Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human-Robot Interaction and Cooperative Robots. Vol.\u00a01. pp.\u00a0399\u2013406. doi:10.1109/IROS.1995.525827. hdl:1721.1/36966. ISBN\u00a00-8186-7108-4. S2CID\u00a017120394.^Furn\u00e9mont, Rapha\u00ebl; Mathijssen, Glenn; Verstraten, Tom; Lefeber, Dirk; Vanderborght, Bram (27 January 2016). \"Bi-directional series-parallel elastic actuator and overlap of the actuation layers\"(PDF). Bioinspiration & Biomimetics. 11 (1) 016005. Bibcode:2016BiBi...11a6005F. doi:10.1088/1748-3190/11/1/016005. PMID\u00a026813145. S2CID\u00a037031990. Archived(PDF) from the original on 2022-10-01. Retrieved 2023-03-15.^Pratt, Jerry E.; Krupp, Benjamin T. (2004). \"Series Elastic Actuators for legged robots\". In Gerhart, Grant R; Shoemaker, Chuck M; Gage, Douglas W (eds.). Unmanned Ground Vehicle Technology VI. Vol.\u00a05422. pp.\u00a0135\u2013144. doi:10.1117/12.548000. S2CID\u00a016586246.^Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2013). \"Walking Pattern Generation for a Humanoid Robot with Compliant Joints\". Autonomous Robots. 35 (1): 1\u201314. doi:10.1007/s10514-013-9330-7. S2CID\u00a0624563.^Colgate, J. Edward (1988). The control of dynamically interacting systems (Thesis). hdl:1721.1/14380.^Calanca, Andrea; Muradore, Riccardo; Fiorini, Paolo (November 2017). \"Impedance control of series elastic actuators: Passivity and acceleration-based control\". Mechatronics. 47: 37\u201348. doi:10.1016/j.mechatronics.2017.08.010.^Tosun, Fatih Emre; Patoglu, Volkan (June 2020). \"Necessary and Sufficient Conditions for the Passivity of Impedance Rendering With Velocity-Sourced Series Elastic Actuation\". IEEE Transactions on Robotics. 36 (3): 757\u2013772. Bibcode:2020ITRob..36..757T. doi:10.1109/TRO.2019.2962332. S2CID\u00a0212907787.^www.imagesco.com, Images SI Inc -. \"Air Muscle actuators, going further, page 6\". Archived from the original on 2020-11-14. Retrieved 2010-05-24.^\"Air Muscles\". Shadow Robot. Archived from the original on 2007-09-27.^Tondu, Bertrand (2012). \"Modelling of the McKibben artificial muscle: A review\". Journal of Intelligent Material Systems and Structures. 23 (3): 225\u2013253. doi:10.1177/1045389X11435435. S2CID\u00a0136854390.^\"TALKING ELECTRONICS Nitinol Page-1\". Talkingelectronics.com. Archived from the original on 2020-01-18. Retrieved 2010-11-27.^\"lf205, Hardware: Building a Linux-controlled walking robot\". Ibiblio.org. 1 November 2001. Archived from the original on 2016-03-03. Retrieved 2010-11-27.^\"WW-EAP and Artificial Muscles\". Eap.jpl.nasa.gov. Archived from the original on 2017-01-20. Retrieved 2010-11-27.^\"Empa \u2013 a117-2-eap\". Empa.ch. Archived from the original on 2015-09-24. Retrieved 2010-11-27.^\"Electroactive Polymers (EAP) as Artificial Muscles (EPAM) for Robot Applications\". Hizook. Archived from the original on 2020-08-06. Retrieved 2010-11-27.^\"Piezo LEGS \u2013 -09-26\". Archived from the original on 2008-01-30. Retrieved 2007-10-28.^\"Squiggle Motors: Overview\". Archived from the original on 2007-10-07. Retrieved 2007-10-08.^Nishibori; et\u00a0al. (2003). \"Robot Hand with Fingers Using Vibration-Type Ultrasonic Motors (Driving Characteristics)\". Journal of Robotics and Mechatronics. 15 (6): 588\u2013595. doi:10.20965/jrm.2003.p0588.^Otake, Mihoko; Kagami, Yoshiharu; Ishikawa, Kohei; Inaba, Masayuki; Inoue, Hirochika (6 April 2001). Wilson, Alan R.; Asanuma, Hiroshi (eds.). \"Shape design of gel robots made of electroactive polymer gel\". Smart Materials. 4234: 194\u2013202. Bibcode:2001SPIE.4234..194O. doi:10.1117/12.424407. S2CID\u00a030357330.^Madden, John D. (16 November 2007). \"Mobile Robots: Motor Challenges and Materials Solutions\". Science. 318 (5853): 1094\u20131097. Bibcode:2007Sci...318.1094M. CiteSeerX\u00a010.1.1.395.4635. doi:10.1126/science.1146351. PMID\u00a018006737. S2CID\u00a052827127.^\"Syntouch LLC: BioTac(R) Biomimetic Tactile Sensor Array\". Archived from the original on 2009-10-03. Retrieved 2009-08-10.^Wettels, Nicholas; Santos, Veronica J.; Johansson, Roland S.; Loeb, Gerald E. (January 2008). \"Biomimetic Tactile Sensor Array\". Advanced Robotics. 22 (8): 829\u2013849. doi:10.1163/156855308X314533. S2CID\u00a04594917.^\"What is The SmartHand?\". SmartHand Project. Archived from the original on 2015-03-03. Retrieved 2011-02-04.^ abArreguin, Juan (2008). Automation and Robotics. Vienna, Austria: I-Tech and Publishing.^\"Annotated Mythbusters: Episode 78: Ninja Myths \u2013 Walking on Water, Catching a Sword, Catching an Arrow\". Archived from the original on 2020-11-12. Retrieved 2010-02-13. (Discovery Channel's Mythbusters making mechanical gripper from the chain and metal wire)^\"Robonaut hand\". Archived from the original on 2020-02-22. Retrieved 2011-11-21.^\"Delft hand\". TU Delft. Archived from the original on 2012-02-03. Retrieved 2011-11-21.^M&C. \"TU Delft ontwikkelt goedkope, voorzichtige robothand\". TU Delft. Archived from the original on 2017-03-13. Retrieved 2011-11-21.^\"astrictive definition \u2013 English definition dictionary \u2013 Reverso\". Archived from the original on 2020-04-30. Retrieved 2008-01-06.^Tijsma, H.A.; Liefhebber, F.; Herder, J.L. (2005). \"Evaluation of New User Interface Features for the MANUS Robot Arm\". 9th International Conference on Rehabilitation Robotics, 2005. ICORR 2005. pp.\u00a0258\u2013263. doi:10.1109/ICORR.2005.1501097. ISBN\u00a00-7803-9003-2. S2CID\u00a036445389.^Allcock, Andrew (2006). \"Anthropomorphic hand is almost human\". Machinery. Archived from the original on 2007-09-28. Retrieved 2007-10-17.^\"Welcome\". Archived(PDF) from the original on 2013-05-10. Retrieved 2007-10-28.^ abcCorke, Peter (2017). Robotics, Vision and Control. Springer Tracts in Advanced Robotics. Vol.\u00a0118. doi:10.1007/978-3-319-54413-7. ISBN\u00a0978-3-319-54412-0. ISSN\u00a01610-7438. Archived from the original on 2022-10-20. Retrieved 2023-03-15.^ abcLee, K. S. Fu, Ralph Gonzalez, C S. G. (1987). Robotics: Control Sensing. Vis. McGraw-Hill. ISBN\u00a0978-0-07-026510-3. Archived from the original on 2023-03-15. Retrieved 2023-03-15.{{cite book}}:  CS1 maint: multiple names: authors list (link)^ abcdShort, Michael; Burn, Kevin (1 April 2011). \"A generic controller architecture for intelligent robotic systems\". Robotics and Computer-Integrated Manufacturing. 27 (2): 292\u2013305. doi:10.1016/j.rcim.2010.07.013. ISSN\u00a00736-5845.^Ray, Partha Pratim (2016). \"Internet of Robotic Things: Concept, Technologies, and Challenges\". IEEE Access. 4: 9489\u20139500. Bibcode:2016IEEEA...4.9489R. doi:10.1109/ACCESS.2017.2647747. ISSN\u00a02169-3536. S2CID\u00a09273802.^ abBurn, K.; Short, M.; Bicker, R. (July 2003). \"Adaptive and Nonlinear Fuzzy Force Control Techniques Applied to Robots Operating in Uncertain Environments\". Journal of Robotic Systems. 20 (7): 391\u2013400. doi:10.1002/rob.10093. ISSN\u00a00741-2223. Archived from the original on 2022-11-26. Retrieved 2023-03-15.^Burn, Kevin; Home, Geoffrey (1 May 2008). \"Environment classification using Kohonen self-organizing maps\". Expert Systems. 25 (2): 98\u2013114. doi:10.1111/j.1468-0394.2008.00441.x. ISSN\u00a00266-4720. S2CID\u00a033369232.^Mason, Matthew T. (2001). Mechanics of Robotic Manipulation. doi:10.7551/mitpress/4527.001.0001. ISBN\u00a0978-0-262-25662-9. S2CID\u00a05260407.^\"What is a robotic end-effector?\". ATI Industrial Automation. 2007. Archived from the original on 2020-12-17. Retrieved 2007-10-16.^Crane, Carl D.; Joseph Duffy (1998). Kinematic Analysis of Robot Manipulators. Cambridge University Press. ISBN\u00a0978-0-521-57063-3. Archived from the original on 2020-04-02. Retrieved 2007-10-16.^G.J. Monkman, S. Hesse, R. Steinmann & H. Schunk (2007). Robot Grippers. Berlin: Wiley^\"T.O.B.B\". Mtoussaint.de. Archived from the original on 2020-07-08. Retrieved 2010-11-27.^\"nBot, a two wheel balancing robot\". Geology.heroy.smu.edu. Archived from the original on 2021-01-26. Retrieved 2010-11-27.^\"ROBONAUT Activity Report\". NASA. 2004. Archived from the original on 2007-08-20. Retrieved 2007-10-20.^Guizzo, Erico (29 April 2010). \"A Robot That Balances on a Ball\". IEEE Spectrum. Archived from the original on 2023-02-10. Retrieved 2023-03-15.^\"Carnegie Mellon Researchers Develop New Type of Mobile Robot That Balances and Moves on a Ball Instead of Legs or Wheels\" (Press release). Carnegie Mellon. 9 August 2006. Archived from the original on 2007-06-09. Retrieved 2007-10-20.^\"Spherical Robot Can Climb Over Obstacles\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27.^\"Rotundus\". Rotundus.se. Archived from the original on 2011-08-26. Retrieved 2010-11-27.^\"OrbSwarm Gets A Brain\". BotJunkie. 11 July 2007. Archived from the original on 2012-05-16. Retrieved 2010-11-27.^\"Rolling Orbital Bluetooth Operated Thing\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27.^\"Swarm\". Orbswarm.com. Archived from the original on 2021-01-26. Retrieved 2010-11-27.^\"The Ball Bot: Johnnytronic@Sun\". Blogs.sun.com. Archived from the original on 2011-08-24. Retrieved 2010-11-27.^\"Senior Design Projects | College of Engineering & Applied Science| University of Colorado at Boulder\". Engineering.colorado.edu. 30 April 2008. Archived from the original on 2011-07-23. Retrieved 2010-11-27.^\"JPL Robotics: System: Commercial Rovers\". Archived from the original on 2006-06-15.^\"AMBER Lab\". Archived from the original on 2020-11-25. Retrieved 2012-01-23.^\"Micromagic Systems Robotics Lab\". Archived from the original on 2017-06-01. Retrieved 2009-04-29.^\"AMRU-5 hexapod robot\"(PDF). Archived(PDF) from the original on 2016-08-17. Retrieved 2009-04-29.^\"Achieving Stable Walking\". Honda Worldwide. Archived from the original on 2011-11-08. Retrieved 2007-10-22.^\"Funny Walk\". Pooter Geek. 28 December 2004. Archived from the original on 2011-09-28. Retrieved 2007-10-22.^\"ASIMO's Pimp Shuffle\". Popular Science. 9 January 2007. Archived from the original on 2011-07-24. Retrieved 2007-10-22.^\"Robot Shows Prime Minister How to Loosen Up > > A drunk robot?\". The Temple of VTEC \u2013 Honda and Acura Enthusiasts Online Forums. 25 August 2003. Archived from the original on 2020-04-30.^\"3D One-Leg Hopper (1983\u20131984)\". MIT Leg Laboratory. Archived from the original on 2018-07-25. Retrieved 2007-10-22.^\"3D Biped (1989\u20131995)\". MIT Leg Laboratory. Archived from the original on 2011-09-26. Retrieved 2007-10-28.^\"Quadruped (1984\u20131987)\". MIT Leg Laboratory. Archived from the original on 2011-08-23. Retrieved 2007-10-28.^\"MIT Leg Lab Robots- Main\". Archived from the original on 2020-08-07. Retrieved 2007-10-28.^\"About the Robots\". Anybots. Archived from the original on 2007-09-09. Retrieved 2007-10-23.^\"Anything, Anytime, Anywhere\". Anybots. Archived from the original on 2007-10-27. Retrieved 2007-10-23.^\"Dexter Jumps video\". YouTube. 1 March 2007. Archived from the original on 2021-10-30. Retrieved 2007-10-23.^Collins, Steve; Ruina, Andy; Tedrake, Russ; Wisse, Martijn (18 February 2005). \"Efficient Bipedal Robots Based on Passive-Dynamic Walkers\". Science. 307 (5712): 1082\u20131085. Bibcode:2005Sci...307.1082C. doi:10.1126/science.1107799. PMID\u00a015718465. S2CID\u00a01315227.^Collins, S.H.; Ruina, A. (2005). \"A Bipedal Walking Robot with Efficient and Human-Like Gait\". Proceedings of the 2005 IEEE International Conference on Robotics and Automation. pp.\u00a01983\u20131988. doi:10.1109/ROBOT.2005.1570404. ISBN\u00a00-7803-8914-X. S2CID\u00a015145353.^\"Testing the Limits\"(PDF). Boeing. p.\u00a029. Archived(PDF) from the original on 2018-12-15. Retrieved 2008-04-09.^Zhang, Jun; Zhao, Ning; Qu, Feiyang (15 November 2022). \"Bio-inspired flapping wing robots with foldable or deformable wings: a review\". Bioinspiration & Biomimetics. 18 (1): 011002. doi:10.1088/1748-3190/ac9ef5. ISSN\u00a01748-3182. PMID\u00a036317380. S2CID\u00a0253246037.^ abcShin, Won Dong; Park, Jaejun; Park, Hae-Won (1 September 2019). \"Development and experiments of a bio-inspired robot with multi-mode in aerial and terrestrial locomotion\". Bioinspiration & Biomimetics. 14 (5): 056009. Bibcode:2019BiBi...14e6009S. doi:10.1088/1748-3190/ab2ab7. ISSN\u00a01748-3182. PMID\u00a031212268. S2CID\u00a0195066183.^Ramezani, Alireza; Shi, Xichen; Chung, Soon-Jo; Hutchinson, Seth (May 2016). \"Bat Bot (B2), a biologically inspired flying machine\". 2016 IEEE International Conference on Robotics and Automation (ICRA). Stockholm, Sweden: IEEE. pp.\u00a03219\u20133226. doi:10.1109/ICRA.2016.7487491. ISBN\u00a0978-1-4673-8026-3. S2CID\u00a08581750.^ abDaler, Ludovic; Mintchev, Stefano; Stefanini, Cesare; Floreano, Dario (19 January 2015). \"A bioinspired multi-modal flying and walking robot\". Bioinspiration & Biomimetics. 10 (1) 016005. Bibcode:2015BiBi...10a6005D. doi:10.1088/1748-3190/10/1/016005. ISSN\u00a01748-3190. PMID\u00a025599118. S2CID\u00a011132948.^ abKilian, Lukas; Shahid, Farzeen; Zhao, Jing-Shan; Nayeri, Christian Navid (1 July 2022). \"Bioinspired morphing wings: mechanical design and wind tunnel experiments\". Bioinspiration & Biomimetics. 17 (4): 046019. Bibcode:2022BiBi...17d6019K. doi:10.1088/1748-3190/ac72e1. ISSN\u00a01748-3182. PMID\u00a035609562. S2CID\u00a0249045806.^Savastano, E.; Perez-Sanchez, V.; Arrue, B.C.; Ollero, A. (July 2022). \"High-Performance Morphing Wing for Large-Scale Bio-Inspired Unmanned Aerial Vehicles\". IEEE Robotics and Automation Letters. 7 (3): 8076\u20138083. Bibcode:2022IRAL....7.8076S. doi:10.1109/LRA.2022.3185389. ISSN\u00a02377-3766. S2CID\u00a0250008824.^Grant, Daniel T.; Abdulrahim, Mujahid; Lind, Rick (June 2010). \"Flight Dynamics of a Morphing Aircraft Utilizing Independent Multiple-Joint Wing Sweep\". International Journal of Micro Air Vehicles. 2 (2): 91\u2013106. doi:10.1260/1756-8293.2.2.91. ISSN\u00a01756-8293. S2CID\u00a0110577545.^Phan, Hoang Vu; Park, Hoon Cheol (4 December 2020). \"Mechanisms of collision recovery in flying beetles and flapping-wing robots\". Science. 370 (6521): 1214\u20131219. Bibcode:2020Sci...370.1214P. doi:10.1126/science.abd3285. ISSN\u00a00036-8075. PMID\u00a033273101. S2CID\u00a0227257247.^Hu, Zheng; McCauley, Raymond; Schaeffer, Steve; Deng, Xinyan (May 2009). \"Aerodynamics of dragonfly flight and robotic design\". 2009 IEEE International Conference on Robotics and Automation. pp.\u00a03061\u20133066. doi:10.1109/ROBOT.2009.5152760. ISBN\u00a0978-1-4244-2788-8. S2CID\u00a012291429.^Balta, Miquel; Deb, Dipan; Taha, Haithem E (26 October 2021). \"Flow visualization and force measurement of the clapping effect in bio-inspired flying robots\". Bioinspiration & Biomimetics. 16 (6): 066020. Bibcode:2021BiBi...16f6020B. doi:10.1088/1748-3190/ac2b00. ISSN\u00a01748-3182. PMID\u00a034584023. S2CID\u00a0238217893.^Miller, Gavin. \"Introduction\". snakerobots.com. Archived from the original on 2011-08-17. Retrieved 2007-10-22.^\"ACM-R5\". Archived from the original on 2011-10-11.^\"Swimming snake robot (commentary in Japanese)\". Archived from the original on 2012-02-08. Retrieved 2007-10-28.^\"Commercialized Quadruped Walking Vehicle \"TITAN VII\"\". Hirose Fukushima Robotics Lab. Archived from the original on 2007-11-06. Retrieved 2007-10-23.^Pachal, Peter (23 January 2007). \"Plen, the robot that skates across your desk\". SCI FI Tech. Archived from the original on 2007-10-11.^Capuchin on YouTube^Wallbot on YouTube^Stanford University: Stickybot on YouTube^Sfakiotakis, M.; Lane, D.M.; Davies, J.B.C. (April 1999). \"Review of fish swimming modes for aquatic locomotion\". IEEE Journal of Oceanic Engineering. 24 (2): 237\u2013252. Bibcode:1999IJOE...24..237S. CiteSeerX\u00a010.1.1.459.8614. doi:10.1109/48.757275. S2CID\u00a017226211.^Richard Mason. \"What is the market for robot fish?\". Archived from the original on 2009-07-04.^\"Robotic fish powered by Gumstix PC and PIC\". Human Centred Robotics Group at Essex University. Archived from the original on 2011-08-14. Retrieved 2007-10-25.^Witoon Juwarahawong. \"Fish Robot\". Institute of Field Robotics. Archived from the original on 2007-11-04. Retrieved 2007-10-25.^\"Festo - AquaPenguin\". 17 April 2009 \u2013 via YouTube.^\"High-Speed Robotic Fish\". iSplash-Robotics. Archived from the original on 2020-03-11. Retrieved 2017-01-07.^\"iSplash-II: Realizing Fast Carangiform Swimming to Outperform a Real Fish\"(PDF). Robotics Group at Essex University. Archived from the original(PDF) on 2015-09-30. Retrieved 2015-09-29.^\"iSplash-I: High Performance Swimming Motion of a Carangiform Robotic Fish with Full-Body Coordination\"(PDF). Robotics Group at Essex University. Archived from the original(PDF) on 2015-09-30. Retrieved 2015-09-29.^Jaulin, Luc; Le Bars, Fabrice (February 2013). \"An Interval Approach for Stability Analysis: Application to Sailboat Robotics\". IEEE Transactions on Robotics. 29 (1): 282\u2013287. Bibcode:2013ITRob..29..282J. CiteSeerX\u00a010.1.1.711.7180. doi:10.1109/TRO.2012.2217794. S2CID\u00a04977937.^\"A Ping-Pong-Playing Terminator\". Popular Science. Archived from the original on 2021-01-22. Retrieved 2010-12-19.^\"Synthiam Exosphere combines AI, human operators to train robots\". The Robot Report. Archived from the original on 2020-10-06. Retrieved 2020-04-29.^ abKagan, Eugene; Ben-Gal, Irad (2015). Search and foraging:individual motion and swarm dynamics. Chapman and Hall/CRC. ISBN\u00a0978-1-4822-4210-2. Archived from the original on 2023-03-15. Retrieved 2020-08-26.^Banks, Jaime (2020). \"Optimus Primed: Media Cultivation of Robot Mental Models and Social Judgments\". Frontiers in Robotics and AI. 7 62. doi:10.3389/frobt.2020.00062. PMC\u00a07805817. PMID\u00a033501230.^ abWullenkord, Ricarda; Fraune, Marlena R.; Eyssel, Friederike; Sabanovic, Selma (2016). \"Getting in Touch: How imagined, actual, and physical contact affect evaluations of robots\". 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). pp.\u00a0980\u2013985. doi:10.1109/ROMAN.2016.7745228. ISBN\u00a0978-1-5090-3929-6. S2CID\u00a06305599.^Norberto Pires, J. (December 2005). \"Robot-by-voice: experiments on commanding an industrial robot using the human voice\". Industrial Robot. 32 (6): 505\u2013511. doi:10.1108/01439910510629244.^\"Survey of the State of the Art in Human Language Technology: 1.2: Speech Recognition\". Archived from the original on 2007-11-11.^Fournier, Randolph Scott; Schmidt, B. June (1995). \"Voice input technology: Learning style and attitude toward its use\". Delta Pi Epsilon Journal. 37 (1): 1\u201312. ProQuest\u00a01297783046.^\"History of Speech & Voice Recognition and Transcription Software\". Dragon Naturally Speaking. Archived from the original on 2015-08-13. Retrieved 2007-10-27.^Cheng Lin, Kuan; Huang, Tien-Chi; Hung, Jason C.; Yen, Neil Y.; Ju Chen, Szu (7 June 2013). \"Facial emotion recognition towards affective computing-based learning\". Library Hi Tech. 31 (2): 294\u2013307. doi:10.1108/07378831311329068.^Walters, M. L.; Syrdal, D. S.; Koay, K. L.; Dautenhahn, K.; Te Boekhorst, R. (2008). \"Human approach distances to a mechanical-looking robot with different robot voice styles\". RO-MAN 2008 - the 17th IEEE International Symposium on Robot and Human Interactive Communication. pp.\u00a0707\u2013712. doi:10.1109/ROMAN.2008.4600750. ISBN\u00a0978-1-4244-2212-8. S2CID\u00a08653718.^Pauletto, Sandra; Bowles, Tristan (2010). \"Designing the emotional content of a robotic speech signal\". Proceedings of the 5th Audio Mostly Conference on a Conference on Interaction with Sound - AM '10. pp.\u00a01\u20138. doi:10.1145/1859799.1859804. ISBN\u00a0978-1-4503-0046-9. S2CID\u00a030423778.^Bowles, Tristan; Pauletto, Sandra (2010). Emotions in the Voice: Humanising a Robotic Voice(PDF). Proceedings of the 7th Sound and Music Computing Conference. Barcelona. Archived(PDF) from the original on 2023-02-10. Retrieved 2023-03-15.^\"World of 2-XL: Leachim\". www.2xlrobot.com. Archived from the original on 2020-07-05. Retrieved 2019-05-28.^\"The Boston Globe from Boston, Massachusetts on June 23, 1974 \u00b7 132\". Newspapers.com. 23 June 1974. Archived from the original on 2020-01-10. Retrieved 2019-05-28.^ ab\"cyberneticzoo.com - Page 135 of 194 - a history of cybernetic animals and early robots\". cyberneticzoo.com. Archived from the original on 2020-08-06. Retrieved 2019-05-28.^\"Frubber facial expressions\". Archived from the original on 2009-02-07.^\"Best Inventions of 2008 \u2013 TIME\". Time. 29 October 2008. Archived from the original on 2008-11-02 \u2013 via www.time.com.^\"Kismet: Robot at MIT's AI Lab Interacts With Humans\". Sam Ogden. Archived from the original on 2007-10-12. Retrieved 2007-10-28.^Waldherr, Stefan; Romero, Roseli; Thrun, Sebastian (1 September 2000). \"A Gesture Based Interface for Human-Robot Interaction\". Autonomous Robots. 9 (2): 151\u2013173. doi:10.1023/A:1008918401478. S2CID\u00a01980239.^Li, Ling Hua; Du, Ji Fang (December 2012). \"Visual Based Hand Gesture Recognition Systems\". Applied Mechanics and Materials. 263\u2013266: 2422\u20132425. Bibcode:2012AMM...263.2422L. doi:10.4028/www.scientific.net/AMM.263-266.2422. S2CID\u00a062744240.^\"Armenian Robin the Robot to comfort kids at U.S. clinics starting July\". Public Radio of Armenia. Archived from the original on 2021-05-13. Retrieved 2021-05-13.^Park, S.; Sharlin, Ehud; Kitamura, Y.; Lau, E. (29 April 2005). Synthetic Personality in Robots and its Effect on Human-Robot Relationship (Report). doi:10.11575/PRISM/31041. hdl:1880/45619.^\"Robot Receptionist Dishes Directions and Attitude\". NPR.org. Archived from the original on 2020-12-01. Retrieved 2018-04-05.^\"New Scientist: A good robot has personality but not looks\"(PDF). Archived from the original(PDF) on 2006-09-29.^\"Playtime with Pleo, your robotic dinosaur friend\". 25 September 2008. Archived from the original on 2019-01-20. Retrieved 2014-12-14.^NOVA conversation with Professor Moravec, October 1997. NOVA OnlineArchived 2017-08-02 at the Wayback Machine^Agarwal, P.K. Elements of Physics XI. Rastogi Publications. p.\u00a02. ISBN\u00a0978-81-7133-911-2.^Sandhana, Lakshmi (5 September 2002). \"A Theory of Evolution, for Robots\". Wired. Archived from the original on 2014-03-29. Retrieved 2007-10-28.^\"Experimental Evolution In Robots Probes The Emergence Of Biological Communication\". Science Daily. 24 February 2007. Archived from the original on 2018-11-16. Retrieved 2007-10-28.^\u017dlajpah, Leon (15 December 2008). \"Simulation in robotics\". Mathematics and Computers in Simulation. 79 (4): 879\u2013897. doi:10.1016/j.matcom.2008.02.017.^\"Evolution trains robot teams TRN 051904\". Technology Research News. Archived from the original on 2016-06-23. Retrieved 2009-01-22.^M\u00fcller, Christopher (2023). World Robotics 2023 \u2013 Industrial Robots. Frankfurt, Germany: IFR Statistical Department, VDMA Services GmbH.^Tandon, Prateek (2017). Quantum Robotics. Morgan & Claypool Publishers. ISBN\u00a0978-1-62705-913-8.^Dragani, Rachelle (8 November 2018). \"Can a robot make you a 'superworker'?\". Verizon Communications. Archived from the original on 2020-08-06. Retrieved 2018-12-03.^\"Robotics\". American Elements. Retrieved 2023-04-10.^\"Career: Robotics Engineer\". Princeton Review. 2012. Archived from the original on 2015-01-21. Retrieved 2012-01-27.^Saad, Ashraf; Kroutil, Ryan (2012). Hands-on Learning of Programming Concepts Using Robotics for Middle and High School Students. Proceedings of the 50th Annual Southeast Regional Conference of the Association for Computing Machinery. ACM. pp.\u00a0361\u2013362. doi:10.1145/2184512.2184605.^Toy, Tommy (29 June 2011). \"Outlook for robotics and Automation for 2011 and beyond are excellent says expert\". PBT Consulting. Archived from the original on 2012-01-27. Retrieved 2012-01-27.^Frey, Carl Benedikt; Osborne, Michael A. (January 2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254\u2013280. CiteSeerX\u00a010.1.1.395.416. doi:10.1016/j.techfore.2016.08.019.^McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID\u00a0243172487. SSRN\u00a03044448.^Hawking, Stephen (1 January 2016). \"This is the most dangerous time for our planet\". The Guardian. Archived from the original on 2021-01-31. Retrieved 2019-11-22.^\"Robotics \u2013 Thematic Research\". GlobalData. Archived from the original on 2021-09-28. Retrieved 2021-09-22.^\"Focal Points Seminar on review articles in the future of work \u2013 Safety and health at work \u2013 EU-OSHA\". osha.europa.eu. Archived from the original on 2020-01-25. Retrieved 2016-04-19.^\"Robotics: Redefining crime prevention, public safety and security\". SourceSecurity.com. Archived from the original on 2017-10-09. Retrieved 2016-09-16.^\"Draft Standard for Intelligent Assist Devices \u2014 Personnel Safety Requirements\"(PDF). Archived(PDF) from the original on 2020-11-25. Retrieved 2016-06-01.^\"ISO/TS 15066:2016 \u2013 Robots and robotic devices \u2013 Collaborative robots\". 8 March 2016. Archived from the original on 2016-10-10. Retrieved 2016-06-01.^Brog\u00e5rdh, Torgny (January 2007). \"Present and future robot control development\u2014An industrial perspective\". Annual Reviews in Control. 31 (1): 69\u201379. doi:10.1016/j.arcontrol.2007.01.002. ISSN\u00a01367-5788.^Wang, Tian-Miao; Tao, Yong; Liu, Hui (17 April 2018). \"Current Researches and Future Development Trend of Intelligent Robot: A Review\". International Journal of Automation and Computing. 15 (5): 525\u2013546. doi:10.1007/s11633-018-1115-1. ISSN\u00a01476-8186. S2CID\u00a0126037910.^Needham, Joseph (1991). Science and Civilisation in China: Volume 2, History of Scientific Thought. Cambridge University Press. ISBN\u00a0978-0-521-05800-1.^Fowler, Charles B. (October 1967). \"The Museum of Music: A History of Mechanical Instruments\". Music Educators Journal. 54 (2): 45\u201349. doi:10.2307/3391092. JSTOR\u00a03391092. S2CID\u00a0190524140.^Rosheim, Mark E. (1994). Robot Evolution: The Development of Anthrobotics. Wiley-IEEE. pp.\u00a09\u201310. ISBN\u00a0978-0-471-02622-8.^al-Jazari (Islamic artist)Archived 2008-05-07 at the Wayback Machine, Encyclop\u00e6dia Britannica.^A. P. Yuste. Electrical Engineering Hall of Fame. Early Developments of Wireless Remote Control: The Telekino of Torres-Quevedo,(pdf) vol. 96, No. 1, January 2008, Proceedings of the IEEE.^H. R. Everett (2015). Unmanned Systems of World Wars I and II. MIT Press. pp.\u00a091\u201395. ISBN\u00a0978-0-262-02922-3.^Randy Alfred, \"Nov. 7, 1905: Remote Control Wows Public\", Wired, 7 November 2011.^Williams, Andrew (16 March 2017). History of Digital Games: Developments in Art, Design and Interaction. CRC Press. ISBN\u00a0978-1-317-50381-1.^Randell, Brian (October 1982). \"From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush\". IEEE Annals of the History of Computing. 4 (4): 327\u2013341. doi:10.1109/MAHC.1982.10042. S2CID\u00a01737953.^L. Torres Quevedo. Ensayos sobre Autom\u00e1tica - Su definicion. Extension te\u00f3rica de sus aplicaciones, Revista de la Academia de Ciencias Exacta, Revista 12, pp.391-418, 1914.^Torres Quevedo, Leonardo. Autom\u00e1tica: Complemento de la Teor\u00eda de las M\u00e1quinas, (pdf), pp. 575-583, Revista de Obras P\u00fablicas, 19 November 1914.^L. Torres Quevedo. Essais sur l'Automatique - Sa d\u00e9finition. Etendue th\u00e9orique de ses applicationsArchived 2023-02-10 at the Wayback Machine, Revue G\u00e9nerale des Sciences Pures et Appliqu\u00e9es, vol.2, pp.601-611, 1915.^B. Randell. Essays on Automatics, The Origins of Digital Computers, pp.89-107, 1982.^PhD, Renato M.E. Sabbatini. \"Sabbatini, RME: An Imitation of Life: The First Robots\". Archived from the original on 2009-07-20. Retrieved 2023-03-15.^Waurzyniak, Patrick (2006). \"Masters of Manufacturing: Joseph F. Engelberger\". Society of Manufacturing Engineers. 137 (1). Archived from the original on 2011-11-09.^\"Humanoid History -WABOT-\". www.humanoid.waseda.ac.jp. Archived from the original on 2017-09-01. Retrieved 2017-05-06.^Zeghloul, Sa\u00efd; Laribi, Med Amine; Gazeau, Jean-Pierre (21 September 2015). Robotics and Mechatronics: Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics. Springer. ISBN\u00a0978-3-319-22368-1. Archived from the original on 2023-03-15. Retrieved 2017-09-10 \u2013 via Google Books.^\"Historical Android Projects\". androidworld.com. Archived from the original on 2005-11-25. Retrieved 2017-05-06.^Robots: From Science Fiction to Technological RevolutionArchived 2023-03-15 at the Wayback Machine, page 130^Duffy, Vincent G. (19 April 2016). Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering. CRC Press. ISBN\u00a0978-1-4200-6352-3. Archived from the original on 2023-03-15. Retrieved 2017-09-10 \u2013 via Google Books.^\"KUKA Industrial Robot FAMULUS\". Archived from the original on 2009-02-20. Retrieved 2008-01-10.^\"History of Industrial Robots\"(PDF). Archived from the original(PDF) on 2012-12-24. Retrieved 2012-10-27.^R. J. Popplestone; A. P. Ambler; I. Bellos (1978). \"RAPT: A language for describing assemblies\". Industrial Robot. 5 (3): 131\u2013137. doi:10.1108/eb004501.^Bozinovski, S. (1994). \"Parallel programming for mobile robot control: Agent-based approach\". 14th International Conference on Distributed Computing Systems. pp.\u00a0202\u2013208. doi:10.1109/ICDCS.1994.302412. ISBN\u00a00-8186-5840-1. S2CID\u00a027855786.Further reading[edit]R. Andrew Russell (1990). Robot Tactile Sensing. New York: Prentice Hall. ISBN\u00a0978-0-13-781592-0.McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID\u00a0243172487. SSRN\u00a03044448.Autor, David H. (1 August 2015). \"Why Are There Still So Many Jobs? The History and Future of Workplace Automation\". Journal of Economic Perspectives. 29 (3): 3\u201330. doi:10.1257/jep.29.3.3. hdl:1721.1/109476.Tooze, Adam (6 June 2019). \"Democracy and Its Discontents\". The New York Review of Books. Vol.\u00a066, no.\u00a010.External links[edit].mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}.mw-parser-output .sister-box .side-box-abovebelow{padding:0.75em 0;text-align:center}.mw-parser-output .sister-box .side-box-abovebelow>b{display:block}.mw-parser-output .sister-box .side-box-text>ul{border-top:1px solid #aaa;padding:0.75em 0;width:220px;margin:0 auto}.mw-parser-output .sister-box .side-box-text>ul>li{min-height:31px}.mw-parser-output .sister-logo{display:inline-block;width:31px;line-height:31px;vertical-align:middle;text-align:center}.mw-parser-output .sister-link{display:inline-block;margin-left:7px;width:182px;vertical-align:middle}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Robotics  at Wikipedia's sister projectsDefinitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from WikiversityIEEE Robotics and Automation SocietyInvestigation of social robots \u2013 Robots that mimic human behaviors and gestures.Wired's guide to the '50 best robots ever', a mix of robots in fiction (Hal, R2D2, K9) to real robots (Roomba, Mobot, Aibo)..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutlinevteEngineeringHistoryOutlineList of engineering branchesSpecialtiesandinterdisciplinarityCivilArchitecturalCoastalConstructionEarthquakeEcologicalEnvironmentalSanitaryGeologicalGeotechnicalHydraulicMiningMunicipal/urbanOffshoreRiverStructuralTransportationTrafficRailwayMechanicalAcousticAerospaceAutomotiveBiomechanicalEnergyManufacturingMarineNaval architectureRailwaySportsThermalTribologyElectricalBroadcastoutlineControlElectromechanicsElectronicsMicrowavesOpticalPowerRadio-frequencySignal processingTelecommunicationsChemicalBiochemical/bioprocessBiologicalBioresourceGeneticTissueChemical reactionElectrochemicalFoodMolecularPaperPetroleumProcessReactionMaterialsBiomaterialCeramicsCorrosionMetallurgyMolecularNanotechnologyPolymersSemiconductorsSurfacesComputerAIComputerCybersecurityDataNetworksRoboticsSoftwareEngineering educationBachelor of EngineeringBachelor of ScienceMaster's degreeDoctorateGraduate certificateEngineer's degreeLicensed engineerRelated topicsEngineerGlossariesEngineering\nA\u2013LM\u2013ZAerospace engineeringCivil engineeringElectrical and electronics engineeringMechanical engineeringStructural engineeringOtherAgriculturalAudioAutomationBiomedicalBioinformaticsClinicalHealth technologyPharmaceuticalRehabilitationBuilding servicesMEPDesignExplosivesFacilitiesFireForensicClimateGeomaticsGraphicsIndustrialInformationInstrumentationInstrumentation and controlLogisticsManagementMathematicsMechatronicsMilitaryNuclearOntologyPackagingPhysicsPrivacySafetySecuritySurveySustainabilitySystemsTextileCategoryCommonsWikiprojectPortalvteEmerging technologiesFieldsManufacturing3D microfabrication3D printing3D publishingClaytronicsMolecular assemblerSmart manufacturingUtility fogMaterials scienceAerogelAmorphous metalArtificial muscleConductive polymerFemtotechnologyFullereneGrapheneHigh-temperature superconductivityHigh-temperature superfluidityLinear acetylenic carbonMetamaterialsMetamaterial cloakingMetal foamMulti-function structuresNanotechnologyCarbon nanotubesMolecular nanotechnologyNanomaterialsPicotechnologyProgrammable matterQuantum dotsSiliceneSynthetic diamondRoboticsDomoticsNanoroboticsPowered exoskeletonSelf-reconfiguring modular robotSwarm roboticsUncrewed vehicleTopicsAutomationCollingridge dilemmaDifferential technological developmentDisruptive innovationEphemeralizationEthicsAIBioethicsCyberethicsNeuroethicsRobot ethicsExploratory engineeringProactionary principleTechnological changeTechnological unemploymentTechnological convergenceTechnological evolutionTechnological paradigmTechnology forecastingAccelerating changeFuture-oriented technology analysisHorizon scanningMoore's lawTechnological singularityTechnology scoutingTechnology in science fictionTechnology readiness levelTechnology roadmapTranshumanismListvteGlossaries of science and engineeringAerospace engineeringAgricultureArchaeologyArchitectureArtificial intelligenceAstronomyBiologyBotanyCalculusCell biologyCellular and molecular biology\n0\u2013LM\u2013ZChemistryCivil engineeringClinical researchComputer hardwareComputer scienceDevelopmental and reproductive biologyEcologyEconomicsElectrical and electronics engineeringEngineering\nA\u2013LM\u2013ZEntomologyEnvironmental scienceGenetics and evolutionary biologyGeography\nA\u2013MN\u2013ZArabic toponymsHebrew toponymsWestern and South AsiaGeologyIchthyologyMachine visionMathematicsMechanical engineeringMedicineMeteorologyMycologyNanotechnologyOrnithologyPhysicsProbability and statisticsPsychiatryQuantum computingRoboticsScientific namingStructural engineeringVirology.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDNationalUnited StatesFranceBnF dataCzech RepublicSpainIsraelOtherNARAYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robotics&oldid=1319748071\"", "tags": ["en.wikipedia.org", "wiki", "robotics"]}
{"url": "https://en.wikipedia.org/wiki/Robot", "title": null, "text": "Machine capable of carrying out a complex series of actions automatically.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For other uses, see Robot (disambiguation).\n\nASIMO (2000) at the Expo 2005\"Number 5\" from Short Circuit (1986 film) is a specimen of tracked semi-humanoid robotArticulatedwelding robots used in a factory are a type of industrial robot.The quadrupedalmilitary robotCheetah, an evolution of BigDog (pictured), was clocked as the world's fastest legged robot in 2012, beating the record set by an MITbipedal robot in 1989.[1].mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onAutomationAutomation in generalBankingBuildingHomeHighway systemLaboratoryLibraryBroadcastMixPool cleanerPop musicReasoningSemi-automationTelephone\nAttendantSwitchboardTeller machineVehicularVending machineRobotics and robotsDomesticVacuum cleanerRoombaLawn mowerGuided vehicleIndustrialPaintODD\nImpact of automationManumationOOLBiasSelf-driving carsTechnological unemploymentJobless recoveryPost-work societyThreat\nTrade shows and awardsASP-DACDACDATEIEEE Robotics and Automation AwardICCAD.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteA robot is a machine\u2014especially one programmable by a computer\u2014capable of carrying out a complex series of actions automatically.[2] A robot can be guided by an external control device, or the control may be embedded within. Robots may be constructed to evoke human form, but most robots are task-performing machines, designed with an emphasis on stark functionality, rather than expressive aesthetics.\nRobots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical operating robots, patient assist robots, dog therapy robots, collectively programmed swarm robots, UAV drones such as General Atomics MQ-1 Predator, and even microscopic nanorobots. By mimicking a lifelike appearance or automating movements, a robot may convey a sense of intelligence or thought of its own. Autonomous things are expected to proliferate in the future, with home robotics and the autonomous car as some of the main drivers.[3]The branch of technology that deals with the design, construction, operation, and application of robots,[4] as well as computer systems for their control, sensory feedback, and information processing is robotics. These technologies deal with automated machines that can take the place of humans in dangerous environments or manufacturing processes, or resemble humans in appearance, behavior, or cognition. Many of today's robots are inspired by nature contributing to the field of bio-inspired robotics. These robots have also created a newer branch of robotics: soft robotics.\nFrom the time of ancient civilization, there have been many accounts of user-configurable automated devices and even automata, resembling humans and other animals, such as animatronics, designed primarily as entertainment. As mechanical techniques developed through the Industrial age, there appeared more practical applications such as automated machines, remote control and wireless remote-control.\nThe term comes from a Slavic root, robot-, with meanings associated with labor. The word \"robot\" was first used to denote a fictional humanoid in a 1920 Czech-language play R.U.R. (Rossumovi Univerz\u00e1ln\u00ed Roboti \u2013 Rossum's Universal Robots) by Karel \u010capek, though it was Karel's brother Josef \u010capek who was the word's true inventor.[5][6][7] Electronics evolved into the driving force of development with the advent of the first electronic autonomous robots created by William Grey Walter in Bristol, England, in 1948, as well as Computer Numerical Control (CNC) machine tools in the late 1940s by John T. Parsons and Frank L. Stulen.\nThe first commercial, digital and programmable robot was built by George Devol in 1954 and was named the Unimate. It was sold to General Motors in 1961, where it was used to lift pieces of hot metal from die casting machines at the Inland Fisher Guide Plant in the West Trenton section of Ewing Township, New Jersey.[8]Robots have replaced humans[9] in performing repetitive and dangerous tasks which humans prefer not to do, or are unable to do because of size limitations, or which take place in extreme environments such as outer space or the bottom of the sea. There are concerns about the increasing use of robots and their role in society. Robots are blamed for rising technological unemployment as they replace workers in increasing number of functions.[10] The use of robots in military combat raises ethical concerns. The possibilities of robot autonomy and potential repercussions have been addressed in fiction and may be a realistic concern in the future.\n.mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}SummaryiCub is physically anthropomorphic; it looks like a human.There is no consensus on which machines qualify as robots but there is general agreement among experts, and the public, that robots tend to possess some or all of the following abilities and functions: accept electronic programming, process data or physical perceptions electronically, operate autonomously to some degree, move around, operate physical parts of itself or physical processes, sense and manipulate their environment, and exhibit intelligent behavior, especially behavior which mimics humans or other animals.[11][12]The word robot can refer to both physical robots and virtualsoftware agents, but the latter are usually referred to as bots.[13] Related to the concept of a robot is the field of synthetic biology, which studies entities whose nature is more comparable to living things than to machines.\nSimpler automated machines are called automatons, like animatronics, often made to resemble humans or animals. Humanoid robots that resemble humans esthetically, possibly even  organically, are called androids, while android can be shortened to droid, referring to robots with a broader likeness. On the other hand, a human that is augmented with artificial machines is called a cyborg, which is a particular type of transhuman.\nHistoryMain article: History of robotsA hypothetical reconstruction of Philo's automatic robot servant (3rd century BCE) in the Kotsanas Museum of Ancient Greek Technology, Athens, GreeceSu Song's astronomical clock tower showing the mechanical figurines which chimed the hoursal-Jazari's musical toy, from the 13th century Book of Knowledge of Ingenious Mechanical DevicesModel of Leonardo's robot with inner workings. Possibly constructed by Leonardo da Vinci around 1495.[14]The Brennan torpedo, one of the earliest 'guided missiles'William H. Richards with \"George\", 1932Early beginningsMany ancient cultures described artificial people in their writings. Examples from Greek mythology include Galatea (the mythical statue carved by Pygmalion that came to life), Talos (a man of bronze who guarded Crete from pirates), and the mechanical servants built by the Greek god Hephaestus.[15] Giants made of stone or clay are found in Jewish and Norse mythology.\nDuring classical antiquity, Greek engineers contributed many innovations. For example, in the 4th century BCE, Archytas described a steam-operated mechanical bird he called \"The Pigeon\",[16] while Ctesibius improved the clepsydra and produced the first hydraulus several decades later.[17]:\u200a2\u200a[18]Philo of Byzantium described a washstand automaton. Hero of Alexandria(10\u201370 AD) created numerous user-configurable automated devices and described machines powered by pneumatics, hydraulics, and steam, even including a \"speaking\" automaton.[19] Greek engineers also built the Antikythera mechanism \u2014 the oldest known example of an analog computer \u2014 during this period.[20][21]Ancient Chinese texts described automata, some of which were capable of flight. For example, the Han Feizi reports that 5th century BCE Mohist philosopher Mozi and his contemporary Lu Ban built artificial wooden birds that could fly. The Liezi (attributed to Lie Yukou, a 4th-century BCE Chinese philosopher) describes humanoid automata.[22] In 1066, Chinese inventor Su Song built a water clock in the form of a tower which featured mechanical figurines that chimed the hours.[23][24][25] His mechanism had a programmable drum machine with pegs that bumped into little levers that operated percussion instruments. The drummer could be programmed to play different drum patterns by moving the pegs to different locations.[25]11th century texts of Buddhist mythology also describe automata. Examples include the Samarangana Sutradhara, a treatise by Bhoja (king of Malwa) which includes a chapter about the construction of mechanical automata, including mechanical bees and birds, fountains shaped like humans and animals, and male and female dolls that refilled oil lamps, danced, played instruments, and re-enacted scenes from Hindu mythology.[26][27][28] The Lokapannatti is an 11th-12th century Buddhist cosmological text that tells of how the Buddha's relics were protected by mechanical robots (bhuta vahana yanta or \"spirit movement machines\") until they were disarmed by King Ashoka.[29]Ismail al-Jazari was a 13th-century polymath who built several automated devices driven by hydropower, including peacocks,[30] automatic gates,[31] and water clocks.[32] Among his humanoid automata was a waitress that could serve drinks. The drink was stored in a reservoir tank, from where it would drip into a bucket and then a cup, after which the waitress would appear out of an automatic door to serve the drink.[33] Al-Jazari also invented a hand washing automaton that incorporated a flush mechanism similar to that used in modern flush toilets. The automaton stood next to a basin filled with water. When the user pulled a lever, the water would drain and the automaton would refill the basin.[17]In 1377, the coronation of Richard II of England featured an automaton angel.[34] Around 1495, Leonardo da Vinci sketched plans for a mechanical humanoid robot that was able to sit up, wave its arms and move its head and jaw.[35] The design was probably based on anatomical research recorded in his Vitruvian Man. Da Vinci may have been influenced by the automata of al-Jazari.[30]In Japan, complex automata were built between the 17th to 19th centuries, with many described in the 1796 Karakuri zui (Illustrated Machinery). One such automaton was the karakuri ningy\u014d.[36] Different variations of the karakuri existed: the butai karakuri, which were used in theatre, the zashiki karakuri, which were small and used in homes, and the dashi karakuri which were used in religious festivals, where the puppets were used to perform reenactments of traditional myths and legends.\nIn France, between 1738 and 1739, Jacques de Vaucanson exhibited several automatons: a flute player, a pipe player and a duck. The duck could flap its wings, crane its neck, swallow food from the exhibitor's hand, and it gave the illusion of digesting its food by excreting matter stored in a hidden compartment.[37] About 30 years later in Switzerland, Pierre Jaquet-Droz made several mechanical figures that could write and play music. Several of these devices still exist and work.[38]Remote-controlled systemsRemotely operated vehicles were demonstrated in the late 19th century in the form of several types of remotely controlled torpedoes. The early 1870s saw remotely controlled torpedoes by John Ericsson, John Louis Lay, and Victor von Scheliha.[39]The Brennan torpedo, invented by Louis Brennan in 1877, was powered by two contra-rotating propellers that were spun by rapidly pulling out wires from drums wound inside the torpedo. Differential speed on the wires connected to the shore station allowed the torpedo to be guided to its target, making it \"the world's first practicalguided missile\".[40] In 1897 the British inventor Ernest Wilson was granted a patent for a torpedo remotely controlled by \"Hertzian\" (radio) waves[41][42] and in 1898 Nikola Tesla publicly demonstrated a wireless-controlled torpedo that he hoped to sell to the US Navy.[43][44]In 1903, the Spanish engineer Leonardo Torres Quevedo demonstrated a radio control system called Telekino at the Paris Academy of Sciences,[45] which he wanted to use to control an airship of his own design. He obtained several patents for the system in other countries.[46][47] Unlike previous 'on/off' techniques, Torres established a method for controlling any mechanical or electrical device with different states of operation.[48] The Telekino remotely controlled a tricycle in 1904, considered the first case of an unmanned ground vehicle, and an electric boat with a crew in 1906, which was controlled at a distance over 2\u00a0km.[49]Archibald Low, known as the \"father of radio guidance systems\" for his pioneering work on guided rockets and planes during the First World War. In 1917, he demonstrated a remote controlled aircraft to the Royal Flying Corps and in the same year built the first wire-guided rocket.\nEarly robotsIn 1928, one of the first humanoid robots, Eric, was exhibited at the annual exhibition of the Model Engineers Society in London, where it delivered a speech. Invented by W. H. Richards, the robot's frame consisted of an aluminium body of armour with eleven electromagnets and one motor powered by a twelve-volt power source. The robot could move its hands and head and could be controlled through remote control or voice control.[50] Both Eric and his \"brother\" George toured the world.[51]Westinghouse Electric Corporation built Televox in 1926; it was a cardboard cutout connected to various devices which users could turn on and off. In 1939, the humanoid robot known as Elektro was debuted at the 1939 New York World's Fair.[52][53] Seven feet tall (2.1 m) and weighing 265 pounds (120.2\u00a0kg), it could walk by voice command, speak about 700 words (using a 78-rpm record player), smoke cigarettes, blow up balloons, and move its head and arms. The body consisted of a steel gear, cam and motor skeleton covered by an aluminum skin. In 1928, Japan's first robot, Gakutensoku, was designed and constructed by biologist Makoto Nishimura.\nThe German V-1 flying bomb was equipped with systems for automatic guidance and range control, flying on a predetermined course (which could include a 90-degree turn) and entering a terminal dive after a predetermined distance. It was reported as being a 'robot' in contemporary descriptions.[54]Modern autonomous robotsThe first electronic autonomous robots with complex behaviour were created by William Grey Walter of the Burden Neurological Institute at Bristol, England in 1948 and 1949. He wanted to prove that rich connections between a small number of brain cells could give rise to very complex behaviors \u2013 essentially that the secret of how the brain worked lay in how it was wired up. His first robots, named Elmer and Elsie, were constructed between 1948 and 1949 and were often described as tortoises due to their shape and slow rate of movement. The three-wheeled tortoise robots were capable of phototaxis, by which they could find their way to a recharging station when they ran low on battery power.\nWalter stressed the importance of using purely analogue electronics to simulate brain processes at a time when his contemporaries such as Alan Turing and John von Neumann were all turning towards a view of mental processes in terms of digitalcomputation. His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden. Modern incarnations of Walter's turtles may be found in the form of BEAM robotics.[55]The first digitally operated and programmable robot was invented by George Devol in 1954 and was ultimately called the Unimate. This ultimately laid the foundations of the modern robotics industry.[56] Devol sold the first Unimate to General Motors in 1960, and it was installed in 1961 in a plant in Trenton, New Jersey to lift hot pieces of metal from a die casting machine and stack them.[57]The first palletizing robot was introduced in 1963 by the Fuji Yusoki Kogyo Company.[58] In 1973, a robot with six electromechanically driven axes was patented[59][60][61] by KUKA robotics in Germany, and the programmable universal manipulation arm was invented by Victor Scheinman in 1976, and the design was sold to Unimation.\nCommercial and industrial robots are now in widespread use performing jobs more cheaply or with greater accuracy and reliability than humans. They are also employed for jobs which are too dirty, dangerous or dull to be suitable for humans. Robots are widely used in manufacturing, assembly and packing, transport, earth and space exploration, surgery, weaponry, laboratory research, and mass production of consumer and industrial goods.[62]Future development and trends.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}External videosAtlas, The Next GenerationFurther information: RoboticsVarious techniques have emerged to develop the science of robotics and robots. One method is evolutionary robotics, in which a number of differing robots are submitted to tests. Those which perform best are used as a model to create a subsequent \"generation\" of robots. Another method is developmental robotics, which tracks changes and development within a single robot in the areas of problem-solving and other functions. Another new type of robot is just recently introduced which acts both as a smartphone and robot and is named RoboHon.[63]As robots become more advanced, eventually there may be a standard computer operating system designed mainly for robots. Robot Operating System (ROS) is an open-source software set of programs being developed at Stanford University, the Massachusetts Institute of Technology, and the Technical University of Munich, Germany, among others. ROS provides ways to program a robot's navigation and limbs regardless of the specific hardware involved. It also provides high-level commands for items like image recognition and even opening doors. When ROS boots up on a robot's computer, it would obtain data on attributes such as the length and movement of robots' limbs. It would relay this data to higher-level algorithms. Microsoft is also developing a \"Windows for robots\" system with its Robotics Developer Studio, which has been available since 2007.[64]Japan hopes to have full-scale commercialization of service robots by 2025. Much technological research in Japan is led by Japanese government agencies, particularly the Trade Ministry.[65]Many future applications of robotics seem obvious to people, even though they are well beyond the capabilities of robots available at the time of the prediction.[66][67] As early as 1982 people were confident that someday robots would:[68] 1. Clean parts by removing molding flash 2. Spray paint automobiles with absolutely no human presence 3. Pack things in boxes\u2014for example, orient and nest chocolate candies in candy boxes 4. Make electrical cable harness 5. Load trucks with boxes\u2014a packing problem 6. Handle soft goods, such as garments and shoes 7. Shear sheep 8. Be used as prostheses 9. Cook fast food and work in other service industries 10. Work as a household robot.\nGenerally such predictions are overly optimistic in timescale.\nNew functionalities and prototypes.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs to be updated. Please help update this article to reflect recent events or newly available information.  (August 2021)In 2008, Caterpillar Inc. developed a dump truck which can drive itself without any human operator.[69] Many analysts believe that self-driving trucks may eventually revolutionize logistics.[70] By 2014, Caterpillar had a self-driving dump truck which is expected to greatly change the process of mining. In 2015, these Caterpillar trucks were actively used in mining operations in Australia by the mining company Rio Tinto Coal Australia.[71][72][73][74] Some analysts believe that within the next few decades, most trucks will be self-driving.[75]A literate or 'reading robot' named Marge has intelligence that comes from software. She can read newspapers, find and correct misspelled words, learn about banks like Barclays, and understand that some restaurants are better places to eat than others.[76]Baxter is a new robot introduced in 2012 which learns by guidance. A worker could teach Baxter how to perform a task by moving its hands in the desired motion and having Baxter memorize them. Extra dials, buttons, and controls are available on Baxter's arm for more precision and features. Any regular worker could program Baxter and it only takes a matter of minutes, unlike usual industrial robots that take extensive programs and coding to be used. This means Baxter needs no programming to operate. No software engineers are needed. This also means Baxter can be taught to perform multiple, more complicated tasks. Sawyer was added in 2015 for smaller, more precise tasks.[77]Prototype cooking robots have been developed and could be programmed for autonomous, dynamic and adjustable preparation of discrete meals.[78][79]EtymologySee also: Glossary of roboticsA scene from Karel \u010capek's 1920 play R.U.R. (Rossum's Universal Robots), showing three robotsThe word robot was introduced to the public by the Czechinterwar writer Karel \u010capek in his play R.U.R. (Rossum's Universal Robots), published in 1920.[6] The play begins in a factory that uses a chemical substitute for protoplasm to manufacture living, simplified people called robots. The play does not focus in detail on the technology behind the creation of these living creatures, but in their appearance they prefigure modern ideas of androids, creatures who can be mistaken for humans. These mass-produced workers are depicted as efficient but emotionless, incapable of original thinking and indifferent to self-preservation. At issue is whether the robots are being exploited and the consequences of human dependence upon commodified labor (especially after a number of specially-formulated robots achieve self-awareness and incite robots all around the world to rise up against the humans).\nKarel \u010capek himself did not coin the word. He wrote a short letter in reference to an etymology in the Oxford English Dictionary in which he named his brother, the painter and writer Josef \u010capek, as its actual originator.[6]In an article in the Czech journal Lidov\u00e9 noviny in 1933, he explained that he had originally wanted to call the creatures labo\u0159i ('workers', from Latinlabor). However, he did not like the word, and sought advice from his brother Josef, who suggested roboti. The word robota means literally 'corv\u00e9e, serf labor', and figuratively 'drudgery, hard work' in Czech and also (more general) 'work, labor' in many Slavic languages (e.g.: Bulgarian, Russian, Serbian, Croatian, Slovenian, Slovak, Polish, Macedonian, Ukrainian and archaic Czech) as well as robot in Hungarian. Traditionally the robota (Hungarian robot) was the work period a serf (corv\u00e9e) had to give for his lord, typically six months of the year. The origin of the word is the Old Church Slavonicrabota'servitude' ('work' in contemporary Bulgarian, Macedonian and Russian), which in turn comes from the Proto-Indo-European root *orbh-. Robot is cognate with the German Arbeit'work'.[80][81]English pronunciation of the word has evolved relatively quickly since its introduction. In the U.S. during the late 1930s to early 1940s it was pronounced /\u02c8ro\u028abo\u028at/.[82][better\u00a0source\u00a0needed] By the late 1950s to early 1960s, some were pronouncing it /\u02c8ro\u028ab\u0259t/, while others used /\u02c8ro\u028ab\u0252t/[83] By the 1970s, its current pronunciation /\u02c8ro\u028ab\u0252t/ had become predominant.\nThe word robotics, used to describe this field of study,[4] was coined by the science fiction writer Isaac Asimov. Asimov created the Three Laws of Robotics which are a recurring theme in his books. These have since been used by many others to define laws used in fiction. (The three laws are pure fiction, and no technology yet created has the ability to understand or follow them, and in fact most robots serve military purposes, which run quite contrary to the first law and often the third law. \"People think about Asimov's laws, but they were set up to point out how a simple ethical system doesn't work. If you read the short stories, every single one is about a failure, and they are totally impractical,\" said Dr. Joanna Bryson of the University of Bath.[84])\nModern robotsMobile robotMain articles: Mobile robot and Automated guided vehicleMobile robots[85] have the capability to move around in their environment and are not fixed to one physical location. An example of a mobile robot that is in common use today is the automated guided vehicle or automatic guided vehicle (AGV). An AGV is a mobile robot that follows markers or wires in the floor, or uses vision or lasers.[86] AGVs are discussed later in this article.\nMobile robots are also found in industry, military and security environments.[87] They also appear as consumer products, for entertainment or to perform certain tasks like vacuum cleaning. Mobile robots are the focus of a great deal of current research and almost every major university has one or more labs that focus on mobile robot research.[88]Mobile robots are usually used in tightly controlled environments such as on assembly lines because they have difficulty responding to unexpected interference. Because of this most humans rarely encounter robots. However domestic robots for cleaning and maintenance are increasingly common in and around homes in developed countries. Robots can also be found in military applications.[89]Industrial robots (manipulating)Main articles: Industrial robot and Manipulator (device)Industrial robots usually consist of a jointed arm (multi-linked manipulator) and an end effector that is attached to a fixed surface. One of the most common type of end effector is a gripper assembly.\nThe International Organization for Standardization gives a definition of a  manipulating industrial robot in ISO 8373:\n\"an automatically controlled, reprogrammable, multipurpose, manipulator programmable in three or more axes, which may be either fixed in place or mobile for use in industrial automation applications.\"[90]This definition is used by the International Federation of Robotics, the European Robotics Research Network (EURON) and many national standards committees.[91]The industrial robots in food and drink processing plants are used for tasks such as feeding machines, packaging, and palletizing, which have replaced many manual, physical tasks. The complexity of digital skills required by workers varies depending on the level of automation and the specific tasks involved.[92] \nService robotMain article: Service robotMost commonly industrial robots are fixed robotic arms and manipulators used primarily for production and distribution of goods. The term \"service robot\" is less well-defined. The International Federation of Robotics has proposed a tentative definition, \"A service robot is a robot which operates semi- or fully autonomously to perform services useful to the well-being of humans and equipment, excluding manufacturing operations.\"[93]Educational (interactive) robotsMain article: Educational roboticsRobots are used as educational assistants to teachers. From the 1980s, robots such as turtles were used in schools and programmed using the Logo language.[94][95]There are robot kits like Lego Mindstorms, BIOLOID, OLLO from ROBOTIS, or BotBrain Educational Robots can help children to learn about mathematics, physics, programming, and electronics. Robotics have also been introduced into the lives of elementary and high school students in the form of robot competitions with the company FIRST (For Inspiration and Recognition of Science and Technology). The organization is the foundation for the FIRST Robotics Competition, FIRST Tech Challenge, FIRST Lego League Challenge and FIRST Lego League Explore competitions.\nThere have also been robots such as the teaching computer, Leachim (1974).[96] Leachim was an early example of speech synthesis using the Diphone synthesis method. 2-XL (1976) was a robot shaped game / teaching toy based on branching between audible tracks on an 8-track tape player, both invented by Michael J. Freeman.[97] Later, the 8-track was upgraded to tape cassettes and then to digital.\nModular robotMain article: Self-reconfiguring modular robotModular robots are a new breed of robots that are designed to increase the use of robots by modularizing their architecture.[98] The functionality and effectiveness of a modular robot is easier to increase compared to conventional robots. These robots are composed of a single type of identical, several different identical module types, or similarly shaped modules, which vary in size. Their architectural structure allows hyper-redundancy for modular robots, as they can be designed with more than 8 degrees of freedom (DOF). Creating the programming, inverse kinematics and dynamics for modular robots is more complex than with traditional robots. Modular robots may be composed of L-shaped modules, cubic modules, and U and H-shaped modules. ANAT technology, an early modular robotic technology patented by Robotics Design Inc., allows the creation of modular robots from U- and H-shaped modules that connect in a chain, and are used to form heterogeneous and homogenous modular robot systems. These \"ANAT robots\" can be designed with \"n\" DOF as each module is a complete motorized robotic system that folds relatively to the modules connected before and after it in its chain, and therefore a single module allows one degree of freedom. The more modules that are connected to one another, the more degrees of freedom it will have. L-shaped modules can also be designed in a chain, and must become increasingly smaller as the size of the chain increases, as payloads attached to the end of the chain place a greater strain on modules that are further from the base. ANAT H-shaped modules do not suffer from this problem, as their design allows a modular robot to distribute pressure and impacts evenly amongst other attached modules, and therefore payload-carrying capacity does not decrease as the length of the arm increases. Modular robots can be manually or self-reconfigured to form a different robot, that may perform different applications. Because modular robots of the same architecture type are composed of modules that compose different modular robots, a snake-arm robot can combine with another to form a dual or quadra-arm robot, or can split into several mobile robots, and mobile robots can split into multiple smaller ones, or combine with others into a larger or different one. This allows a single modular robot the ability to be fully specialized in a single task, as well as the capacity to be specialized to perform multiple different tasks.\nModular robotic technology is currently being applied in hybrid transportation,[99] industrial automation,[100] duct cleaning[101] and handling. Many research centres and universities have also studied this technology, and have developed prototypes.\nCollaborative robotsA collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks. However, end-effectors and other environmental conditions may create hazards, and as such risk assessments should be done before using any industrial motion-control application.[102]The collaborative robots most widely used in industries today are manufactured by Universal Robots in Denmark.[103]Rethink Robotics\u2014founded by Rodney Brooks, previously with iRobot\u2014introduced Baxter in September 2012; as an industrial robot designed to safely interact with neighboring human workers, and be programmable for performing simple tasks.[104] Baxters stop if they detect a human in the way of their robotic arms and have prominent off switches. Intended for sale to small businesses, they are promoted as the robotic analogue of the personal computer.[105] As of May\u00a02014[update], 190 companies in the US have bought Baxters and they are being used commercially in the UK.[10]Robots in societyTOPIO, a humanoid robot, played ping pong at Tokyo International Robot Exhibition (IREX) 2009.[106][107]Roughly half of all the robots in the world are in Asia, 32% in Europe, and 16% in North America, 1% in Australasia and 1% in Africa.[108] 40% of all the robots in the world are in Japan,[109] making Japan the country with the highest number of robots.\nAutonomy and ethical questionsMain articles: Roboethics and Ethics of artificial intelligenceAn android, or robot designed to resemble a human, can appear comforting to some people and disturbing to others.[110]As robots have become more advanced and sophisticated, experts and academics have increasingly explored the questions of what ethics might govern robots' behavior,[111][112] and whether robots might be able to claim any kind of social, cultural, ethical or legal rights.[113] One scientific team has said that it was possible that a robot brain would exist by 2019.[114] Others predict robot intelligence breakthroughs by 2050.[115] Recent advances have made robotic behavior more sophisticated.[116] The social impact of intelligent robots is subject of a 2010 documentary film called Plug & Pray.[117]Vernor Vinge has suggested that a moment may come when computers and robots are smarter than humans. He calls this \"the Singularity\".[118] He suggests that it may be somewhat or possibly very dangerous for humans.[119] This is discussed by a philosophy called Singularitarianism.\nIn 2009, experts attended a conference hosted by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to acquire any autonomy, and how much these abilities might pose a threat or hazard. They noted that some robots have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence.\" They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.[118] Various media sources and scientific groups have noted separate trends in differing areas which might together result in greater robotic functionalities and autonomy, and which pose some inherent concerns.[120][121][122]Military robotsSome experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.[123] There are also concerns about technology which might allow some armed robots to be controlled mainly by other robots.[124] The US Navy has funded a report which indicates that, as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.[125][126] One researcher states that autonomous robots might be more humane, as they could make decisions more effectively. However, other experts question this.[127]One robot in particular, the EATR, has generated public concerns[128] over its fuel source, as it can continually refuel itself using organic substances.[129] Although the engine for the EATR is designed to run on biomass and vegetation[130] specifically selected by its sensors, which it can find on battlefields or other local environments, the project has stated that chicken fat can also be used.[131]Manuel De Landa has noted that \"smart missiles\" and autonomous bombs equipped with artificial perception can be considered robots, as they make some of their decisions autonomously. He believes this represents an important and dangerous trend in which humans are handing over important decisions to machines.[132]Relationship to unemploymentMain article: Technological unemploymentFor centuries, people have predicted that machines would make workers obsolete and increase unemployment, although the causes of unemployment are usually thought to be due to social policy.[133][134][135]A recent example of human replacement involves Taiwanese technology company Foxconn who, in July 2011, announced a three-year plan to replace workers with more robots. At present the company uses ten thousand robots but will increase them to a million robots over a three-year period.[136]Lawyers have speculated that an increased prevalence of robots in the workplace could lead to the need to improve redundancy laws.[137]Kevin J. Delaney said \"Robots are taking human jobs. But Bill Gates believes that governments should tax companies' use of them, as a way to at least temporarily slow the spread of automation and to fund other types of employment.\"[138] The robot tax would also help pay a guaranteed living wage to the displaced workers.\nThe World Bank's World Development Report 2019 puts forth evidence showing that while automation displaces workers, technological innovation creates more new industries and jobs on balance.[139]Contemporary usesSee also: List of robotsAt present, there are two main types of robots, based on their use: general-purpose autonomous robots and dedicated robots.\nRobots can be classified by their specificity of purpose. A robot might be designed to perform one particular task extremely well, or a range of tasks less well. All robots by their nature can be re-programmed to behave differently, but some are limited by their physical form. For example, a factory robot arm can perform jobs such as cutting, welding, gluing, or acting as a fairground ride, while a pick-and-place robot can only populate printed circuit boards.\nGeneral-purpose autonomous robotsMain article: Autonomous robotGeneral-purpose autonomous robots can perform a variety of functions independently. General-purpose autonomous robots typically can navigate independently in known spaces, handle their own re-charging needs, interface with electronic doors and elevators and perform other basic tasks. Like computers, general-purpose robots can link with networks, software and accessories that increase their usefulness. They may recognize people or objects, talk, provide companionship, monitor environmental quality, respond to alarms, pick up supplies and perform other useful tasks. General-purpose robots may perform a variety of functions simultaneously or they may take on different roles at different times of day. Some such robots try to mimic human beings and may even resemble people in appearance; this type of robot is called a humanoid robot. Humanoid robots are still in a very limited stage, as no humanoid robot can, as of yet, actually navigate around a room that it has never been in.[140] Thus, humanoid robots are really quite limited, despite their intelligent behaviors in their well-known environments.\nFactory robotsCar productionOver the last three decades, automobile factories have become dominated by robots. A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers. On an automated production line, a vehicle chassis on a conveyor is welded, glued, painted and finally assembled at a sequence of robot stations.\nPackagingIndustrial robots are also used extensively for palletizing and packaging of manufactured goods, for example for rapidly taking drink cartons from the end of a conveyor belt and placing them into boxes, or for loading and unloading machining centers.\nElectronicsMass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, typically with SCARA manipulators, which remove tiny electronic components from strips or trays, and place them on to PCBs with great accuracy.[141] Such robots can place hundreds of thousands of components per hour, far out-performing a human in speed, accuracy, and reliability.[142]Automated guided vehicles (AGVs)Mobile robots, following markers or wires in the floor, or using vision[86] or lasers, are used to transport goods around large facilities, such as warehouses, container ports, or hospitals.[143]Early AGV-style robotsLimited to tasks that could be accurately defined and had to be performed the same way every time. Very little feedback or intelligence was required, and the robots needed only the most basic exteroceptors (sensors). The limitations of these AGVs are that their paths are not easily altered and they cannot alter their paths if obstacles block them. If one AGV breaks down, it may stop the entire operation.\nInterim AGV technologiesDeveloped to deploy triangulation from beacons or bar code grids for scanning on the floor or ceiling. In most factories, triangulation systems tend to require moderate to high maintenance, such as daily cleaning of all beacons or bar codes. Also, if a tall pallet or large vehicle blocks beacons or a bar code is marred, AGVs may become lost. Often such AGVs are designed to be used in human-free environments.\nIntelligent AGVs (i-AGVs)Such as SmartLoader,[144] SpeciMinder,[145] ADAM,[146] Tug[147] Eskorta,[148] and MT 400 with Motivity[149] are designed for people-friendly workspaces. They navigate by recognizing natural features. 3D scanners or other means of sensing the environment in two or three dimensions help to eliminate cumulative errors in dead-reckoning calculations of the AGV's current position. Some AGVs can create maps of their environment using scanning lasers with simultaneous localization and mapping (SLAM) and use those maps to navigate in real time with other path planning and obstacle avoidance algorithms. They are able to operate in complex environments and perform non-repetitive and non-sequential tasks such as transporting photomasks in a semiconductor lab, specimens in hospitals and goods in warehouses. For dynamic areas, such as warehouses full of pallets, AGVs require additional strategies using three-dimensional sensors such as time-of-flight or stereovision cameras.\nDirty, dangerous, dull, or inaccessible tasksSee also: Dirty, dangerous and demeaningThere are many jobs that humans would rather leave to robots. The job may be boring, such as domestic cleaning or sports field line marking, or dangerous, such as exploring inside a volcano.[150] Other jobs are physically inaccessible, such as exploring another planet,[151] cleaning the inside of a long pipe, or performing laparoscopic surgery.[152]Space probesAlmost every unmanned space probe ever launched was a robot.[153][154] Some were launched in the 1960s with very limited abilities, but their ability to fly and land (in the case of Luna 9) is an indication of their status as a robot. This includes the Voyager probes and the Galileo probes, among others.\nTelerobotsA U.S. Marine Corps technician prepares to use a telerobot to detonate a buried improvised explosive device near Camp Fallujah, Iraq.Teleoperated robots, or telerobots, are devices remotely operated from a distance by a human operator rather than following a predetermined sequence of movements, but which has semi-autonomous behaviour. They are used when a human cannot be present on site to perform a job because it is dangerous, far away, or inaccessible. The robot may be in another room or another country, or may be on a very different scale to the operator. For instance, a laparoscopic surgery robot allows the surgeon to work inside a human patient on a relatively small scale compared to open surgery, significantly shortening recovery time.[152] They can also be used to avoid exposing workers to the hazardous and tight spaces such as in duct cleaning. When disabling a bomb, the operator sends a small robot to disable it. Several authors have been using a device called the Longpen to sign books remotely.[155] Teleoperated robot aircraft, like the Predator Unmanned Aerial Vehicle, are increasingly being used by the military. These pilotless drones can search terrain and fire on targets.[156][157] Hundreds of robots such as iRobot's Packbot and the Foster-Miller TALON are being used in Iraq and Afghanistan by the U.S. military to defuse roadside bombs or improvised explosive devices (IEDs) in an activity known as explosive ordnance disposal (EOD).[158]Automated fruit harvesting machinesRobots are used to automate picking fruit on orchards at a cost lower than that of human pickers.\nDomestic robotsThe Roomba domestic vacuum cleaner robot does a single, menial job.Domestic robots are simple robots dedicated to a single task work in home use. They are used in simple but often disliked jobs, such as vacuum cleaning, floor washing, and lawn mowing. An example of a domestic robot is a Roomba.\nMilitary robotsMain article: Military robotMilitary robots include the SWORDS robot which is currently used in ground-based combat. It can use a variety of weapons and there is some discussion of giving it some degree of autonomy in battleground situations.[159][160][161]Unmanned combat air vehicles (UCAVs), which are an upgraded form of UAVs, can do a wide variety of missions, including combat. UCAVs are being designed such as the BAE Systems Mantis which would have the ability to fly themselves, to pick their own course and target, and to make most decisions on their own.[162] The BAE Taranis is a UCAV built by Great Britain which can fly across continents without a pilot and has new means to avoid detection.[163] Flight trials are expected to begin in 2011.[164]The AAAI has studied this topic in depth[111] and its president has commissioned a study to look at this issue.[165]Some have suggested a need to build \"Friendly AI\", meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.[166] Several such measures reportedly already exist, with robot-heavy countries such as Japan and South Korea[167] having begun to pass regulations requiring robots to be equipped with safety systems, and possibly sets of 'laws' akin to Asimov's Three Laws of Robotics.[168][169] An official report was issued in 2009 by the Japanese government's Robot Industry Policy Committee.[170] Chinese officials and researchers have issued a report suggesting a set of ethical rules, and a set of new legal guidelines referred to as \"Robot Legal Studies.\"[171] Some concern has been expressed over a possible occurrence of robots telling apparent falsehoods.[172]Mining robotsMining robots are designed to solve a number of problems currently facing the mining industry, including skills shortages, improving productivity from declining ore grades, and achieving environmental targets. Due to the hazardous nature of mining, in particular underground mining, the prevalence of autonomous, semi-autonomous, and tele-operated robots has greatly increased in recent times. A number of vehicle manufacturers provide autonomous trains, trucks and loaders that will load material, transport it on the mine site to its destination, and unload without requiring human intervention. One of the world's largest mining corporations, Rio Tinto, has recently expanded its autonomous truck fleet to the world's largest, consisting of 150 autonomous Komatsu trucks, operating in Western Australia.[173] Similarly, BHP has announced the expansion of its autonomous drill fleet to the world's largest, 21 autonomous Atlas Copco drills.[174]Drilling, longwall and rockbreaking machines are now also available as autonomous robots.[175] The Atlas Copco Rig Control System can autonomously execute a drilling plan on a drilling rig, moving the rig into position using GPS, set up the drill rig and drill down to specified depths.[176] Similarly, the Transmin Rocklogic system can automatically plan a path to position a rockbreaker at a selected destination.[177] These systems greatly enhance the safety and efficiency of mining operations.\nHealthcareRobots in healthcare have two main functions. Those which assist an individual, such as a sufferer of a disease like Multiple Sclerosis, and those which aid in the overall systems such as pharmacies and hospitals.\nHome automation for the elderly and disabledFurther information: Disability robotRobots used in home automation have developed over time from simple basic robotic assistants, such as the Handy 1,[178] through to semi-autonomous robots, such as Care-Providing Robot \"FRIEND\" which can assist the elderly and disabled with common tasks.\nThe population is aging in many countries, especially Japan, meaning that there are increasing numbers of elderly people to care for, but relatively fewer young people to care for them.[179][180] Humans make the best carers, but where they are unavailable, robots are gradually being introduced.[181]FRIEND is a semi-autonomous robot designed to support disabled and elderly people in their daily life activities, like preparing and serving a meal. FRIEND make it possible for patients who are paraplegic, have muscle diseases or serious paralysis (due to strokes etc.), to perform tasks without help from other people like therapists or nursing staff.\nPharmaciesMain article: Pharmacy automationThis section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  (July 2009) (Learn how and when to remove this message)Script Pro manufactures a robot designed to help pharmacies fill prescriptions that consist of oral solids or medications in pill form.[182][better\u00a0source\u00a0needed] The pharmacist or pharmacy technician enters the prescription information into its information system. The system, upon determining whether or not the drug is in the robot, will send the information to the robot for filling. The robot has 3 different size vials to fill determined by the size of the pill. The robot technician, user, or pharmacist determines the needed size of the vial based on the tablet when the robot is stocked. Once the vial is filled it is brought up to a conveyor belt that delivers it to a holder that spins the vial and attaches the patient label. Afterwards it is set on another conveyor that delivers the patient's medication vial to a slot labeled with the patient's name on an LED read out. The pharmacist or technician then checks the contents of the vial to ensure it's the correct drug for the correct patient and then seals the vials and sends it out front to be picked up.\nMcKesson's Robot RX is another healthcare robotics product that helps pharmacies dispense thousands of medications daily with little or no errors.[183] The robot can be ten feet wide and thirty feet long and can hold hundreds of different kinds of medications and thousands of doses. The pharmacy saves many resources like staff members that are otherwise unavailable in a resource scarce industry. It uses an electromechanical head coupled with a pneumatic system to capture each dose and deliver it to either its stocked or dispensed location. The head moves along a single axis while it rotates 180 degrees to pull the medications. During this process it uses barcode technology to verify it's pulling the correct drug. It then delivers the drug to a patient specific bin on a conveyor belt. Once the bin is filled with all of the drugs that a particular patient needs and that the robot stocks, the bin is then released and returned out on the conveyor belt to a technician waiting to load it into a cart for delivery to the floor.\nResearch robotsSee also: Robotics researchWhile most robots today are installed in factories or homes, performing labour or life saving jobs, many new types of robot are being developed in laboratories around the world. Much of the research in robotics focuses not on specific industrial tasks, but on investigations into new types of robot, alternative ways to think about or design robots, and new ways to manufacture them. It is expected that these new types of robot will be able to solve real world problems when they are finally realized.[citation needed]Bionic and biomimetic robotsFurther information: BiomimeticsFurther information: BionicsOne approach to designing robots is to base them on animals. BionicKangaroo was designed and engineered by studying and applying the physiology and methods of locomotion of a kangaroo.\nNanorobotsFurther information: NanoroboticsNanorobotics is the emerging technology field of creating machines or robots whose components are at or close to the microscopic scale of a nanometer (10\u22129 meters). Also known as \"nanobots\" or \"nanites\", they would be constructed from molecular machines. So far, researchers have mostly produced only parts of these complex systems, such as bearings, sensors, and synthetic molecular motors, but functioning robots have also been made such as the entrants to the Nanobot Robocup contest.[184] Researchers also hope to be able to create entire robots as small as viruses or bacteria, which could perform tasks on a tiny scale. Possible applications include micro surgery (on the level of individual cells), utility fog,[185] manufacturing, weaponry and cleaning.[186] Some people have suggested that if there were nanobots which could reproduce, the earth would turn into \"grey goo\", while others argue that this hypothetical outcome is nonsense.[187][188]Reconfigurable robotsMain article: Self-reconfiguring modular robotA few researchers have investigated the possibility of creating robots which can alter their physical form to suit a particular task,[189] like the fictional T-1000. Real robots are nowhere near that sophisticated however, and mostly consist of a small number of cube shaped units, which can move relative to their neighbours. Algorithms have been designed in case any such robots become a reality.[190]Robotic, mobile laboratory operatorsFurther information: Laboratory roboticsIn July 2020 scientists reported the development of a mobile robot chemist and demonstrate that it can assist in experimental searches. According to the scientists their strategy was automating the researcher rather than the instruments \u2013 freeing up time for the human researchers to think creatively \u2013 and could identify photocatalyst mixtures for hydrogen production from water that were six times more active than initial formulations. The modular robot can operate laboratory instruments, work nearly around the clock, and autonomously make decisions on his next actions depending on experimental results.[191][192]Soft-bodied robotsRobots with silicone bodies and flexible actuators (air muscles, electroactive polymers, and ferrofluids) look and feel different from robots with rigid skeletons, and can have different behaviors.[193] Soft, flexible (and sometimes even squishy) robots are often designed to mimic the biomechanics of animals and other things found in nature, which is leading to new applications in medicine, care giving, search and rescue, food handling and manufacturing, and scientific exploration.[194][195]Swarm robotsMain article: Swarm roboticsInspired by colonies of insects such as ants and bees, researchers are modeling the behavior of swarms of thousands of tiny robots which together perform a useful task, such as finding something hidden, cleaning, or spying. Each robot is quite simple, but the emergent behavior of the swarm is more complex. The whole set of robots can be considered as one single distributed system, in the same way an ant colony can be considered a superorganism, exhibiting swarm intelligence. The largest swarms so far created include the iRobot swarm, the SRI/MobileRobots CentiBots project[196] and the Open-source Micro-robotic Project swarm, which are being used to research collective behaviors.[197][198] Swarms are also more resistant to failure. Whereas one large robot may fail and ruin a mission, a swarm can continue even if several robots fail. This could make them attractive for space exploration missions, where failure is normally extremely costly.[199]Haptic interface robotsFurther information: Haptic technologyRobotics also has application in the design of virtual reality interfaces. Specialized robots are in widespread use in the haptic research community. These robots, called \"haptic interfaces\", allow touch-enabled user interaction with real and virtual environments. Robotic forces allow simulating the mechanical properties of \"virtual\" objects, which users can experience through their sense of touch.[200]Contemporary art and sculptureFurther information: Robotic artRobots are used by contemporary artists to create works that include mechanical automation. There are many branches of robotic art, one of which is robotic installation art, a type of installation art that is programmed to respond to viewer interactions, by means of computers, sensors and actuators. The future behavior of such installations can therefore be altered by input from either the artist or the participant, which differentiates these artworks from other types of kinetic art.\nLe Grand Palais in Paris organized an exhibition \"Artists & Robots\", featuring artworks created by more than forty artists with the help of robots in 2018.[201]Robots in popular cultureToy robots on display at the Museo del Objeto del Objeto in Mexico CitySee also: List of fictional robots and androids and Droid (Star Wars)LiteratureMain article: Robots in literatureRobotic characters, androids (artificial men/women) or gynoids (artificial women), and cyborgs (also \"bionic men/women\", or humans with significant mechanical enhancements) have become a staple of science fiction.\nThe first reference in Western literature to mechanical servants appears in Homer's Iliad. In Book XVIII, Hephaestus, god of fire, creates new armor for the hero Achilles, assisted by robots.[202] According to the Rieu translation, \"Golden maidservants hastened to help their master. They looked like real women and could not only speak and use their limbs but were endowed with intelligence and trained in handwork by the immortal gods.\" The words \"robot\" or \"android\" are not used to describe them, but they are nevertheless mechanical devices human in appearance. \"The first use of the word Robot was in Karel \u010capek's play R.U.R. (Rossum's Universal Robots) (written in 1920)\". Writer Karel \u010capek was born in Czechoslovakia (Czech Republic).\nPossibly the most prolific author of the twentieth century was Isaac Asimov (1920\u20131992)[203] who published over five-hundred books.[204] Asimov is probably best remembered for his science-fiction stories and especially those about robots, where he placed robots and their interaction with society at the center of many of his works.[205][206] Asimov carefully considered the problem of the ideal set of instructions robots might be given to lower the risk to humans, and arrived at his Three Laws of Robotics: a robot may not injure a human being or, through inaction, allow a human being to come to harm; a robot must obey orders given it by human beings, except where such orders would conflict with the First Law; and a robot must protect its own existence as long as such protection does not conflict with the First or Second Law.[207] These were introduced in his 1942 short story \"Runaround\", although foreshadowed in a few earlier stories. Later, Asimov added the Zeroth Law: \"A robot may not harm humanity, or, by inaction, allow humanity to come to harm\"; the rest of the laws are modified sequentially to acknowledge this.\nAccording to the Oxford English Dictionary, the first passage in Asimov's short story \"Liar!\" (1941) that mentions the First Law is the earliest recorded use of the word robotics. Asimov was not initially aware of this; he assumed the word already existed by analogy with mechanics,hydraulics, and other similar terms denoting branches of applied knowledge.[208]Robot competitionsMain article: Robot competitionRobots are used in a number of competitive events. Robot combat competitions have been popularized by television shows such as Robot Wars and BattleBots, featuring mostly remotely controlled 'robots' that compete against each other directly using various weaponry, there are also amateur robot combat leagues active globally outside of the televised events. Micromouse events, in which autonomous robots compete to solve mazes or other obstacle courses are also held internationally.\nRobot competitions are also often used within educational settings to introduce the concept of robotics to children such as the FIRST Robotics Competition in the US.\nFilmsSee also: Category:Films about robotsRobots appear in many films. Most of the robots in cinema are fictional. Two of the most famous are R2-D2 and C-3PO from the Star Wars franchise.\nSex robotsMain article: Sex robotThe concept of humanoid sex robots has drawn public attention and elicited debate regarding their supposed benefits and potential effects on society. Opponents argue that the introduction of such devices would be socially harmful, and demeaning to women and children,[209] while proponents cite their potential therapeutical benefits, particularly in aiding people with dementia or depression.[210]Problems depicted in popular cultureFears and concerns about robots have been repeatedly expressed in a wide range of books and films. A common theme is the development of a master race of conscious and highly intelligent robots, motivated to take over or destroy the human race. Frankenstein (1818), often called the first science fiction novel, has become synonymous with the theme of a robot or android advancing beyond its creator.\nOther works with similar themes include The Mechanical Man, The Terminator, Runaway, RoboCop, the Replicators in Stargate, the Cylons in Battlestar Galactica, the Cybermen and Daleks in Doctor Who, The Matrix, Enthiran and I, Robot. Some fictional robots are programmed to kill and destroy; others gain superhuman intelligence and abilities by upgrading their own software and hardware. Examples of popular media where the robot becomes evil are 2001: A Space Odyssey, Red Planet and Enthiran.\nThe 2017 game Horizon Zero Dawn explores themes of robotics in warfare, robot ethics, and the AI control problem, as well as the positive or negative impact such technologies could have on the environment.\nAnother common theme is the reaction, sometimes called the \"uncanny valley\", of unease and even revulsion at the sight of robots that mimic humans too closely.[110]More recently, fictional representations of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina and the 2016 TV adaptation of Westworld have engaged audience sympathy for the robots themselves.\nEmancipation or revolution as a theme in relation to robots was already present in the term coining play of R.U.R.\nThe Star Wars universe for example has several instances of droid revolts.\nThe Dune series on the other hand has the premise of humans revolting against thinking machines and finding human-biological alternatives to them.\nSee also.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Index of robotics articlesOutline of roboticsArtificial intelligenceWilliam Grey WalterSpecific robotics conceptsRobot locomotionSimultaneous localization and mappingTactile sensorTeleoperationUncanny valleyvon Neumann machineWake-up robot problemNeuromorphic engineeringRobotics methods and categoriesCognitive roboticsCompanion robotDomestic robotEpigenetic roboticsEvolutionary roboticsHumanoid robotAutonomous robotSwarm roboticsMicroboticsRobot controlSpecific robots and devicesAIBOAutonomous spaceport drone shipDriverless carFriendly RoboticsLely Juno familyLiquid handling robotParo (robot)PatrolBotRoboBeeRoboriorRobot App StoreOther related articlesAutomated guided vehicleAnimatronicsRemote control vehicleRobot AwardRobot economicsRobotoidUnmanned vehicleHybrotBiohybrid robotFurther reading.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Al-Arshani, Sarah (29 November 2021). \"Researchers behind the world's first living robot have found a way to make it reproduce \u2014 by shaping it like Pac-Man\". Business Insider.See this humanoid robot artist sketch drawings from sight (CNN, Video, 2019)Margolius, Ivan. 'The Robot of Prague', Newsletter, The Friends of Czech Heritage no. 17, Autumn 2017, pp.\u00a03 \u2013 6. https://czechfriends.net/images/RobotsMargoliusJul2017.pdfArchived 11 September 2017 at the Wayback MachineGlaser, Horst Albert and Rossbach, Sabine: The Artificial Human, Frankfurt/M., Bern, New York 2011 \"A Tragical History\"Gutkind, L. (2006). Almost Human: Making Robots Think. New York: W. W. Norton & Company, Inc.Craig, J.J. (2005). Introduction to Robotics, Pearson Prentice Hall. Upper Saddle River, NJ.Tsai, L. W. (1999). Robot Analysis. Wiley. New York.Sotheby's New York. The Tin Toy Robot Collection of Matt Wyse (1996)DeLanda, Manuel. War in the Age of Intelligent Machines. 1991. Swerve. New York.Needham, Joseph (1986). Science and Civilization in China: Volume 2. Taipei: Caves Books Ltd.Cheney, Margaret [1989:123] (1981). Tesla, Man Out of Time. Dorset Press. New York. ISBN\u00a00-88029-419-1\u010capek, Karel (1920). R.U.R., Aventinum, Prague.TechCast Article Series, Jason Rupinski and Richard Mix, \"Public Attitudes to Androids: Robot Gender, Tasks, & Pricing\"References.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^\"Four-legged Robot, 'Cheetah,' Sets New Speed Record\". Reuters. 6 March 2012. Archived from the original on 22 October 2013. Retrieved 5 October 2013.^Definition of 'robot'. Oxford English Dictionary. Retrieved 27 November 2016.^\"Forecasts \u2013 Driverless car market watch\". driverless-future.com. Archived from the original on 25 September 2023. Retrieved 26 September 2023.^ ab\"robotics\". Oxford Dictionaries. Archived from the original on 18 May 2011. Retrieved 4 February 2011.^Margolius, Ivan (Autumn 2017). \"The Robot of Prague\"(PDF). The Friends of Czech Heritage (17): 3\u20136. Archived(PDF) from the original on 11 September 2017.^ abcZunt, Dominik. \"Who did actually invent the word \"robot\" and what does it mean?\". The Karel \u010capek website. Archived from the original on 4 February 2012. Retrieved 11 September 2007.^Kurfess, Thomas R. (1 January 2005). Robotics and Automation Handbook. Taylor & Francis. ISBN\u00a0978-0-8493-1804-7. Archived from the original on 4 December 2016. Retrieved 5 July 2016 \u2013 via Google Books.^Pearce, Jeremy (15 August 2011). \"George C. Devol, Inventor of Robot Arm, Dies at 99\". The New York Times. Archived from the original on 25 December 2016. Retrieved 7 February 2012. In 1961, General Motors put the first Unimate arm on an assembly line at the company's plant in Ewing Township, N.J., a suburb of Trenton. The device was used to lift and stack die-cast metal parts taken hot from their molds.^Akins, Crystal. \"5 jobs being replaced by robots\". Excelle. Monster. Archived from the original on 24 April 2013. Retrieved 15 April 2013.^ abHoy, Greg (28 May 2014). \"Robots could cost Australian economy 5 million jobs, experts warn, as companies look to cut costs\". ABC News. Australian Broadcasting Corporation. Archived from the original on 29 May 2014. Retrieved 29 May 2014.^Polk, Igor (16 November 2005). \"RoboNexus 2005 robot exhibition virtual tour\". Robonexus Exhibition 2005. Archived from the original on 12 August 2007. Retrieved 10 September 2007.^Harris, Tom (16 April 2002). \"How Robots Work\". How Stuff Works. Archived from the original on 26 August 2007. Retrieved 10 September 2007.^\"Telecom glossary \"bot\"\". Alliance for Telecommunications Solutions. 26 September 2023.^Moran, M. E. (December 2006). \"The da Vinci robot\". J. Endourol. 20 (12): 986\u201390. doi:10.1089/end.2006.20.986. PMID\u00a017206888. ... the date of the design and possible construction of this robot was 1495 ... Beginning in the 1950s, investigators at the University of California began to ponder the significance of some of da Vinci's markings on what appeared to be technical drawings ... It is now known that da Vinci's robot would have had the outer appearance of a Germanic knight.^Deborah Levine Gera (2003). Ancient Greek Ideas on Speech, Language, and Civilization. Oxford University Press. ISBN\u00a0978-0-19-925616-7. Archived from the original on 5 December 2016. Retrieved 25 September 2016.^Noct. Att. L. 10^ abRosheim, Mark E. (1994). Robot evolution: the development of anthrobotics. Wiley-IEEE. ISBN\u00a00-471-02622-0.^\"\"Robots then and now\". BBC. 22 July 2004. Archived from the original on 20 December 2010.^O'Connor, J.J. and E.F. Robertson. \"Heron biography\". The MacTutor History of Mathematics archive. Retrieved 26 September 2023.^Efstathiou, Kyriakos; Efstathiou, Marianna (2018). \"Celestial Gearbox: Oldest Known Computer is a Mechanism Designed to Calculate the Location of the Sun, Moon, and Planets\". Mechanical Engineering. 140 (9): 31\u201335. doi:10.1115/1.2018-SEP1.^Steiglitz, Ken (2019). The Discrete Charm of the Machine: Why the World Became Digital. Princeton, New Jersey: Princeton University Press. p.\u00a0108. ISBN\u00a0978-0-691-18417-3.^Needham, Joseph (1991). Science and Civilisation in China. Vol.\u00a02. Cambridge, England: Cambridge University Press. pp.\u00a053\u201354. ISBN\u00a0978-0-521-05800-1.^Fowler, Charles B. (1967). \"The Museum of Music: A History of Mechanical Instruments\". Music Educators Journal. 54 (2): 45\u201349. doi:10.2307/3391092. JSTOR\u00a03391092. S2CID\u00a0190524140.^\"Early Clocks\". A Walk Through Time. NIST Physics Laboratory. 12 August 2009. Retrieved 13 October 2022.^ ab\"The programmable robot of ancient Greece\". New Scientist: 32\u201335. 6 July 2007.^Varadpande, Manohar Laxman (1987). History of Indian Theatre, Volume 1. Abhinav Publications. p.\u00a068. ISBN\u00a0978-81-7017-221-5.^Wujastyk, Dominik (2003). The Roots of Ayurveda: Selections from Sanskrit Medical Writings. Penguin. p.\u00a0222. ISBN\u00a0978-0-14-044824-5.^Needham, Joseph (1965). Science and Civilisation in China: Volume 4, Physics and Physical Technology Part 2, Mechanical Engineering. Cambridge University Press. p.\u00a0164. ISBN\u00a0978-0-521-05803-2.^Strong, J.S. (2007). Relics of the Buddha. Princeton, New Jersey: Princeton University Press. pp.\u00a0132\u2013136. ISBN\u00a0978-0-691-11764-5.^ ab\"Al-Jazar\u012b | Arab inventor\". Encyclop\u00e6dia Britannica. Retrieved 15 June 2019.^Howard R. Turner (1997). Science in Medieval Islam: An Illustrated Introduction. University of Texas Press. p.\u00a081. ISBN\u00a00-292-78149-0.^Hill, Donald (May 1991). \"Mechanical Engineering in the Medieval Near East\". Scientific American. pp.\u00a064\u201369. (cf.Hill, Donald. \"History of Sciences in the Islamic World\". IX. Mechanical Engineering. Archived from the original on 25 December 2007.)^Ancient Discoveries Islamic Science Part1. Archived from the original on 11 December 2021. Retrieved 15 June 2019.^Truitt, E.R. (2015). Medieval Robots: Mechanism, Magic, Nature, and Art. The Middle Ages Series. University of Pennsylvania Press, Incorporated. p.\u00a0136. ISBN\u00a0978-0-8122-9140-7.^\"Leonardo da Vinci's Robots\". Leonardo3.net. Archived from the original on 24 September 2008. Retrieved 25 September 2008.^Law, Jane Marie (1997). Puppets of Nostalgia \u2013 The Life, Death and Rebirth of the Japanese Awaji Ningyo Tradition. Princeton University Press. ISBN\u00a0978-0-691-02894-1.^Wood, Gabby (16 February 2002). \"Living Dolls: A Magical History Of The Quest For Mechanical Life\". The Guardian. Archived from the original on 20 December 2016.^\"The Boy Robot of 1774\". 21 February 2018.^Edwyn Gray, Nineteenth-century torpedoes and their inventors, page 18^Gray, Edwyn (2004). Nineteenth-Century Torpedoes and Their Inventors. Naval Institute Press. ISBN\u00a0978-1-59114-341-3.^Seifer, Marc (24 October 2011). Life and Times of Nikola Tesla. Citadel. p.\u00a01893. ISBN\u00a0978-0-8065-3556-2. Archived from the original on 5 December 2016.^Miessner, Benjamin Franklin (1916). Radiodynamics: The Wireless Control of Torpedoes and Other Mechanisms. D. Van Nostrand Company. p.\u00a083.^.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US 613809, Tesla, Nikola, \"Method of and apparatus for controlling mechanism of moving vessels or vehicles\", published 8 November 1898\u00a0^\"Tesla \u2013 Master of Lightning\". PBS. Archived from the original on 28 September 2008. Retrieved 24 September 2008.^Sarkar 2006, page 97^Torres, Leonardo, \"FR327218A Syst\u00e8me dit telekine pour commander \u00e0 distance un mouvement m\u00e9canique.Archived 22 August 2023 at the Wayback Machine\", Espacenet, 10 December 1902.^Torres, Leonardo, \"GB190327073 (A) \u2015 Means or Method for Directing Mechanical Movements at or from a Distance.[permanent dead link]\", Espacenet, 10 December 1903.^A. P. Yuste (January 2008). \"Early Developments of Wireless Remote Control: The Telekino of Torres-Quevedo\". Proceedings of the IEEE. 96 (1): 186\u2013190. doi:10.1109/JPROC.2007.909931. S2CID\u00a0111010868.^H. R. Everett (2015). Unmanned Systems of World Wars I and II. MIT Press. pp.\u00a091\u201395. ISBN\u00a0978-0-262-02922-3.^\"AH Reffell & Eric the Robot (1928) - the UK's Firs Robot\". Retrieved 26 September 2023.^\"1932 - George Robot - Capt. W.H. Richards (British)\". cyberneticzoo.com. Retrieved 26 September 2023.^\"Robot Dreams: The Strange Tale Of A Man's Quest To Rebuild His Mechanical Childhood Friend\". The Cleveland Free Times. Archived from the original on 15 January 2010. Retrieved 25 September 2008.^Schaut, Scott (2006). Robots of Westinghouse: 1924-Today. Mansfield Memorial Museum. ISBN\u00a0978-0-9785844-1-2.^Secrets of the Flying Bomb Revealed: Special Sectional Drawing and How the Robot's Flight and Dive are Controlled Automatically. Illustrated London News. 1944.^Holland, Owen. \"The Grey Walter Online Archive\". Archived from the original on 9 October 2008. Retrieved 25 September 2008.^Waurzyniak, Patrick (July 2006). \"Masters of Manufacturing: Joseph F. Engelberger\". Society of Manufacturing Engineers. 137 (1). Archived from the original on 9 November 2011. Retrieved 25 September 2008.^\"Robot Hall of Fame \u2013 Unimate\". Carnegie Mellon University. Retrieved 26 September 2023.^\"Company History\". Fuji Yusoki Kogyo Co. Archived from the original on 4 February 2013. Retrieved 12 September 2008.^\"KUKA Industrial Robot FAMULUS\". Archived from the original on 10 June 2013. Retrieved 10 January 2008.^\"History of Industrial Robots\"(PDF). Archived from the original(PDF) on 24 December 2012. Retrieved 27 October 2012.^\"History of Industrial Robots\". robots.com. Archived from the original on 8 July 2015. Retrieved 24 August 2015.^\"About us\". Archived from the original on 9 January 2014.^\"RoboHon: Cute little Robot cum Smartphone | Codexify\". Archived from the original on 7 October 2015. Retrieved 6 October 2015.^Tesfaye, Mehret (13 August 2009). \"Robots to get their own operating system\". Ethiopian Review. Archived from the original on 18 September 2009.^Myoken, Yumiko (January 2009). Research and Development for Next-generation Service Robots in Japan (United Kingdom Foreign Ministry report). Science and Innovation Section, British Embassy, Tokyo, Japan. Archived from the original on 23 July 2012.^Dahiya, Ravinder S.; Valle, Maurizio (30 July 2012). Robotic Tactile Sensing \u2013 Technologies and System. Springer. doi:10.1007/978-94-007-0579-1. ISBN\u00a0978-94-007-0578-4. Archived from the original on 29 December 2013. Retrieved 8 February 2014.^Dahiya, Ravinder S.; Metta, Giorgio; Cannata, Giorgio; Valle, Maurizio (2011). \"Guest Editorial Special Issue on Robotic Sense of Touch\". IEEE Transactions on Robotics. 27 (3): 385\u2013388. Bibcode:2011ITRob..27..385D. doi:10.1109/TRO.2011.2155830. S2CID\u00a018608163.^Engelberger, Joseph F. (August 1982). \"Robotics in practice: Future capabilities\". Electronic Servicing & Technology.^McKeough, Tim (1 December 2008). \"The Caterpillar Self-Driving Dump Truck\". Fast Company. Archived from the original on 7 June 2011.^Weiss, Richard (9 December 2014). \"Self-Driving Trucks to Revolutionize Logistics, DHL Says\". Bloomberg News. Archived from the original on 22 July 2016.^Grayson, Wayne (16 October 2014). VIDEO: Why Caterpillar's autonomous mining tech is \"completely different from anything\" it's ever done. Archived from the original on 13 May 2016.^Takahashi, Kaori (23 April 2015). \"Self-driving dump trucks, automatic shovels coming to Australian mines\". Nikkei Asia. Archived from the original on 9 May 2016.^Hall, Matthew (20 October 2014). \"Forget self-driving Google cars, Australia has self-driving trucks\". The Age. Archived from the original on 26 April 2016.^Clark, Charles (19 October 2015). \"Australian mining giant Rio Tinto is using these huge self-driving trucks to transport iron ore\". Business Insider. Archived from the original on 9 May 2016.^Berman, Dennis K. (23 July 2013). \"Daddy, What Was a Truck Driver? Over the Next Two Decades, the Machines Themselves Will Take Over the Driving\". The Wall Street Journal. Archived from the original on 4 March 2017.^\"Robot can read, learn like a human\". NBC News. 6 December 2010. Archived from the original on 28 July 2020. Retrieved 10 December 2010.^Melik, James (3 January 2013). \"Robots: Brave New World moves a step closer\". Business Daily. BBC World Service. Archived from the original on 14 January 2019.^\"Kitchen robot in Riga cooks up new future for fast food\". techxplore.com. Retrieved 14 August 2021.^\"Tech May Widen the Gap Between Rich and Poor\". Futurism. Retrieved 23 August 2021.^\"Indo-European root *orbh-\". Bartleby. 12 May 2008. Archived from the original on 24 January 2009. Retrieved 8 February 2014.^\"robot\". Online Etymology Dictionary. Retrieved 26 September 2023.^\"Hank Green's First Novel Is An Absolutely Remarkable Thing\". Indianapolis Monthly. 1 October 2018. Retrieved 20 November 2019.^\"You Are Pronouncing the Word \"Robot\" Wrong\". Daily Kos. Retrieved 20 November 2019.^Ranger, Steve (20 December 2013). \"Robots of death, robots of love: The reality of android soldiers and why laws for robots are doomed to failure\". TechRepublic. Archived from the original on 27 January 2017. Retrieved 21 January 2017.^Moubarak, Paul M.; Ben-Tzvi, Pinhas (2011). \"Adaptive manipulation of a Hybrid Mechanism Mobile Robot\". 2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE). pp.\u00a0113\u2013118. doi:10.1109/ROSE.2011.6058520. ISBN\u00a0978-1-4577-0819-0. S2CID\u00a08659998.^ ab\"Smart Caddy\". Seegrid. Archived from the original on 11 October 2007. Retrieved 13 September 2007.^Zhang, Gexiang; P\u00e9rez-Jim\u00e9nez, Mario J.; Gheorghe, Marian (5 April 2017). Real-life Applications with Membrane Computing. Springer. ISBN\u00a0978-3-319-55989-6.^Kagan, E.; Shvalb, N.; Gal, I. (2019). Autonomous Mobile Robots and Multi-Robot Systems: Motion-Planning, Communication, and Swarming. John Wiley and Sons. ISBN\u00a0978-1-119-21286-7.PP 65-69.^Patic, Deepack; Ansari, Munsaf; Tendulkar, Dilisha; Bhatlekar, Ritesh; Naik, Vijaykumar; Shailendra, Pawar (2020). \"A Survey On Autonomous Military Service Robot\". 2020 International Conference on Emerging Trends in Information Technology and Engineering (Ic-ETITE). IEEE International Conference on Emerging Trends in Information Technology and Engineering. pp.\u00a01\u20137. doi:10.1109/ic-ETITE47903.2020.78. ISBN\u00a0978-1-7281-4142-8. S2CID\u00a0216588335.^\"Definition of a robot\"(PDF). Dansk Robot Forening. Archived from the original(PDF) on 28 June 2007. Retrieved 10 September 2007.^\"Robotics-related Standards Sites\". European Robotics Research Network. Archived from the original on 17 June 2006. Retrieved 15 July 2008.^Lloyd, Caroline; Payne, Jonathan (November 2023). \"Digital skills in context: Working with robots in lower-skilled jobs\". Economic and Industrial Democracy. 44 (4): 1084\u20131104. doi:10.1177/0143831X221111416. hdl:2086/21987. ISSN\u00a00143-831X.^\"Service Robots\". International Federation of Robotics. 27 October 2012. Archived from the original on 18 February 2010.^Mitgang, Lee (25 October 1983). \"'Nova's' 'Talking Turtle' Profiles High Priest of School Computer Movement\". Gainesville Sun.^Barnard, Jeff (January 29, 1985). \"Robots In School: Games Or Learning?\". Observer-Reporter. Washington. Archived from the original on September 22, 2015. Retrieved March 7, 2012.^\"Education: Marvel of the Bronx\". Time. April 1974. Archived from the original on 24 May 2019. Retrieved 19 May 2019.^\"Leachim Archives\". cyberneticzoo.com. 13 September 2010. Archived from the original on 28 May 2019. Retrieved 29 May 2019.^P. Moubarak, et al., Modular and Reconfigurable Mobile Robotics, Journal of Robotics and Autonomous Systems, 60 (12) (2012) 1648\u20131663.^R\u00e9daction (25 December 2011). \"Le consortium franco-qu\u00e9b\u00e9cois Mix d\u00e9voile son projet de voiture volante\" (in French). aerobuzz.fr. Archived from the original on 6 October 2012. Retrieved 7 September 2012.^Scanlan, Steve (September 2009). \"Modularity in robotics provides automation for all\". Electronic Products and Technology. Archived from the original on 5 July 2012. Retrieved 7 September 2012.^\"Duct cleaning robots\"(PDF). Robotics Design Inc. Plumbing & HVAC. April 2010. Archived(PDF) from the original on 25 April 2013. Retrieved 29 April 2010.^\"Universal Robots collaborate outside enclosures | Control Engineering\". Controleng.com. February 2013. Archived from the original on 18 May 2013. Retrieved 4 June 2013.^Pittman, Kagan (19 May 2016). \"INFOGRAPHIC: A Brief History of Collaborative Robots\". Engineering.com. Archived from the original on 10 June 2016.^Hagerty, James (18 September 2012). \"Baxter Robot Heads to Work'\". The Wall Street Journal. New York. Archived from the original on 10 April 2015. Retrieved 29 May 2014.^Markoff, John (18 September 2012). \"A Robot With a Reassuring Touch\". The New York Times. Archived from the original on 19 September 2012. Retrieved 18 September 2012.^\"A Ping-Pong-Playing Terminator\". Popular Science. Archived from the original on 29 March 2011. Retrieved 18 December 2010.^\"Best robot 2009\". Neterion. Tech Magazine. Archived from the original on 27 December 2022.^\"Robots Today and Tomorrow: IFR Presents the 2007 World Robotics Statistics Survey\". RobotWorx. 29 October 2007. Archived from the original on 5 February 2008. Retrieved 14 December 2007.^\"Japan's robots slug it out to be world champ\". Reuters. 2 December 2007. Archived from the original on 13 December 2007. Retrieved 1 January 2007.^ abHo, C. C.; MacDorman, K. F.; Pramono, Z. A. D. (2008). Human emotion and the uncanny valley: A GLM, MDS, and ISOMAP analysis of robot video ratings(PDF). 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI). Archived(PDF) from the original on 11 September 2008. Retrieved 24 September 2008.^ ab\"AI Topics / Ethics\". Association for the Advancement of Artificial Intelligence. Archived from the original on 5 August 2011.^\"Robots can be racist and sexist, new study warns\". TRT World. Retrieved 27 June 2022.^\"News Index by Topic - ETHICAL & SOCIAL IMPLICATIONS Archive\". Association for the Advancement of Artificial Intelligence. Archived from the original on 6 April 2012.^McNealy, Kristie (29 July 2009). \"Scientists Predict Artificial Brain in 10 Years\". Archived from the original on 29 November 2009.^Moravec, Hans (1999). Robot: Mere Machine to Transcendent Mind. Oxford University Press. ISBN\u00a0978-0-19-513630-2. Archived from the original on 5 December 2016.^Weigand, Matthew (17 August 2009). \"Robots Almost Conquering Walking, Reading, Dancing\". Korea IT times. Archived from the original on 21 July 2011.^Schanze, Jens. \"Plug & Pray\". Archived from the original on 12 February 2016.^ abMarkoff, John (26 July 2009). \"Scientists Worry Machines May Outsmart Man\". The New York Times. Archived from the original on 1 July 2017.^Vinge, Vernor (1993). \"The Coming Technological Singularity: How to Survive in the Post-Human Era\". Archived from the original on 1 January 2007.^Singer, P. W. (21 May 2009). \"Gaming the Robot Revolution: A military technology expert weighs in on Terminator: Salvation\". Slate. Archived from the original on 27 January 2010.^\"Robot takeover\". gyre.org. Archived from the original on 19 April 2012.^\"Robotapocalypse\". Engadget. Archived from the original on 4 May 2018.^Palmer, Jason (3 August 2009). \"Call for debate on killer robots\". BBC News. Archived from the original on 7 August 2009.^Axe, David (13 August 2009). \"Robot three-way portends autonomous future\". Wired. Archived from the original on 7 November 2012.^Mick, Jason (17 February 2009). \"New Navy-funded Report Warns of War Robots Going \"Terminator\"\". DailyTech. Archived from the original on 28 July 2009.^Flatley, Joseph L. (18 February 2009). \"Navy report warns of robot uprising, suggests a strong moral compass\". Engadget. Archived from the original on 4 June 2011.^Lamb, Gregory M. (17 February 2010). \"New role for robot warriors\". The Christian Science Monitor. Archived from the original on 24 September 2015.^\"Biomass-Eating Military Robot Is a Vegetarian, Company Says\". Fox News. 16 July 2009. Archived from the original on 3 August 2009. Retrieved 31 July 2009.^Shachtman, Noah (17 July 2009). \"Danger Room What's Next in National Security Company Denies its Robots Feed on the Dead\". Wired. Archived from the original on 29 July 2009. Retrieved 31 July 2009.^\"Cyclone Power Technologies Responds to Rumors about \"Flesh Eating\" Military Robot\"(PDF) (Press release). RTI Inc. 16 July 2009. pp.\u00a01\u20132. Archived(PDF) from the original on 23 August 2009.^\"Brief Project Overview, EATR: Energetically Autonomous Tactical Robot\"(PDF). RTI Inc. 6 April 2009. p.\u00a022.^Manuel de Landa, War in the Age of Intelligent Machines, New York: Zone Books, 1991, 280 pages, Hardcover, ISBN\u00a00-942299-76-0; Paperback, ISBN\u00a00-942299-75-2.^McGaughey, E (2022) [January 10, 2018]. \"Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy\". Industrial Law Journal. 51 (3). doi:10.2139/ssrn.3119589. SSRN\u00a03119589.^Porter, Eduardo; Manjoo, Farhad (9 March 2016). \"A Future Without Jobs? Two Views of the Changing Work Force\". The New York Times. Archived from the original on 15 February 2017. Retrieved 23 February 2017.^Thompson, Derek (July\u2013August 2015). \"A World Without Work\". The Atlantic. Archived from the original on 27 February 2017. Retrieved 11 March 2017.^Yan (30 July 2011). \"Foxconn to replace workers with 1 million robots in 3 years\". Xinhua News Agency. Archived from the original on 8 October 2011. Retrieved 4 August 2011.^\"Judgment day \u2013 employment law and robots in the workplace\". futureofworkhub. 20 November 2014. Archived from the original on 3 April 2015. Retrieved 7 January 2015.^Delaney, Kevin (17 February 2017). \"The robot that takes your job should pay taxes, says Bill Gates\". Quartz. Archived from the original on 5 March 2017. Retrieved 4 March 2017.^\"The Changing Nature of Work\". Archived from the original on 30 September 2018. Retrieved 8 October 2018.^Talbot, Ben; Dayoub, Feras; Corke, Peter; Wyeth, Gordon (December 2021). \"Robot Navigation in Unseen Spaces Using an Abstract Map\". IEEE Transactions on Cognitive and Developmental Systems. 13 (4): 791\u2013805. arXiv:2001.11684. Bibcode:2021ITCDS..13..791T. doi:10.1109/TCDS.2020.2993855. ISSN\u00a02379-8939. S2CID\u00a0211004032.^\"Contact Systems Pick and Place robots\". Contact Systems. Archived from the original on 14 September 2008. Retrieved 21 September 2008.^\"SMT pick-and-place equipment\". Assembleon. Archived from the original on 3 August 2008. Retrieved 21 September 2008.^\"The Basics of Automated Guided Vehicles\". Savant Automation, AGV Systems. Archived from the original on 8 October 2007. Retrieved 13 September 2007.^\"Automatic Trailer Loading Vehicle - SmartLoader\". Archived from the original on 23 May 2013. Retrieved 2 September 2011.^\"SpeciMinder\". CSS Robotics. Archived from the original on 1 July 2009. Retrieved 25 September 2008.^\"ADAM robot\". RMT Robotics. Archived from the original on 17 May 2006. Retrieved 25 September 2008.^\"Can Do\". Aethon. Archived from the original on 3 August 2008. Retrieved 25 September 2008.^\"Eskorta robot\". Fennec Fox Technologies. Archived from the original on 6 December 2011. Retrieved 25 November 2011.^\"Delivery Robots & AGVs\". Mobile Robots. Archived from the original on 26 February 2010. Retrieved 25 September 2008.^\"Dante II, list of published papers\". The Robotics Institute of Carnegie Mellon University. Archived from the original on 15 May 2008. Retrieved 16 September 2007.^\"Mars Pathfinder Mission: Rover Sojourner\". NASA. 8 July 1997. Archived from the original on 1 February 2017. Retrieved 19 September 2007.^ ab\"Robot assisted surgery: da Vinci Surgical System\". Brown University Division of Biology and Medicine. Archived from the original on 16 September 2007. Retrieved 19 September 2007.^\"The Utilization of Robotic Space Probes in Deep Space Missions:Case Study of AI Protocols and Nuclear Power Requirements\". Proceedings of 2011 International Conference on Mechanical Engineering, Robotics and Aerospace. October 2011.^Foust, Jeff (16 January 2012). \"Review: Space Probes\". Archived from the original on 31 August 2012. Review of Space Probes: 50 Years of Exploration from Luna 1 to New Horizons, by Philippe S\u00e9gu\u00e9la Firefly, 2011.^\"Celebrities set to reach for Atwood's LongPen\". Canadian Broadcasting Corporation. 15 August 2007. Archived from the original on 22 May 2009. Retrieved 21 September 2008.^Graham, Stephen (12 June 2006). \"America's robot army\". New Statesman. Archived from the original on 17 February 2012. Retrieved 24 September 2007.^\"Battlefield Robots: to Iraq, and Beyond\". Defense Industry Daily. 20 June 2005. Archived from the original on 26 August 2007. Retrieved 24 September 2007.^Shachtman, Noah (November 2005). \"The Baghdad Bomb Squad\". Wired. Archived from the original on 22 April 2008. Retrieved 14 September 2007.^Shachtman, Noah (2 August 2007). \"WIRED: First Armed Robots on Patrol in Iraq (Updated)\". Wired. Retrieved 26 September 2023.^Shachtman, Noah (28 March 2013). \"WIRED: Armed Robots Pushed To Police\". Wired. Archived from the original on 12 April 2009. Retrieved 8 February 2014.^\"America's Robot Army: Are Unmanned Fighters Ready for Combat?\". Popular Mechanics. 17 December 2009. Retrieved 26 September 2023.^Hagerman, Eric (23 February 2010). \"The Present and Future of Unmanned Drone Aircraft: An Illustrated Field Guide\". Popular Science. Archived from the original on 26 February 2010.^Higgins, Kat (12 July 2010). \"Taranis: The \u00a3143m Fighter Jet Of The Future\". Sky News Online. Archived from the original on 15 July 2010. Retrieved 13 July 2010.^Emery, Daniel (12 July 2010). \"MoD lifts lid on unmanned combat plane prototype\". BBC News. Archived from the original on 12 July 2010. Retrieved 12 July 2010.^AAAI Presidential Panel on Long-Term AI Futures 2008\u20132009 Study (Report). Association for the Advancement of Artificial Intelligence. Archived from the original on 28 August 2009. Retrieved 26 July 2009.^\"Why We Need Friendly AI\". 3 Laws Unsafe. July 2004. Archived from the original on 24 May 2012. Retrieved 27 July 2009.^\"Robotic age poses ethical dilemma\". BBC News. 7 March 2007. Archived from the original on 15 February 2009. Retrieved 2 January 2007.^Christensen, Bill (26 May 2006). \"Asimov's First Law: Japan Sets Rules for Robots\". Live Science. Archived from the original on 13 October 2008.^\"Japan drafts rules for advanced robots\". UPI. 6 April 2007. Archived from the original on 11 October 2008 \u2013 via physorg.com.^\"Building a Safe and Secure Social System Incorporating the Coexistence of Humans and Robots\" (Press release). Ministry of Economy, Trade and Industry. March 2009. Archived from the original on 27 September 2011.^Weng, Yueh-Hsuan; Chen, Chien-Hsun; Sun, Chuen-Tsai (25 April 2009). \"Toward the Human\u2013Robot Co-Existence Society: On Safety Intelligence for Next Generation Robots\". International Journal of Social Robotics. 1 (4): 267\u2013282. doi:10.1007/s12369-009-0019-1. S2CID\u00a036232530.^Fox, Stuart (19 August 2009). \"Evolving Robots Learn To Lie To Each Other\". Popular Science.^\"Rio Tinto Media Center \u2013 Rio Tinto boosts driverless truck fleet to 150 under Mine of the Future\u2122 programme\". Riotinto.com. Archived from the original on 24 April 2013. Retrieved 8 February 2014.^\"BHP Billiton hits go on autonomous drills\". Retrieved 13 February 2023.^Adrian (6 September 2011). \"AIMEX blog \u2013 Autonomous mining equipment\". Adrianboeing.blogspot.com. Archived from the original on 18 December 2013. Retrieved 8 February 2014.^\"Atlas Copco \u2013 RCS\". Atlascopco.com. Archived from the original on 7 February 2014. Retrieved 8 February 2014.^\"Transmin \u2013 Rocklogic\". Rocklogic.com.au. Archived from the original on 25 January 2014. Retrieved 8 February 2014.^Topping, Mike; Smith, Jane (1999). \"An Overview Of Handy 1, A Rehabilitation Robot For The Severely Disabled\". CSUN Center on Disabilities Conference Proceedings. 1999. Proceedings: Session 59. Archived from the original on 5 August 2009. Retrieved 14 August 2010. The early version of the Handy 1 system consisted of a Cyber 310 robotic arm with five degrees of freedom plus a gripper.^Jeavans, Christine (29 November 2004). \"Welcome to the ageing future\". BBC News. Archived from the original on 16 October 2007. Retrieved 26 September 2007.^\"Statistical Handbook of Japan: Chapter 2 Population\". Statistics Bureau & Statistical Research and Training Institute. Archived from the original on 6 September 2013. Retrieved 26 September 2007.^\"Robotic future of patient care\". E-Health Insider. 16 August 2007. Archived from the original on 21 November 2007. Retrieved 26 September 2007.^Gebhart, Fred (4 July 2019). \"The Future of Pharmacy Automation\". Drug Topics Journal. Drug Topics July 2019. 163 (7). Retrieved 16 October 2022.^Dolan, Kerry A. \"R2D2 Has Your Pills\". Forbes. Retrieved 20 November 2019.^\"Nanobots Play Football\". Techbirbal. Archived from the original on 3 April 2013. Retrieved 8 February 2014.^\"KurzweilAI.net\". 21 June 2010. Archived from the original on 21 June 2010. Retrieved 5 July 2016.^\"(Eric Drexler 1986) Engines of Creation, The Coming Era of Nanotechnology\". E-drexler.com. Archived from the original on 6 September 2014. Retrieved 8 February 2014.^Phoenix, Chris (December 2003). \"Of Chemistry, Nanobots, and Policy\". Center for Responsible Nanotechnology. Archived from the original on 11 October 2007. Retrieved 28 October 2007.^\"Nanotechnology pioneer slays 'grey goo' myths\". ScienceDaily. 9 June 2004.^Toth-Fejel, Tihamer (May 1996). LEGO(TM)s to the Stars: Active MesoStructures, Kinetic Cellular Automata, and Parallel Nanomachines for Space Applications. 1996 International Space Development Conference. New York City. Archived from the original on 27 September 2007.^Fitch, Robert; Butler, Zack; Rus, Daniela. \"Reconfiguration Planning for Heterogeneous Self-Reconfiguring Robots\"(PDF). Massachusetts Institute of Technology. Archived from the original(PDF) on 19 June 2007.^\"Researchers build robot scientist that has already discovered a new catalyst\". phys.org. Retrieved 16 August 2020.^Burger, Benjamin; Maffettone, Phillip M.; Gusev, Vladimir V.; Aitchison, Catherine M.; Bai, Yang; Wang, Xiaoyan; Li, Xiaobo; Alston, Ben M.; Li, Buyi; Clowes, Rob; Rankin, Nicola; Harris, Brandon; Sprick, Reiner Sebastian; Cooper, Andrew I. (July 2020). \"A mobile robotic chemist\". Nature. 583 (7815): 237\u2013241. Bibcode:2020Natur.583..237B. doi:10.1038/s41586-020-2442-2. ISSN\u00a01476-4687. PMID\u00a032641813. S2CID\u00a0220420261. Retrieved 16 August 2020.^Schwartz, John (27 March 2007). \"In the Lab: Robots That Slink and Squirm\". The New York Times. Archived from the original on 3 April 2015. Retrieved 22 September 2008.^Eschner, Kat (25 March 2019). \"Squishy robots now have squishy computers to control them\". Popular Science.^\"The softer side of robotics\". May 2019. Retrieved 13 February 2023.^\"SRI/MobileRobots\". activrobots.com. Archived from the original on 12 February 2009.^\"Open-source micro-robotic project\". Archived from the original on 11 November 2007. Retrieved 28 October 2007.^\"Swarm\". iRobot Corporation. Archived from the original on 27 September 2007. Retrieved 28 October 2007.^Knapp, Louise (21 December 2000). \"Look, Up in the Sky: Robofly\". Wired. Archived from the original on 26 June 2012. Retrieved 25 September 2008.^\"The Cutting Edge of Haptics\". MIT Technology review. Retrieved 25 September 2008.^\"Artists & Robots Exposition au Grand Palais du 5 avril au 9 juillet 2018\". 14 August 2019. Archived from the original on 14 August 2019. Retrieved 3 February 2020.^\"Comic Potential: Q&A with Director Stephen Cole\". Cornell University. Archived from the original on 3 January 2009. Retrieved 21 November 2007.^Freedman, Carl, ed. (2005). Conversations with Isaac Asimov (1.\u00a0ed.). Jackson: Univ. Press of Mississippi. p.\u00a0vii. ISBN\u00a0978-1-57806-738-1. Retrieved 4 August 2011. ... quite possibly the most prolific^Oakes, Elizabeth H. (2004). American writers. New York: Facts on File. p.\u00a024. ISBN\u00a0978-0-8160-5158-8. Retrieved 4 August 2011. most prolific authors asimov.^He wrote \"over 460 books as well as thousands of articles and reviews\", and was the \"third most prolific writer of all time [and] one of the founding fathers of modern science fiction\". White, Michael (2005). Isaac Asimov: a life of the grand master of science fiction. Carroll & Graf. pp.\u00a01\u20132. ISBN\u00a0978-0-7867-1518-3. Archived from the original on 5 December 2016. Retrieved 25 September 2016.^R. Clarke. \"Asimov's Laws of Robotics \u2013 Implications for Information Technology\". Australian National University/IEEE. Archived from the original on 22 July 2008. Retrieved 25 September 2008.^Seiler, Edward; Jenkins, John H. (27 June 2008). \"Isaac Asimov FAQ\". Isaac Asimov Home Page. Archived from the original on 16 July 2012. Retrieved 24 September 2008.^White, Michael (2005). Isaac Asimov: A Life of the Grand Master of Science Fiction. Carroll & Graf. p.\u00a056. ISBN\u00a0978-0-7867-1518-3.^\"Intelligent machines: Call for a ban on robots designed as sex toys\". BBC News. 15 September 2015. Archived from the original on 30 June 2018. Retrieved 21 June 2018.^Abdollahi, Hojjat; Mollahosseini, Ali; Lane, Josh T.; Mahoor, Mohammad H. (November 2017). A pilot study on using an intelligent life-like robot as a companion for elderly individuals with dementia and depression. 2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids). pp.\u00a0541\u2013546. arXiv:1712.02881. Bibcode:2017arXiv171202881A. doi:10.1109/humanoids.2017.8246925. ISBN\u00a0978-1-5386-4678-6. S2CID\u00a01962455.External links.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Wikiquote has quotations related to Robot.Journal of Field Robotics.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutlinevteMachinesClassical simple machinesInclined planeLeverPulleyScrewWedgeWheel and axleClocksAtomic clockChronometerPendulum clockQuartz clockCompressors and pumpsArchimedes' screwEductor-jet pumpHydraulic ramPumpTrompeVacuum pumpExternal combustion enginesSteam engineStirling engineInternal combustion enginesGas turbineReciprocating engineRotary engineNutating disc engineLinkagesPantographPeaucellier-LipkinTurbineGas turbineJet engineSteam turbineWater turbineWind generatorWindmillAerofoilSailWingRudderFlapPropellerElectronicsVacuum tubeTransistorDiodeResistorCapacitorInductorVehiclesAutomobileMiscellaneousMechaRobotAgriculturalSeed-counting machineVending machineWind tunnelCheck weighing machinesRiveting machinesSpringsSpring (device)vteScience fictionOutlineAuthorsDefinitionsAnthropologicalHardScientific romanceSoftHistoryPulp eraGolden AgeNew WaveTimelineSubgenresApocalyptic and post-apocalypticComedySitcomsFeministGrimdarkInner spaceMechaAnime and mangaMundaneSpace warfareMilitarySpace operaSpace WesternParallel universesIsekaiScience fantasyDying EarthPlanetary romanceSuperheroSword and planetSocialClimate fictionChristianLibertarianUtopian and dystopianTech noirSpy-FiTechno-thrillerTokusatsuKaijuUnderwaterCyberpunk derivativesCyberpunkJapaneseBiopunkDieselpunkNanopunkSolarpunkSteampunkCultureConventionsFandomFanzinesISFDBLibraries and museumsScience Fiction MuseumStudiesWomen in SFWorldconRegionAustralianBengaliBrazilianCanadianChileanChineseCroatianCzechEstonianFrenchHungarianJapaneseKoreanNorwegianPolishRomanianRussianSerbianSpanishYugoslavAwardsCinematicJules VerneSaturnLiterary, art,and audioAstoundingAurealisBSFACampbell MemorialChesleyClarkeCrookDeutscherDickDitmarEndeavorFantLabGalaxyGaughanGeffenGolden DuckGrand MasterGrand PrixHarlandHeinleinIgnotusKitschiesLambdaLa\u00dfwitzLocusNautilusNebulaNommoNortonParsecPrometheusRhyslingSFERASidewiseSkylarkSturgeonSunburstT\u00e4htivaeltajaTBDTiptreeTour-ApolloTranslationUraniaVogelWriters and Illustrators of the FutureZajdelMultimediaAuroraChandlerDragonHugoSeiunSpectrumMediaFilmFilm historyFilmsIndianJapaneseAnimeTokusatsuLiteratureComicsMagazinesNovelsPublishersShort storiesStageOperaTheatreTelevisionList of TV showsAustralasianBritishCanadianEuropeanJapaneseAnimeLive-actionU.S.ThemesArchitecturalDyson sphereEcumenopolisMatrioshka brainSpace stations and habitatsStellar engineTerraformingTopopolisBiologicalBiological warfareEvolutionExtraterrestrialsListGenderGenetic engineeringInvisibilityNanotechnologyOrgan transplantationParasitismSex and sexualitySuperhumansSymbiosisPhysicalBlack holesExtrasolar planetsMultiverseParallel universesListPortable holeSpace travelStarsTachyonsTeleportationTime travelTime viewerWormholePsychologicalGroup mindMind uploadingPsionicsSimulated consciousnessSocialAfricanfuturismAfrofuturismAlien invasionAlien languageAncient astronautsBlackEvil corporationFirst contactFrankenstein complexGalactic empireLGBTMessage from spaceTranshumanismUpliftXenoarchaeologyTechnologicalAnsibleArtificial intelligenceAI takeoverAstroengineeringForce fieldHolographyHyperspaceInertialessRobots and CyborgsSelf-replicating machinesSimulated realitySpacecraftStargateWarp driveWeaponsReligiousChristian science fictionRelatedAlternate historyFantasyFictional astronautsFictional technologyFuture historyHorrorMagic realismMuseum of Science FictionRubber scienceScience and technology studiesSense of wonderSpeculative fictionSupernaturalTechnology and societyWeirdCategoryPortal.mw-parser-output .sister-bar{display:flex;justify-content:center;align-items:baseline;font-size:88%;background-color:#fdfdfd;border:1px solid #a2a9b1;clear:both;margin:1em 0 0;padding:0 2em}.mw-parser-output .sister-bar-header{margin:0 1em 0 0.5em;padding:0.2em 0;flex:0 0 auto;min-height:24px;line-height:22px}.mw-parser-output .sister-bar-content{display:flex;flex-flow:row wrap;flex:0 1 auto;align-items:baseline;padding:0.2em 0;column-gap:1em;margin:0;list-style:none}.mw-parser-output .sister-bar-item{display:flex;align-items:baseline;margin:0.15em 0;min-height:24px;text-align:left}.mw-parser-output .sister-bar-logo{width:22px;line-height:22px;margin:0 3px 0 2px;text-align:right}.mw-parser-output .sister-bar-link{margin:0 2px 0 4px;text-align:left}@media screen and (max-width:960px){.mw-parser-output .sister-bar{flex-flow:column wrap;margin:1em auto 0}.mw-parser-output .sister-bar-header{flex:0 1}.mw-parser-output .sister-bar-content{flex:1;border-top:1px solid #a2a9b1;margin:0;list-style:none}.mw-parser-output .sister-bar-item{flex:0 0 20em;min-width:20em}}.mw-parser-output .navbox+link+.sister-bar,.mw-parser-output .navbox+style+.sister-bar,.mw-parser-output .portal-bar+link+.sister-bar,.mw-parser-output .portal-bar+style+.sister-bar,.mw-parser-output .sister-bar+.navbox-styles+.navbox,.mw-parser-output .sister-bar+.navbox-styles+.portal-bar{margin-top:-1px}@media print{body.ns-0 .mw-parser-output .sister-bar{display:none!important}}Robot at Wikipedia's sister projects:Definitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from Wikiversity.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDFASTNationalUnited States2FranceBnF dataJapanCzech RepublicIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robot&oldid=1312300730\"", "tags": ["en.wikipedia.org", "wiki", "robot"]}
{"url": "https://en.wikipedia.org/wiki/Reinforcement_learning", "title": null, "text": "Field of machine learning.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For reinforcement learning in psychology, see Reinforcement and Operant conditioning. The typical framing of a reinforcement learning (RL) scenario: an agent takes actions in an environment, which is interpreted into a reward and a state representation, which are fed back to the agent..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}.mw-parser-output .nobold{font-weight:normal}Part of a series onMachine learningand data miningParadigmsSupervised learningUnsupervised learningSemi-supervised learningSelf-supervised learningReinforcement learningMeta-learningOnline learningBatch learningCurriculum learningRule-based learningNeuro-symbolic AINeuromorphic engineeringQuantum machine learningProblemsClassificationGenerative modelingRegressionClusteringDimensionality reductionDensity estimationAnomaly detectionData cleaningAutoMLAssociation rulesSemantic analysisStructured predictionFeature engineeringFeature learningLearning to rankGrammar inductionOntology learningMultimodal learningSupervised learning(classification\u00a0\u2022 regression)Apprenticeship learningDecision treesEnsemblesBaggingBoostingRandom forestk-NNLinear regressionNaive BayesArtificial neural networksLogistic regressionPerceptronRelevance vector machine (RVM)Support vector machine (SVM)ClusteringBIRCHCUREHierarchicalk-meansFuzzyExpectation\u2013maximization (EM)DBSCANOPTICSMean shiftDimensionality reductionFactor analysisCCAICALDANMFPCAPGDt-SNESDLStructured predictionGraphical modelsBayes netConditional random fieldHidden MarkovAnomaly detectionRANSACk-NNLocal outlier factorIsolation forestNeural networksAutoencoderDeep learningFeedforward neural networkRecurrent neural networkLSTMGRUESNreservoir computingBoltzmann machineRestrictedGANDiffusion modelSOMConvolutional neural networkU-NetLeNetAlexNetDeepDreamNeural fieldNeural radiance fieldPhysics-informed neural networksTransformerVisionMambaSpiking neural networkMemtransistorElectrochemical RAM (ECRAM)Reinforcement learningQ-learningPolicy gradientSARSATemporal difference (TD)Multi-agentSelf-playLearning with humansActive learningCrowdsourcingHuman-in-the-loopMechanistic interpretabilityRLHFModel diagnosticsCoefficient of determinationConfusion matrixLearning curveROC curveMathematical foundationsKernel machinesBias\u2013variance tradeoffComputational learning theoryEmpirical risk minimizationOccam learningPAC learningStatistical learningVC theoryTopological deep learningJournals and conferencesAAAIECML PKDDNeurIPSICMLICLRIJCAIMLJMLRRelated articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteIn machine learning and optimal control, reinforcement learning (RL) is concerned with how an intelligent agent should take actions in a dynamic environment in order to maximize a reward signal. Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\nReinforcement learning differs from supervised learning in not needing labelled input-output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the cumulative reward (the feedback of which might be incomplete or delayed).[1] The search for this balance is known as the exploration\u2013exploitation dilemma.\n\nThe environment is typically stated in the form of a Markov decision process, as many reinforcement learning algorithms use dynamic programming techniques.[2] The main difference between classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process, and they target large Markov decision processes where exact methods become infeasible.[3].mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}Principles[edit]Due to its generality, reinforcement learning is studied in many disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, and statistics. In the operations research and control literature, RL is called approximate dynamic programming, or neuro-dynamic programming. The problems of interest in RL have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation (particularly in the absence of a mathematical model of the environment).\nBasic reinforcement learning is modeled as a Markov decision process:\nA set of environment and agent states (the state space), \n  \n    \n      \n        \n          \n            S\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {S}}}\n  ;A set of actions (the action space), \n  \n    \n      \n        \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {A}}}\n  , of the agent;\n  \n    \n      \n        \n          P\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n        =\n        Pr\n        (\n        \n          S\n          \n            t\n            +\n            1\n          \n        \n        \n          =\n        \n        \n          s\n          \u2032\n        \n        \u2223\n        \n          S\n          \n            t\n          \n        \n        \n          =\n        \n        s\n        ,\n        \n          A\n          \n            t\n          \n        \n        \n          =\n        \n        a\n        )\n      \n    \n    {\\displaystyle P_{a}(s,s')=\\Pr(S_{t+1}{=}s'\\mid S_{t}{=}s,A_{t}{=}a)}\n  , the transition probability (at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ) from state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to state \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   under action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .\n  \n    \n      \n        \n          R\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle R_{a}(s,s')}\n  , the immediate reward after transition from \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   under action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .The purpose of reinforcement learning is for the agent to learn an optimal (or near-optimal) policy that maximizes the reward function or other user-provided reinforcement signal that accumulates from immediate rewards. This is similar to processes that appear to occur in animal psychology. For example, biological brains are hardwired to interpret signals such as pain and hunger as negative reinforcements, and interpret pleasure and food intake as positive reinforcements. In some circumstances, animals learn to adopt behaviors that optimize these rewards. This suggests that animals are capable of reinforcement learning.[4][5]A basic reinforcement learning agent interacts with its environment in discrete time steps. At each time step t, the agent receives the current state \n  \n    \n      \n        \n          S\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle S_{t}}\n   and reward \n  \n    \n      \n        \n          R\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle R_{t}}\n  . It then chooses an action \n  \n    \n      \n        \n          A\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle A_{t}}\n   from the set of available actions, which is subsequently sent to the environment. The environment moves to a new state \n  \n    \n      \n        \n          S\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle S_{t+1}}\n   and the reward \n  \n    \n      \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle R_{t+1}}\n   associated with the transition\n  \n    \n      \n        (\n        \n          S\n          \n            t\n          \n        \n        ,\n        \n          A\n          \n            t\n          \n        \n        ,\n        \n          S\n          \n            t\n            +\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (S_{t},A_{t},S_{t+1})}\n   is determined. The goal of a reinforcement learning agent is to learn a policy:\n\n  \n    \n      \n        \n          \n            \n              \n              \n                \u03c0\n                :\n                \n                  \n                    S\n                  \n                \n                \u00d7\n                \n                  \n                    A\n                  \n                \n                \u2192\n                [\n                0\n                ,\n                1\n                ]\n              \n            \n            \n              \n              \n                \u03c0\n                (\n                s\n                ,\n                a\n                )\n                =\n                Pr\n                (\n                \n                  A\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                a\n                \u2223\n                \n                  S\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                s\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {S}}\\times {\\mathcal {A}}\\to [0,1]\\\\&\\pi (s,a)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\n  that maximizes the expected cumulative reward.\nFormulating the problem as a Markov decision process assumes the agent directly observes the current environmental state; in this case, the problem is said to have full observability. If the agent only has access to a subset of states, or if the observed states are corrupted by noise, the agent is said to have partial observability, and formally the problem must be formulated as a partially observable Markov decision process. In both cases, the set of actions available to the agent can be restricted. For example, the state of an account balance could be restricted to be positive; if the current value of the state is 3 and the state transition attempts to reduce the value by 4, the transition will not be allowed.\nWhen the agent's performance is compared to that of an agent that acts optimally, the difference in performance yields the notion of regret. In order to act near optimally, the agent must reason about long-term consequences of its actions (i.e., maximize future rewards), although the immediate reward associated with this might be negative.\nThus, reinforcement learning is particularly well-suited to problems that include a long-term versus short-term reward trade-off. It has been applied successfully to various problems, including energy storage,[6]robot control,[7]photovoltaic generators,[8]backgammon, checkers,[9]Go (AlphaGo), and autonomous driving systems.[10]Two elements make reinforcement learning powerful: the use of samples to optimize performance, and the use of function approximation to deal with large environments. Thanks to these two key components, RL can be used in large environments in the following situations:\nA model of the environment is known, but an analytic solution is not available;Only a simulation model of the environment is given (the subject of simulation-based optimization);[11]The only way to collect information about the environment is to interact with it.The first two of these problems could be considered planning problems (since some form of model is available), while the last one could be considered to be a genuine learning problem. However, reinforcement learning converts both planning problems to machine learning problems.\nExploration[edit]The trade-off between exploration and exploitation has been most thoroughly studied through the multi-armed bandit problem and for finite state space Markov decision processes in Burnetas and Katehakis (1997).[12]Reinforcement learning requires clever exploration mechanisms; randomly selecting actions, without reference to an estimated probability distribution, shows poor performance. The case of (small) finite Markov decision processes is relatively well understood. However, due to the lack of algorithms that scale well with the number of states (or scale to problems with infinite state spaces), simple exploration methods are the most practical.\nOne such method is \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  -greedy, where \n  \n    \n      \n        0\n        <\n        \u03b5\n        <\n        1\n      \n    \n    {\\displaystyle 0<\\varepsilon <1}\n   is a parameter controlling the amount of exploration vs. exploitation. With probability \n  \n    \n      \n        1\n        \u2212\n        \u03b5\n      \n    \n    {\\displaystyle 1-\\varepsilon }\n  , exploitation is chosen, and the agent chooses the action that it believes has the best long-term effect (ties between actions are broken uniformly at random). Alternatively, with probability \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  , exploration is chosen, and the action is chosen uniformly at random. \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n   is usually a fixed parameter but can be adjusted either according to a schedule (making the agent explore progressively less), or adaptively based on heuristics.[13]Algorithms for control learning[edit]Even if the issue of exploration is disregarded and even if the state was observable (assumed hereafter), the problem remains to use past experience to find out which actions lead to higher cumulative rewards.\nCriterion of optimality[edit]Policy[edit]The agent's action selection is modeled as a map called policy:\n\n  \n    \n      \n        \n          \n            \n              \n              \n                \u03c0\n                :\n                \n                  \n                    A\n                  \n                \n                \u00d7\n                \n                  \n                    S\n                  \n                \n                \u2192\n                [\n                0\n                ,\n                1\n                ]\n              \n            \n            \n              \n              \n                \u03c0\n                (\n                a\n                ,\n                s\n                )\n                =\n                Pr\n                (\n                \n                  A\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                a\n                \u2223\n                \n                  S\n                  \n                    t\n                  \n                \n                \n                  =\n                \n                s\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}&\\pi :{\\mathcal {A}}\\times {\\mathcal {S}}\\to [0,1]\\\\&\\pi (a,s)=\\Pr(A_{t}{=}a\\mid S_{t}{=}s)\\end{aligned}}}\n  The policy map gives the probability of taking action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   when in state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  .[14]:\u200a61\u200a There are also deterministic policies  \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   for which \n  \n    \n      \n        \u03c0\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\pi (s)}\n   denotes the action that should be played at state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  .\nState-value function[edit]The state-value function \n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V_{\\pi }(s)}\n   is defined as, expected discounted return starting with state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  , i.e. \n  \n    \n      \n        \n          S\n          \n            0\n          \n        \n        =\n        s\n      \n    \n    {\\displaystyle S_{0}=s}\n  , and successively following policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  . Hence, roughly speaking, the value function estimates \"how good\" it is to be in a given state.[14]:\u200a60\u200a\n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        \n          S\n          \n            0\n          \n        \n        \n          =\n        \n        s\n        ]\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        \n          [\n          \n            \n              \u2211\n              \n                t\n                =\n                0\n              \n              \n                \u221e\n              \n            \n            \n              \u03b3\n              \n                t\n              \n            \n            \n              R\n              \n                t\n                +\n                1\n              \n            \n            \u2223\n            \n              S\n              \n                0\n              \n            \n            \n              =\n            \n            s\n          \n          ]\n        \n        ,\n      \n    \n    {\\displaystyle V_{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid S_{0}{=}s]=\\operatorname {\\mathbb {E} } \\left[\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}\\mid S_{0}{=}s\\right],}\n  where the random variable \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   denotes the discounted return, and is defined as the sum of future discounted rewards:\n\n  \n    \n      \n        G\n        =\n        \n          \u2211\n          \n            t\n            =\n            0\n          \n          \n            \u221e\n          \n        \n        \n          \u03b3\n          \n            t\n          \n        \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n        =\n        \n          R\n          \n            1\n          \n        \n        +\n        \u03b3\n        \n          R\n          \n            2\n          \n        \n        +\n        \n          \u03b3\n          \n            2\n          \n        \n        \n          R\n          \n            3\n          \n        \n        +\n        \u22ef\n        ,\n      \n    \n    {\\displaystyle G=\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}=R_{1}+\\gamma R_{2}+\\gamma ^{2}R_{3}+\\cdots ,}\n  where \n  \n    \n      \n        \n          R\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle R_{t+1}}\n   is the reward for transitioning from state \n  \n    \n      \n        \n          S\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle S_{t}}\n   to \n  \n    \n      \n        \n          S\n          \n            t\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle S_{t+1}}\n  ,\n  \n    \n      \n        0\n        \u2264\n        \u03b3\n        <\n        1\n      \n    \n    {\\displaystyle 0\\leq \\gamma <1}\n   is the discount rate. \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is less than 1, so rewards in the distant future are weighted less than rewards in the immediate future.\nThe algorithm must find a policy with maximum expected discounted return. From the theory of Markov decision processes it is known that, without loss of generality, the search can be restricted to the set of so-called stationary policies. A policy is stationary if the action-distribution returned by it depends only on the last state visited (from the observation agent's history). The search can be further restricted to deterministic stationary policies. A deterministic stationary policy deterministically selects actions based on the current state. Since any such policy can be identified with a mapping from the set of states to the set of actions, these policies can be identified with such mappings with no loss of generality.\nBrute force[edit]The brute force approach entails two steps:\nFor each possible policy, sample returns while following itChoose the policy with the largest expected discounted returnOne problem with this is that the number of policies can be large, or even infinite. Another is that the variance of the returns may be large, which requires many samples to accurately estimate the discounted return of each policy.\nThese problems can be ameliorated if we assume some structure and allow samples generated from one policy to influence the estimates made for others. The two main approaches for achieving this are value function estimation and direct policy search.\nValue function[edit]See also: Value functionValue function approaches attempt to find a policy that maximizes the discounted return by maintaining a set of estimates of expected discounted returns \n  \n    \n      \n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        ]\n      \n    \n    {\\displaystyle \\operatorname {\\mathbb {E} } [G]}\n   for some policy (usually either the \"current\" [on-policy] or the optimal [off-policy] one).\nThese methods rely on the theory of Markov decision processes, where optimality is defined in a sense stronger than the one above: A policy is optimal if it achieves the best-expected discounted return from any initial state (i.e., initial distributions play no role in this definition). Again, an optimal policy can always be found among stationary policies.\nTo define optimality in a formal manner, define the state-value of a policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   by\n\n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        s\n        ,\n        \u03c0\n        ]\n        ,\n      \n    \n    {\\displaystyle V^{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid s,\\pi ],}\n  where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   stands for the discounted return associated with following \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   from the initial state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  . Defining \n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V^{*}(s)}\n   as the maximum possible state-value of \n  \n    \n      \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n      \n    \n    {\\displaystyle V^{\\pi }(s)}\n  , where \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   is allowed to change,\n\n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n        =\n        \n          max\n          \n            \u03c0\n          \n        \n        \n          V\n          \n            \u03c0\n          \n        \n        (\n        s\n        )\n        .\n      \n    \n    {\\displaystyle V^{*}(s)=\\max _{\\pi }V^{\\pi }(s).}\n  A policy that achieves these optimal state-values in each state is called optimal. Clearly, a policy that is optimal in this sense is also optimal in the sense that it maximizes the expected discounted return, since \n  \n    \n      \n        \n          V\n          \n            \u2217\n          \n        \n        (\n        s\n        )\n        =\n        \n          max\n          \n            \u03c0\n          \n        \n        \n          E\n        \n        [\n        G\n        \u2223\n        s\n        ,\n        \u03c0\n        ]\n      \n    \n    {\\displaystyle V^{*}(s)=\\max _{\\pi }\\mathbb {E} [G\\mid s,\\pi ]}\n  , where \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is a state randomly sampled from the distribution \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   of initial states (so \n  \n    \n      \n        \u03bc\n        (\n        s\n        )\n        =\n        Pr\n        (\n        \n          S\n          \n            0\n          \n        \n        =\n        s\n        )\n      \n    \n    {\\displaystyle \\mu (s)=\\Pr(S_{0}=s)}\n  ).Although state-values suffice to define optimality, it is useful to define action-values. Given a state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  , an action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   and a policy \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  , the action-value of the pair \n  \n    \n      \n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle (s,a)}\n   under \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   is defined by\n\n  \n    \n      \n        \n          Q\n          \n            \u03c0\n          \n        \n        (\n        s\n        ,\n        a\n        )\n        =\n        \n          \n            E\n          \n        \n        \u2061\n        [\n        G\n        \u2223\n        s\n        ,\n        a\n        ,\n        \u03c0\n        ]\n        ,\n      \n    \n    {\\displaystyle Q^{\\pi }(s,a)=\\operatorname {\\mathbb {E} } [G\\mid s,a,\\pi ],}\n  where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   now stands for the random discounted return associated with first taking action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   in state \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   and following \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  , thereafter.\nThe theory of Markov decision processes states that if \n  \n    \n      \n        \n          \u03c0\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\pi ^{*}}\n   is an optimal policy, we act optimally (take the optimal action) by choosing the action from \n  \n    \n      \n        \n          Q\n          \n            \n              \u03c0\n              \n                \u2217\n              \n            \n          \n        \n        (\n        s\n        ,\n        \u22c5\n        )\n      \n    \n    {\\displaystyle Q^{\\pi ^{*}}(s,\\cdot )}\n   with the highest action-value at each state, \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  . The action-value function of such an optimal policy (\n  \n    \n      \n        \n          Q\n          \n            \n              \u03c0\n              \n                \u2217\n              \n            \n          \n        \n      \n    \n    {\\displaystyle Q^{\\pi ^{*}}}\n  ) is called the optimal action-value function and is commonly denoted by \n  \n    \n      \n        \n          Q\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle Q^{*}}\n  . In summary, the knowledge of the optimal action-value function alone suffices to know how to act optimally.\nAssuming full knowledge of the Markov decision process, the two basic approaches to compute the optimal action-value function are value iteration and policy iteration. Both algorithms compute a sequence of functions \n  \n    \n      \n        \n          Q\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle Q_{k}}\n   (\n  \n    \n      \n        k\n        =\n        0\n        ,\n        1\n        ,\n        2\n        ,\n        \u2026\n      \n    \n    {\\displaystyle k=0,1,2,\\ldots }\n  ) that converge to \n  \n    \n      \n        \n          Q\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle Q^{*}}\n  . Computing these functions involves computing expectations over the whole state-space, which is impractical for all but the smallest (finite) Markov decision processes. In reinforcement learning methods, expectations are approximated by averaging over samples and using function approximation techniques to cope with the need to represent value functions over large state-action spaces.\nMonte Carlo methods[edit]Monte Carlo methods[15] are used to solve reinforcement learning problems by averaging sample returns. Unlike methods that require full knowledge of the environment's dynamics, Monte Carlo methods rely solely on actual or simulated experience\u2014sequences of states, actions, and rewards obtained from interaction with an environment. This makes them applicable in situations where the complete dynamics are unknown. Learning from actual experience does not require prior knowledge of the environment and can still lead to optimal behavior. When using simulated experience, only a model capable of generating sample transitions is required, rather than a full specification of transition probabilities, which is necessary for dynamic programming methods.\nMonte Carlo methods apply to episodic tasks, where experience is divided into episodes that eventually terminate. Policy and value function updates occur only after the completion of an episode, making these methods incremental on an episode-by-episode basis, though not on a step-by-step (online) basis. The term \"Monte Carlo\" generally refers to any method involving random sampling; however, in this context, it specifically refers to methods that compute averages from complete returns, rather than partial returns.\nThese methods function similarly to the bandit algorithms, in which returns are averaged for each state-action pair. The key difference is that actions taken in one state affect the returns of subsequent states within the same episode, making the problem non-stationary. To address this non-stationarity, Monte Carlo methods use the framework of general policy iteration (GPI). While dynamic programming computes value functions using full knowledge of the Markov decision process, Monte Carlo methods learn these functions through sample returns. The value functions and policies interact similarly to dynamic programming to achieve optimality, first addressing the prediction problem and then extending to policy improvement and control, all based on sampled experience.[14]Temporal difference methods[edit]Main article: Temporal difference learningThe first problem is corrected by allowing the procedure to change the policy (at some or all states) before the values settle. This too may be problematic as it might prevent convergence. Most current algorithms do this, giving rise to the class of generalized policy iteration algorithms. Many actor-critic methods belong to this category.\nThe second issue can be corrected by allowing trajectories to contribute to any state-action pair in them. This may also help to some extent with the third problem, although a better solution when returns have high variance is Sutton's temporal difference (TD) methods that are based on the recursive Bellman equation.[16][17] The computation in TD methods can be incremental (when after each transition the memory is changed and the transition is thrown away), or batch (when the transitions are batched and the estimates are computed once based on the batch). Batch methods, such as the least-squares temporal difference method,[18] may use the information in the samples better, while incremental methods are the only choice when batch methods are infeasible due to their high computational or memory complexity. Some methods try to combine the two approaches. Methods based on temporal differences also overcome the fourth issue.\nAnother problem specific to TD comes from their reliance on the recursive Bellman equation. Most TD methods have a so-called \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   parameter \n  \n    \n      \n        (\n        0\n        \u2264\n        \u03bb\n        \u2264\n        1\n        )\n      \n    \n    {\\displaystyle (0\\leq \\lambda \\leq 1)}\n   that can continuously interpolate between Monte Carlo methods that do not rely on the Bellman equations and the basic TD methods that rely entirely on the Bellman equations. This can be effective in palliating this issue.\nFunction approximation methods[edit]In order to address the fifth issue, function approximation methods are used. Linear function approximation starts with a mapping \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   that assigns a finite-dimensional vector to each state-action pair. Then, the action values of a state-action pair \n  \n    \n      \n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle (s,a)}\n   are obtained by linearly combining the components of \n  \n    \n      \n        \u03d5\n        (\n        s\n        ,\n        a\n        )\n      \n    \n    {\\displaystyle \\phi (s,a)}\n   with some weights\n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  :\n  \n    \n      \n        Q\n        (\n        s\n        ,\n        a\n        )\n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            d\n          \n        \n        \n          \u03b8\n          \n            i\n          \n        \n        \n          \u03d5\n          \n            i\n          \n        \n        (\n        s\n        ,\n        a\n        )\n        .\n      \n    \n    {\\displaystyle Q(s,a)=\\sum _{i=1}^{d}\\theta _{i}\\phi _{i}(s,a).}\n  The algorithms then adjust the weights, instead of adjusting the values associated with the individual state-action pairs. Methods based on ideas from nonparametric statistics (which can be seen to construct their own features) have been explored.\nValue iteration can also be used as a starting point, giving rise to the Q-learning algorithm and its many variants.[19] Including Deep Q-learning methods when a neural network is used to represent Q, with various applications in stochastic search problems.[20]The problem with using action-values is that they may need highly precise estimates of the competing action values that can be hard to obtain when the returns are noisy, though this problem is mitigated to some extent by temporal difference methods. Using the so-called compatible function approximation method compromises generality and efficiency.\nDirect policy search[edit]An alternative method is to search directly in (some subset of) the policy space, in which case the problem becomes a case of stochastic optimization. The two approaches available are gradient-based and gradient-free methods.\nGradient-based methods (policy gradient methods) start with a mapping from a finite-dimensional (parameter) space to the space of policies: given the parameter vector \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  , let \n  \n    \n      \n        \n          \u03c0\n          \n            \u03b8\n          \n        \n      \n    \n    {\\displaystyle \\pi _{\\theta }}\n   denote the policy associated to \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  . Defining the performance function by \n  \n    \n      \n        \u03c1\n        (\n        \u03b8\n        )\n        =\n        \n          \u03c1\n          \n            \n              \u03c0\n              \n                \u03b8\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho (\\theta )=\\rho ^{\\pi _{\\theta }}}\n   under mild conditions this function will be differentiable as a function of the parameter vector \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  . If the gradient of \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   was known, one could use gradient ascent. Since an analytic expression for the gradient is not available, only a noisy estimate is available. Such an estimate can be constructed in many ways, giving rise to algorithms such as Williams's REINFORCE method[21] (which is known as the likelihood ratio method in the simulation-based optimization literature).[22]A large class of methods avoids relying on gradient information. These include simulated annealing, cross-entropy search or methods of evolutionary computation. Many gradient-free methods can achieve (in theory and in the limit) a global optimum.\nPolicy search methods may converge slowly given noisy data. For example, this happens in episodic problems when the trajectories are long and the variance of the returns is large. Value-function based methods that rely on temporal differences might help in this case. In recent years, actor\u2013critic methods have been proposed and performed well on various problems.[23]Policy search methods have been used in the robotics context.[24] Many policy search methods may get stuck in local optima (as they are based on local search).\nModel-based algorithms[edit]Finally, all of the above methods can be combined with algorithms that first learn a model of the Markov decision process, the probability of each next state given an action taken from an existing state. For instance, the Dyna algorithm learns a model from experience, and uses that to provide more modelled transitions for a value function, in addition to the real transitions.[25] Such methods can sometimes be extended to use of non-parametric models, such as when the transitions are simply stored and \"replayed\" to the learning algorithm.[26]Model-based methods can be more computationally intensive than model-free approaches, and their utility can be limited by the extent to which the Markov decision process can be learnt.[27]There are other ways to use models than to update a value function.[28] For instance, in model predictive control the model is used to update the behavior directly.\nTheory[edit]Both the asymptotic and finite-sample behaviors of most algorithms are well understood. Algorithms with provably good online performance (addressing the exploration issue) are known.\nEfficient exploration of Markov decision processes is given in Burnetas and Katehakis (1997).[12] Finite-time performance bounds have also appeared for many algorithms, but these bounds are expected to be rather loose and thus more work is needed to better understand the relative advantages and limitations.\nFor incremental algorithms, asymptotic convergence issues have been settled.[clarification needed] Temporal-difference-based algorithms converge under a wider set of conditions than was previously possible (for example, when used with arbitrary, smooth function approximation).\nResearch[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  (October 2022) (Learn how and when to remove this message)Research topics include:\nactor-critic architecture[29]actor-critic-scenery architecture[3]adaptive methods that work with fewer (or no) parameters under a large number of conditionsbug detection in software projects[30]continuous learningcombinations with logic-based frameworks (e.g., temporal-logic specifications,[31] reward machines,[32] and probabilistic argumentation).[33]exploration in large Markov decision processesentity-based reinforcement learning[34][35][36]human feedback[37]interaction between implicit and explicit learning in skill acquisitionintrinsic motivation which differentiates information-seeking, curiosity-type behaviours from task-dependent goal-directed behaviours large-scale empirical evaluationslarge (or continuous) action spacesmodular and hierarchical reinforcement learning[38]multiagent/distributed reinforcement learning is a topic of interest. Applications are expanding.[39]occupant-centric controloptimization of computing resources[40][41][42]partial information (e.g., using predictive state representation)reward function based on maximising novel information[43][44][45]sample-based planning (e.g., based on Monte Carlo tree search).securities trading[46]transfer learning[47]TD learning modeling dopamine-based learning in the brain. Dopaminergic projections from the substantia nigra to the basal ganglia function are the prediction error.value-function and policy search methodsComparison of key algorithms[edit]The following table lists the key algorithms for learning a policy depending on several criteria:\nThe algorithm can be on-policy (it performs policy updates using trajectories sampled via the current policy)[48] or off-policy.The action space may be discrete (e.g. the action space could be \"going up\", \"going left\", \"going right\", \"going down\", \"stay\") or continuous (e.g. moving the arm with a given angle).The state space may be discrete (e.g. the agent could be in a cell in a grid) or continuous (e.g. the agent could be located at a given position in the plane).\n\nAlgorithmDescriptionPolicyAction spaceState spaceOperator\nMonte CarloEvery visit to Monte CarloEitherDiscreteDiscreteSample-means of state-values or action-values\nTD learningState\u2013action\u2013reward\u2013stateOff-policyDiscreteDiscreteState-value\nQ-learningState\u2013action\u2013reward\u2013stateOff-policyDiscreteDiscreteAction-value\nSARSAState\u2013action\u2013reward\u2013state\u2013actionOn-policyDiscreteDiscreteAction-value\nDQNDeep Q NetworkOff-policyDiscreteContinuousAction-value\nDDPGDeep Deterministic Policy GradientOff-policyContinuousContinuousAction-value\nA3CAsynchronous Advantage Actor-Critic AlgorithmOn-policyDiscreteContinuousAdvantage (=action-value - state-value)\nTRPOTrust Region Policy OptimizationOn-policyContinuous or DiscreteContinuousAdvantage\nPPOProximal Policy OptimizationOn-policyContinuous or DiscreteContinuousAdvantage\nTD3\nTwin Delayed Deep Deterministic Policy Gradient\nOff-policy\nContinuous\nContinuous\nAction-value\nSAC\nSoft Actor-Critic\nOff-policy\nContinuous\nContinuous\nAdvantage\nDSAC[49][50][51]Distributional Soft Actor CriticOff-policyContinuousContinuousAction-value distribution\nAssociative reinforcement learning[edit]Associative reinforcement learning tasks combine facets of stochastic learning automata tasks and supervised learning pattern classification tasks. In associative reinforcement learning tasks, the learning system interacts in a closed loop with its environment.[52]Deep reinforcement learning[edit]This approach extends reinforcement learning by using a deep neural network and without explicitly designing the state space.[53] The work on learning ATARI games by Google DeepMind increased attention to deep reinforcement learning or end-to-end reinforcement learning.[54]Adversarial deep reinforcement learning[edit]Adversarial deep reinforcement learning is an active area of research in reinforcement learning focusing on vulnerabilities of learned policies. In this research area some studies initially showed that reinforcement learning policies are susceptible to imperceptible adversarial manipulations.[55][56][57] While some methods have been proposed to overcome these susceptibilities, in the most recent studies it has been shown that these proposed solutions are far from providing an accurate representation of current vulnerabilities of deep reinforcement learning policies.[58]Fuzzy reinforcement learning[edit]By introducing fuzzy inference in reinforcement learning,[59] approximating the state-action value function with fuzzy rules in continuous space becomes possible. The IF - THEN form of fuzzy rules make this approach suitable for expressing the results in a form close to natural language. Extending FRL with Fuzzy Rule Interpolation[60] allows the use of reduced size sparse fuzzy rule-bases to emphasize cardinal rules (most important state-action values).\nInverse reinforcement learning[edit]In inverse reinforcement learning (IRL), no reward function is given. Instead, the reward function is inferred given an observed behavior from an expert. The idea is to mimic observed behavior, which is often optimal or close to optimal.[61] One popular IRL paradigm is named maximum entropy inverse reinforcement learning (MaxEnt IRL).[62] MaxEnt IRL estimates the parameters of a linear model of the reward function by maximizing the entropy of the probability distribution of observed trajectories subject to constraints related to matching expected feature counts. Recently it has been shown that MaxEnt IRL is a particular case of a more general framework named random utility inverse reinforcement learning (RU-IRL).[63] RU-IRL is based on random utility theory and Markov decision processes. While prior IRL approaches assume that the apparent random behavior of an observed agent is due to it following a random policy, RU-IRL assumes that the observed agent follows a deterministic policy but randomness in observed behavior is due to the fact that an observer only has partial access to the features the observed agent uses in decision making. The utility function is modeled as a random variable to account for the ignorance of the observer regarding the features the observed agent actually considers in its utility function.\nMulti-objective reinforcement learning[edit]Multi-objective reinforcement learning (MORL) is a form of reinforcement learning concerned with conflicting alternatives. It is distinct from multi-objective optimization in that it is concerned with agents acting in environments.[64][65]Safe reinforcement learning[edit]Safe reinforcement learning (SRL) can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes.[66] An alternative approach is risk-averse reinforcement learning, where instead of the expected return, a risk-measure of the return is optimized, such as the conditional value at risk (CVaR).[67] In addition to mitigating risk, the CVaR objective increases robustness to model uncertainties.[68][69] However, CVaR optimization in risk-averse RL requires special care, to prevent gradient bias[70] and blindness to success.[71]Self-reinforcement learning[edit]Self-reinforcement learning (or self-learning), is a learning paradigm which does not use the concept of immediate reward \n  \n    \n      \n        \n          R\n          \n            a\n          \n        \n        (\n        s\n        ,\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle R_{a}(s,s')}\n   after transition from \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   to \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n   with action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  . It does not use an external reinforcement, it only uses the agent internal self-reinforcement. The internal self-reinforcement is provided by mechanism of feelings and emotions. In the learning process emotions are backpropagated by a mechanism of secondary reinforcement. The learning equation does not include the immediate reward, it only includes the state evaluation.\nThe self-reinforcement algorithm updates a memory matrix \n  \n    \n      \n        W\n        =\n        \u2016\n        w\n        (\n        a\n        ,\n        s\n        )\n        \u2016\n      \n    \n    {\\displaystyle W=\\|w(a,s)\\|}\n   such that in each iteration executes the following machine learning routine:\nIn situation \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   perform action \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  .Receive a consequence situation \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n  .Compute state evaluation \n  \n    \n      \n        v\n        (\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle v(s')}\n   of how good is to be in the consequence situation \n  \n    \n      \n        \n          s\n          \u2032\n        \n      \n    \n    {\\displaystyle s'}\n  .Update crossbar memory \n  \n    \n      \n        \n          w\n          \u2032\n        \n        (\n        a\n        ,\n        s\n        )\n        =\n        w\n        (\n        a\n        ,\n        s\n        )\n        +\n        v\n        (\n        \n          s\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle w'(a,s)=w(a,s)+v(s')}\n  .Initial conditions of the memory are received as input from the genetic environment. It is a system with only one input (situation), and only one output (action, or behavior).\nSelf-reinforcement (self-learning) was introduced in 1982 along with a neural network capable of self-reinforcement learning, named Crossbar Adaptive Array (CAA).[72][73] The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence states. The system is driven by the interaction between cognition and emotion.[74]Reinforcement Learning in Natural Language Processing[edit]In recent years, reinforcement learning has become a significant concept in natural language processing (NLP), where tasks are often sequential decision-making rather than static classification. Reinforcement learning is where an agent take actions in an environment to maximize the accumulation of rewards. This framework is best fit for many NLP tasks, including dialogue generation, text summarization, and machine translation, where the quality of the output depends on optimizing long-term or human-centered goals rather than the prediction of single correct label.\nEarly application of RL in NLP emerged in dialogue systems, where conversation was determined as a series of actions optimized for fluency and coherence. These early attempts, including policy gradient and sequence-level training techniques, laid a foundation for the broader application of reinforcement learning to other areas of NLP.\nA major breakthrough happened with the introduction of reinforcement learning from human feedback (RLHF), a method in which human feedback ratings are used to train a reward model that guides the RL agent. Unlike traditional rule-based or supervised systems, RLHF allows models to align their behavior with human judgments on complex and subjective tasks. This technique was initially used in the development of InstructGPT, an effective language model trained to follow human instructions and later in ChatGPT which incorporates RLHF for improving output responses and ensuring safety.\nMore recently, researchers have explored the use of offline RL in NLP to improve dialogue systems without the need of live human interaction. These methods optimize for user engagement, coherence, and diversity based on past conversation logs and pre-trained reward models.\nStatistical comparison of reinforcement learning algorithms[edit]Efficient comparison of RL algorithms is essential for research, deployment and monitoring of RL systems. To compare different algorithms on a given environment, an agent can be trained for each algorithm. Since the performance is sensitive to implementation details, all algorithms should be implemented as closely as possible to each other.[75] After the training is finished, the agents can be run on a sample of test episodes, and their scores (returns) can be compared. Since episodes are typically assumed to be i.i.d, standard statistical tools can be used for hypothesis testing, such as T-test and permutation test.[76] This requires to accumulate all the rewards within an episode into a single number\u2014the episodic return. However, this causes a loss of information, as different time-steps are averaged together, possibly with different levels of noise. Whenever the noise level varies across the episode, the statistical power can be improved significantly, by weighting the rewards according to their estimated noise.[77]Challenges and Limitations[edit]Despite significant advancements, reinforcement learning (RL) continues to face several challenges and limitations that hinder its widespread application in real-world scenarios.\nSample Inefficiency[edit]RL algorithms often require a large number of interactions with the environment to learn effective policies, leading to high computational costs and time-intensive to train the agent. For instance, OpenAI's Dota-playing bot utilized thousands of years of simulated gameplay to achieve human-level performance. Techniques like experience replay and curriculum learning have been proposed to deprive sample inefficiency, but these techniques add more complexity and are not always sufficient for real-world applications.\nStability and Convergence Issues[edit]Training RL models, particularly for deep neural network-based models, can be unstable and prone to divergence. A small change in the policy or environment can lead to extreme fluctuations in performance, making it difficult to achieve consistent results. This instability is further enhanced in the case of the continuous or high-dimensional action space, where the learning step becomes more complex and less predictable.\nGeneralization and Transferability[edit]The RL agents trained in specific environments often struggle to generalize their learned policies to new, unseen scenarios. This is the major setback preventing the application of RL to dynamic real-world environments where adaptability is crucial. The challenge is to develop such algorithms that can transfer knowledge across tasks and environments without extensive retraining.\nBias and Reward Function Issues[edit]Designing appropriate reward functions is critical in RL because poorly designed reward functions can lead to unintended behaviors. In addition, RL systems trained on biased data may perpetuate existing biases and lead to discriminatory or unfair outcomes. Both of these issues requires careful consideration of reward structures and data sources to ensure fairness and desired behaviors.\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Active learning (machine learning)Apprenticeship learningError-driven learningModel-free (reinforcement learning)Multi-agent reinforcement learningOptimal controlQ-learningReinforcement learning from human feedbackState\u2013action\u2013reward\u2013state\u2013action (SARSA)Temporal difference learningReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Kaelbling, Leslie P.; Littman, Michael L.; Moore, Andrew W. (1996). \"Reinforcement Learning: A Survey\". Journal of Artificial Intelligence Research. 4: 237\u2013285. arXiv:cs/9605103. doi:10.1613/jair.301. S2CID\u00a01708582. Archived from the original on 2001-11-20.^van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol.\u00a012. pp.\u00a03\u201342. doi:10.1007/978-3-642-27645-3_1. ISBN\u00a0978-3-642-27644-6.^ abLi, Shengbo (2023). Reinforcement Learning for Sequential Decision and Optimal Control (First\u00a0ed.). Springer Verlag, Singapore. pp.\u00a01\u2013460. doi:10.1007/978-981-19-7784-8. ISBN\u00a0978-9-811-97783-1. S2CID\u00a0257928563.{{cite book}}:  CS1 maint: location missing publisher (link)^Russell, Stuart J.; Norvig, Peter (2010). Artificial intelligence: a modern approach (Third\u00a0ed.). Upper Saddle River, New Jersey: Prentice Hall. pp.\u00a0830, 831. ISBN\u00a0978-0-13-604259-4.^Lee, Daeyeol; Seo, Hyojung; Jung, Min Whan (21 July 2012). \"Neural Basis of Reinforcement Learning and Decision Making\". Annual Review of Neuroscience. 35 (1): 287\u2013308. doi:10.1146/annurev-neuro-062111-150512. PMC\u00a03490621. PMID\u00a022462543.^Salazar Duque, Edgar Mauricio; Giraldo, Juan S.; Vergara, Pedro P.; Nguyen, Phuong; Van Der Molen, Anne; Slootweg, Han (2022). \"Community energy storage operation via reinforcement learning with eligibility traces\". Electric Power Systems Research. 212 108515. Bibcode:2022EPSR..21208515S. doi:10.1016/j.epsr.2022.108515. S2CID\u00a0250635151.^Xie, Zhaoming; Hung Yu Ling; Nam Hee Kim; Michiel van de Panne (2020). \"ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills\". arXiv:2005.04323 [cs.GR].^Vergara, Pedro P.; Salazar, Mauricio; Giraldo, Juan S.; Palensky, Peter (2022). \"Optimal dispatch of PV inverters in unbalanced distribution systems using Reinforcement Learning\". International Journal of Electrical Power & Energy Systems. 136 107628. Bibcode:2022IJEPE.13607628V. doi:10.1016/j.ijepes.2021.107628. S2CID\u00a0244099841.^Sutton & Barto 2018, Chapter 11.^Ren, Yangang; Jiang, Jianhua; Zhan, Guojian; Li, Shengbo Eben; Chen, Chen; Li, Keqiang; Duan, Jingliang (2022). \"Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections\". IEEE Transactions on Intelligent Transportation Systems. 23 (12): 24145\u201324156. arXiv:2110.12359. Bibcode:2022ITITr..2324145R. doi:10.1109/TITS.2022.3196167.^Gosavi, Abhijit (2003). Simulation-based Optimization: Parametric Optimization Techniques and Reinforcement. Operations Research/Computer Science Interfaces Series. Springer. ISBN\u00a0978-1-4020-7454-7.^ abBurnetas, Apostolos N.; Katehakis, Michael N. (1997), \"Optimal adaptive policies for Markov Decision Processes\", Mathematics of Operations Research, 22 (1): 222\u2013255, doi:10.1287/moor.22.1.222, JSTOR\u00a03690147^Tokic, Michel; Palm, G\u00fcnther (2011), \"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax\"(PDF), KI 2011: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol.\u00a07006, Springer, pp.\u00a0335\u2013346, ISBN\u00a0978-3-642-24455-1^ abc\"Reinforcement learning: An introduction\"(PDF). Archived from the original(PDF) on 2017-07-12. Retrieved 2017-07-23.^Singh, Satinder P.; Sutton, Richard S. (1996-03-01). \"Reinforcement learning with replacing eligibility traces\". Machine Learning. 22 (1): 123\u2013158. doi:10.1007/BF00114726. ISSN\u00a01573-0565.^Sutton, Richard S. (1984). Temporal Credit Assignment in Reinforcement Learning (PhD thesis). University of Massachusetts, Amherst, MA. Archived from the original on 2017-03-30. Retrieved 2017-03-29.^Sutton & Barto 2018, \u00a76. Temporal-Difference Learning.^Bradtke, Steven J.; Barto, Andrew G. (1996). \"Learning to predict by the method of temporal differences\". Machine Learning. 22: 33\u201357. CiteSeerX\u00a010.1.1.143.857. doi:10.1023/A:1018056104778. S2CID\u00a020327856.^Watkins, Christopher J.C.H. (1989). Learning from Delayed Rewards(PDF) (PhD thesis). King's College, Cambridge, UK.^Matzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022). \"Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities\". Entropy. 24 (8): 1168. Bibcode:2022Entrp..24.1168M. doi:10.3390/e24081168. PMC\u00a09407070. PMID\u00a036010832.^Williams, Ronald J. (1987). \"A class of gradient-estimating algorithms for reinforcement learning in neural networks\". Proceedings of the IEEE First International Conference on Neural Networks. CiteSeerX\u00a010.1.1.129.8871.^Peters, Jan; Vijayakumar, Sethu; Schaal, Stefan (2003). Reinforcement Learning for Humanoid Robotics(PDF). IEEE-RAS International Conference on Humanoid Robots. Archived from the original(PDF) on 2013-05-12. Retrieved 2006-05-08.^Juliani, Arthur (2016-12-17). \"Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)\". Medium. Retrieved 2018-02-22.^Deisenroth, Marc Peter; Neumann, Gerhard; Peters, Jan (2013). A Survey on Policy Search for Robotics(PDF). Foundations and Trends in Robotics. Vol.\u00a02. NOW Publishers. pp.\u00a01\u2013142. doi:10.1561/2300000021. hdl:10044/1/12051.^Sutton, Richard (1990). \"Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming\". Machine Learning: Proceedings of the Seventh International Workshop.^Lin, Long-Ji (1992). \"Self-improving reactive agents based on reinforcement learning, planning and teaching\"(PDF). Machine Learning. Vol.\u00a08. doi:10.1007/BF00992699.^Zou, Lan (2023-01-01), Zou, Lan (ed.), \"Chapter 7 - Meta-reinforcement learning\", Meta-Learning, Academic Press, pp.\u00a0267\u2013297, doi:10.1016/b978-0-323-89931-4.00011-0, ISBN\u00a0978-0-323-89931-4, retrieved 2023-11-08^van Hasselt, Hado; Hessel, Matteo; Aslanides, John (2019). \"When to use parametric models in reinforcement learning?\"(PDF). Advances in Neural Information Processing Systems. Vol.\u00a032.^Grondman, Ivo; Vaandrager, Maarten; Busoniu, Lucian; Babuska, Robert; Schuitema, Erik (2012-06-01). \"Efficient Model Learning Methods for Actor\u2013Critic Control\". IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics. 42 (3): 591\u2013602. Bibcode:2012ITSMC..42..591G. doi:10.1109/TSMCB.2011.2170565. ISSN\u00a01083-4419. PMID\u00a022156998.^\"On the Use of Reinforcement Learning for Testing Game Mechanics: ACM - Computers in Entertainment\". cie.acm.org. Retrieved 2018-11-27.^Li, Xiao; Vasile, Cristian-Ioan; Belta, Calin (2017). \"Reinforcement Learning with Temporal Logic Rewards\". 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). pp.\u00a03834\u20133839. doi:10.1109/IROS.2017.8206234.^Toro Icarte, Rodrigo; Klassen, Toryn Q.; Valenzano, Richard; McIlraith, Sheila A. (2022). \"Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning\". Journal of Artificial Intelligence Research. 73: 173\u2013208. arXiv:2010.03950. doi:10.1613/jair.1.12440.^Riveret, R\u00e9gis; Gao, Yang; Governatori, Guido; Rotolo, Antonino; Pitt, Jeremy; Sartor, Giovanni (2019). \"A probabilistic argumentation framework for reinforcement learning agents\". Autonomous Agents and Multi-Agent Systems. 33 (1\u20132): 216\u2013274. doi:10.1007/s10458-019-09404-2.^Haramati, Dan; Daniel, Tal; Tamar, Aviv (2024). \"Entity-Centric Reinforcement Learning for Object Manipulation from Pixels\". arXiv:2404.01220 [cs.RO].^Thompson, Isaac Symes; Caron, Alberto; Hicks, Chris; Mavroudis, Vasilios (2024-11-07). \"Entity-based Reinforcement Learning for Autonomous Cyber Defence\". Proceedings of the Workshop on Autonomous Cybersecurity (AutonomousCyber '24). ACM. pp.\u00a056\u201367. arXiv:2410.17647. doi:10.1145/3689933.3690835.^Winter, Clemens (2023-04-14). \"Entity-Based Reinforcement Learning\". Clemens Winter's Blog.^Yamagata, Taku; McConville, Ryan; Santos-Rodriguez, Raul (2021-11-16). \"Reinforcement Learning with Feedback from Multiple Humans with Diverse Skills\". arXiv:2111.08596 [cs.LG].^Kulkarni, Tejas D.; Narasimhan, Karthik R.; Saeedi, Ardavan; Tenenbaum, Joshua B. (2016). \"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\". Proceedings of the 30th International Conference on Neural Information Processing Systems. NIPS'16. USA: Curran Associates Inc.: 3682\u20133690. arXiv:1604.06057. Bibcode:2016arXiv160406057K. ISBN\u00a0978-1-5108-3881-9.^\"Reinforcement Learning / Successes of Reinforcement Learning\". umichrl.pbworks.com. Retrieved 2017-08-06.^Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (March 2020). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)(PDF). pp.\u00a01728\u20131733. doi:10.23919/DATE48585.2020.9116294. ISBN\u00a0978-3-9819263-4-7. S2CID\u00a0219858480.^Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Retrieved 2021-06-17.^Williams, Rhiannon (2020-07-21). \"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\". i. Retrieved 2021-06-17.^Kaplan, F.; Oudeyer, P. (2004). \"Maximizing Learning Progress: An Internal Reward System for Development\". In Iida, F.; Pfeifer, R.; Steels, L.; Kuniyoshi, Y. (eds.). Embodied Artificial Intelligence. Lecture Notes in Computer Science. Vol.\u00a03139. Berlin; Heidelberg: Springer. pp.\u00a0259\u2013270. doi:10.1007/978-3-540-27833-7_19. ISBN\u00a0978-3-540-22484-6. S2CID\u00a09781221.^Klyubin, A.; Polani, D.; Nehaniv, C. (2008). \"Keep your options open: an information-based driving principle for sensorimotor systems\". PLOS ONE. 3 (12) e4018. Bibcode:2008PLoSO...3.4018K. doi:10.1371/journal.pone.0004018. PMC\u00a02607028. PMID\u00a019107219.^Barto, A. G. (2013). \"Intrinsic motivation and reinforcement learning\". Intrinsically Motivated Learning in Natural and Artificial Systems(PDF). Berlin; Heidelberg: Springer. pp.\u00a017\u201347.^Dab\u00e9rius, Kevin; Granat, Elvin; Karlsson, Patrik (2020). \"Deep Execution - Value and Policy Based Reinforcement Learning for Trading and Beating Market Benchmarks\". The Journal of Machine Learning in Finance. 1. SSRN\u00a03374766.^George Karimpanal, Thommen; Bouffanais, Roland (2019). \"Self-organizing maps for storage and transfer of knowledge in reinforcement learning\". Adaptive Behavior. 27 (2): 111\u2013126. arXiv:1811.08318. doi:10.1177/1059712318818568. ISSN\u00a01059-7123. S2CID\u00a053774629.^cf. Sutton & Barto 2018, Section 5.4, p. 100^J Duan; Y Guan; S Li (2021). \"Distributional Soft Actor-Critic: Off-policy reinforcement learning for addressing value estimation errors\". IEEE Transactions on Neural Networks and Learning Systems. 33 (11): 6584\u20136598. arXiv:2001.02811. doi:10.1109/TNNLS.2021.3082568. PMID\u00a034101599. S2CID\u00a0211259373.^Y Ren; J Duan; S Li (2020). \"Improving Generalization of Reinforcement Learning with Minimax Distributional Soft Actor-Critic\". 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC). pp.\u00a01\u20136. arXiv:2002.05502. doi:10.1109/ITSC45102.2020.9294300. ISBN\u00a0978-1-7281-4149-7. S2CID\u00a0211096594.^Duan, J; Wang, W; Xiao, L (2025). \"Distributional Soft Actor-Critic with Three Refinements\". IEEE Transactions on Pattern Analysis and Machine Intelligence. PP (5): 3935\u20133946. arXiv:2310.05858. Bibcode:2025ITPAM..47.3935D. doi:10.1109/TPAMI.2025.3537087. PMID\u00a040031258.^Soucek, Branko (6 May 1992). Dynamic, Genetic and Chaotic Programming: The Sixth-Generation Computer Technology Series. John Wiley & Sons, Inc. p.\u00a038. ISBN\u00a00-471-55717-X.^Francois-Lavet, Vincent; et\u00a0al. (2018). \"An Introduction to Deep Reinforcement Learning\". Foundations and Trends in Machine Learning. 11 (3\u20134): 219\u2013354. arXiv:1811.12560. Bibcode:2018arXiv181112560F. doi:10.1561/2200000071. S2CID\u00a054434537.^Mnih, Volodymyr; et\u00a0al. (2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529\u2013533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID\u00a025719670. S2CID\u00a0205242740.^Goodfellow, Ian; Shlens, Jonathan; Szegedy, Christian (2015). \"Explaining and Harnessing Adversarial Examples\". International Conference on Learning Representations. arXiv:1412.6572.^Behzadan, Vahid; Munir, Arslan (2017). \"Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks\". Machine Learning and Data Mining in Pattern Recognition. Lecture Notes in Computer Science. Vol.\u00a010358. pp.\u00a0262\u2013275. arXiv:1701.04143. doi:10.1007/978-3-319-62416-7_19. ISBN\u00a0978-3-319-62415-0. S2CID\u00a01562290.^Huang, Sandy; Papernot, Nicolas; Goodfellow, Ian; Duan, Yan; Abbeel, Pieter (2017-02-07). Adversarial Attacks on Neural Network Policies. OCLC\u00a01106256905.^Korkmaz, Ezgi (2022). \"Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs\". Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22). 36 (7): 7229\u20137238. arXiv:2112.09025. doi:10.1609/aaai.v36i7.20684. S2CID\u00a0245219157.^Berenji, H.R. (1994). \"Fuzzy Q-learning: A new approach for fuzzy dynamic programming\". Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference. Orlando, FL, USA: IEEE. pp.\u00a0486\u2013491. doi:10.1109/FUZZY.1994.343737. ISBN\u00a00-7803-1896-X. S2CID\u00a056694947.^Vincze, David (2017). \"Fuzzy rule interpolation and reinforcement learning\"(PDF). 2017 IEEE 15th International Symposium on Applied Machine Intelligence and Informatics (SAMI). IEEE. pp.\u00a0173\u2013178. doi:10.1109/SAMI.2017.7880298. ISBN\u00a0978-1-5090-5655-2. S2CID\u00a017590120.^Ng, A. Y.; Russell, S. J. (2000). \"Algorithms for Inverse Reinforcement Learning\"(PDF). Proceeding ICML '00 Proceedings of the Seventeenth International Conference on Machine Learning. Morgan Kaufmann Publishers. pp.\u00a0663\u2013670. ISBN\u00a01-55860-707-2.^Ziebart, Brian D.; Maas, Andrew; Bagnell, J. Andrew; Dey, Anind K. (2008-07-13). \"Maximum entropy inverse reinforcement learning\". Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3. AAAI'08. Chicago, Illinois: AAAI Press: 1433\u20131438. ISBN\u00a0978-1-57735-368-3. S2CID\u00a0336219.^Pitombeira-Neto, Anselmo R.; Santos, Helano P.; Coelho da Silva, Ticiana L.; de Macedo, Jos\u00e9 Antonio F. (March 2024). \"Trajectory modeling via random utility inverse reinforcement learning\". Information Sciences. 660 120128. arXiv:2105.12092. doi:10.1016/j.ins.2024.120128. ISSN\u00a00020-0255. S2CID\u00a0235187141.^Hayes C, Radulescu R, Bargiacchi E, et\u00a0al. (2022). \"A practical guide to multi-objective reinforcement learning and planning\". Autonomous Agents and Multi-Agent Systems. 36 26. arXiv:2103.09568. doi:10.1007/s10458-022-09552-y. S2CID\u00a0254235920.,^Tzeng, Gwo-Hshiung; Huang, Jih-Jeng (2011). Multiple Attribute Decision Making: Methods and Applications (1st\u00a0ed.). CRC Press. ISBN\u00a0978-1-4398-6157-8.^Garc\u00eda, Javier; Fern\u00e1ndez, Fernando (1 January 2015). \"A comprehensive survey on safe reinforcement learning\"(PDF). The Journal of Machine Learning Research. 16 (1): 1437\u20131480.^Dabney, Will; Ostrovski, Georg; Silver, David; Munos, Remi (2018-07-03). \"Implicit Quantile Networks for Distributional Reinforcement Learning\". Proceedings of the 35th International Conference on Machine Learning. PMLR: 1096\u20131105. arXiv:1806.06923.^Chow, Yinlam; Tamar, Aviv; Mannor, Shie; Pavone, Marco (2015). \"Risk-Sensitive and Robust Decision-Making: a CVaR Optimization Approach\". Advances in Neural Information Processing Systems. 28. Curran Associates, Inc. arXiv:1506.02188.^\"Train Hard, Fight Easy: Robust Meta Reinforcement Learning\". scholar.google.com. Retrieved 2024-06-21.^Tamar, Aviv; Glassner, Yonatan; Mannor, Shie (2015-02-21). \"Optimizing the CVaR via Sampling\". Proceedings of the AAAI Conference on Artificial Intelligence. 29 (1). arXiv:1404.3862. doi:10.1609/aaai.v29i1.9561. ISSN\u00a02374-3468.^Greenberg, Ido; Chow, Yinlam; Ghavamzadeh, Mohammad; Mannor, Shie (2022-12-06). \"Efficient Risk-Averse Reinforcement Learning\". Advances in Neural Information Processing Systems. 35: 32639\u201332652. arXiv:2205.05138.^Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397\u2013402. ISBN 978-0-444-86488-8^Bozinovski S. (1995) \"Neuro genetic agents and structural theory of self-reinforcement learning systems\". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst [1]^Bozinovski, S. (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255\u2013263^Engstrom, Logan; Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Janoos, Firdaus; Rudolph, Larry; Madry, Aleksander (2019-09-25). \"Implementation Matters in Deep RL: A Case Study on PPO and TRPO\". ICLR.^Colas, C\u00e9dric (2019-03-06). \"A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms\". International Conference on Learning Representations. arXiv:1904.06979.^Greenberg, Ido; Mannor, Shie (2021-07-01). \"Detecting Rewards Deterioration in Episodic Reinforcement Learning\". Proceedings of the 38th International Conference on Machine Learning. PMLR: 3842\u20133853. arXiv:2010.11660.Further reading[edit]Annaswamy, Anuradha M. (3 May 2023). \"Adaptive Control and Intersections with Reinforcement Learning\". Annual Review of Control, Robotics, and Autonomous Systems. 6 (1): 65\u201393. doi:10.1146/annurev-control-062922-090153. ISSN\u00a02573-5144. S2CID\u00a0255702873.Auer, Peter; Jaksch, Thomas; Ortner, Ronald (2010). \"Near-optimal regret bounds for reinforcement learning\". Journal of Machine Learning Research. 11: 1563\u20131600.Bertsekas, Dimitri P. (2023) [2019]. Reinforcement Learning and Optimal Control (1st\u00a0ed.). Athena Scientific. ISBN\u00a0978-1-886-52939-7.Busoniu, Lucian; Babuska, Robert; De Schutter, Bart; Ernst, Damien (2010). Reinforcement Learning and Dynamic Programming using Function Approximators. Taylor & Francis CRC Press. ISBN\u00a0978-1-4398-2108-4.Fran\u00e7ois-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle (2018). \"An Introduction to Deep Reinforcement Learning\". Foundations and Trends in Machine Learning. 11 (3\u20134): 219\u2013354. arXiv:1811.12560. Bibcode:2018arXiv181112560F. doi:10.1561/2200000071. S2CID\u00a054434537.Li, Shengbo Eben (2023). Reinforcement Learning for Sequential Decision and Optimal Control (1st\u00a0ed.). Springer Verlag, Singapore. doi:10.1007/978-981-19-7784-8. ISBN\u00a0978-9-811-97783-1.Powell, Warren (2011). Approximate dynamic programming: solving the curses of dimensionality. Wiley-Interscience. Archived from the original on 2016-07-31. Retrieved 2010-09-08.Sutton, Richard S. (1988). \"Learning to predict by the method of temporal differences\". Machine Learning. 3: 9\u201344. doi:10.1007/BF00115009.Sutton, Richard S.; Barto, Andrew G. (2018) [1998]. Reinforcement Learning: An Introduction (2nd\u00a0ed.). MIT Press. ISBN\u00a0978-0-262-03924-6.Szita, Istvan; Szepesvari, Csaba (2010). \"Model-based Reinforcement Learning with Nearly Tight Exploration Complexity Bounds\"(PDF). ICML 2010. Omnipress. pp.\u00a01031\u20131038. Archived from the original(PDF) on 2010-07-14.External links[edit]Dissecting Reinforcement Learning Series of blog post on reinforcement learning with Python codeA (Long) Peek into Reinforcement Learning.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteArtificial intelligence (AI)HistorytimelineGlossaryCompaniesProjectsConceptsParameterHyperparameterLoss functionsRegressionBias\u2013variance tradeoffDouble descentOverfittingClusteringGradient descentSGDQuasi-Newton methodConjugate gradient methodBackpropagationAttentionConvolutionNormalizationBatchnormActivationSoftmaxSigmoidRectifierGatingWeight initializationRegularizationDatasetsAugmentationPrompt engineeringReinforcement learningQ-learningSARSAImitationPolicy gradientDiffusionLatent diffusion modelAutoregressionAdversaryRAGUncanny valleyRLHFSelf-supervised learningReflectionRecursive self-improvementHallucinationWord embeddingVibe codingSafety (Alignment)ApplicationsMachine learningIn-context learningArtificial neural networkDeep learningLanguage modelLargeNMTReasoningModel Context ProtocolIntelligent agentArtificial human companionHumanity's Last ExamArtificial general intelligence (AGI)ImplementationsAudio\u2013visualAlexNetWaveNetHuman image synthesisHWROCRComputer visionSpeech synthesis15.aiElevenLabsSpeech recognitionWhisperFacial recognitionAlphaFoldText-to-image modelsAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyRecraftStable DiffusionText-to-video modelsDream MachineRunway GenHailuo AIKlingSoraVeoMusic generationRiffusionSuno AIUdioTextWord2vecSeq2seqGloVeBERTT5LlamaChinchilla AIPaLMGPT123JChatGPT44oo1o34.54.1o4-mini5ClaudeGeminiGemini (language model)GemmaGrokLaMDABLOOMDBRXProject DebaterIBM WatsonIBM WatsonxGranitePanGu-\u03a3DeepSeekQwenDecisionalAlphaGoAlphaZeroOpenAI FiveSelf-driving carMuZeroAction selectionAutoGPTRobot controlPeopleAlan TuringWarren Sturgis McCullochWalter PittsJohn von NeumannChristopher D. ManningClaude ShannonShun'ichi AmariKunihiko FukushimaTakeo KanadeMarvin MinskyJohn McCarthyNathaniel RochesterAllen NewellCliff ShawHerbert A. SimonOliver SelfridgeFrank RosenblattBernard WidrowJoseph WeizenbaumSeymour PapertSeppo LinnainmaaPaul WerbosGeoffrey HintonJohn HopfieldJ\u00fcrgen SchmidhuberYann LeCunYoshua BengioLotfi A. ZadehStephen GrossbergAlex GravesJames GoodnightAndrew NgFei-Fei LiAlex KrizhevskyIlya SutskeverOriol VinyalsQuoc V. LeIan GoodfellowDemis HassabisDavid SilverAndrej KarpathyAshish VaswaniNoam ShazeerAidan GomezJohn SchulmanMustafa SuleymanJan LeikeDaniel KokotajloFran\u00e7ois CholletArchitecturesNeural Turing machineDifferentiable neural computerTransformerVision transformer (ViT)Recurrent neural network (RNN)Long short-term memory (LSTM)Gated recurrent unit (GRU)Echo state networkMultilayer perceptron (MLP)Convolutional neural network (CNN)Residual neural network (RNN)Highway networkMambaAutoencoderVariational autoencoder (VAE)Generative adversarial network (GAN)Graph neural network (GNN)CategoryvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.HardwarePrinted circuit boardPeripheralIntegrated circuitVery-large-scale integrationSystem on a chip (SoC)Energy consumption (green computing)Electronic design automationHardware accelerationProcessorSize / FormComputer systems organizationComputer architectureComputational complexityDependabilityEmbedded systemReal-time computingCyber-physical systemFault toleranceWireless sensor networkNetworksNetwork architectureNetwork protocolNetwork componentsNetwork schedulerNetwork performance evaluationNetwork serviceSoftware organizationInterpreterMiddlewareVirtual machineOperating systemSoftware qualitySoftware notations and toolsProgramming paradigmProgramming languageCompilerDomain-specific languageModeling languageSoftware frameworkIntegrated development environmentSoftware configuration managementSoftware librarySoftware repositorySoftware developmentControl variableSoftware development processRequirements analysisSoftware designSoftware constructionSoftware deploymentSoftware engineeringSoftware maintenanceProgramming teamOpen-source modelTheory of computationModel of computationStochasticFormal languageAutomata theoryComputability theoryComputational complexity theoryLogicSemanticsAlgorithmsAlgorithm designAnalysis of algorithmsAlgorithmic efficiencyRandomized algorithmComputational geometryMathematics of computingDiscrete mathematicsProbabilityStatisticsMathematical softwareInformation theoryMathematical analysisNumerical analysisTheoretical computer scienceComputational problemInformation systemsDatabase management systemInformation storage systemsEnterprise information systemSocial information systemsGeographic information systemDecision support systemProcess control systemMultimedia information systemData miningDigital libraryComputing platformDigital marketingWorld Wide WebInformation retrievalSecurityCryptographyFormal methodsSecurity hackerSecurity servicesIntrusion detection systemHardware securityNetwork securityInformation securityApplication securityHuman-centered computingInteraction designAugmented realityVirtual realitySocial computingUbiquitous computingVisualizationAccessibilityHuman\u2013computer interactionMobile computingConcurrencyConcurrent computingParallel computingDistributed computingMultithreadingMultiprocessingArtificial intelligenceNatural language processingKnowledge representation and reasoningComputer visionAutomated planning and schedulingSearch methodologyControl methodPhilosophy of artificial intelligenceDistributed artificial intelligenceMachine learningSupervised learningUnsupervised learningReinforcement learningMulti-task learningCross-validationGraphicsAnimationRenderingPhotograph manipulationGraphics processing unitImage compressionSolid modelingApplied computingQuantum computingE-commerceEnterprise softwareComputational mathematicsComputational physicsComputational chemistryComputational biologyComputational social scienceComputational engineeringDifferentiable computingComputational healthcareDigital artElectronic publishingCyberwarfareElectronic votingVideo gamesWord processingOperations researchEducational technologyDocument managementIn developmentThermodynamic computingCategoryOutlineGlossaries\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Reinforcement_learning&oldid=1319501801\"", "tags": ["en.wikipedia.org", "wiki", "reinforcement", "learning"]}
{"url": "https://en.wikipedia.org/wiki/Robot_Operating_System", "title": null, "text": "Set of software frameworks for robot software development.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent;color:inherit}.mw-parser-output .infobox-3cols-child{margin:-3px}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}Robot Operating SystemCart pushing simulation in RVIZOriginal authorsWillow GarageStanford Artificial Intelligence LaboratoryOpen RoboticsInitial release2007; 18\u00a0years ago\u00a0(2007)Stable releaseJazzy Jalisco [1]\n   / 27\u00a0May 2024; 16 months ago\u00a0(2024-05-27)Preview releaseKilted Kaiju (ROS 2)[2]\n   Repository.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}github.com/ros2Written inC++, Python, and LispOperating systemLinux, macOS (experimental), Windows 10 (experimental)TypeRobotics suite, OS, libraryLicenseApache 2.0Websiteros.org\u00a0As ofFebruary 2025 \nRobot Operating System (ROS or ros) is an open-sourcerobotics middleware suite. Although ROS is not an operating system (OS) but a set of software frameworks for robot software development, it provides services designed for a heterogeneous computer cluster such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management. Running sets of ROS-based processes are represented in a graph architecture where processing takes place in nodes that may receive, post, and multiplex sensor data, control, state, planning, actuator, and other messages. Despite the importance of reactivity and low latency in robot control, ROS is not a real-time operating system (RTOS). However, it is possible to integrate ROS with real-time computing code.[3] The lack of support for real-time systems has been addressed in the creation of ROS 2,[4][5][6] a major revision of the ROS API which will take advantage of modern libraries and technologies for core ROS functions and add support for real-time code and embedded system hardware.\nSoftware in the ROS Ecosystem[7] can be separated into three groups:\nlanguage- and platform-independent tools used for building and distributing ROS-based software;ROS client library implementations such as roscpp,[8] rospy,[9] and roslisp;[10]packages containing application-related code that uses one or more ROS client libraries.[11]Both the language-independent tools and the main client libraries (C++, Python, and Lisp) are released under the terms of the BSD license, and as such are open-source software and free for both commercial and research use. The majority of other packages are licensed under a variety of open-source licenses. These other packages implement commonly used functionality and applications such as hardware drivers, robot models, datatypes, planning, perception, simultaneous localization and mapping (SLAM), simulation tools, and other algorithms.\nThe main ROS client libraries are geared toward a Unix-like system, mostly because of their dependence on large sets of open-source software dependencies. For these client libraries, Ubuntu Linux is listed as \"Supported\" while other variants such as Fedora Linux, macOS, and Microsoft Windows are designated \"experimental\" and are supported by the community.[12] The native Java ROS client library, rosjava,[13] however, does not share these limitations and has enabled ROS-based software to be written for the Android OS.[14] rosjava has also enabled ROS to be integrated into an officially supported MATLAB toolbox which can be used on Linux, macOS, and Microsoft Windows.[15] A JavaScript client library, roslibjs[16] has also been developed which enables integration of software into a ROS system via any standards-compliant web browser.\nHistory[edit]Early days at Stanford (2007 and earlier)[edit]Sometime before 2007, the first pieces of what eventually would become ROS began coalescing at Stanford University.[17][18] Eric Berger and Keenan Wyrobek, PhD students working in Kenneth Salisbury's[19] The Robotics laboratory at Stanford, was leading the Personal Robotics Program.[20] While working on robots to do manipulation tasks in human environments, the two students noticed that many of their colleagues were held back by the diverse nature of robotics: an excellent software developer might not have the hardware knowledge required, someone developing state of the art path planning might not know how to do the computer vision required. In an attempt to remedy this situation, the two students set out to make a baseline system that would provide a starting place for others in academia to build upon. In the words of Eric Berger, \"something that didn\u2019t suck, in all of those different dimensions\".[17]In their first steps towards this unifying system, the two built the PR1 as a hardware prototype and began to work on software from it, borrowing the best practices from other early open-source robotic software frameworks, particularly switchyard, a system that Morgan Quigley, another Stanford PhD student, had been working on in support of the STanford Artificial Intelligence Robot (STAIR)[21][22][23][24] by the Stanford Artificial Intelligence Laboratory. Early funding of US$50,000 was provided by Joanna Hoffman and Alain Rossmann, which supported the development of the PR1. While seeking funding for further development,[25] Eric Berger and Keenan Wyrobek met Scott Hassan, the founder of Willow Garage, a technology incubator which was working on an autonomous SUV and a solar autonomous boat. Hassan shared Berger and Wyrobek's vision of a \"Linux for robotics\", and invited them to come and work at Willow Garage. Willow Garage was started in January 2007, and the first commit of ROS code was made to SourceForge on 7 November 2007.[26]Willow Garage (2007\u20132013)[edit]Willow Garage began developing the PR2 robot as a follow-up to the PR1, and ROS as the software to run it. Groups from more than twenty institutions made contributions to ROS, both the core software and the growing number of packages that worked with ROS to form a greater software ecosystem.[27][28] That people outside of Willow were contributing to ROS (especially from Stanford's STAIR project) meant that ROS was a multi-robot platform from the start. While Willow Garage had originally had other projects in progress, they were scrapped in favor of the Personal Robotics Program: which focused on producing the PR2 as a research platform for academia and ROS as the open-source robotics stack that would underlie both academic research and tech startups, much like the LAMP stack did for web-based startups.\nIn December 2008, Willow Garage met the first of its three internal milestones: continuous navigation for the PR2 over two days and a distance of pi kilometers.[29] Soon after, an early version of ROS (0.4 Mango Tango)[30] was released, followed by the first RVIZ documentation and the first paper on ROS.[28] In early summer, the second internal milestone: having the PR2 navigate the office, open doors, and plug itself it in, was reached.[31] This was followed in August by the initiation of the ROS.org website.[32] Early tutorials on ROS were posted in December,[33] preparing for the release of ROS 1.0, in January 2010.[34] This was Milestone 3: producing tons of documentation and tutorials for the enormous abilities that Willow Garage's engineers had developed over the preceding 3 years.\nFollowing this, Willow Garage achieved one of its longest-held goals: giving away 10 PR2 robots to worthy academic institutions. This had long been a goal of the founders, as they felt that the PR2 could kick-start robotics research around the world. They ended up awarding eleven PR2s to different institutions, including University of Freiburg (Germany), Robert Bosch GmbH, Georgia Institute of Technology, KU Leuven (Belgium), Massachusetts Institute of Technology (MIT), Stanford University, Technical University of Munich (Germany), University of California, Berkeley, University of Pennsylvania, University of Southern California (USC), and University of Tokyo (Japan).[35] This, combined with Willow Garage's highly successful internship program[36] (run from 2008 to 2010 by Melonee Wise), helped to spread the word about ROS throughout the robotics world. The first official ROS distribution release: ROS Box Turtle, was released on 2 March 2010, marking the first time that ROS was officially distributed with a set of versioned packages for public use. These developments led to the first drone running ROS,[37] the first autonomous car running ROS,[38] and the adaption of ROS for Lego Mindstorms.[39] With the PR2 Beta program well underway, the PR2 robot was officially released for commercial purchase on 9 September 2010.[40]An image of Robot Operating System (ROS) running in Antarctica2011 was a banner year for ROS with the launch of ROS Answers, a Q/A forum for ROS users, on 15 February;[41] the introduction of the highly successful TurtleBot robot kit on 18 April;[42] and the total number of ROS repositories passing 100 on 5 May.[43] Willow Garage began 2012 by creating the Open Source Robotics Foundation (OSRF)[44] in April. The OSRF was immediately awarded a software contract by the Defense Advanced Research Projects Agency (DARPA).[45] Later that year, the first ROSCon was held in St. Paul, Minnesota,[46] the first book on ROS, ROS By Example,[47] was published, and Baxter, the first commercial robot to run ROS, was announced by Rethink Robotics.[48] Soon after passing its fifth anniversary in November, ROS began running on every continent on 3 December 2012.[49]In February 2013, the OSRF became the primary software maintainers for ROS,[50] foreshadowing the announcement in August that Willow Garage would be absorbed by its founders, Suitable Technologies.[51] At this point, ROS had released seven major versions (up to ROS Groovy),[52] and had users all over the globe. This chapter of ROS development would be finalized when Clearpath Robotics took over support responsibilities for PR2 in early 2014.[53]OSRF and Open Robotics (2013\u2013present)[edit]In the years since OSRF took over the primary development of ROS, a new version has been released every year,[52] while interest in ROS continues to grow. ROSCons have occurred every year since 2012, co-located with either ICRA or IROS, two flagship robotics conferences. Meetups of ROS developers have been organized in a variety of countries,[54][55][56] a number of ROS books have been published,[57] and many educational programs initiated.[58][59] On 1 September 2014, NASA announced the first robot to run ROS in space: Robotnaut 2, on the International Space Station.[60] In 2017, the OSRF changed its name to Open Robotics. Tech giants Amazon and Microsoft began to take an interest in ROS during this time, with Microsoft porting core ROS to Windows in September 2018,[61] followed by Amazon Web Services releasing RoboMaker in November 2018.[62]Perhaps the most important development of the OSRF/Open Robotics years thus far (not to discount the explosion of robot platforms that began to support ROS or the enormous improvements in each ROS version) was the proposal of ROS 2, a significant API change to ROS which is intended to support real-time programming, a wider variety of computing environments, and more modern technology.[63] ROS 2 was announced at ROSCon 2014,[64] the first commits to the ros2 repository were made in February 2015, followed by alpha releases in August 2015.[65] The first distribution release of ROS 2, Ardent Apalone, was released on 8 December 2017,[65] ushering in a new era of next-generation ROS development.\nDesign[edit]Philosophy[edit]An image depicting the ROS equation: Plumbing + Tools + Capabilities + Ecosystem = ROS!ROS was designed to be open source, intending that users would be able to choose the configuration of tools and libraries that interacted with the core of ROS so that users could shift their software stacks to fit their robot and application area. As such, there is very little which is core to ROS, beyond the general structure within which programs must exist and communicate. In one sense, ROS is the underlying plumbing behind nodes and message passing. However, in reality, ROS is not only plumbing, but a rich and mature set of tools, a wide-ranging set of robot-agnostic abilities provided by packages, and a greater ecosystem of additions to ROS.\nComputation graph model[edit]ROS processes are represented as nodes in a graph structure, connected by edges called topics.[66] ROS nodes can pass messages to one another through topics, make service calls to other nodes, provide a service for other nodes, or set or retrieve shared data from a communal database called the parameter server. A process called the ROS1 Master[66] makes all of this possible by registering nodes to themselves, setting up node-to-node communication for topics, and controlling parameter server updates. Messages and service calls do not pass through the master, rather the master sets up peer-to-peer communication between all node processes after they register themselves with the master. This decentralized architecture lends itself well to robots, which often consist of a subset of networked computer hardware, and may communicate with off-board computers for heavy computing or commands.\nNodes[edit]A node represents one process running the ROS graph. Every node has a name, which registers with the ROS1 master before it can take any other actions. Multiple nodes with different names can exist under different namespaces, or a node can be defined as anonymous, in which case it will randomly generate an additional identifier to add to its given name. Nodes are at the center of ROS programming, as most ROS client code is in the form of a ROS node which takes actions based on information received from other nodes, sends information to other nodes, or sends and receives requests for actions to and from other nodes.\nTopics[edit]Topics are named buses over which nodes send and receive messages.[67] Topic names must be unique within their namespace as well. To send messages to a topic, a node must publish to said topic, while to receive messages it must subscribe. The publish/subscribe model is anonymous: no node knows which nodes are sending or receiving on a topic, only that it is sending/receiving on that topic. The types of messages passed on a topic vary widely and can be user-defined. The content of these messages can be sensor data, motor control commands, state information, actuator commands, or anything else.\nServices[edit]A node may also advertise services.[68] A service represents an action that a node can take which will have a single result. As such, services are often used for actions that have a defined start and end, such as capturing a one-frame image, rather than processing velocity commands to a wheel motor or odometer data from a wheel encoder. Nodes advertise services and call services from one another.\nParameter server[edit]The parameter server[68] is a database shared between nodes which allows for communal access to static or semi-static information. Data that does not change frequently and as such will be infrequently accessed, such as the distance between two fixed points in the environment, or the weight of the robot, are good candidates for storage in the parameter server.\nTools[edit]ROS's core functionality is augmented by a variety of tools that allow developers to visualize and record data, easily navigate the ROS package structures, and create scripts automating complex configuration and setup processes. The addition of these tools greatly increases the abilities of systems using ROS by simplifying and providing solutions to several common robotics development problems. These tools are provided in packages like any other algorithm, but rather than providing implementations of hardware drivers or algorithms for various robotic tasks, these packages provide task and robot-agnostic tools that come with the core of most modern ROS installations.\nrviz[edit]rviz[69] (Robot Visualization tool) is a three-dimensional visualizer used to visualize robots, the environments they work in, and sensor data. It is a highly configurable tool, with many different types of visualizations and plugins. Unified Robot Description Format (URDF) is an XML file format for robot model description.\nrosbag[edit]rosbag[70] is a command line tool used to record and playback ROS message data. rosbag uses a file format called bags,[71] which log ROS messages by listening to topics and recording messages as they come in. Playing messages back from a bag is largely the same as having the original nodes that produced the data in the ROS computation graph, making bags a useful tool for recording data to be used in later development. While rosbag is a command line only tool, rqt_bag[72] provides a GUI interface to rosbag.\ncatkin[edit]catkin[73] is the ROS1 build system, having replaced rosbuild[74] as of ROS Groovy. catkin is based on CMake and is similarly cross-platform, open-source, and language-independent. As of ROS2 catkin is no longer in use, but still maintained for legacy support.[75]rosbash[edit]The rosbash[76] package provides a suite of tools which augment the functionality of the bash shell. These tools include rosls, roscd, and roscp, which replicate the functionalities of ls, cd, and cp respectively. The ROS versions of these tools allow users to use ros package names in place of the file path where the package is located. The package also adds tab-completion to most ROS utilities and includes rosed, which edits a given file with the chosen default text editor, as well rosrun, which runs executables in ROS packages. rosbash supports the same functionalities for zsh and tcsh, to a lesser extent.\nroslaunch[edit]roslaunch[77] is a tool used to launch multiple ROS nodes both locally and remotely, as well as setting parameters on the ROS parameter server. roslaunch configuration files, which are written using XML can easily automate a complex startup and configuration process into a single command. roslaunch scripts can include other roslaunch scripts, launch nodes on specific machines, and even restart processes that die during execution.\nPackages of note[edit]ROS contains many open-source implementations of common robotics functionality and algorithms. These open-source implementations are organized into packages. Many packages are included as part of ROS distributions, while others may be developed by individuals and distributed through code-sharing sites such as github. Some packages of note include:\nSystems and tools[edit]actionlib[78] provides a standardized interface for interfacing with preemptable tasks.nodelet[79] provides a way to run multiple algorithms in a single process.rosbridge[80] provides a JSON API to ROS functionalities for non-ROS programs.Mapping and localization[edit]slam toolbox[81] provides full 2D SLAM and localization system.gmapping[82] provides a wrapper for OpenSlam'sGmapping algorithm for simultaneous localization and mapping.cartographer[83] provides real time 2D and 3D SLAM algorithms developed at Google.amcl[84] provides an implementation of adaptive Monte-Carlo localization.Navigation[edit]navigation[85] provides the capability of navigating a mobile robot in a planar environment.Manipulation[edit]MoveIt![86] provides motion planning capabilities for robot manipulators. Its default planning library is the Open Motion Planning Library (OMPL).[87]Perception[edit]vision_opencv[88] is a meta-package which provides packages for integrating ROS with OpenCV.Coordinate frame representation[edit]tf[89] provided a system for representing, tracking and transforming coordinate frames until ROS Hydro, when it was deprecated in favor of tf2.tf2[90] is the second generation of the tf library, and provides the same abilities for ROS versions after Hydro.Simulation[edit]gazebo_ros_pkgs[91] is a meta-package which provides packages for integrating ROS with the Gazebo simulator.stage[92] provides an interface for the 2D Stage simulator.Versions and releases[edit]ROS releases may be incompatible with other releases and are often referred to by code name rather than version number. ROS 2 currently releases a version every year in May, following the release of Ubuntu LTS versions.[93][94] These releases are alternating supported for 5 years (even years/LTS Ubuntu version release) and 1.5 years (uneven years/no LTS Ubuntu version release). ROS 1 does not see any new version. Aside from this, there has been the ROS-Industrial or ROS-I derivate project since at least 2012.\nROS 2[edit]ROS 2 Distribution Releases[65][95]Distribution\nRelease date\nPoster\nEOL date\nSupport duration\nRolling Ridley[96][97](rolling release with latest features)\nprogressing sinceJune 2020\nN/A\nN/A\nLyrical Luth[98]May 2026\nN/A\nN/A\nN/A\nKilted Kaiju\n23 May 2025\nLatest version:November 2026.mw-parser-output .version-legend{display:flex;flex-wrap:wrap;column-gap:12px}.mw-parser-output .version-legend-vertical{display:flex;flex-wrap:wrap;column-gap:4px;flex-direction:column}.mw-parser-output .version-legend .legend-item,.mw-parser-output .version-legend-vertical .legend-item{page-break-inside:avoid;break-inside:avoid-column;gap:4px}.mw-parser-output .version-legend .legend-item .swatch,.mw-parser-output .version-legend-vertical .legend-item .swatch{display:inline-block;width:1.25em;height:1.25em;border:1px solid #aaa;margin-top:1px}.mw-parser-output .swatch-unsupported{background-color:#fdb3ab}.mw-parser-output .swatch-maintained{background-color:#f8eaba}.mw-parser-output .swatch-latest{background-color:#d4f4b4}.mw-parser-output .swatch-preview{background-color:#c1e6f5}.mw-parser-output .swatch-future{background-color:#f2e2fc}@media screen{html.skin-theme-clientpref-night .mw-parser-output .version-legend .legend-item .swatch,html.skin-theme-clientpref-night .mw-parser-output .version-legend-vertical .legend-item .swatch{border-color:#72777d}html.skin-theme-clientpref-night .mw-parser-output .swatch-unsupported{background-color:#421511}html.skin-theme-clientpref-night .mw-parser-output .swatch-maintained{background-color:#433500}html.skin-theme-clientpref-night .mw-parser-output .swatch-latest{background-color:#334423}html.skin-theme-clientpref-night .mw-parser-output .swatch-preview{background-color:#154467}html.skin-theme-clientpref-night .mw-parser-output .swatch-future{background-color:#3C2e69}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .version-legend .legend-item .swatch,html.skin-theme-clientpref-os .mw-parser-output .version-legend-vertical .legend-item .swatch{border-color:#72777d}html.skin-theme-clientpref-os .mw-parser-output .swatch-unsupported{background-color:#421511}html.skin-theme-clientpref-os .mw-parser-output .swatch-maintained{background-color:#433500}html.skin-theme-clientpref-os .mw-parser-output .swatch-latest{background-color:#334423}html.skin-theme-clientpref-os .mw-parser-output .swatch-preview{background-color:#154467}html.skin-theme-clientpref-os .mw-parser-output .swatch-future{background-color:#3C2e69}}1.5 years\nJazzy Jalisco\n23 May 2024[99]Supported: May 20295 years\nIron Irwini\n23 May 2023[100]Unsupported: November 20241.5 years\nHumble Hawksbill\n23 May 2022[101]Supported: May 20275 years\nGalactic Geochelone\n23 May 2021[102]Unsupported: December 20221.5 years\nFoxy Fitzroy\n5 June 2020[103]Unsupported: June 20233 years\nEloquent Elusor\n22 November 2019\nUnsupported: November 20201 year\nDashing Diademata\n31 May 2019\nUnsupported: May 20212 years\nCrystal Clemmys\n14 December 2018\nUnsupported: December 20191 year\nBouncy Bolson\n2 July 2018\nUnsupported: July 20191 year\nArdent Apalone\n8 December 2017\nUnsupported: December 20181 year\nbeta3\n13 September 2017\nN/A\nUnsupported: December 20174 months\nbeta2\n5 July 2017\nN/A\nUnsupported: September 20172 months\nbeta1\n19 December 2016\nN/A\nUnsupported: July 20177 months\n(ROS 2 real-time proposal)\n7 January 2016[104]N/A\nN/A\nN/A\nalpha1 (Anchor) -alpha8 (Hook-and-Loop)[105]31 August 2015 -5 October 2016[106]N/A\nUnsupported: December 2016total: 16 months\n(\"Why ROS 2?\")\n20 July 2015[107]N/A\nN/A\nN/A\n(batch CI jobs for ROS 2and http://design.ros2.org)\nreferenced in Q&A6 May 2015[108]N/A\nN/A\nN/A\n(first commits toROS 2 repository)\nFebruary 2015\nN/A\nN/A\nN/A\nROSCon 2014:[109][110]\"Next-generation ROS: Building on DDS\",\"ROS 2.0: Developer preview\"\n12 September 2014\nN/A\nN/A\nN/A\nLegend:UnsupportedSupportedLatest versionPreview versionFuture versionROS 1[edit]ROS 1 Distribution Releases[52]Distribution\nRelease date\nPoster\nEOL date\nSupport duration\nNoetic Ninjemys(last ROS 1 release)\n23 May 2020\nUnsupported: May 20255 years\nMelodic Morenia\n23 May 2018\nUnsupported: 2023-05-305 years\nLunar Loggerhead\n23 May 2017\nUnsupported: 2019-05-302 years\nKinetic Kame\n23 May 2016\nUnsupported: 2021-05-305 years\nJade Turtle\n23 May 2015\nUnsupported: 2017-05-302 years\nIndigo Igloo\n22 July 2014\nUnsupported: 2019-04-305 years\nHydro Medusa\n4 September 2013\nUnsupported: 2014-05-310.5 years\nGroovy Galapagos\n31 December 2012\nUnsupported: 2014-07-312 years\nFuerte Turtle\n23 April 2012\nUnsupported: --\u2014\nElectric Emys\n30 August 2011\nUnsupported: --\u2014\nDiamondback\n2 March 2011\nUnsupported: --\u2014\nC Turtle\n2 August 2010\nUnsupported: --\u2014\nBox Turtle\n2 March 2010\nUnsupported: --\u2014\n(Initial Release)\n2007\nn/a\nUnsupported: --\u2014\nLegend:UnsupportedSupportedLatest versionPreview versionFuture versionROS-Industrial[edit]ROS-Industrial[111] is an open-source project (BSD (legacy)/Apache 2.0 (preferred) license) that extends the advanced abilities of ROS to manufacturing automation and robotics. In the industrial environment, there are two different approaches to programming a robot: either through an external proprietary controller, typically implemented using ROS, or via the respective native programming language of the robot. ROS can therefore be seen as the software-based approach to programming industrial robots instead of the classic robot controller-based approach.\nThe ROS-Industrial repository includes interfaces for common industrial manipulators, grippers, sensors, and device networks. It also provides software libraries for automatic 2D/3D sensor calibration, process path/motion planning, applications like Scan-N-Plan, developer tools like the Qt Creator ROS Plugin, and training curricula that are specific to the needs of manufacturers. ROS-I is supported by an international Consortium of industry and research members. The project began as a collaborative endeavor between Yaskawa Motoman Robotics, Southwest Research Institute, and Willow Garage to support the use of ROS for manufacturing automation, with the GitHub repository being founded in January 2012 by Shaun Edwards (SwRI). Currently, the Consortium is divided into three groups; the ROS-Industrial Consortium Americas (led by SwRI and located in San Antonio, Texas), the ROS-Industrial Consortium Europe (led by Fraunhofer IPA and located in Stuttgart, Germany), and the ROS-Industrial Consortium Asia Pacific (led by Advanced Remanufacturing and Technology Centre (ARTC) and Nanyang Technological University (NTU) and located in Singapore).\nThe Consortia supports the global ROS-Industrial community by conducting ROS-I training, providing technical support and setting the future roadmap for ROS-I, as well as conducting pre-competitive joint industry projects to develop new ROS-I abilities.[112]Space ROS[edit]In November 2020, NASA announced Blue Origin had been selected through the Space Technology Mission Directorate\u2019s Announcement of Collaboration Opportunity (ACO) to co-develop Space Robot Operating System (Space ROS) together with three NASA centers.[113]  The purpose of Space ROS is to provide a reusable and modular software framework for robotic and autonomous space systems predicated on ROS 2 that is compliant to aerospace mission and safety assurance requirements (such as NPR 7150.2 and DO-178C). The project was formulated and led by Will Chambers,[114] Blue Origin's principal technologist of robotics at the time. In 2021, Blue Origin subcontracted software development workload to Open Robotics who remained on the team until the program ended in 2022. Space ROS is currently an open community project.[115][116]PickNik Robotics and Open Source Robotics Foundation currently lead the Space ROS effort.[117]ROS-compatible robots and hardware[edit]Robots[edit]ABB, Adept, Fanuc, Motoman, and Universal Robots are supported by ROS-Industrial.[118]Baxter[119] at Rethink Robotics, Inc.CK-9: robotics development kit by Centauri Robotics, supports ROS.[120]GoPiGo3: Raspberry Pi-based educational robot, supports ROS.[121]HERB[122] developed at Carnegie Mellon University in Intel's personal robotics programHusky A200: robot developed (and integrated into ROS) by Clearpath Robotics[123]Nao[124] humanoid: University of Freiburg's Humanoid Robots Lab[125] developed a ROS integration for the Nao humanoid based on an initial port by Brown University[126][127]PR1: personal robot developed in Ken Salisbury's lab at Stanford[128]PR2: personal robot being developed at Willow Garage[129]Raven II Surgical Robotic Research Platform[130][131]ROSbot: autonomous robot platform by Husarion[132]Shadow Robot Hand:[133] a fully dexterous humanoid hand.STAIR I and II:[134] robots developed in Andrew Ng's lab at StanfordStretch: an integrated mobile manipulator by Hello Robot targeting assistive applications.[135][136]SummitXL:[137] mobile robot developed by Robotnik, an engineering company specialized in mobile robots, robotic arms, and industrial solutions with ROS architecture.UBR1:[138][139] developed by Unbounded Robotics, a spin-off of Willow Garage.Webots: robot simulator integrating a complete ROS programming interface.[140]SBCs and hardware[edit]BeagleBoard: the robotics lab of the Katholieke Universiteit Leuven, Belgium[141] has ported ROS to the Beagleboard.Raspberry Pi: image of Ubuntu Mate with ROS[142] by Ubiquity Robotics; installation guide for Raspbian;[143] Installation guide for ROS2 to Raspberry Pi.[144]Sitara ARM Processors have support for the ROS package as part of the official Linux SDK.[145]See also[edit].mw-parser-output .portalbox{padding:0;margin:0.5em 0;display:table;box-sizing:border-box;max-width:175px;list-style:none}.mw-parser-output .portalborder{border:1px solid var(--border-color-base,#a2a9b1);padding:0.1em;background:var(--background-color-neutral-subtle,#f8f9fa)}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;height:1.9em;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}Free and open-source software portalOpen-source hardwareOpen-source softwareRobotics middlewareList of free and open-source software packagesReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"ROS 2 Jazzy Jalisco\". ROS.org. Open Robotics. Retrieved 25 February 2025.^\"ROS 2 Kilted Kaiju\". ROS.org. Open Robotics. May 2025. Retrieved 25 February 2025.^\"ROS/Introduction \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 30 July 2021.^Kay, Jackie (January 2016). \"Proposal for Implementation of Real-time Systems in ROS 2\". ROS.org. Open Robotics. Retrieved 23 January 2023.^Kay, Jackie (January 2016). \"Realtime Design Guidelines For ROS 2\". ROS.org. Open Robotics. Retrieved 23 January 2023.^\"ROS 2 For Realtime Applications\". ROS.org. Open Robotics. 17 October 2018. Retrieved 22 November 2018.^\"Browsing packages for melodic\". ROS.org. Open Robotics. Archived from the original on 24 September 2015. Retrieved 21 February 2016.^\"Package Summary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"Package SUmmary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"Package Summary\". ROS.org. Open Robotics. Retrieved 21 February 2016.^\"client libraries\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS/Installation \u2013 ROS Wiki\". ROS.org. Open Robotics. 29 September 2013. Retrieved 12 July 2014.^\"rosjava \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"android \u2013 ROS Wiki\". ROS.org. Open Robotics. 12 April 2014. Retrieved 12 July 2014.^\"Robot Operating System (ROS) Support from MATLAB \u2013 Hardware Support\". Mathworks.com. Retrieved 12 July 2014.^\"roslibjs \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^ abGuizzo, Evan Ackerman and Erico (7 November 2017). \"Wizards of ROS: Willow Garage and the Making of the Robot Operating System\". IEEE Spectrum: Technology, Engineering, and Science News. Retrieved 29 April 2019.^Wyrobek, Keenan (31 October 2017). \"The Origin Story of ROS, the Linux of Robotics\". IEEE Spectrum: Technology, Engineering, and Science News. Retrieved 29 April 2019.^\"J. Kenneth Salisbury, Ph.D. | Salisbury Robotics Lab\". Retrieved 29 April 2019.^\"Stanford Personal Robotics Program\". personalrobotics.stanford.edu. Retrieved 29 April 2019.^\"Stanford's Robot Makers\". 16 January 2019.^Ng, Andrew; Gould, Stephen; Quigley, Morgan; Saxena, Ashutosh; Berger, Eric (2008). \"STAIR: The STanford Artificial Intelligence Robot project\". Snowbird Workshop.^\"STAIR\". stair.Stanford.edu. Retrieved 12 December 2017.^Quigley, Morgan; Berger, Eric; Ng, Andrew Y. (2007), STAIR: Hardware and Software Architecture(PDF), AAAI 2007 Robotics Workshop^Keenan Wyrobek (3 July 2017). \"Personal Robotics Program Fund Fundraising Deck from 2006\".^\"Repository: code\". Sourceforge.net. Retrieved 12 December 2017.^\"Repositories\". ROS.org. Retrieved 7 June 2011.^ abQuigley, Morgan; Gerkey, Brian; Conley, Ken; Faust, Josh; Foote, Tully; Leibs, Jeremy; Berger, Eric; Wheeler, Rob; Ng, Andrew. \"ROS: an open-source Robot Operating System\"(PDF). Retrieved 3 April 2010.^WillowGaragevideo (19 December 2008), Milestone 1, retrieved 29 April 2019^\"ROS 0.4 Release \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 29 April 2019.^WillowGaragevideo (2 July 2009), Milestone 2 Explained, retrieved 29 April 2019^\"Welcome to ros.org \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS Tutorials and Turtles \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS 1.0 \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"The Results Are In: PR2 Beta Program Recipients!\". Willow Garage. Archived from the original on 13 July 2018. Retrieved 29 April 2019.^\"Interns and Visiting Scholars\". Willow Garage. Retrieved 29 April 2019.^\"Robots Using ROS: Penn Quadrotors \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Robots Using ROS: Marvin autonomous car (Austin Robot Technology/UT Austin) \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Robots Using ROS: Lego NXT \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"PR2 Robots Available for Purchase\".^\"Announcing ROS Answers \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"ROS on the Move: TurtleBots available for preorder\". Willow Garage. Retrieved 12 December 2017.^\"100 Repositories \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Willow Garage Spins Out OSRF\". Archived from the original on 6 November 2017. Retrieved 13 October 2017.^\"DARPA Awards Simulation Software Contract to Open Source Robotics Foundation\".^\"Thanks for a great ROSCon 2012! \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"New Book: ROS by Example \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"Rethink ROS \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"ROS: Five Years \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"Osrf \u2013 Ros @ Osrf\". Osrfoundation.org. 11 February 2013. Retrieved 12 July 2014.^\"employees join Suitable Technologies\". Willow Garage. Archived from the original on 8 October 2017. Retrieved 12 July 2014.^ abc\"Distributions \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"Clearpath Welcomes PR2 to the Family\". 15 January 2014.^\"Notes from the first Korean ROS Users Meetup \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"First Danish ROS Meetup\".^\"First Ukrainian ROS Meetup\".^\"Programming Robots with ROS: A Practical Introduction to the Robot Operating System\". OReilly.com. Retrieved 12 December 2017.^\"Report from first ROS Summer School in China \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 24 November 2018.^\"ROS Robot Ignite Academy\".^\"ROS running on ISS \u2013 ROS robotics news\". ROS.org. Open Robotics. Retrieved 12 December 2017.^\"Summary\". ros-win.visualstudio.com. Retrieved 29 April 2019.^\"Announcing AWS RoboMaker\". Amazon Web Services, Inc. Retrieved 29 April 2019.^\"Why ROS 2?\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS 2 Overview\". ROS.org. Open Robotics. Retrieved 21 September 2021.^ abc\"ROS 2 Distributions\". ROS.org. Open Robotics. Retrieved 21 September 2021.^ ab\"ROS/Tutorials/UnderstandingNodes \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS/Tutorials/UnderstandingTopics \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^ ab\"ROS/Tutorials/UnderstandingServicesParams \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rviz \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"rosbag \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"Bags \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"rqt_bag \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"catkin \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rosbuild \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"Migrating a C++ Package Example \u2014 ROS 2 Documentation: Humble documentation\". docs.ros.org. Retrieved 7 October 2025.^\"rosbash \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"roslaunch \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 23 April 2019.^\"actionlib \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"nodelet \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"rosbridge_suite \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"slam_toolbox \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 11 February 2020.^\"gmapping \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"cartographer \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"amcl \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"navigation \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"MoveIt Motion Planning Framework\". ROS MoveIt!.^\"MoveIt Documentation: Rolling\".^\"vision_opencv \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"tf \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"tf2 \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"gazebo_ros_pkgs \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"stage \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 29 April 2019.^\"ROS Release Schedule Changes\". 9 May 2018.^\"REP 2000 -- ROS 2 Releases and Target Platforms (ROS.org)\". www.ros.org. Retrieved 25 February 2025.^\"REP 2000 \u2013 ROS 2 Releases and Target Platforms\". ROS.org. Open Robotics. Retrieved 20 February 2021.^\"ROS 2 Rolling Ridley (codename 'rolling'; June 2020) \u2013 ROS 2 Documentation: Foxy documentation\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"ROS 2 rolling distribution name brainstorming\". ROS.org. Open Robotics. 15 June 2020. Retrieved 30 July 2021.^\":kilted: ROS 2 Kilted Kaiju Release!\". Open Robotics Discourse. 23 May 2025. Retrieved 8 October 2025.^\"ROS 2 Jazzy Jalisco Released!\". 23 May 2024.^\"ROS 2 Iron Irwini Released!\". 23 May 2023.^\"ROS 2 Humble Hawksbill Released!\". 23 May 2022.^\"ROS Galactic Geochelone Released\". 23 May 2021. Retrieved 10 July 2021.^\"ROS Foxy Fitzroy Released\". 5 June 2020. Retrieved 24 June 2020.^\"ROS 2 design\". GitHub. 29 January 2022.^\"ROS 2 alpha releases (Aug 2015 \u2013 Oct 2016) \u2013 ROS 2 Documentation: Foxy documentation\".^\"ROS 2 alpha8\". 5 October 2016.^\"Why ROS 2?\".^\"Is there a release date of ros 2 or more pieces of information about it? \u2013 ROS Answers: Open Source Q&A Forum\".^\"Program | ROSCon 2014\".^\"Home \u00b7 ros2-wiki\".^\"ROS-Industrial About\". rosindustrial.org. Retrieved 12 December 2017.^\"Brief History\". ROS-Industrial. Retrieved 11 July 2018.^\"2020 NASA Announcement of Collaboration Opportunity (ACO) Selections - NASA\". 9 November 2020. Retrieved 31 October 2024.^The Construct (13 March 2023). RDP120: Space ROS. Retrieved 31 October 2024 \u2013 via YouTube.^\"Home\". space.ros.org. Retrieved 31 October 2024.^\"Space ROS\". GitHub. Retrieved 31 October 2024.^\"Space ROS | Space Robotics Operating System\". PickNik. Retrieved 31 October 2024.^\"Home\". ROS-Industrial. Retrieved 12 December 2017.^\"Baxter Research Robots Q&A | Rethink Robotics\". 24 July 2014. Archived from the original on 24 July 2014. Retrieved 30 July 2021.^\"CK-9 | Centauri Robotics\". centaurirobotics.in. Retrieved 30 July 2021.^\"Robots/gopigo3 \u2013 ROS Wiki\". ROS.org. Open Robotics. Retrieved 30 July 2021.^\"CMU Personal Robotics Lab\". personalrobotics.Intel-Research.net. Retrieved 12 December 2017.^\"Husky UGV \u2013 Outdoor Field Research Robot by Clearpath\". ClearPathRobotics.com. Retrieved 12 December 2017.^\"nao \u2013 ROS Wiki\". ROS.org. Open Robotics. 28 October 2013. Retrieved 12 July 2014.^\"Welcome to the Humanoid Robots Lab at the University of Bonn!\". Humanoid Robots Lab \u2013 University of Bonn. Retrieved 30 July 2021.^\"Brown University Robotics\". 28 January 2013. Archived from the original on 28 January 2013. Retrieved 30 July 2021.^\"[ros-users] ROS NAO Driver\". 29 October 2013. Archived from the original on 29 October 2013. Retrieved 30 July 2021.^\"Stanford Personal Robotics Program\". personalrobotics.Stanford.edu. Retrieved 12 December 2017.^\"Featured\". Willow Garage. 20 June 2010. Archived from the original on 20 June 2010. Retrieved 30 July 2021.^B. Hannaford, J. Rosen, Diana CW Friedman, H. King, P. Roan, L. Cheng, D. Glozman, J. Ma, S.N. Kosari, L. White, 'Raven-II: AN Open Platform for Surgical Robotics Research,' IEEE Transactions on Biomedical Engineering, vol. 60, pp. 954-959, April 2013.^\"BioRobotics Laboratory | Biorobotics Laboratory \u2013 University of Washington\". Brl.ee.washington.edu. Archived from the original on 14 July 2014. Retrieved 12 July 2014.^\"ROSbot 2.0 & ROSbot 2.0 PRO \u00b7 Husarion Docs\". husarion.com. Retrieved 30 July 2021.^\"Dexterous Hand Series \u2013 Shadow Robot Company\". Retrieved 30 July 2021.^\"STAIR\". stair.stanford.edu. Retrieved 30 July 2021.^\"Hello Robot\".^\"This Robot Could Be The Key To Empowering People With Disabilities\".^\"Summit XL \u2013 Robotnik\". Robotnik.es. Retrieved 12 July 2014.^\"Specification\". Unbounded Robotics. Archived from the original on 28 April 2015. Retrieved 12 July 2014.^Ackerman, Evan (21 October 2013). \"UBR-1 Robot From Unbounded Robotics Revolutionizes Affordable Mobile Manipulation\". IEEE Spectrum. Retrieved 12 July 2014.^\"Using ROS with Webots\". Retrieved 18 May 2018.^\"Koen Buys\". 29 October 2013. Archived from the original on 29 October 2013. Retrieved 30 July 2021.^\"Ubiquity Robotics Downloads\". Retrieved 29 January 2018.^\"ROSberryPi/Installing ROS Kinetic on the Raspberry Pi\". Retrieved 29 January 2018.^\"ROS 2 on Raspberry Pi\". Retrieved 17 October 2025.^\"5.3.6. ROS and Radar \u2013 Processor SDK Linux Documentation\". software-dl.ti.com. Retrieved 1 May 2020.Notes.mw-parser-output .refbegin{margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}@media screen{.mw-parser-output .refbegin{font-size:90%}}STAIR: The STanford Artificial Intelligence Robot project, Andrew Y. Ng, Stephen Gould, Morgan Quigley, Ashutosh Saxena, Eric Berger. Snowbird, 2008.Related projects[edit]RT middleware \u2013 Robot middleware standard/implementations. RT-component is discussed/defined by the Object Management Group.External links[edit]Official website.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteReal-time operating systems (RTOS)OperatingsystemsPOSIX supportUnix-likeDNIXJunos OSLynxOSMulti-Environment Real-Time^ (MERT \u2013 Unix-RT)OS2000QNX^Real-Time Linux\u00b0RTLinux\u00b0UNOSLiteOSLiteOS\u00b0PartialChorusOS^Integrity^Nucleus RTOS^NuttX^\u00b0Operating System Embedded^ (OSE)PX5 RTOS^RIOT^\u00b0RTEMS\u00b0TRON supportITRON projectT-KernelMicro T-KernelT-Engine Forum (organization)T-LicensePartialeCos\u00b0RTEMS\u00b0Capability-basedEROS^\u00b0seL4^\u00b0Java virtual machineChorus/Jazz^ (JavaOS + ChorusOS^)DOSMultiuser DOSConcurrent DOSFlexOSREAL/32L4 kernelL4Linux^\u00b0PikeOS^REX OS^Wombat^\u00b0PsionEKA2^\u00b0 kernel \u2192 Symbian OS^\u00b0MicrosoftThreadX^Windows Embedded CompactIBM4680 OS4690 OSTransaction Processing Facility (TPF)Texas InstrumentsDSOSTI-RTOS Kernel^\u00b0DECPDP-11 & VAXRSX-11RT-11VAXELNLow resourceChibiOS/RT^\u00b0Contiki\u00b0ERIKA Enterprise\u00b0FunkOS\u00b0Mynewt\u00b0Nano-RK\u00b0OpenComRTOS^PX5 RTOS^RT-Thread\u00b0 NanoRIOT\u00b0RTEMS\u00b0ThreadX^Zephyr^\u00b0BeRTOS^\u00b0DioneOSembOSFreeRTOS^\u00b0\u00b5C/OS^\u00b0\u00b5-velOSity^MQX^OS-9 (Microware)Phantom OS^\u00b0pSOSRMXRT-Thread\u00b0 StandardScreenOSSintran IIITHEOSThoth^ \u2192 Harmony^VRTX^VxWorksUniProtonFrameworks, kitsRobot Operating System\u00b0 2RTAI\u00b0TI-RTOS^\u00b0Xenomai\u00b0DevelopersGordon BellDavid CheritonDave CutlerDan DodgeAdam DunkelsKen SakamuraItalics= discontinued^ = Microkernel\u00b0 = Open-source softwareComparisonCategory\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robot_Operating_System&oldid=1317312908\"", "tags": ["en.wikipedia.org", "wiki", "robot", "operating", "system"]}
{"url": "https://en.wikipedia.org/wiki/Intelligent_agent", "title": null, "text": "Software agent which acts autonomously.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For the term in intelligent design, see Intelligent designer.Not to be confused with Embodied agent..mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}It has been suggested that Agentic AI be merged into this article. (Discuss) Proposed since May 2025.Simple reflex agent diagramIn artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. AI textbooks[which?] define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\nA specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods.\nIntelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria\u2014such as a firm, a state, or a biome.[1]Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[2] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[3] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[4]Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinarysocio-cognitivemodeling and computer social simulations.\nIntelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents\u2014autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[1]Intelligent agents as the foundation of AI[edit]This section possibly contains original research. Relevant discussion may be found on Talk:Intelligent agent. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed.  (February 2023) (Learn how and when to remove this message)The concept of intelligent agents provides a foundational lens through which to define and understand artificial intelligence. For instance, the influential textbook Artificial Intelligence: A Modern Approach (Russell & Norvig) describes:\nAgent: Anything that perceives its environment (using sensors) and acts upon it (using actuators). E.g., a robot with cameras and wheels, or a software program that reads data and makes recommendations.Rational Agent: An agent that strives to achieve the *best possible outcome* based on its knowledge and past experiences. \"Best\" is defined by a performance measure \u2013 a way of evaluating how well the agent is doing.Artificial Intelligence (as a field): The study and creation of these rational agents.Other researchers and definitions build upon this foundation. Padgham & Winikoff emphasize that intelligent agents should react to changes in their environment in a timely way, proactively pursue goals, and be flexible and robust (able to handle unexpected situations). Some also suggest that ideal agents should be \"rational\" in the economic sense (making optimal choices) and capable of complex reasoning, like having beliefs, desires, and intentions (BDI model). Kaplan and Haenlein offer a similar definition, focusing on a system's ability to understand external data, learn from that data, and use what is learned to achieve goals through flexible adaptation.\nDefining AI in terms of intelligent agents offers several key advantages:\nAvoids Philosophical Debates: It sidesteps arguments about whether AI is \"truly\" intelligent or conscious, like those raised by the Turing test or Searle's Chinese Room. It focuses on behavior and goal achievement, not on replicating human thought.Objective Testing: It provides a clear, scientific way to evaluate AI systems. Researchers can compare different approaches by measuring how well they maximize a specific \"goal function\" (or objective function). This allows for direct comparison and combination of techniques.Interdisciplinary Communication: It creates a common language for AI researchers to collaborate with other fields like mathematical optimization and economics, which also use concepts like \"goals\" and \"rational agents.\"Objective function[edit]Further information: utility function (economics) and loss function (mathematics)An objective function (or goal function) specifies the goals of an intelligent agent. An agent is deemed more intelligent if it consistently selects actions that yield outcomes better aligned with its objective function. In effect, the objective function serves as a measure of success.\nThe objective function may be:\nSimple: For example, in a game of Go, the objective function might assign a value of 1 for a win and 0 for a loss.Complex: It might require the agent to evaluate and learn from past actions, adapting its behavior based on patterns that have proven effective.The objective function encapsulates all of the goals the agent is designed to achieve. For rational agents, it also incorporates the trade-offs between potentially conflicting goals. For instance, a self-driving car's objective function might balance factors such as safety, speed, and passenger comfort.\nDifferent terms are used to describe this concept, depending on the context.  These include:\nUtility function:  Often used in economics and decision theory, representing the desirability of a state.Objective function: A general term used in optimization.Loss function:  Typically used in machine learning, where the goal is to minimize the loss (error).Reward Function: Used in reinforcement learning.Fitness Function: Used in evolutionary systems.Goals, and therefore the objective function, can be:\nExplicitly defined: Programmed directly into the agent.Induced: Learned or evolved over time.\nIn reinforcement learning, a \"reward function\" provides feedback, encouraging desired behaviors and discouraging undesirable ones. The agent learns to maximize its cumulative reward.In evolutionary systems, a \"fitness function\" determines which agents are more likely to reproduce. This is analogous to natural selection, where organisms evolve to maximize their chances of survival and reproduction.[5]Some AI systems, such as nearest-neighbor, reason by analogy rather than being explicitly goal-driven. However, even these systems can have goals implicitly defined within their training data.[6] Such systems can still be benchmarked by framing the non-goal system as one whose \"goal\" is to accomplish its narrow classification task.[7]Systems not traditionally considered agents, like knowledge-representation systems, are sometimes included in the paradigm by framing them as agents with a goal of, for example, answering questions accurately. Here, the concept of an \"action\" is extended to encompass the \"act\" of providing an answer. As a further extension, mimicry-driven systems can be framed as agents optimizing a \"goal function\" based on how closely the IA mimics the desired behavior.[2] In generative adversarial networks (GANs) of the 2010s, an \"encoder\"/\"generator\" component attempts to mimic and improvise human text composition. The generator tries to maximize a function representing how well it can fool an antagonistic \"predictor\"/\"discriminator\" component.[8]While symbolic AI systems often use an explicit goal function, the paradigm also applies to neural networks and evolutionary computing. Reinforcement learning can generate intelligent agents that appear to act in ways intended to maximize a \"reward function\".[9] Sometimes, instead of setting the reward function directly equal to the desired benchmark evaluation function, machine learning programmers use reward shaping to initially give the machine rewards for incremental progress.[10]Yann LeCun stated in 2018, \"Most of the learning algorithms that people have come up with essentially consist of minimizing some objective function.\"[11]AlphaZero chess had a simple objective function: +1 point for each win, and -1 point for each loss. A self-driving car's objective function would be more complex.[12] Evolutionary computing can evolve intelligent agents that appear to act in ways intended to maximize a \"fitness function\" influencing how many descendants each agent is allowed to leave.[4]The mathematical formalism of AIXI was proposed as a maximally intelligent agent in this paradigm.[13] However, AIXI is uncomputable. In the real world, an IA is constrained by finite time and hardware resources, and scientists compete to produce algorithms that achieve progressively higher scores on benchmark tests with existing hardware.[14]Agent function[edit]An intelligent agent's behavior can be described mathematically by an agent function. This function determines what the agent does based on what it has seen.\nA percept refers to the agent's sensory inputs at a single point in time. For example, a self-driving car's percepts might include camera images, lidar data, GPS coordinates, and speed readings at a specific instant. The agent uses these percepts, and potentially its history of percepts, to decide on its next action (e.g., accelerate, brake, turn).\nThe agent function, often denoted as f, maps the agent's entire history of percepts to an action.[15]Mathematically, this can be represented as\n\n  \n    \n      \n        f\n        :\n        \n          P\n          \n            \u2217\n          \n        \n        \u2192\n        A\n        ,\n      \n    \n    {\\displaystyle f\\colon P^{*}\\rightarrow A,}\n  where:\n\n  \n    \n      \n        \n          \n            P\n            \n              \u2217\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {P^{*}}}}\n   represents the set of all possible percept sequences (the agent's entire perceptual history). The asterisk (*) indicates a sequence of zero or more percepts.\n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {A}}}\n   represents the set of all possible actions the agent can take.\n  \n    \n      \n        \n          f\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {f}}}\n   is the agent function that maps a percept sequence to an action.It's crucial to distinguish between the agent function (an abstract mathematical concept) and the agent program (the concrete implementation of that function).\nThe agent function is a theoretical description.The agent program is the actual code that runs on the agent. The agent program takes the current percept as input and produces an action as output.The agent function can incorporate a wide range of decision-making approaches, including:[16]Calculating the utility (desirability) of different actions.Using logical rules and deduction.Employing fuzzy logic.Other methods.Classes of intelligent agents[edit]Russell and Norvig's classification[edit]Russell & Norvig (2003) group agents into five classes based on their degree of perceived intelligence and capability:[17]Simple reflex agents[edit]Simple reflex agentSimple reflex agents act only on the basis of the current percept, ignoring the rest of the percept history. The agent function is based on the condition-action rule: \"if condition, then action\".\nThis agent function only succeeds when the environment is fully observable. Some reflex agents can also contain information on their current state which allows them to disregard conditions whose actuators are already triggered.\nInfinite loops are often unavoidable for simple reflex agents operating in partially observable environments. If the agent can randomize its actions, it may be possible to escape from infinite loops.\nA home thermostat, which turns on or off when the temperature drops below a certain point, is an example of a simple reflex agent.[18][19]Model-based reflex agents[edit]Model-based reflex agentA model-based agent can handle partially observable environments. Its current state is stored inside the agent, maintaining a structure that describes the part of the world which cannot be seen. This knowledge about \"how the world works\" is referred to as a model of the world, hence the name \"model-based agent\".\nA model-based reflex agent should maintain some sort of internal model that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. Percept history and impact of action on the environment can be determined by using the internal model. It then chooses an action in the same way as reflex agent.\nAn agent may also use models to describe and predict the behaviors of other agents in the environment.[20]Goal-based agents[edit]Model-based, goal-based agentGoal-based agents further expand on the capabilities of the model-based agents, by using \"goal\" information. Goal information describes situations that are desirable. This provides the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. Search and planning are the subfields of artificial intelligence devoted to finding action sequences that achieve the agent's goals.\nChatGPT and the Roomba vacuum are examples of goal-based agents.[21]Utility-based agents[edit]Model-based, utility-based agentGoal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is.\nA rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning.\nLearning agents[edit]A general learning agentLearning lets agents begin in unknown environments and gradually surpass the bounds of their initial knowledge. A key distinction in such agents is the separation between a \"learning element,\" responsible for improving performance, and a \"performance element,\" responsible for choosing external actions.\nThe learning element gathers feedback from a \"critic\" to assess the agent's performance and decides how the performance element\u2014also called the \"actor\"\u2014can be adjusted to yield better outcomes. The performance element, once considered the entire agent, interprets percepts and takes actions.\nThe final component, the \"problem generator,\" suggests new and informative experiences that encourage exploration and further improvement.\nWeiss's classification[edit]According to Weiss (2013), agents can be categorized into four classes:\nLogic-based agents, where decisions about actions are derived through logical deduction.Reactive agents, where decisions occur through a direct mapping from situation to action.Belief\u2013desire\u2013intention agents, where decisions depend on manipulating data structures that represent the agent's beliefs, desires, and intentions.Layered architectures, where decision-making takes place across multiple software layers, each of which reasons about the environment at a different level of abstraction.Other[edit]In 2013, Alexander Wissner-Gross published a theory exploring the relationship between Freedom and Intelligence in intelligent agents.[22][23]Hierarchies of agents[edit]Main article: Multi-agent systemIntelligent agents can be organized hierarchically into multiple \"sub-agents.\" These sub-agents handle lower-level functions, and together with the main agent, they form a complete system capable of executing complex tasks and achieving challenging goals.\nTypically, an agent is structured by dividing it into sensors and actuators. The perception system gathers input from the environment via the sensors and feeds this information to a central controller, which then issues commands to the actuators. Often, a multilayered hierarchy of controllers is necessary to balance the rapid responses required for low-level tasks with the more deliberative reasoning needed for high-level objectives.[24]Alternative definitions and uses[edit]\"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\".[25] Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user.[26] These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\".\nAccording to Nikola Kasabov in 1998, IA systems should exhibit the following characteristics:[27]Accommodate new problem solving rules incrementally.Adapt online and in real time.Are able to analyze themselves in terms of behavior, error and success.Learn and improve through interaction with the environment (embodiment).Learn quickly from large amounts of data.Have memory-based exemplar storage and retrieval capacities.Have parameters to represent short- and long-term memory, age, forgetting, etc.Agentic AI[edit]Main article: Agentic AIIn the context of generative artificial intelligence, AI agents (also referred to as compound AI systems) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.[28]They possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs).[29]Researchers and commentators have noted that AI agents do not have a standard definition.[29][30][31][32]A common application of AI agents is the automation of tasks\u2014for example, booking travel plans based on a user's prompted request.[33][34] Prominent examples include Devin AI, AutoGPT, and SIMA.[35] Further examples of agents released since 2025 include OpenAI Operator,[36]ChatGPT Deep Research,[37]Manus,[38] Quark (based on Qwen),[39]AutoGLM Rumination,[39] and Coze (by ByteDance).[39] Frameworks for building AI agents include LangChain,[40] as well as tools such as CAMEL,[41][42] Microsoft AutoGen,[43] and OpenAI Swarm.[44]Companies such as Google, Microsoft and Amazon Web Services have offered platforms for deploying pre-built AI agents.[45]Proposed protocols for standardizing inter-agent communication include the Agent Protocol (by LangChain), the Model Context Protocol (by Anthropic), AGNTCY,[46]Gibberlink,[47] the Internet of Agents,[48] Agent2Agent (by Google),[49] and the Agent Network Protocol.[50] Software frameworks for addressing agent reliability include AgentSpec, ToolEmu, GuardAgent, Agentic Evaluations, and predictive models from H2O.ai.[51]In February 2025, Hugging Face released Open Deep Research, an open source version of OpenAI Deep Research.[52] Hugging Face also released a free web browser agent, similar to OpenAI Operator.[53] Galileo AI published on Hugging Face a leadership board for agents, which ranks their performance based on their underlying LLMs.[54]Autonomous capabilities[edit]The Financial Times compared the autonomy of AI agents to the SAE classification of self-driving cars, comparing most applications to level 2 or level 3, with some achieving level 4 in highly specialized circumstances, and level 5 being theoretical.[55]Multimodal AI agents[edit]In addition to large language models (LLMs), vision language models (VLMs) and multimodalfoundation models can be used as the basis for agents. In September 2024, Allen Institute for AI released an open source vision language model, which Wired noted could give AI agents the ability to perform complex computer tasks, including the possibility of automated computer hacking.[56]Nvidia released a framework for developers to use VLMs, LLMs and retrieval-augmented generation for building AI agents that can analyze images and videos, including video search and video summarization.[57][58] Microsoft released a multimodal agent model - trained on images, video, software user interface interactions, and robotics data - that the company claimed can manipulate software and robots.[59]Applications[edit]As of April 2025, per the Associated Press, there are few real world applications of AI agents.[60] As of June 2025, per Fortune, many companies are primarily experimenting with AI agents.[61]A recruiter for the Department of Government Efficiency proposed in April 2025 to use AI agents to automate the work of about 70,000 United States federal government employees, as part of a startup with funding from OpenAI and a partnership agreement with Palantir. This proposal was criticized by experts for its impracticality, if not impossibility, and the lack of corresponding widespread adoption by businesses.[62]Proposed benefits[edit]Proponents argue that AI agents can increase personal and economic productivity,[34][63] foster greater innovation,[64] and liberate users from monotonous tasks.[64][65] A Bloomberg opinion piece by Parmy Olson argued that agents are best suited for narrow, repetitive tasks with low risk.[66] Conversely, researchers suggest that agents could be applied to web accessibility for people who have disabilities,[67][68] and researchers at Hugging Face propose that agents could be used for coordinating resources such as during disaster response.[69] The R&D Advisory Team of the BBC views AI agents as being most useful when their assigned goal is uncertain.[70]Concerns[edit]Concerns include potential issues of liability,[63][70] an increased risk of cybercrime,[33][63]ethical challenges,[63] as well as problems related to AI safety[63] and AI alignment.[33][65] Other issues involve data privacy,[33][71] weakened human oversight,[33][63][69] a lack of guaranteed repeatability,[70]reward hacking,[72]algorithmic bias,[71][73] compounding software errors,[33][35] lack of explainability of agents' decisions,[33][74]security vulnerabilities,[33][75] problems with underemployment,[73]job displacement,[34][73] and the potential for user manipulation,[74][76]misinformation[69] or malinformation.[69] They may also complicate legal frameworks and risk assessments, foster hallucinations, hinder countermeasures against rogue agents, and suffer from the lack of standardized evaluation methods.[65][77][78] They have also been criticized for being expensive[29][77] and having a negative impact on internet traffic,[77] and potentially on the environment due to high energy usage.[70][79][80] There is also the risk of increased concentration of power by political leaders, as AI agents may not question instructions in the same way that humans would.[72]Journalists have described AI agents as part of a push by Big Tech companies to \"automate everything\".[81] Several CEOs of those companies have stated in early 2025 that they expect AI agents to eventually \"join the workforce\".[82][83] However, in a non-peer-reviewed study, Carnegie Mellon University researchers tested the behavior of agents in a simulated software company and found that none of the agents could complete a majority of the assigned tasks.[82][84] Other researchers had similar findings with Devin AI.[85]Yoshua Bengio warned at the 2025 World Economic Forum that \"all of the catastrophic scenarios with AGI or superintelligence happen if we have agents\".[86]In March 2025, Scale AI signed a contract with the United States Department of Defense to work with them, in collaboration with Anduril Industries and Microsoft, to develop and deploy AI agents for the purpose of assisting the military with \"operational decision-making\".[87] Researchers have expressed concerns that agents and the large language models they are based on could be biased towards aggressive foreign policy decisions.[88][89]Research-focused agents have the risk of consensus bias and coverage bias due to collecting information available on the public Internet.[90]NY Mag unfavorably compared the user workflow of agent-based web browsers to Amazon Alexa, which was \"software talking to software, not humans talking to software pretending to be humans to use software.\"[91]Agents have been linked to the dead Internet theory due to their ability to both publish and engage with online content.[92]Agents may get stuck in infinite loops.[36][93]Since many inter-agent protocols are being developed by large technology companies, there are concerns that those companies could use these protocols for self-benefit.[50]Possible mitigation[edit]Zico Kolter noted the possibility of emergent behavior as a result of interactions between agents, and proposed research in game theory to model the risks of these interactions.[94]Guardrails, defined by Business Insider as \"filters, rules, and tools that can be used to identify and remove inaccurate content\" have been suggested to help reduce errors.[95]To address security vulnerabilities related to data access, language models could be redesigned to separate instructions and data, or agentic applications could be required to include guardrails. These ideas were proposed in response to a zero-click exploit that affected Microsoft 365 Copilot.[61]Applications[edit]This section may lend undue weight to certain ideas, incidents, or controversies. Please help improve it by rewriting it to create a more balanced presentation. Discuss and resolve this issue before removing this message.  (September 2023)The concept of agent-based modeling for self-driving cars was discussed as early as 2003.[96]Hallerbach et al. explored the use of agent-based approaches for developing and validating automated driving systems. Their method involved a digital twin of the vehicle under test and microscopic traffic simulations using independent agents.[97]Waymo developed a multi-agent simulation environment called Carcraft, to test algorithms for self-driving cars.[98][99] This system simulates interactions between human drivers, pedestrians, and automated vehicles. Artificial agents replicate human behavior using real-world data.\nSalesforce's Agentforce is an agentic AI platform that allows for the building of autonomous agents to perform tasks.[100][101]The Transport Security Administration is integrating agentic AI into new technologies, including machines to authenticate passenger identities using biometrics and photos, and also for incident response.[102]See also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Ambient intelligenceArtificial conversational entityArtificial intelligence systems integrationAutonomous agentCognitive architecturesCognitive radio \u2013 a practical field for implementationCyberneticsDAYDREAMEREmbodied agentFederated search \u2013 the ability for agents to search heterogeneous data sources using a single vocabularyFriendly artificial intelligenceFuzzy agents \u2013 IA implemented with adaptive fuzzy logicGOAL agent programming languageHybrid intelligent systemIntelligent controlIntelligent systemJACK Intelligent AgentsMulti-agent system and multiple-agent system \u2013 multiple interactive agentsReinforcement learningSemantic Web \u2013 making data on the Web available for automated processing by agentsSocial simulationSoftware agentSoftware botReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^ abRussell & Norvig 2003, chpt. 2.^ ab.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Bringsjord, Selmer; Govindarajulu, Naveen Sundar (12 July 2018). \"Artificial Intelligence\". In Edward N. Zalta (ed.). The Stanford Encyclopedia of Philosophy (Summer 2020 Edition).^Wolchover, Natalie (30 January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 21 June 2020.^ abBull, Larry (1999). \"On model-based evolutionary computation\". Soft Computing. 3 (2): 76\u201382. doi:10.1007/s005000050055. S2CID\u00a09699920.^Domingos 2015, Chapter 5.^Domingos 2015, Chapter 7.^Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling for nearest neighbor classifiers. Machine learning, 54(2), 125\u2013152.^\"Generative adversarial networks: What GANs are and how they've evolved\". VentureBeat. 26 December 2019. Retrieved 18 June 2020.^Wolchover, Natalie (January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 18 June 2020.^Andrew Y. Ng, Daishi Harada, and Stuart Russell. \"Policy invariance under reward transformations: Theory and application to reward shaping.\" In ICML, vol. 99, pp. 278-287. 1999.^Martin Ford. Architects of Intelligence: The truth about AI from the people building it. Packt Publishing Ltd, 2018.^\"Why AlphaZero's Artificial Intelligence Has Trouble With the Real World\". Quanta Magazine. 2018. Retrieved 18 June 2020.^Adams, Sam; Arel, Itmar; Bach, Joscha; Coop, Robert; Furlan, Rod; Goertzel, Ben; Hall, J. Storrs; Samsonovich, Alexei; Scheutz, Matthias; Schlesinger, Matthew; Shapiro, Stuart C.; Sowa, John (15 March 2012). \"Mapping the Landscape of Human-Level Artificial General Intelligence\". AI Magazine. 33 (1): 25. doi:10.1609/aimag.v33i1.2322.^Hutson, Matthew (27 May 2020). \"Eye-catching advances in some AI fields are not real\". Science | AAAS. Retrieved 18 June 2020.^Russell & Norvig 2003, p.\u00a033^Salamon, Tomas (2011). Design of Agent-Based Models. Repin: Bruckner Publishing. pp.\u00a042\u201359. ISBN\u00a0978-80-904661-1-1.^Russell & Norvig 2003, pp.\u00a046\u201354^Thakur, Shreeya. \"AI Agents: 5 Key Types Explained With Examples // Unstop\". unstop.com. Retrieved 2025-04-24.^\"Types of AI Agents | IBM\". www.ibm.com. 2025-03-17. Retrieved 2025-04-24.^Stefano Albrecht and Peter Stone (2018). Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems.\nArtificial Intelligence, Vol. 258, pp. 66-95. https://doi.org/10.1016/j.artint.2018.01.002^\"What is an AI agent? A computer scientist explains the next wave of artificial intelligence tools\". Inverse. 2024-12-24. Retrieved 2025-04-24.^Box, Geeks out of the (2019-12-04). \"A Universal Formula for Intelligence\". Geeks out of the box. Retrieved 2022-10-11.^Wissner-Gross, A. D.; Freer, C. E. (2013-04-19). \"Causal Entropic Forces\". Physical Review Letters. 110 (16) 168702. Bibcode:2013PhRvL.110p8702W. doi:10.1103/PhysRevLett.110.168702. hdl:1721.1/79750. PMID\u00a023679649.^Poole, David; Mackworth, Alan. \"1.3 Agents Situated in Environments\u2023 Chapter 2 Agent Architectures and Hierarchical Control\u2023 Artificial Intelligence: Foundations of Computational Agents, 2nd Edition\". artint.info. Retrieved 28 November 2018.^Fingar, Peter (2018). \"Competing For The Future With Intelligent Agents... And A Confession\". Forbes Sites. Retrieved 18 June 2020.^Burgin, Mark; Dodig-Crnkovic, Gordana (2009). \"A Systematic Approach to Artificial Agents\". arXiv:0902.3513 [cs.AI].^Kasabov 1998.^Purdy, Mark (2024-12-12). \"What Is Agentic AI, and How Will It Change Work?\". Harvard Business Review. ISSN\u00a00017-8012. Retrieved 2025-04-24.^ abcKapoor, Sayash; Stroebl, Benedikt; Siegel, Zachary S.; Nadgir, Nitya; Narayanan, Arvind (2024). \"AI Agents That Matter\". arXiv:2407.01502 [cs.LG].^Zeff, Maxwell; Wiggers, Kyle (2025-03-14). \"No one knows what the hell an AI agent is\". TechCrunch. Archived from the original on 2025-03-18. Retrieved 2025-05-15.^Varanasi, Lakshmi. \"AI agents are all the rage. But no one can agree on what they do\". Business Insider. Archived from the original on 2025-04-11. Retrieved 2025-05-15.^Bort, Julie (2025-05-12). \"Even a16z VCs say no one really knows what an AI agent is\". TechCrunch. Archived from the original on 2025-05-12. Retrieved 2025-05-15.^ abcdefgh\"AI Agents: The Next Generation of Artificial Intelligence\". The National Law Review. 2024-12-30. Archived from the original on 2025-01-11. Retrieved 2025-01-14.^ abc\"What are the risks and benefits of 'AI agents'?\". World Economic Forum. 2024-12-16. Archived from the original on 2024-12-28. Retrieved 2025-01-14.^ abKnight, Will (2024-03-14). \"Forget Chatbots. AI Agents Are the Future\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-01-05. Retrieved 2025-01-14.^ abMarshall, Matt (2025-02-22). \"The rise of browser-use agents: Why Convergence's Proxy is beating OpenAI's Operator\". VentureBeat. Archived from the original on 2025-02-22. Retrieved 2025-04-02.^Milmo, Dan (2025-02-03). \"OpenAI launches 'deep research' tool that it says can match research analyst\". The Guardian. ISSN\u00a00261-3077. Archived from the original on 2025-02-03. Retrieved 2025-04-02.^Chen, Caiwei (2025-03-11). \"Everyone in AI is talking about Manus. We put it to the test\". MIT Technology Review. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^ abc\"China is gaining ground in the global race to develop AI agents\". Rest of World. 2025-06-02. Archived from the original on 2025-06-02. Retrieved 2025-06-12.^David, Emilia (2024-12-30). \"Why 2025 will be the year of AI orchestration\". VentureBeat. Archived from the original on 2024-12-30. Retrieved 2025-01-14.^\"CAMEL: Finding the Scaling Law of Agents. The first and the best multi-agent framework\". GitHub.^Li, Guohao (2023). \"Camel: Communicative agents for \"mind\" exploration of large language model society\"(PDF). Advances in Neural Information Processing Systems. 36: 51991\u201352008. arXiv:2303.17760. S2CID\u00a0257900712.^Dickson, Ben (2023-10-03). \"Microsoft's AutoGen framework allows multiple AI agents to talk to each other and complete your tasks\". VentureBeat. Archived from the original on 2024-12-27. Retrieved 2025-01-14.^\"The next AI wave \u2014 agents \u2014 should come with warning labels\". Computerworld. 2025-01-13. Archived from the original on 2025-01-14. Retrieved 2025-01-14.^David, Emilia (2025-04-15). \"Moveworks joins AI agent library craze\". VentureBeat. Archived from the original on 2025-04-15. Retrieved 2025-05-14.^David, Emilia (2025-03-06). \"A standard, open framework for building AI agents is coming from Cisco, LangChain and Galileo\". VentureBeat. Archived from the original on 2025-03-09. Retrieved 2025-04-02.^Zeff, Maxwell (2025-03-05). \"GibberLink lets AI agents call each other in robo-language\". TechCrunch. Archived from the original on 2025-03-05. Retrieved 2025-04-02.^Cooney, Michael (2025-01-30). \"Cisco touts 'Internet of Agents' for secure AI agent collaboration\". Network World. Archived from the original on 2025-01-31. Retrieved 2025-04-02.^Clark, Lindsay (2025-04-10). \"Did someone say AI agents, Google asks, bursting in\". The Register. Archived from the original on 2025-04-10. Retrieved 2025-05-14.^ abStokel-Walker, Chris (2025-06-11). \"Can we stop big tech from controlling the internet with AI agents?\". New Scientist. Archived from the original on 2025-06-11. Retrieved 2025-06-12.^David, Emilia (2025-03-28). \"New approach to agent reliability, AgentSpec, forces agents to follow rules\". VentureBeat. Archived from the original on 2025-04-12. Retrieved 2025-05-14.^Edwards, Benj (2025-02-05). \"Hugging Face clones OpenAI's Deep Research in 24 hours\". Ars Technica. Archived from the original on 2025-02-06. Retrieved 2025-04-02.^Wiggers, Kyle (2025-05-06). \"Hugging Face releases a free Operator-like agentic AI tool\". TechCrunch. Archived from the original on 2025-05-06. Retrieved 2025-05-14.^Ortiz, Sabrina (2025-02-14). \"Which AI agent is the best? This new leaderboard can tell you\". ZDNET. Archived from the original on 2025-03-30. Retrieved 2025-04-02.^Colback, Lucy (2025-05-07). \"AI agents: from co-pilot to autopilot\". Financial Times. Archived from the original on 2025-05-07. Retrieved 2025-05-14.^Knight, Will (2024-09-25). \"The Most Capable Open Source AI Model Yet Could Supercharge AI Agents\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-03-28. Retrieved 2025-06-12.^Takahashi, Dean (2024-11-04). \"Nvidia AI Blueprint makes it easy for any devs to build automated agents that analyze video\". VentureBeat. Archived from the original on 2024-12-05. Retrieved 2025-06-12.^Takahashi, Dean (2025-01-07). \"Nvidia launches blueprint for AI agents that can analyze video\". VentureBeat. Archived from the original on 2025-04-04. Retrieved 2025-06-12.^Edwards, Benj (2025-02-20). \"Microsoft's new AI agent can control software and robots\". Ars Technica. Archived from the original on 2025-05-20. Retrieved 2025-06-12.^\"Visa wants to give artificial intelligence 'agents' your credit card\". Associated Press. 2025-04-30. Archived from the original on 2025-05-01. Retrieved 2025-05-14.^ abGoldman, Sharon (2025-06-11). \"Microsoft Copilot flaw raises urgent questions for any business deploying AI agents\". Fortune. Archived from the original on 2025-06-11. Retrieved 2025-06-12.^Haskins, Caroline (2025-05-02). \"A DOGE Recruiter Is Staffing a Project to Deploy AI Agents Across the US Government\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-05-03. Retrieved 2025-05-14.^ abcdefPiper, Kelsey (2024-03-29). \"AI \"agents\" could do real work in the real world. That might not be a good thing\". Vox. Archived from the original on 2024-12-19. Retrieved 2025-01-14.^ abPurdy, Mark (2024-12-12). \"What Is Agentic AI, and How Will It Change Work?\". Harvard Business Review. ISSN\u00a00017-8012. Archived from the original on 2024-12-30. Retrieved 2025-01-20.^ abcWright, Webb (2024-12-12). \"AI Agents with More Autonomy Than Chatbots Are Coming. Some Safety Experts Are Worried\". Scientific American. Archived from the original on 2024-12-23. Retrieved 2025-01-14.^Olson, Parmy (2025-01-27). \"Skip the Hype, Here's How AI 'Agents' Can Really Help\". Bloomberg News. Archived from the original on 2025-01-27. Retrieved 2025-04-02.^Deng, Xiang; Gu, Yu; Zheng, Boyuan; Chen, Shijie; Stevens, Samuel; Wang, Boshi; Sun, Huan; Su, Yu (2023). \"Mind2Web: Towards a Generalist Agent for the Web\". arXiv:2306.06070 [cs.CL].^Woodall, Tatyana (2024-01-09). \"Researchers developing AI to make the internet more accessible\". Ohio State News. Archived from the original on 2025-03-28. Retrieved 2025-04-02.^ abcdMitchell, Margaret; Ghosh, Avijit; Luccioni, Sasha; Pistilli, Giada (2025-03-24). \"Why handing over total control to AI agents would be a huge mistake\". MIT Technology Review. Archived from the original on 2025-03-24. Retrieved 2025-04-02.^ abcd\"AI agents: Exploring the potential and the problems\". BBC Online. 2025-05-30. Archived from the original on 2025-06-10. Retrieved 2025-06-12.^ abO'Neill, Brian (2024-12-18). \"What is an AI agent? A computer scientist explains the next wave of artificial intelligence tools\". The Conversation. Archived from the original on 2025-01-04. Retrieved 2025-01-14.^ abHuckins, Grace (2025-06-12). \"Are we ready to hand AI agents the keys?\". MIT Technology Review. Archived from the original on 2025-06-12. Retrieved 2025-06-15.^ abcLin, Belle (2025-01-06). \"How Are Companies Using AI Agents? Here's a Look at Five Early Users of the Bots\". The Wall Street Journal. ISSN\u00a00099-9660. Archived from the original on 2025-01-06. Retrieved 2025-01-20.^ abZittrain, Jonathan L. (2024-07-02). \"We Need to Control AI Agents Now\". The Atlantic. Archived from the original on 2024-12-31. Retrieved 2025-01-20.^Kerner, Sean Michael (2025-01-16). \"Nvidia tackles agentic AI safety and security with new NeMo Guardrails NIMs\". VentureBeat. Archived from the original on 2025-01-16. Retrieved 2025-01-20.^Crawford, Kate (2024-12-23). \"AI Agents Will Be Manipulation Engines\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-01-03. Retrieved 2025-01-14.^ abc\"The argument against AI agents and unnecessary automation\". The Register. 2025-01-27. Archived from the original on 2025-01-27. Retrieved 2025-01-30.^Blackman, Reid (2025-06-13). \"Organizations Aren't Ready for the Risks of Agentic AI\". Harvard Business Review. ISSN\u00a00017-8012. Archived from the original on 2025-06-13. Retrieved 2025-06-15.^\"We did the math on AI's energy footprint. Here's the story you haven't heard\". MIT Technology Review. 2025-05-20. Archived from the original on 2025-05-20. Retrieved 2025-06-12. We started small, as the question of how much a single query costs is vitally important to understanding the bigger picture. That's because those queries are being built into ever more applications beyond standalone chatbots: from search, to agents, to the mundane daily apps we use to track our fitness, shop online, or book a flight. The energy resources required to power this artificial-intelligence revolution are staggering, and the world's biggest tech companies have made it a top priority to harness ever more of that energy, aiming to reshape our energy grids in the process.^\"Inside the effort to tally AI's energy appetite\". MIT Technology Review. 2025-06-03. Archived from the original on 2025-06-03. Retrieved 2025-06-12. Lots of AI companies are building reasoning models, which \"think\" for longer and use more energy. They're building hardware devices, perhaps like the one Jony Ive has been working on (which OpenAI just acquired for $6.5 billion), that have AI constantly humming along in the background of our conversations. They're designing agents and digital clones of us to act on our behalf. All these trends point to a more energy-intensive future (which, again, helps explain why OpenAI and others are spending such inconceivable amounts of money on energy).^Wong, Matteo (2025-03-14). \"Was Sam Altman Right About the Job Market?\". The Atlantic. Archived from the original on 2025-03-17. Retrieved 2025-04-02. In other words, flawed products won't stop tech companies' push to automate everything\u2014the AI-saturated future will be imperfect at best, but it is coming anyway.^ abAgarwal, Shubham. \"Carnegie Mellon staffed a fake company with AI agents. It was a total disaster\". Business Insider. Archived from the original on 2025-04-28. Retrieved 2025-05-15.^Sabin, Sam (2025-04-22). \"Exclusive: Anthropic warns fully AI employees are a year away\". Axios. Archived from the original on 2025-04-23. Retrieved 2025-05-15.^Xu, Frank F.; Song, Yufan; Li, Boxuan; Tang, Yuxuan; Jain, Kritanjali; Bao, Mengxue; Wang, Zora Z.; Zhou, Xuhui; Guo, Zhitong; Cao, Murong; Yang, Mingyang; Hao Yang Lu; Martin, Amaad; Su, Zhe; Maben, Leander; Mehta, Raj; Chi, Wayne; Jang, Lawrence; Xie, Yiqing; Zhou, Shuyan; Neubig, Graham (2024). \"TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks\". arXiv:2412.14161 [cs.CL].^Claburn, Thomas (2025-01-23). \"Tool touted as 'first AI software engineer' is bad at its job, testers claim\". The Register. Archived from the original on 2025-03-30. Retrieved 2025-06-15.^Balevic, Katie. \"Signal president warns the hyped agentic AI bots threaten user privacy\". Business Insider. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^Hornstein, Julia. \"AI agents are coming to the military. VCs love it, but researchers are a bit wary\". Business Insider. Archived from the original on 2025-03-12. Retrieved 2025-04-02.^Tangermann, Victor (2025-03-06). \"Pentagon Signs Deal to \"Deploy AI Agents for Military Use\"\". Futurism. Archived from the original on 2025-03-08. Retrieved 2025-04-02.^Jensen, Benjamin (2025-03-04). \"The Troubling Truth About How AI Agents Act in a Crisis\". Foreign Policy. Archived from the original on 2025-03-04. Retrieved 2025-04-02.^Nu\u00f1ez, Michael (2025-02-25). \"OpenAI expands Deep Research access to Plus users, heating up AI agent wars with DeepSeek and Claude\". VentureBeat. Archived from the original on 2025-03-11. Retrieved 2025-04-02.^Herrman, John (2025-01-25). \"What Are AI 'Agents' For?\". Intelligencer. Archived from the original on 2025-01-25. Retrieved 2025-04-02.^Caramela, Sammi (2025-02-01). \"'Dead Internet Theory' Is Back Thanks to All of That AI Slop\". VICE. Archived from the original on 2025-02-01. Retrieved 2025-04-02.^Metz, Cade; Weise, Karen (2023-10-16). \"How 'A.I. Agents' That Roam the Internet Could One Day Replace Workers\". The New York Times. ISSN\u00a00362-4331. Archived from the original on 2023-12-19. Retrieved 2025-04-02.^Knight, Will (2025-04-09). \"The AI Agent Era Requires a New Kind of Game Theory\". Wired. ISSN\u00a01059-1028. Archived from the original on 2025-04-09. Retrieved 2025-05-15.^Varanasi, Lakshmi. \"Don't get too excited about AI agents yet. They make a lot of mistakes\". Business Insider. Archived from the original on 2025-04-18. Retrieved 2025-05-15.^Yang, Guoqing; Wu, Zhaohui; Li, Xiumei; Chen, Wei (2003). \"SVE: embedded agent-based smart vehicle environment\". Proceedings of the 2003 IEEE International Conference on Intelligent Transportation Systems. Vol.\u00a02. pp.\u00a01745\u20131749. doi:10.1109/ITSC.2003.1252782. ISBN\u00a00-7803-8125-4. S2CID\u00a0110177067.^Hallerbach, S.; Xia, Y.; Eberle, U.; Koester, F. (2018). \"Simulation-Based Identification of Critical Scenarios for Cooperative and Automated Vehicles\". SAE International Journal of Connected and Automated Vehicles. 1 (2). SAE International: 93. doi:10.4271/2018-01-1066.^Madrigal, Story by Alexis C. \"Inside Waymo's Secret World for Training Self-Driving Cars\". The Atlantic. Retrieved 14 August 2020.^Connors, J.; Graham, S.; Mailloux, L. (2018). \"Cyber Synthetic Modeling for Vehicle-to-Vehicle Applications\". In International Conference on Cyber Warfare and Security. Academic Conferences International Limited: 594-XI.^Nu\u00f1ez, Michael (2025-03-05). \"Salesforce launches Agentforce 2dx, letting AI run autonomously across enterprise systems\". VentureBeat. Retrieved 2025-04-24.^\"Salesforce unveils Agentforce to help create autonomous AI bots\". CIO. Retrieved 2025-04-24.^\"TSA Showcase Biometric AI-powered Airport Immigration Security\". techinformed.com. 2025-01-23. Retrieved 2025-04-24.Sources[edit]Domingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\u00a0978-0-465-06570-7.Russell, Stuart J.; Norvig, Peter (2003). Artificial Intelligence: A Modern Approach (2nd\u00a0ed.). Upper Saddle River, New Jersey: Prentice Hall. Chapter 2. ISBN\u00a00-13-790395-2.Kasabov, N. (1998). \"Introduction: Hybrid intelligent adaptive systems\". International Journal of Intelligent Systems. 13 (6): 453\u2013454. doi:10.1002/(SICI)1098-111X(199806)13:6<453::AID-INT1>3.0.CO;2-K. S2CID\u00a0120318478.Weiss, G. (2013). Multiagent systems (2nd\u00a0ed.). Cambridge, MA: MIT Press. ISBN\u00a0978-0-262-01889-0..mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteArtificial intelligence (AI)HistorytimelineGlossaryCompaniesProjectsConceptsParameterHyperparameterLoss functionsRegressionBias\u2013variance tradeoffDouble descentOverfittingClusteringGradient descentSGDQuasi-Newton methodConjugate gradient methodBackpropagationAttentionConvolutionNormalizationBatchnormActivationSoftmaxSigmoidRectifierGatingWeight initializationRegularizationDatasetsAugmentationPrompt engineeringReinforcement learningQ-learningSARSAImitationPolicy gradientDiffusionLatent diffusion modelAutoregressionAdversaryRAGUncanny valleyRLHFSelf-supervised learningReflectionRecursive self-improvementHallucinationWord embeddingVibe codingSafety (Alignment)ApplicationsMachine learningIn-context learningArtificial neural networkDeep learningLanguage modelLargeNMTReasoningModel Context ProtocolIntelligent agentArtificial human companionHumanity's Last ExamArtificial general intelligence (AGI)ImplementationsAudio\u2013visualAlexNetWaveNetHuman image synthesisHWROCRComputer visionSpeech synthesis15.aiElevenLabsSpeech recognitionWhisperFacial recognitionAlphaFoldText-to-image modelsAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyRecraftStable DiffusionText-to-video modelsDream MachineRunway GenHailuo AIKlingSoraVeoMusic generationRiffusionSuno AIUdioTextWord2vecSeq2seqGloVeBERTT5LlamaChinchilla AIPaLMGPT123JChatGPT44oo1o34.54.1o4-mini5ClaudeGeminiGemini (language model)GemmaGrokLaMDABLOOMDBRXProject DebaterIBM WatsonIBM WatsonxGranitePanGu-\u03a3DeepSeekQwenDecisionalAlphaGoAlphaZeroOpenAI FiveSelf-driving carMuZeroAction selectionAutoGPTRobot controlPeopleAlan TuringWarren Sturgis McCullochWalter PittsJohn von NeumannChristopher D. ManningClaude ShannonShun'ichi AmariKunihiko FukushimaTakeo KanadeMarvin MinskyJohn McCarthyNathaniel RochesterAllen NewellCliff ShawHerbert A. SimonOliver SelfridgeFrank RosenblattBernard WidrowJoseph WeizenbaumSeymour PapertSeppo LinnainmaaPaul WerbosGeoffrey HintonJohn HopfieldJ\u00fcrgen SchmidhuberYann LeCunYoshua BengioLotfi A. ZadehStephen GrossbergAlex GravesJames GoodnightAndrew NgFei-Fei LiAlex KrizhevskyIlya SutskeverOriol VinyalsQuoc V. LeIan GoodfellowDemis HassabisDavid SilverAndrej KarpathyAshish VaswaniNoam ShazeerAidan GomezJohn SchulmanMustafa SuleymanJan LeikeDaniel KokotajloFran\u00e7ois CholletArchitecturesNeural Turing machineDifferentiable neural computerTransformerVision transformer (ViT)Recurrent neural network (RNN)Long short-term memory (LSTM)Gated recurrent unit (GRU)Echo state networkMultilayer perceptron (MLP)Convolutional neural network (CNN)Residual neural network (RNN)Highway networkMambaAutoencoderVariational autoencoder (VAE)Generative adversarial network (GAN)Graph neural network (GNN)Category.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesNationalUnited StatesFranceBnF dataIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Intelligent_agent&oldid=1319453939\"", "tags": ["en.wikipedia.org", "wiki", "intelligent", "agent"]}
{"url": "https://en.wikipedia.org/wiki/Software_agent", "title": null, "text": "Computer program acting for a user.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onMulti-agent systemsMulti-agent simulationIn computational economicsIn biologyIn social simulationModeling softwareAgent-oriented programmingAuto-GPTBotnetsFIPAPlatforms for software agentsJADEJACKGORITESoftware agent\nRelatedDistributed artificial intelligenceMulti-agent pathfindingMulti-agent planningMulti-agent reinforcement learningSelf-propelled particlesSwarm robotics.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteIn computer science, a software agent is a computer program that acts for a user or another program in a relationship of agency.\nThe term agent is derived from the Latinagere (to do): an agreement to act on one's behalf. Such \"action on behalf of\" implies the authority to decide which, if any, action is appropriate.[1][2] Some agents are colloquially known as bots, from robot. They may be embodied, as when execution is paired with a robot body, or as software such as a chatbot executing on a computer, such as a mobile device, e.g. Siri. Software agents may be autonomous or work together with other agents or people. Software agents interacting with people (e.g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo).\nRelated and derived concepts include intelligent agents (in particular exhibiting some aspects of artificial intelligence, such as reasoning), autonomous agents (capable of modifying the methods of achieving their objectives), distributed agents (being executed on physically distinct computers), multi-agent systems (distributed agents that work together to achieve an objective that could not be accomplished by a single agent acting alone), and mobile agents (agents that can relocate their execution onto different processors).\nConcepts[edit]The basic attributes of an autonomous software agent are that agents:\nare not strictly invoked for a task, but activate themselves,may reside in wait status on a host, perceiving context,may get to run status on a host upon starting conditions,do not require interaction of user,may invoke other tasks including communication.Nwana's Category of Software AgentThe concept of an agent provides a convenient and powerful way to describe a complex software entity that is capable of acting with a certain degree of autonomy in order to accomplish tasks on behalf of its host. But unlike objects, which are defined in terms of methods and attributes, an agent is defined in terms of its behavior.[3]Various authors have proposed different definitions of agents, these commonly include concepts such as:\npersistence: code is not executed on demand but runs continuously and decides for itself when it should perform some activity;autonomy: agents have capabilities of task selection, prioritization, goal-directed behavior, decision-making without human intervention;social ability: agents are able to engage other components through some sort of communication and coordination, they may collaborate on a task;reactivity: agents perceive the context in which they operate and react to it appropriately.Distinguishing agents from programs[edit]All agents are programs, but not all programs are agents. Contrasting the term with related concepts may help clarify its meaning. Franklin & Graesser (1997)[4] discuss four key notions that distinguish agents from arbitrary programs: reaction to the environment, autonomy, goal-orientation and persistence.\nIntuitive distinguishing agents from objects[edit]Agents are more autonomous than objects.Agents have flexible behavior: reactive, proactive, social.Agents have at least one thread of control but may have more.[5]Distinguishing agents from expert systems[edit]Expert systems are not coupled to their environment.Expert systems are not designed for reactive, proactive behavior.Expert systems do not consider social ability.[5]Distinguishing intelligent software agents from intelligent agents in AI[edit]Intelligent agents (also known as rational agents) are not just computer programs: they may also be machines, human beings, communities of human beings (such as firms) or anything that is capable of goal-directed behavior.(Russell & Norvig 2003) harv error: no target: CITEREFRussellNorvig2003 (help)Impact of software agents[edit]Software agents may offer various benefits to their end users by automating complex or repetitive tasks.[6] However, there are organizational and cultural impacts of this technology that need to be considered prior to implementing software agents.\nOrganizational impact[edit]Work contentment and job satisfaction impact[edit]People like to perform easy tasks providing the sensation of success unless the repetition of the simple tasking is affecting the overall output. In general implementing software agents to perform administrative requirements provides a substantial increase in work contentment, as administering their own work does never please the worker. The effort freed up serves for a higher degree of engagement in the substantial tasks of individual work. Hence, software agents may provide the basics to implement self-controlled work, relieved from hierarchical controls and interference.[7] Such conditions may be secured by application of software agents for required formal support.\nCultural impact[edit]The cultural effects of the implementation of software agents include trust affliction, skills erosion, privacy attrition and social detachment. Some users may not feel entirely comfortable fully delegating important tasks to software applications. Those who start relying solely on intelligent agents may lose important skills, for example, relating to information literacy. In order to act on a user's behalf, a software agent needs to have a complete understanding of a user's profile, including his/her personal preferences. This, in turn, may lead to unpredictable privacy issues. When users start relying on their software agents more, especially for communication activities, they may lose contact with other human users and look at the world with the eyes of their agents. These consequences are what agent researchers and users must consider when dealing with intelligent agent technologies.[8]History[edit]The concept of an agent can be traced back to Hewitt's Actor Model (Hewitt, 1977) - \"A self-contained, interactive and concurrently-executing object, possessing internal state and communication capability.\"[citation needed]To be more academic, software agent systems are a direct evolution of Multi-Agent Systems (MAS). MAS evolved from Distributed Artificial Intelligence (DAI), Distributed Problem Solving (DPS) and Parallel AI (PAI), thus inheriting all characteristics (good and bad) from DAI and AI.\nJohn Sculley's 1987 \"Knowledge Navigator\" video portrayed an image of a relationship between end-users and agents. Being an ideal first, this field experienced a series of unsuccessful top-down implementations, instead of a piece-by-piece, bottom-up approach. The range of agent types is now (from 1990) broad: WWW, search engines, etc.\nExamples  of intelligent software agents[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Intelligent agentBuyer agents (shopping bots)[edit]Buyer agents[9] travel around a network (e.g. the internet) retrieving information about goods and services. These agents, also known as 'shopping bots', work very efficiently for commodity products such as CDs, books, electronic components, and other one-size-fits-all products. Buyer agents are typically optimized to allow for digital payment services used in e-commerce and traditional businesses.[10]User agents (personal agents)[edit]User agents, or personal agents, are intelligent agents that take action on your behalf. In this category belong those intelligent agents that already perform, or will shortly perform, the following tasks:\nCheck your e-mail, sort it according to the user's order of preference, and alert you when important emails arrive.Play computer games as your opponent or patrol game areas for you.Assemble customized news reports for you. There are several versions of these, including CNN.Find information for you on the subject of your choice.Fill out forms on the Web automatically for you, storing your information for future referenceScan Web pages looking for and highlighting text that constitutes the \"important\" part of the information thereDiscuss topics with you ranging from your deepest fears to sportsFacilitate with online job search duties by scanning known job boards and sending the resume to opportunities who meet the desired criteriaProfile synchronization across heterogeneous social networksMonitoring-and-surveillance (predictive) agents[edit]Monitoring and surveillance agents are used to observe and report on equipment, usually computer systems. The agents may keep track of company inventory levels, observe competitors' prices and relay them back to the company, watch stock manipulation by insider trading and rumors, etc.\nService monitoringFor example, NASA's Jet Propulsion Laboratory has an agent that monitors inventory, planning, schedules equipment orders to keep costs down, and manages food storage facilities. These agents usually monitor complex computer networks that can keep track of the configuration of each computer connected to the network.\nA special case of monitoring-and-surveillance agents are organizations of agents used to automate decision-making process during tactical operations. The agents monitor the status of assets (ammunition, weapons available, platforms for transport, etc.) and receive goals from higher level agents. The agents then pursue the goals with the assets at hand, minimizing expenditure of the assets while maximizing goal attainment.\nData-mining agents[edit]This agent uses information technology to find trends and patterns in an abundance of information from many different sources. The user can sort through this information in order to find whatever information they are seeking.\nA data mining agent operates in a data warehouse discovering information. A 'data warehouse' brings together information from many different sources. \"Data mining\" is the process of looking through the data warehouse to find information that you can use to take action, such as ways to increase sales or keep customers who are considering defecting.\n'Classification' is one of the most common types of data mining, which finds patterns in information and categorizes them into different classes. Data mining agents can also detect major shifts in trends or a key indicator and can detect the presence of new information and alert you to it. For example, the agent may detect a decline in the construction industry for an economy; based on this relayed information construction companies will be able to make intelligent decisions regarding the hiring/firing of employees or the purchase/lease of equipment in order to best suit their firm.\nNetworking and communicating agents[edit]Some other examples of current intelligent agents include some spam filters, game bots, and server monitoring tools. Search engine indexing bots also qualify as intelligent agents.\nUser agent - for browsing the World Wide WebBuyer Agent [11]- As of 2025, advanced AI agents enable agentic commerce, autonomously handling product discovery, price comparison, and transactions in platforms like OpenAI integrations[12].Mail transfer agent - For serving E-mail, such as Microsoft Outlook. Why? It communicates with the POP3 mail server, without users having to understand POP3 command protocols. It even has rule sets that filter mail for the user, thus sparing them the trouble of having to do it themselves.SNMP agentIn Unix-style networking servers, httpd is an HTTP daemon that implements the Hypertext Transfer Protocol at the root of the World Wide WebManagement agents used to manage telecom devicesCrowd simulation for safety planning or 3D computer graphics,Wireless beaconing agent is a simple process hosted single tasking entity for implementing wireless lock or electronic leash in conjunction with more complex software agents hosted e.g. on wireless receivers.Use of autonomous agents (deliberately equipped with noise) to optimize coordination in groups online.[13]Software development agents (aka software bots)[edit]Main article: Software botSoftware bots are becoming important in software engineering.[14]Security agents[edit]Agents are also used in software security application to intercept, examine and act on various types of content.  Example include: \nData Loss Prevention (DLP) Agents[15] - examine user operations on a computer or network, compare with policies specifying allowed actions, and take appropriate action (e.g. allow, alert, block).  The more comprehensive DLP agents can also be used to perform EDR functions.Endpoint Detection and Response (EDR) Agents - monitor all activity on an endpoint computer in order to detect and respond to malicious activitiesCloud Access Security Broker (CASB) Agents - similar to DLP Agents, however examining traffic going to cloud applicationsDesign issues[edit]Issues to consider in the development of agent-based systems include \nhow tasks are scheduled and how synchronization of tasks is achievedhow tasks are prioritized by agentshow agents can collaborate, or recruit resources,how agents can be re-instantiated in different environments, and how their internal state can be stored,how the environment will be probed and how a change of environment leads to behavioral changes of the agentshow messaging and communication can be achieved,what hierarchies of agents are useful (e.g. task execution agents, scheduling agents, resource providers ...).For software agents to work together efficiently they must share semantics of their data elements. This can be done by having computer systems publish their metadata.\nThe definition of agent processing can be approached from two interrelated directions:\ninternal state processing and ontologies for representing knowledgeinteraction protocols \u2013 standards for specifying communication of tasksAgent systems are used to model real-world systems with concurrency or parallel processing.\nAgent Machinery \u2013 Engines of various kinds, which support the varying degrees of intelligenceAgent Content \u2013 Data employed by the machinery in Reasoning and LearningAgent Access \u2013 Methods to enable the machinery to perceive content and perform actions as outcomes of ReasoningAgent Security \u2013 Concerns related to distributed computing, augmented by a few special concerns related to agentsThe agent uses its access methods to go out into local and remote databases to forage for content. These access methods may include setting up news stream delivery to the agent, or retrieval from bulletin boards, or using a spider to walk the Web. The content that is retrieved in this way is probably already partially filtered\u00a0\u2013 by the selection of the newsfeed or the databases that are searched. The agent next may use its detailed searching or language-processing machinery to extract keywords or signatures from the body of the content that has been received or retrieved. This abstracted content (or event) is then passed to the agent's Reasoning or inferencing machinery in order to decide what to do with the new content. This process combines the event content with the rule-based or knowledge content provided by the user. If this process finds a good hit or match in the new content, the agent may use another piece of its machinery to do a more detailed search on the content. Finally, the agent may decide to take an action based on the new content; for example, to notify the user that an important event has occurred. This action is verified by a security function and then given the authority of the user. The agent makes use of a user-access method to deliver that message to the user. If the user confirms that the event is important by acting quickly on the notification, the agent may also employ its learning machinery to increase its weighting for this kind of event.\nBots can act on behalf of their creators to do good as well as bad. There are a few ways which bots can be created to demonstrate that they are designed with the best intention and are not built to do harm. This is first done by having a bot identify itself in the user-agent HTTP header when communicating with a site. The source IP address must also be validated to establish itself as legitimate. Next, the bot must also always respect a site's robots.txt file since it has become the standard across most of the web. And like respecting the robots.txt file, bots should shy away from being too aggressive and respect any crawl delay instructions.[16]Notions and frameworks for agents[edit]DAML (DARPA Agent Markup Language)3APL (Artificial Autonomous Agents Programming Language)GOAL agent programming languageOpen Agent Architecture (OAA)Web Ontology Language (OWL)daemons in Unix-like systems.Java Agent Template (JAT)Java Agent Development Framework (JADE)SARL agent programming language (arguably an Actor and not Agent oriented paradigm)See also[edit]Agent architectureChatbotData loss preventionEndpoint detection and responseSoftware botReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Nwana, H.\u00a0S. (1996). \"Software Agents: An Overview\". Knowledge Engineering Review. 21 (3): 205\u2013244. CiteSeerX\u00a010.1.1.50.660. doi:10.1017/s026988890000789x. S2CID\u00a07839197.^Schermer, B.\u00a0W. (2007). Software agents, surveillance, and the right to privacy: A legislative framework for agent-enabled surveillance(paperback). Vol.\u00a021. Leiden University Press. pp.\u00a0140, 205\u2013244. hdl:1887/11951. ISBN\u00a0978-0-596-00712-6. Retrieved October 30, 2012.^Wooldridge, M.; Jennings, N. R. (1995). \"Intelligent agents: theory and practice\". Knowledge Engineering Review. 10 (2): 115\u2013152. doi:10.1017/S0269888900008122. hdl:10044/1/35975.^Franklin, S.; Graesser, A. (1996). \"Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents\". Intelligent Agents III Agent Theories, Architectures, and Languages. Lecture Notes in Computer Science. Vol.\u00a01193. University of Memphis, Institute for Intelligent Systems. pp.\u00a021\u201335. doi:10.1007/BFb0013570. ISBN\u00a0978-3-540-62507-0.^ abWooldridge, Michael J. (2002). An Introduction to Multiagent Systems. New York: John Wiley & Sons. p.\u00a027. ISBN\u00a0978-0-471-49691-5.^Serenko, A.; Detlor, B. (2004). \"Intelligent agents as innovations\"(PDF). Artificial Intelligence & Society. 18 (4): 364\u2013381.^Adonisi, M. (2003). \"The relationship between Corporate Entrepreneurship, Market Orientation, Organisational Flexibility and Job satisfaction\"(PDF) (Diss.). Fac.of Econ.and Mgmt.Sci., Univ.of Pretoria.^Serenko, A.; Ruhi, U.; Cocosila, M. (2007). \"Unplanned effects of intelligent agents on Internet use: Social Informatics approach\"(PDF). Artificial Intelligence & Society. 21 (1\u20132): 141\u2013166.^Haag, Stephen; Cummings, Maeve; Dawkins, James (2006). Management Information Systems for the Information Age. pp.\u00a0224\u2013228.^\"Maximize Your Business Impact | How to Use Facebook Chatbots\". Keystone Click. August 26, 2016. Retrieved September 7, 2017.^\"Introducing AgentKit\". openai.com. October 29, 2025. Retrieved October 31, 2025.^\"Introducing AgentKit\". openai.com. October 29, 2025. Retrieved October 31, 2025.^Shirado, Hirokazu; Christakis, Nicholas A (2017). \"Locally noisy autonomous agents improve global human coordination in network experiments\". Nature. 545 (7654): 370\u2013374. Bibcode:2017Natur.545..370S. doi:10.1038/nature22332. PMC\u00a05912653. PMID\u00a028516927.^Lebeuf, Carlene; Storey, Margaret-Anne; Zagalsky, Alexey (2018). \"Software Bots\". IEEE Software. 35: 18\u201323. doi:10.1109/MS.2017.4541027. S2CID\u00a031931036.^\"Enterprise IP and DLP Software | Digital Guardian\"(PDF). info.digitalguardian.com. Retrieved December 25, 2024.^\"How to Live by the Code of Good Bots\". DARKReading from Information World. September 27, 2017. Retrieved November 14, 2017.External links[edit]Software Agents: An OverviewArchived July 17, 2011, at the Wayback Machine, Hyacinth S. Nwana. Knowledge Engineering Review, 11(3):1\u201340, September 1996. Cambridge University Press.FIPA The Foundation for Intelligent Physical AgentsJADE Java Agent Developing Framework, an Open Source framework developed by Telecom Italia LabsEuropean Software-Agent Research CenterArchived 2017-09-14 at the Wayback MachineJAFIMA JAFIMA: A Java based Agent Framework for Intelligent and Mobile AgentsSemanticAgent An Open Source framework to develop SWRL based Agents on top of JADEMobile-C A Multi-Agent Platform for Mobile C/C++ Agents.HLL High-Level Logic (HLL) Open Source Project.Open source project KATO for PHP and Java developers to write software agents\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Software_agent&oldid=1319667475\"", "tags": ["en.wikipedia.org", "wiki", "software", "agent"]}
{"url": "https://en.wikipedia.org/wiki/Robotic_process_automation", "title": null, "text": "Form of business process automation technology.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This article may require cleanup to meet Wikipedia's quality standards. The specific problem is: It's disorganized, with pieces thrown together in random places and content placed in sections that is unrelated to the sections' headings; also, lack of clarity and repetitiveness. Please help improve this article if you can.  (February 2025) (Learn how and when to remove this message).mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onAutomationAutomation in generalBankingBuildingHomeHighway systemLaboratoryLibraryBroadcastMixPool cleanerPop musicReasoningSemi-automationTelephone\nAttendantSwitchboardTeller machineVehicularVending machineRobotics and robotsDomesticVacuum cleanerRoombaLawn mowerGuided vehicleIndustrialPaintODD\nImpact of automationManumationOOLBiasSelf-driving carsTechnological unemploymentJobless recoveryPost-work societyThreat\nTrade shows and awardsASP-DACDACDATEIEEE Robotics and Automation AwardICCAD.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteRobotic process automation (RPA) is a form of business process automation that is based on software robots (bots) or artificial intelligence (AI) agents.[1] RPA should not be confused with artificial intelligence as it is based on automation technology following a predefined workflow.[2]  It is sometimes referred to as software robotics (not to be confused with robot software).\nIn traditional workflowautomation tools, a software developer produces a list of actions to automate a task and interface to the back end system using internal application programming interfaces (APIs) or dedicated scripting language. In contrast, RPA systems develop the action list by watching the user perform that task in the application's graphical user interface (GUI) and then perform the automation by repeating those tasks directly in the GUI. This can lower the barrier to the use of automation in products that might not otherwise feature APIs for this purpose.\nRPA tools have strong technical similarities to graphical user interface testing tools. These tools also automate interactions with the GUI, and often do so by repeating a set of demonstration actions performed by a user. RPA tools differ from such systems in that they allow data to be handled in and between multiple applications, for instance, receiving email containing an invoice, extracting the data, and then typing that into a bookkeeping system.\nHistoric evolution[edit]The typical benefits of robotic automation include reduced cost; increased speed, accuracy, and consistency; improved quality and scalability of production. Automation can also provide extra security, especially for sensitive data and financial services.\nAs a form of automation, the concept has been around for a long time in the form of screen scraping, so long that to early PC users the reminder of it often blurs with the idea of malware infection.[3] Yet compared to screen scraping, RPA is much more extensible, consisting of API integration into other enterprise applications, connectors into ITSM systems, terminal services and even some types of AI (e.g. machine learning) services such as image recognition. It is considered to be a significant technological evolution in the sense that new software platforms are emerging which are sufficiently mature, resilient, scalable and reliable to make this approach viable for use in large enterprises[4] (who would otherwise be reluctant due to perceived risks to quality and reputation).\nA principal barrier to the adoption of self-service is often technological: it may not always be feasible or economically viable to retrofit new interfaces onto existing systems. Moreover, organisations may wish to layer a variable and configurable set of process rules on top of the system interfaces which may vary according to market offerings and the type of customer. This only adds to the cost and complexity of the technological implementation. Robotic automation software provides a pragmatic means of deploying new services in this situation, where the robots simply mimic the behaviour of humans to perform the back-end transcription or processing. The relative affordability of this approach arises from the fact that no new IT transformation or investment is required; instead the software robots simply leverage greater use out of existing IT assets.\nUse[edit]The hosting of RPA services also aligns with the metaphor of a software robot, with each robotic instance having its own virtual workstation, much like a human worker. The robot uses keyboard and mouse controls to take actions and execute automations. Normally, all of these actions take place in a virtual environment and not on screen; the robot does not need a physical screen to operate, rather it interprets the screen display electronically. The scalability of modern solutions based on architectures such as these owes much to the advent of virtualization technology, without which the scalability of large deployments would be limited by the available capacity to manage physical hardware and by the associated costs. The implementation of RPA in business enterprises has shown dramatic cost savings when compared to traditional non-RPA solutions.[5]There are however several risks with RPA. Criticism includes risks of stifling innovation and creating a more complex maintenance environment of existing software that now needs to consider the use of graphical user interfaces in a way they weren't intended to be used.[6]Impact on employment[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Technological unemployment and AutomationAccording to Harvard Business Review, most operations groups adopting RPA have promised their employees that automation would not result in layoffs.[7] Instead, workers have been redeployed to do more interesting work. One academic study highlighted that knowledge workers did not feel threatened by automation: they embraced it and viewed the robots as team-mates.[8] The same study highlighted that, rather than resulting in a lower \"headcount\", the technology was deployed in such a way as to achieve more work and greater productivity with the same number of people.\nConversely, however, some analysts proffer that RPA represents a threat to the business process outsourcing (BPO) industry.[9] The thesis behind this notion is that RPA will enable enterprises to \"repatriate\" processes from offshore locations into local data centers, with the benefit of this new technology. The effect, if true, will be to create high-value jobs for skilled process designers in onshore locations (and within the associated supply chain of IT hardware, data center management, etc.) but to decrease the available opportunity to low-skilled workers offshore. On the other hand, this discussion appears to be healthy ground for debate as another academic study was at pains to counter the so-called \"myth\" that RPA will bring back many jobs from offshore.[8]RPA actual use[edit]Banking and finance process automationMortgage and lending processesCustomer care automationeCommerce merchandising operationsSocial media marketingOptical character recognition applicationsData extraction processFixed automation process[clarification needed]Manual and Repetative tasks automationImpact on society[edit]Academic studies[10][11] project that RPA, among other technological trends, is expected to drive a new wave of productivity and efficiency gains in the global labour market. Although not directly attributable to RPA alone, Oxford University conjectures that up to 35% of all jobs might be automated by 2035.[10]There are geographic implications to the trend in robotic automation. In the example above where an offshored process is \"repatriated\" under the control of the client organization (or even displaced by a business process outsourcer) from an offshore location to a data centre, the impact will be a deficit in economic activity to the offshore location and an economic benefit to the originating economy. On this basis, developed economies \u2013 with skills and technological infrastructure to develop and support a robotic automation capability \u2013 can be expected to achieve a net benefit from the trend.\nIn a TEDx talk[12] hosted by University College London (UCL), entrepreneur David Moss explains that digital labour in the form of RPA is likely to revolutionize the cost model of the services industry by driving the price of products and services down, while simultaneously improving the quality of outcomes and creating increased opportunity for the personalization of services.\nIn a separate TEDx in 2019 talk,[13] Japanese business executive, and former CIO of Barclays bank, Koichi Hasegawa noted that digital robots can be a positive effect on society if we start using a robot with empathy to help every person. He provides a case study of the Japanese insurance companies \u2013 Sompo Japan and Aioi \u2013 both of whom introduced bots to speed up the process of insurance pay-outs in past massive disaster incidents.\nMeanwhile, Professor Willcocks, author of the LSE paper[11] cited above, speaks of increased job satisfaction and intellectual stimulation, characterising the technology as having the ability to \"take the robot out of the human\",[14] a reference to the notion that robots will take over the mundane and repetitive portions of people's daily workload, leaving them to be used in more interpersonal roles or to concentrate on the remaining, more meaningful, portions of their day.\nIt was also found in a 2021 study observing the effects of robotization in Europe that, the gender pay gap increased at a rate of .18% for every 1% increase in robotization of a given industry.[15]Unassisted RPA[edit]Unassisted RPA, or RPAAI,[16][17] is the next generation of RPA related technologies. Technological advancements around artificial intelligence allow a process to be run on a computer without needing input from a user.\nHyperautomation[edit]Hyperautomation is the application of advanced technologies like RPA, artificial intelligence, machine learning (ML) and process mining to augment workers and automate processes in ways that are significantly more impactful than traditional automation capabilities.[18][19][20] Hyperautomation is the combination of technologies that allow faster application authorship (like low-code and no-code) with automation technologies that coordinate different worker types (i.e. human and artificial) for intelligent and strategic workflow optimization.[21][22]Gartner's report notes that this trend was kicked off with robotic process automation (RPA). The report notes that, \"RPA alone is not hyperautomation. Hyperautomation requires a combination of tools to help support replicating pieces of where the human is involved in a task.\"[23]Outsourcing[edit]Back office clerical processes outsourced by large organisations - particularly those sent offshore - tend to be simple and transactional in nature, requiring little (if any) analysis or subjective judgement. This would seem to make an ideal starting point for organizations beginning to adopt robotic automation for the back office. Whether client organisations choose to take outsourced processes back \"in house\" from their business process outsourcing (BPO) providers, thus representing a threat to the future of the BPO business,[24] or whether the BPOs implement such automations on their clients' behalf may well depend on a number of factors.\nConversely however, a BPO provider may seek to effect some form of client lock-in by means of automation. By removing cost from a business operation, where the BPO provider is considered to be the owner of the intellectual property and physical implementation of a robotic automation solution (perhaps in terms of hardware, ownership of software licences, etc.), the provider can make it very difficult for the client to take a process back \"in house\" or elect a new BPO provider. This effect occurs as the associated cost savings made through automation would - temporarily at least - have to be reintroduced to the business whilst the technical solution is reimplemented in the new operational context.\nThe geographically agnostic nature of software means that new business opportunities may arise for those organisations that have a political or regulatory impediment to offshoring or outsourcing. A robotised automation can be hosted in a data centre in any jurisdiction and this has two major consequences for BPO providers. Firstly, for example, a sovereign government may not be willing or legally able to outsource the processing of tax affairs and security administration. On this basis, if robots are compared to a human workforce, this creates a genuinely new opportunity for a \"third sourcing\" option, after the choices of onshore vs. offshore. Secondly, and conversely, BPO providers have previously relocated outsourced operations to different political and geographic territories in response to changing wage inflation and new labour arbitrage opportunities elsewhere. By contrast, a data centre solution would seem to offer a fixed and predictable cost base that, if sufficiently low in cost on a robot vs. human basis,  would seem to eliminate any potential need or desire to continually relocate operational bases.\nLimitations of robotic process automation[edit]While robotic process automation has many benefits including cost efficiency and consistency in performance, it also has some limitations. Current RPA solutions demand continual technical support to handle system changes, therefore it lacks the ability to autonomously adapt to new conditions. Because of this limitation, the system sometimes needs manual reconfiguration, which in turn has an effect on efficiency.[25]Difference between RPA and AI[edit]RPA is based on automation technology following a predefined workflow, and artificial intelligence is data-driven and focuses on processing information to make predictions. Therefore, there is a distinct difference between how the two systems operate. AI aims to mimic human intelligence, whereas RPA is focused on reproducing tasks that are typically human-directed.[26] Moreover, RPA could also be explained as virtual robots that take over routinized human work, it can identify data by interpreting the underlying tags. RPA, therefore, is based on machine learning, whereas AI utilizes self-learning technologies.[27]Examples[edit]Voice recognition and digital dictation software linked to join up business processes for straight through processing without manual interventionSpecialised remote infrastructure management software featuring automated investigation and resolution of problems, using robots for the first line IT supportChatbots used by internet retailers and service providers to service customer requests for information. Also used by companies to service employee requests for information from internal databasesPresentation layer automation software, increasingly used by business process outsourcers to displace human labourInteractive voice response (IVR) systems incorporating intelligent interaction with callersSee also[edit]AutomationBusiness process automationReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}AI interns:Software already taking jobs from humans, New Scientist^\"What is Robotic Process Automation (RPA)? | IBM\". www.ibm.com. IBM. 27 March 2024. Retrieved 25 April 2024.^\"what-is-screen-scraping-malware\". www.logixconsulting.com. Retrieved 31 March 2025.^Robotic Automation Emerges as a Threat to Traditional Low-Cost Outsourcing, HfS Research, archived from the original on 2015-09-21^\"10 Facts About The Big Four & Secret Tips To Be Recruited | LiveWell\"(PDF). www.kpmg-institutes.com. 16 November 2019. Retrieved 2025-02-24.^DeBrusk, Chris (24 October 2017). \"Five Robotic Process Automation Risks to Avoid\". MIT Sloan Management Review. Retrieved 28 June 2018.^Lacity, Mary C.; Willcocks, Leslie (19 June 2015), \"What knowledge workers stand to gain from automation\", Harvard Business Review^ abRobotic Process Automation at Xchanging(PDF), London School of Economics^Gartner Predicts 2014: Business and IT Services Are Facing the End of Outsourcing as We Know It, Gartner^ abTHE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION?, archived from the original on 2016-02-05^ abVieira, Helena (29 September 2015). \"Nine likely scenarios arising from the growing use of robots\". LSE Business Review.^White Collar Robots: The Virtual Workforce, TEDx Talks, 28 January 2016^RPA Live, BTOPEX^Jee, Charlotte, \"Technology is not about to steal your job\", Techworld, www.techworld.com^Aksoy, Cevat Giray; \u00d6zcan, Berkay; Philipp, Julia (May 2021). \"Robots and the gender pay gap in Europe\"(PDF). European Economic Review. 134 103693. doi:10.1016/j.euroecorev.2021.103693. S2CID\u00a0233835919.^Technologies, AIMDek (2018-08-29). \"Evolution of Robotic Process Automation (RPA): The Path to Cognitive RPA\". Medium. Retrieved 2019-01-28.^\"RPAAI - Robotic Process Automation\". rpaai.com (in Dutch). Archived from the original on 2020-08-15. Retrieved 2020-05-06.^\"Gartner Top 10 Strategic Technology Trends for 2020\". Gartner.^\"Gartner Tech Trends 2020\". Gigabit Magazine. Archived from the original on 2019-12-03. Retrieved 2019-10-30.^\"Hyperautomation among top 10 technology trends for 2020\". Tech Republic. 21 October 2019.^Lindsay James (2020-03-18). \"What is hyperautomation and how will it transform business?\". ITPro. Retrieved 2024-09-16.^Calkins, Matt (2020). Hyperautomation.^\"Gartner Announces Top 10 Strategic Technology Trends For 2020\". Forbes.^IT Robots May Mean the End of Offshore Outsourcing, CIO Magazine, archived from the original on 2014-02-16, retrieved 2020-05-02^Yatskiv, Nataliya; Yatskiv, Solomiya; Vasylyk, Anatoliy (2020). \"Method of Robotic Process Automation in Software Testing Using Artificial Intelligence\". 2020 10th International Conference on Advanced Computer Information Technologies (ACIT). pp.\u00a0501\u2013504. doi:10.1109/ACIT49673.2020.9208806. ISBN\u00a0978-1-7281-6759-6.^\"What is robotic process automation (RPA)?\". www.IBM.com. IBM. 27 March 2024. Retrieved 25 April 2024.^Andersson, Christoffer; Hallin, Anette; Ivory, Chris (January 2022). \"Unpacking the digitalisation of public services: Configuring work during automation in local government\". Government Information Quarterly. 39 (1) 101662. doi:10.1016/j.giq.2021.101662.Further reading[edit].mw-parser-output .refbegin{margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}@media screen{.mw-parser-output .refbegin{font-size:90%}}  \nvan der Aalst, Wil M. P.; Bichler, Martin; Heinzl, Armin (August 2018). \"Robotic Process Automation\". Business & Information Systems Engineering. 60 (4): 269\u2013272. doi:10.1007/s12599-018-0542-4.Syed, Rehan; Suriadi, Suriadi; Adams, Michael; Bandara, Wasana; Leemans, Sander J.J.; Ouyang, Chun; ter Hofstede, Arthur H.M.; van de Weerd, Inge; Wynn, Moe Thandar; Reijers, Hajo A. (February 2020). \"Robotic Process Automation: Contemporary themes and challenges\"(PDF). Computers in Industry. 115 103162. doi:10.1016/j.compind.2019.103162. hdl:1874/395182.Aguirre, Santiago; Rodriguez, Alejandro (2017). \"Automation of a Business Process Using Robotic Process Automation (RPA): A Case Study\". Applied Computer Sciences in Engineering. Communications in Computer and Information Science. Vol.\u00a0742. pp.\u00a065\u201371. doi:10.1007/978-3-319-66963-2_7. ISBN\u00a0978-3-319-66962-5.Agostinelli, Simone; Marrella, Andrea; Mecella, Massimo (2020). Towards Intelligent Robotic Process Automation for BPMers (Preprint). arXiv:2001.00804.Willcocks, Leslie; Lacity, Mary; Craig, Andrew (May 2017). \"Robotic Process Automation: Strategic Transformation Lever for Global Business Services?\"(PDF). Journal of Information Technology Teaching Cases. 7 (1): 17\u201328. doi:10.1057/s41266-016-0016-9.Leshob, Abderrahmane; Bourgouin, Audrey; Renard, Laurent (2018). \"Towards a Process Analysis Approach to Adopt Robotic Process Automation\". 2018 IEEE 15th International Conference on e-Business Engineering (ICEBE). pp.\u00a046\u201353. doi:10.1109/ICEBE.2018.00018. ISBN\u00a0978-1-5386-7992-0.Santos, Filipa; Pereira, R\u00faben; Vasconcelos, Jos\u00e9 Braga (20 September 2019). \"Toward robotic process automation implementation: an end-to-end perspective\". Business Process Management Journal. 26 (2): 405\u2013420. doi:10.1108/BPMJ-12-2018-0380. hdl:10071/20913.Chakraborti, Tathagata; Isahagian, Vatche; Khalaf, Rania; Khazaeni, Yasaman; Muthusamy, Vinod; Rizk, Yara; Unuvar, Merve (2020). \"From Robotic Process Automation to Intelligent Process Automation: \u2013 Emerging Trends \u2013\". Business Process Management: Blockchain and Robotic Process Automation Forum. Lecture Notes in Business Information Processing. Vol.\u00a0393. pp.\u00a0215\u2013228. doi:10.1007/978-3-030-58779-6_15. ISBN\u00a0978-3-030-58778-9.Enriquez, J. G.; Jimenez-Ramirez, A.; Dominguez-Mayo, F. J.; Garcia-Garcia, J. A. (2020). \"Robotic Process Automation: A Scientific and Industrial Systematic Mapping Study\". IEEE Access. 8: 39113\u201339129. Bibcode:2020IEEEA...839113E. doi:10.1109/ACCESS.2020.2974934.Agostinelli, Simone; Marrella, Andrea; Mecella, Massimo (2019). \"Research Challenges for Intelligent Robotic Process Automation\". Business Process Management Workshops. Lecture Notes in Business Information Processing. Vol.\u00a0362. pp.\u00a012\u201318. doi:10.1007/978-3-030-37453-2_2. ISBN\u00a0978-3-030-37452-5.Ratia, M.; Myll\u00e4rniemi, J.; Helander, N. (2018). \"Robotic Process Automation - Creating Value by Digitalizing Work in the Private Healthcare?\". Proceedings of the 22nd International Academic Mindtrek Conference. pp.\u00a0222\u2013227. doi:10.1145/3275116.3275129. ISBN\u00a0978-1-4503-6589-5.Vincent, Nishani Edirisinghe; Igou, Amy; Burns, Mary B. (September 2020). \"Preparing for the Robots: A Proposed Course in Robotic Process Automation\". Journal of Emerging Technologies in Accounting. 17 (2): 75\u201391. doi:10.2308/JETA-2020-020.Chacon Montero, Jesus; Jimenez Ramirez, Andres; Gonzalez Enriquez, Jose (2019). \"Towards a Method for Automated Testing in Robotic Process Automation Projects\". 2019 IEEE/ACM 14th International Workshop on Automation of Software Test (AST). pp.\u00a042\u201347. doi:10.1109/AST.2019.00012. hdl:11441/134243. ISBN\u00a0978-1-7281-2237-3.Kobayashi, Toru; Arai, Kenichi; Imai, Tetsuo; Tanimoto, Shigeaki; Sato, Hiroyuki; Kanai, Atsushi (2019). \"Communication Robot for Elderly Based on Robotic Process Automation\". 2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC). pp.\u00a0251\u2013256. doi:10.1109/COMPSAC.2019.10215. ISBN\u00a0978-1-7281-2607-4.Herm, Lukas-Valentin; Janiesch, Christian; Helm, Alexander; Imgrund, Florian; Fuchs, Kevin; Hofmann, Adrian; Winkelmann, Axel (2020). \"A Consolidated Framework for Implementing Robotic Process Automation Projects\". Business Process Management. Lecture Notes in Computer Science. Vol.\u00a012168. pp.\u00a0471\u2013488. doi:10.1007/978-3-030-58666-9_27. ISBN\u00a0978-3-030-58665-2.External links[edit]Jobs, productivity and the great decoupling, by Professor McAfee, Principal Research Scientist at MIT's Center for Digital Business.Rise of the software machines, Economist Magazine.London School of Economics Releases First in a Series of RPA Case Studies, ReutersHumans and Machines: The role of people in technology-driven organisationsArchived 2013-03-19 at the Wayback Machine, Economist Magazine.Robotic Automation as Threat to Traditional Low-Cost Outsourcing, HFS Research.\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Robotic_process_automation&oldid=1314554087\"", "tags": ["en.wikipedia.org", "wiki", "robotic", "process", "automation"]}
{"url": "https://en.wikipedia.org/wiki/Chatbot", "title": null, "text": "Program that simulates conversation.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For the bot-creation software, see ChatBot. For bots on Internet Relay Chat, see IRC bot.A virtual assistant chatbotThe 1966 ELIZA chatbot.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}.mw-parser-output .nobold{font-weight:normal}Part of a series onMachine learningand data miningParadigmsSupervised learningUnsupervised learningSemi-supervised learningSelf-supervised learningReinforcement learningMeta-learningOnline learningBatch learningCurriculum learningRule-based learningNeuro-symbolic AINeuromorphic engineeringQuantum machine learningProblemsClassificationGenerative modelingRegressionClusteringDimensionality reductionDensity estimationAnomaly detectionData cleaningAutoMLAssociation rulesSemantic analysisStructured predictionFeature engineeringFeature learningLearning to rankGrammar inductionOntology learningMultimodal learningSupervised learning(classification\u00a0\u2022 regression)Apprenticeship learningDecision treesEnsemblesBaggingBoostingRandom forestk-NNLinear regressionNaive BayesArtificial neural networksLogistic regressionPerceptronRelevance vector machine (RVM)Support vector machine (SVM)ClusteringBIRCHCUREHierarchicalk-meansFuzzyExpectation\u2013maximization (EM)DBSCANOPTICSMean shiftDimensionality reductionFactor analysisCCAICALDANMFPCAPGDt-SNESDLStructured predictionGraphical modelsBayes netConditional random fieldHidden MarkovAnomaly detectionRANSACk-NNLocal outlier factorIsolation forestNeural networksAutoencoderDeep learningFeedforward neural networkRecurrent neural networkLSTMGRUESNreservoir computingBoltzmann machineRestrictedGANDiffusion modelSOMConvolutional neural networkU-NetLeNetAlexNetDeepDreamNeural fieldNeural radiance fieldPhysics-informed neural networksTransformerVisionMambaSpiking neural networkMemtransistorElectrochemical RAM (ECRAM)Reinforcement learningQ-learningPolicy gradientSARSATemporal difference (TD)Multi-agentSelf-playLearning with humansActive learningCrowdsourcingHuman-in-the-loopMechanistic interpretabilityRLHFModel diagnosticsCoefficient of determinationConfusion matrixLearning curveROC curveMathematical foundationsKernel machinesBias\u2013variance tradeoffComputational learning theoryEmpirical risk minimizationOccam learningPAC learningStatistical learningVC theoryTopological deep learningJournals and conferencesAAAIECML PKDDNeurIPSICMLICLRIJCAIMLJMLRRelated articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteA chatbot (originally chatterbot)[1] is a software application or web interface designed to have textual or spoken conversations.[2][3][4] Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\nChatbots have increased in popularity as part of the AI boom of the 2020s, and the popularity of ChatGPT, followed by competitors such as Gemini, Claude and later Grok.  AI chatbots typically use a foundationallarge language model, such as GPT-4 or the Gemini language model, which is fine-tuned for specific uses. \nA major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants.[5]History[edit]Turing test[edit]In 1950, Alan Turing's article \"Computing Machinery and Intelligence\" proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge to the extent that the judge is unable to distinguish reliably\u2014on the basis of the conversational content alone\u2014between the program and a real human.[6]Early chatbots[edit]Joseph Weizenbaum's program ELIZA was first published in 1966. Weizenbaum did not claim that ELIZA was genuinely intelligent, and the introduction to his paper presented it more as a debunking exercise:In artificial intelligence, machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained, its magic crumbles away; it stands revealed as a mere collection of procedures. The observer says to himself \"I could have written that\". With that thought, he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios. The object of this paper is to cause just such a re-evaluation of the program about to be \"explained\". Few programs ever needed it more.[7] ELIZA's key method of operation involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g. by responding to any input that contains the word 'MOTHER' with 'TELL ME MORE ABOUT YOUR FAMILY').[7] Thus an illusion of understanding is generated, even though the processing involved has been merely superficial. ELIZA showed that such an illusion is surprisingly easy to generate because human judges are ready to give the benefit of the doubt when conversational responses are capable of being interpreted as \"intelligent\".\nFollowing ELIZA, psychiatrist Kenneth Colby developed PARRY in 1972.[8][9][10][11]From 1978[12] to some time after 1983,[13] the CYRUS project led by Janet Kolodner constructed a chatbot simulating Cyrus Vance (57th United States Secretary of State). It used case-based reasoning, and updated its database daily by parsing wire news from United Press International. The program was unable to process the news items subsequent to the surprise resignation of Cyrus Vance in April 1980, and the team constructed another chatbot simulating his successor, Edmund Muskie.[14][13]In 1984, an interactive version of the program Racter was released which acted as a chatbot.[15]A.L.I.C.E. was released in 1995. This uses a markup language called AIML,[3] which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so-called, Alicebots. A.L.I.C.E. is a weak AI without any reasoning capabilities. It is based on a similar pattern matching technique as ELIZA in 1966. This is not strong AI, which would require sapience and logical reasoning abilities.\nJabberwacky, released in 1997, learns new responses and context based on real-timeuser interactions, rather than being driven from a static database.\nChatbot competitions focus on the Turing test or more specific goals. Two such annual contests are the Loebner Prize and The Chatterbox Challenge (the latter has been offline since 2015, however, materials can still be found from web archives).[16]DBpedia created a chatbot during the GSoC of 2017.[17] It can communicate through Facebook Messenger.\nModern chatbots based on large language models[edit]A Character.ai conversation with a Wittgenstein chatbotModern chatbots like ChatGPT are often based on large language models called generative pre-trained transformers (GPT). They are based on a deep learning architecture called the transformer, which contains artificial neural networks. They generate text after being trained on a large text corpus.\nApplication[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs to be updated. Please help update this article to reflect recent events or newly available information.  (December 2024)See also: Virtual assistantMessaging apps[edit]Many companies' chatbots run on messaging apps or simply via SMS. They are used for B2C customer service, sales and marketing.[18]In 2016, Facebook Messenger allowed developers to place chatbots on their platform. There were 30,000 bots created for Messenger in the first six months, rising to 100,000 by September 2017.[19]Since September 2017, this has also been as part of a pilot program on WhatsApp. Airlines KLM and Aerom\u00e9xico both announced their participation in the testing;[20][21][22][23] both airlines had previously launched customer services on the Facebook Messenger platform. The Nigerian event platform Demfati, for example, uses its Deeva chatbot on WhatsApp for dedicated B2C functions like ticket purchasing and event voting.[24]The bots usually appear as one of the user's contacts, but can sometimes act as participants in a group chat.\nMany banks, insurers, media companies, e-commerce companies, airlines, hotel chains, retailers, health care providers, government entities, and restaurant chains have used chatbots to answer simple questions, increase customer engagement,[25] for promotion, and to offer additional ways to order from them.[26] Chatbots are also used in market research to collect short survey responses.[27]A 2017 study showed 4% of companies used chatbots.[28] In a 2016 study, 80% of businesses said they intended to have one by 2020.[29]As part of company apps and websites[edit]Previous generations of chatbots were present on company websites, e.g. Ask Jenn from Alaska Airlines which debuted in 2008[30] or Expedia's virtual customer service agent which launched in 2011.[30][31] The newer generation of chatbots includes IBM Watson-powered \"Rocky\", introduced in February 2017 by the New York City-based e-commerce company Rare Carat to provide information to prospective diamond buyers.[32][33]Chatbot sequences[edit]Used by marketers to script sequences of messages, very similar to an autoresponder sequence. Such sequences can be triggered by user opt-in or the use of keywords within user interactions. After a trigger occurs a sequence of messages is delivered until the next anticipated user response. Each user response is used in the decision tree to help the chatbot navigate the response sequences to deliver the correct response message.\nCompany internal platforms[edit]Companies have used chatbots for customer support, human resources, or in Internet-of-Things (IoT) projects. Overstock.com, for one, has reportedly launched a chatbot named Mila to attempt to automate certain processes when customer service employees request sick leave.[34] Other large companies such as Lloyds Banking Group, Royal Bank of Scotland, Renault and Citro\u00ebn are now using chatbots instead of call centres with humans to provide a first point of contact.[citation needed] In large companies, like in hospitals and aviation organizations, chatbots are also used to share information within organizations, and to assist and replace service desks.[citation needed]Customer service[edit]Chatbots have been proposed as a replacement for customer service departments.[35]In 2016, Russia-based Tochka Bank launched a chatbot on Facebook for a range of financial services, including a possibility of making payments.[36] In July 2016, Barclays Africa also launched a Facebook chatbot.[37]Healthcare[edit]See also: Artificial intelligence in healthcareChatbots are also appearing in the healthcare industry.[38][39] A study suggested that physicians in the United States believed that chatbots would be most beneficial for scheduling doctor appointments, locating health clinics, or providing medication information.[40]In 2020, WhatsApp worked with the World Health Organization and the Government of India to make chatbots to answers users' questions on COVID-19.[41][42][43][44]In 2023, US-based National Eating Disorders Association replaced its human helpline staff with a chatbot but had to take it offline after users reported receiving harmful advice from it.[45][46][47]Politics[edit]See also: Government by algorithm \u00a7\u00a0AI politiciansIn New Zealand, the chatbot SAM \u2013 short for Semantic Analysis Machine[48] \u2013 has been developed by Nick Gerritsen of Touchtech.[49] It is designed to share its political thoughts, for example on topics such as climate change, healthcare and education, etc. It talks to people through Facebook Messenger.[50][51][52][53]In 2022, the chatbot \"Leader Lars\" or \"Leder Lars\" was nominated for The Synthetic Party to run in the Danish parliamentary election,[54] and was built by the artist collective Computer Lars.[55] Leader Lars differed from earlier virtual politicians by leading a political party and by not pretending to be an objective candidate.[56] This chatbot engaged in critical discussions on politics with users from around the world.[57]In India, the state government has launched a chatbot for its Aaple Sarkar platform,[58] which provides conversational access to information regarding public services managed.[59][60]Toys[edit]Chatbots have also been incorporated into devices not primarily meant for computing, such as toys.[61]Hello Barbie is an Internet-connected version of the doll that uses a chatbot provided by the company ToyTalk,[62] which previously used the chatbot for a range of smartphone-based characters for children.[63] These characters' behaviors are constrained by a set of rules that in effect emulate a particular character and produce a storyline.[64]The My Friend Cayla doll was marketed as a line of 18-inch (46\u00a0cm) dolls which uses speech recognition technology in conjunction with an Android or iOS mobile app to recognize the child's speech and have a conversation. Like the Hello Barbie doll, it attracted controversy due to vulnerabilities with the doll's Bluetooth stack and its use of data collected from the child's speech.\nIBM's Watson computer has been used as the basis for chatbot-based educational toys for companies such as CogniToys,[61] intended to interact with children for educational purposes.[65]Malicious use[edit]Malicious chatbots are frequently used to fill chat rooms with spam and advertisements by mimicking human behavior and conversations or to entice people into revealing personal information, such as bank account numbers. They were commonly found on Yahoo! Messenger, Windows Live Messenger, AOL Instant Messenger and other instant messaging protocols. There has also been a published report of a chatbot used in a fake personal ad on a dating service's website.[66]Tay, an AI chatbot designed to learn from previous interactions, caused major controversy after being targeted by internet trolls on Twitter. Soon after its launch, the bot was exploited, and with its \"repeat after me\" capability, it started releasing racist, sexist, and controversial responses to Twitter users.[67] This suggests that although the bot learned effectively from experience, adequate protection was not put in place to prevent misuse.[68]If a text-sending algorithm can pass itself off as a human instead of a chatbot, its message would be more credible. Therefore, human-seeming chatbots with well-crafted online identities could start scattering fake news that seems plausible, for instance making false claims during an election. With enough chatbots, it might be even possible to achieve artificial social proof.[69][70]Data security[edit]Data security is one of the major concerns of chatbot technologies. Security threats and system vulnerabilities are weaknesses that are often exploited by malicious users. Storage of user data and past communication, that is highly valuable for training and development of chatbots, can also give rise to security threats.[71] Chatbots operating on third-party networks may be subject to various security issues if owners of the third-party applications have policies regarding user data that differ from those of the chatbot.[71] Security threats can be reduced or prevented by incorporating protective mechanisms. User authentication, chat End-to-end encryption, and self-destructing messages are some effective solutions to resist potential security threats.[71]Mental health[edit]Chatbots have shown to be an emerging technology used in the field of mental health. Its usage may encourage users to seek advice on matters of mental health as a means to avoid the stigmatization that may come from sharing such matters with other people.[72] This is because chatbots can give a sense of privacy and anonymity when sharing sensitive information, as well as providing a space that allows for the user to be free of judgment.[72] An example of this can be seen in a study which found that with social media and AI chatbots both being possible outlets to express mental health online, users were more willing to share their darker and more depressive emotions to the chatbot.[72]Findings prove that chatbots have great potential in scenarios in which it is difficult for users to reach out to family or friends for support.[72] It has been noted that it demonstrates the ability to give young people \"various types of social support such as appraisal, informational, emotional, and instrumental support\".[72] Studies have found that chatbots are able to assist users in managing things such as depression and anxiety.[72] Some examples of chatbots that serve this function are \"Woebot, Wysa, Vivibot, and Tess\".[72]Evidence indicates that when mental health chatbots interact with users, they tend to follow certain conversation flows.[73] These being guided conversation, semi guided conversation, and open ended conversation.[73] The most popular, guided conversation, \"only allows the users to communicate with the chatbot with predefined responses from the chatbot. It does not allow any form of open input from the users\".[73] It has also been noted in a study looking at the methods employed by various mental health chatbots, that most of them employed a form of cognitive behavior therapy with the user.[73]Adverse effects[edit]Further information: Chatbot psychosisResearch has identified potential barriers to entry that come with the usage of chatbots for mental health.[74] There are ongoing privacy concerns with sharing user's personal data in chat logs with chatbots.[74] There is a lack of willingness from those in lower socioeconomic statuses to adopt interactions with chatbots as a meaningful way to improve upon mental health.[74] Though chatbots may be capable of detecting simple human emotions in interactions with users, they are incapable of replicating the level of empathy that human therapists do.[74] \nDue to the nature of chatbots being language-learning models trained on numerous datasets, the issue of algorithmic bias exists.[74] Chatbots with built in biases from their training can have them brought out against individuals of certain backgrounds and may result in incorrect information being conveyed.[74]There is a lack of research about how exactly these interactions help with a user's real life.[73] There are concerns regarding the safety of users when interacting with such chatbots.[73] When improvements and advancements are made to such technologies, how that may affect humans is not a priority.[73] It is possible that this can lead to \"unintended negative consequences, such as biases, inadequate and failed responses, and privacy issues\".[73]A risk in the usage of chatbots to deal with mental health is increased isolation, as well as a lack of support in times of crisis.[73] Another notable risk is a general lack of a strong understanding of mental health.[73] Studies have indicated that mental-health-oriented chatbots have been prone to recommending users medical solutions and to rely upon themselves heavily.[73] \nObsessive use of chatbots has been linked to chatbot psychosis[75] in people already prone to delusional and conspiratorial thinking. This is caused in part by chatbots \"hallucinating\" information,[76] as they are designed for engagement, and to keep people talking.[77]Limitations[edit]Traditional chatbots particularly lacked understanding of user requests, leading to clunky, repetitive conversations. Their pre-programmed responses would often fail to satisfy unexpected user queries, causing frustration. These chatbots were particularly unhelpful for users who lacked a clear understanding of their problem or the service they needed.[78]Chatbots based on large language models are much more versatile, but require a large amount of conversational data to train. These models generate new responses word by word based on user input, and are usually trained on a large dataset of natural-language phrases.[3] They sometimes provide plausible-sounding but incorrect or nonsensical answers, referred to as \"hallucinations\". They can for example make up names, dates, or historical events.[79] When humans use and apply chatbot content contaminated with hallucinations, this results in \"botshit\".[80] Given the increasing adoption and use of chatbots for generating content, there are concerns that this technology will significantly reduce the cost it takes humans to generate misinformation.[81]Impact on jobs[edit]Chatbots and technology in general used to automate repetitive tasks. But advanced chatbots like ChatGPT are also targeting high-paying, creative, and knowledge-based jobs, raising concerns about workforce disruption and quality trade-offs in favor of cost-cutting.[82]Chatbots are increasingly used by small and medium enterprises, to handle customer interactions efficiently, reducing reliance on large call centers and lowering operational costs.[83]Prompt engineering, the task of designing and refining prompts (inputs) leading to desired AI-generated responses has quickly gained significant demand with the advent of large language models,[84] although the viability of this job is questioned due to new techniques for automating prompt engineering.[85]Impact on the environment[edit]See also: Environmental impacts of artificial intelligence and Data_center \u00a7\u00a0Energy_useGenerative AI uses a high amount of electric power. Due to reliance on fossil fuels in its generation, this increases air pollution, water pollution, and greenhouse gas emissions. In 2023, a question to ChatGPT consumed on average 10 times as much energy as a Google search.[86] Data centres in general, and those used for AI tasks specifically, use significant amounts of water for cooling.[87][88]See also[edit].mw-parser-output .portalbox{padding:0;margin:0.5em 0;display:table;box-sizing:border-box;max-width:175px;list-style:none}.mw-parser-output .portalborder{border:1px solid var(--border-color-base,#a2a9b1);padding:0.1em;background:var(--background-color-neutral-subtle,#f8f9fa)}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;height:1.9em;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}Linguistics portalProgramming portal.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}Applications of artificial intelligenceArtificial human companionArtificial intelligence and electionsAutonomous agentConversational user interfaceDeadbotDead Internet theoryDeaths linked to chatbotsFriendly artificial intelligenceHybrid intelligent systemIntelligent agentInternet botList of chatbotsMulti-agent systemSocial botSoftware agentSoftware botStochastic parrotTechnological unemploymentTwitterbotReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Mauldin, Michael (1994), \"ChatterBots, TinyMuds, and the Turing Test: Entering the Loebner Prize Competition\", Proceedings of the Eleventh National Conference on Artificial Intelligence, AAAI Press, archived from the original on 13 December 2007, retrieved 5 March 2008^\"What is a chatbot?\". techtarget.com. Archived from the original on 2 November 2010. Retrieved 30 January 2017.^ abcCaldarini, Guendalina; Jaf, Sardar; McGarry, Kenneth (2022). \"A Literature Survey of Recent Advances in Chatbots\". Information. 13 (1) 41. MDPI. arXiv:2201.06657. doi:10.3390/info13010041.^Adamopoulou, Eleni; Moussiades, Lefteris (2020). \"Chatbots: History, technology, and applications\". Machine Learning with Applications. 2 100006. doi:10.1016/j.mlwa.2020.100006.^\"2017 Messenger Bot Landscape, a Public Spreadsheet Gathering 1000+ Messenger Bots\". 3 May 2017. Archived from the original on 2 February 2019. Retrieved 1 February 2019.^Turing, Alan (1950), \"Computing Machinery and Intelligence\", Mind, 59 (236): 433\u2013460, doi:10.1093/mind/lix.236.433^ abWeizenbaum, Joseph (January 1966), \"ELIZA \u2013 A Computer Program For the Study of Natural Language Communication Between Man And Machine\", Communications of the ACM, 9 (1): 36\u201345, doi:10.1145/365153.365168, S2CID\u00a01896290^G\u00fczeldere, G\u00fcven; Franchi, Stefano (24 July 1995), \"Constructions of the Mind\", Stanford Humanities Review, SEHR, 4 (2), Stanford University, archived from the original on 11 July 2007, retrieved 5 March 2008^Computer History Museum (2006), \"Internet History \u2013 1970's\", Exhibits, Computer History Museum, archived from the original on 21 February 2008, retrieved 5 March 2008^Sondheim, Alan J (1997), <nettime> Important Documents from the Early Internet (1972), nettime.org, archived from the original on 13 June 2008, retrieved 5 March 2008^Network Working Group (1973). \"PARRY Encounters the DOCTOR\". Internet Engineering Task Force. Internet Society. doi:10.17487/RFC0439. RFC439. \u2013 Transcript of a session between Parry and Eliza. (This is not the dialogue from the ICCC, which took place 24\u201326 October 1972, whereas this session is from 18 September 1972.)^Kolodner, Janet L. Memory organization for natural language data-base inquiry. Advanced Research Projects Agency, 1978.^ abKolodner, Janet L. (1 October 1983). \"Maintaining organization in a dynamic long-term memory\". Cognitive Science. 7 (4): 243\u2013280. doi:10.1016/S0364-0213(83)80001-9 (inactive 30 August 2025). ISSN\u00a00364-0213.{{cite journal}}:  CS1 maint: DOI inactive as of August 2025 (link)^Dennett, Daniel C. (2004), Teuscher, Christof (ed.), \"Can Machines Think?\", Alan Turing: Life and Legacy of a Great Thinker, Berlin, Heidelberg: Springer, pp.\u00a0295\u2013316, doi:10.1007/978-3-662-05642-4_12, ISBN\u00a0978-3-662-05642-4^The Policeman's Beard is Half ConstructedArchived 4 February 2010 at the Wayback Machine. everything2.com. 13 November 1999^\"Chat Robots Simiulate People\". 11 October 2015.^\"Meet the DBpedia Chatbot | DBpedia\". wiki.dbpedia.org. 22 August 2018. Archived from the original on 2 September 2019. Retrieved 2 September 2019.^Beaver, Laurie (July 2016). \"The Chatbots Explainer\". Business Insider. BI Intelligence. Archived from the original on 3 May 2019. Retrieved 4 November 2019.^\"Facebook Messenger Hits 100,000 bots\". 18 April 2017. Archived from the original on 22 September 2017. Retrieved 22 September 2017.^\"KLM claims airline first with WhatsApp Business Platform\". www.phocuswire.com. Archived from the original on 5 February 2020. Retrieved 12 December 2021.^Forbes Staff (26 October 2017). \"Aerom\u00e9xico te atender\u00e1 por WhatsApp durante 2018\". Archived from the original on 2 July 2018. Retrieved 2 July 2018.^\"Podr\u00e1s hacer 'check in' y consultar tu vuelo con Aerom\u00e9xico a trav\u00e9s de WhatsApp\". Huffington Post. 27 October 2017. Archived from the original on 10 March 2018. Retrieved 2 July 2018.^\"Building for People, and Now Businesses\". WhatsApp.com. Archived from the original on 9 February 2018. Retrieved 2 July 2018.^\"How a Google deranking issue in 2017 gave birth to an e-ticketing platform\". 18 July 2025. Retrieved 16 October 2025.^\"She is the company's most effective employee\". Nordea News. September 2017. Archived from the original on 23 March 2023. Retrieved 23 March 2023.^\"Better believe the bot boom is blowing up big for B2B, B2C businesses\". VentureBeat. 24 July 2016. Archived from the original on 3 August 2017. Retrieved 30 August 2017.^Dandapani, Arundati (30 April 2020). \"Redesigning Conversations with Artificial Intelligence (Chapter 11)\". In Sha, Mandy (ed.). The Essential Role of Language in Survey Research. RTI Press. pp.\u00a0221\u2013230. doi:10.3768/rtipress.bk.0023.2004. ISBN\u00a0978-1-934831-24-3.^Capan, Faruk (18 October 2017). \"The AI Revolution is Underway!\". www.PM360online.com. Archived from the original on 8 March 2018. Retrieved 7 March 2018.^\"80% of businesses want chatbots by 2020\". Business Insider. 15 December 2016. Archived from the original on 8 March 2018. Retrieved 7 March 2018.^ ab\"A Virtual Travel Agent With All the Answers\". The New York Times. 4 March 2008. Archived from the original on 15 June 2017. Retrieved 3 August 2017.^\"Chatbot vendor directory released\". www.hypergridbusiness.com. October 2011. Archived from the original on 23 April 2017. Retrieved 23 April 2017.^\"Rare Carat's Watson-powered chatbot will help you put a diamond ring on it\". TechCrunch. 15 February 2017. Archived from the original on 22 August 2017. Retrieved 22 August 2017.^\"10 ways you may have already used IBM Watson\". VentureBeat. 10 March 2017. Archived from the original on 22 August 2017. Retrieved 22 August 2017.^Greenfield, Rebecca (5 May 2016). \"Chatbots Are Your Newest, Dumbest Co-Workers\". Bloomberg.com. Archived from the original on 6 April 2017. Retrieved 6 March 2017.^F\u00f8lstad, Asbj\u00f8rn; Nordheim, Cecilie Bertinussen; Bj\u00f8rkli, Cato Alexander (2018). \"What Makes Users Trust a Chatbot for Customer Service? An Exploratory Interview Study\". In Bodrunova, Svetlana S. (ed.). Internet Science. Lecture Notes in Computer Science. Vol.\u00a011193. Cham: Springer International Publishing. pp.\u00a0194\u2013208. doi:10.1007/978-3-030-01437-7_16. hdl:11250/2571164. ISBN\u00a0978-3-030-01437-7.^\"\u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u0438\u0439 \u0431\u0430\u043d\u043a \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u043b \u0447\u0430\u0442-\u0431\u043e\u0442\u0430 \u0432 Facebook\". Vedomosti.ru. 13 July 2016. Archived from the original on 1 April 2019. Retrieved 1 April 2019.^\"Absa launches 'world-first' Facebook Messenger banking\". 19 July 2016. Archived from the original on 1 April 2019. Retrieved 1 April 2019.^Larson, Selena (11 October 2016). \"Baidu is bringing AI chatbots to healthcare\". CNN Money. Archived from the original on 3 January 2020. Retrieved 3 January 2020.^\"AI chatbots have a future in healthcare, with caveats\". AI in Healthcare. Archived from the original on 23 March 2023. Retrieved 17 September 2019.^Palanica, Adam; Flaschner, Peter; Thommandram, Anirudh; Li, Michael; Fossat, Yan (3 January 2019). \"Physicians' Perceptions of Chatbots in Health Care: Cross-Sectional Web-Based Survey\". Journal of Medical Internet Research. 21 (4) e12887. doi:10.2196/12887. PMC\u00a06473203. PMID\u00a030950796.^Ahaskar, Abhijit (27 March 2020). \"How WhatsApp chatbots are helping in the fight against Covid-19\". Mint. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"India's Coronavirus Chatbot on WhatsApp Crosses 1.7 Crore Users in 10 Days\". NDTV Gadgets 360. April 2020. Archived from the original on 21 June 2020. Retrieved 23 July 2020.^Kurup, Rajesh (21 March 2020). \"COVID-19: Govt of India launches a WhatsApp chatbot\". Business Line. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"In focus: Mumbai-based Haptik which developed India's official WhatsApp chatbot for Covid-19\". Hindustan Times. 7 April 2020. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^Crimmins, Tricia (30 May 2023). \"'This robot causes harm': National Eating Disorders Association's new chatbot advises people with disordering eating to lose weight\". The Daily Dot. Retrieved 2 June 2023.^Knight, Taylor (31 May 2023). \"Eating disorder helpline fires AI for harmful advice after sacking humans\".^Aratani, Lauren (31 May 2023). \"US eating disorder helpline takes down AI chatbot over harmful advice\". The Guardian. ISSN\u00a00261-3077. Retrieved 1 June 2023.^\"Sam, the virtual politician\". Tuia Innovation. Archived from the original on 1 September 2019. Retrieved 9 September 2019.^Wellington, Victoria University of (15 December 2017). \"Meet the world's first virtual politician\". Victoria University of Wellington. Archived from the original on 3 January 2020. Retrieved 3 January 2020.^Wagner, Meg (23 November 2017). \"This virtual politician wants to run for office\". CNN. Archived from the original on 1 September 2019. Retrieved 9 September 2019.^\"Talk with the first-ever robot politician on Facebook Messenger\". Engadget. 25 November 2017. Archived from the original on 4 August 2019. Retrieved 9 September 2019.^Prakash, Abishur (8 August 2018). \"AI-Politicians: A Revolution In Politics\". Medium. Archived from the original on 10 August 2019. Retrieved 1 September 2019.^\"SAM website\". Archived from the original on 11 May 2021. Retrieved 23 May 2021.^Sternberg, Sarah (20 June 2022). \"Danskere vil ind p\u00e5 den politiske scene med kunstig intelligens\" [Danes want to enter the political scene with artificial intelligence]. Jyllands-Posten. Archived from the original on 20 June 2022. Retrieved 20 June 2022.^Diwakar, Amar (22 August 2022). \"Can an AI-led Danish party usher in an age of algorithmic politics?\". TRT World. Archived from the original on 22 August 2022. Retrieved 22 August 2022.^Xiang, Chloe (13 October 2022). \"This Danish Political Party Is Led by an AI\". Vice: Motherboard. Archived from the original on 13 October 2022. Retrieved 13 October 2022.^Hearing, Alice (14 October 2022). \"A.I. chatbot is leading a Danish political party and setting its policies. Now users are grilling it for its stance on political landmines\". Fortune. Archived from the original on 22 December 2022. Retrieved 8 December 2022.^\"Maharashtra government launches Aaple Sarkar chatbot to provide info on 1,400 public services\". CNBC TV18. 5 March 2019. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^\"Government of Maharashtra launches Aaple Sarkar chatbot with Haptik\". The Economic Times. Archived from the original on 16 December 2020. Retrieved 23 July 2020.^Aggarwal, Varun (5 March 2019). \"Maharashtra launches Aaple Sarkar chatbot\". Business Line. Archived from the original on 23 July 2020. Retrieved 23 July 2020.^ abAmy (23 February 2015). \"Conversational Toys \u2013 The Latest Trend in Speech Technology\". Virtual Agent Chat. Archived from the original on 21 February 2018. Retrieved 11 August 2016.^Nagy, Evie (13 February 2015). \"Using Toy-talk Technology, New Hello Barbie Will Have Real Conversations With Kids\". Fast Company. Archived from the original on 15 March 2015. Retrieved 18 March 2015.^Oren Jacob, the co-founder and CEO of ToyTalk interviewed on the TV show Triangulation on the TWiT.tv network^\"Artificial intelligence script tool\". Archived from the original on 12 December 2021. Retrieved 12 December 2021.^Takahashi, Dean (23 February 2015). \"Elemental's smart connected toy taps IBM's Watson supercomputer for its brains\". Venture Beat. Archived from the original on 20 May 2015. Retrieved 15 May 2015.^Epstein, Robert (October 2007). \"From Russia With Love: How I got fooled (and somewhat humiliated) by a computer\"(PDF). Scientific American: Mind. pp.\u00a016\u201317. Archived(PDF) from the original on 19 October 2010. Retrieved 9 December 2007.\nPsychologist Robert Epstein reports how he was initially fooled by a chatterbot posing as an attractive girl in a personal ad he answered on a dating website. In the ad, the girl portrayed herself as being in Southern California and then soon revealed, in poor English, that she was actually in Russia. He became suspicious after a couple of months of email exchanges, sent her an email test of gibberish, and she still replied in general terms. The dating website is not named.^Neff, Gina; Nagy, Peter (12 October 2016). \"Automation, Algorithms, and Politics| Talking to Bots: Symbiotic Agency and the Case of Tay\". International Journal of Communication. 10: 17. ISSN\u00a01932-8036.^Bird, Jordan J.; Ekart, Aniko; Faria, Diego R. (June 2018). \"Learning from Interaction: An Intelligent Networked-Based Human-Bot and Bot-Bot Chatbot System\". Advances in Computational Intelligence Systems. Advances in Intelligent Systems and Computing. Vol.\u00a0840 (1st\u00a0ed.). Nottingham, UK: Springer. pp.\u00a0179\u2013190. doi:10.1007/978-3-319-97982-3_15. ISBN\u00a0978-3-319-97982-3. S2CID\u00a052069140.^Temming, Maria (20 November 2018). \"How Twitter bots get people to spread fake news\". Science News. Archived from the original on 27 November 2018. Retrieved 20 November 2018.^Epp, Len (11 May 2016). \"Five Potential Malicious Uses For Chatbots\". Archived from the original on 24 February 2023. Retrieved 24 February 2023.^ abcHasal, Martin; Nowakov\u00e1, Jana; Ahmed Saghair, Khalifa; Abdulla, Hussam; Sn\u00e1\u0161el, V\u00e1clav; Ogiela, Lidia (10 October 2021). \"Chatbots: Security, privacy, data protection, and social aspects\". Concurrency and Computation: Practice and Experience. 33 (19) e6426. doi:10.1002/cpe.6426. hdl:10084/145153. ISSN\u00a01532-0626.^ abcdefgChin, Hyojin; Song, Hyeonho; Baek, Gumhee; Shin, Mingi; Jung, Chani; Cha, Meeyoung; Choi, Junghoi; Cha, Chiyoung (20 October 2023). \"The Potential of Chatbots for Emotional Support and Promoting Mental Well-Being in Different Cultures: Mixed Methods Study\". Journal of Medical Internet Research. 25 e51712. doi:10.2196/51712. ISSN\u00a01438-8871. PMC\u00a010625083. PMID\u00a037862063.^ abcdefghijkHaque, M D Romael; Rubya, Sabirat (22 May 2023). \"An Overview of Chatbot-Based Mobile Mental Health Apps: Insights From App Description and User Reviews\". JMIR mHealth and uHealth. 11 e44838. doi:10.2196/44838. ISSN\u00a02291-5222. PMC\u00a010242473. PMID\u00a037213181.^ abcdefCoghlan, Simon; Leins, Kobi; Sheldrick, Susie; Cheong, Marc; Gooding, Piers; D'Alfonso, Simon (January 2023). \"To chat or bot to chat: Ethical issues with using chatbots in mental health\". Digital Health. 9 20552076231183542. doi:10.1177/20552076231183542. ISSN\u00a02055-2076. PMC\u00a010291862. PMID\u00a037377565.^Harrison Dupr\u00e9, Maggie (28 June 2025). \"People Are Being Involuntarily Committed, Jailed After Spiraling Into \"ChatGPT Psychosis\"\". Futurism. Retrieved 29 June 2025.^Klee, Miles (4 May 2025). \"People Are Losing Loved Ones to AI-Fueled Spiritual Fantasies\". Rolling Stone. Retrieved 29 June 2025.^Hill, Kashmir (13 June 2025). \"They Asked an A.I. Chatbot Questions. The Answers Sent Them Spiraling\". The New York Times. Archived from the original on 28 June 2025. Retrieved 29 June 2025.^Navaluri, Vijay (9 April 2024). \"Chatbots are dead: How generative AI & automation is transforming the way we interact with technology\". The Economic Times. ISSN\u00a00013-0389. Retrieved 25 May 2025.^Stover, Dawn (3 September 2023). \"Will AI make us crazy?\". Bulletin of the Atomic Scientists. 79 (5): 299\u2013303. Bibcode:2023BuAtS..79e.299S. doi:10.1080/00963402.2023.2245247. ISSN\u00a00096-3402.^Hannigan, Timothy R.; McCarthy, Ian P.; Spicer, Andr\u00e9 (20 March 2024). \"Beware of botshit: How to manage the epistemic risks of generative chatbots\". Business Horizons. 67 (5): 471\u2013486. doi:10.1016/j.bushor.2024.03.001. ISSN\u00a00007-6813.^\"Transcript: Ezra Klein Interviews Gary Marcus\". The New York Times. 6 January 2023. ISSN\u00a00362-4331. Retrieved 21 April 2024.^\"ChatGPT took their jobs. Now they walk dogs and fix air conditioners\". The Washington Post. 2 June 2023.^Haugeland, Isabel Kathleen Fornell; F\u00f8lstad, Asbj\u00f8rn; Taylor, Cameron; Bj\u00f8rkli, Cato Alexander (1 May 2022). \"Understanding the user experience of customer service chatbots: An experimental study of chatbot interaction design\". International Journal of Human-Computer Studies. 161 102788. doi:10.1016/j.ijhcs.2022.102788. hdl:10852/104483. ISSN\u00a01071-5819.^\"The Future Belongs to Prompt Engineers\". Inc. 12 March 2024.^\"Is The End of Prompt Engineering Here?\". The Information. 19 November 2024. Retrieved 14 December 2024.^\"AI is poised to drive 160% increase in data center power demand\". Goldman Sachs. 14 May 2024. Retrieved 2 December 2024.^Sreedhar, Nitin (22 October 2023). \"AI and its carbon footprint: How much water does ChatGPT consume?\". Mint Lounge.^Crownhart, Casey. \"AI is an energy hog. This is what it means for climate change\". MIT Technology Review.Further reading[edit]Gertner, Jon. (2023) \"Wikipedia's Moment of Truth: Can the online encyclopedia help teach A.I. chatbots to get their facts right \u2014 without destroying itself in the process?\" New York Times Magazine (18 July 2023) onlineSearle, John (1980), \"Minds, Brains and Programs\", Behavioral and Brain Sciences, 3 (3): 417\u2013457, doi:10.1017/S0140525X00005756, S2CID\u00a055303721Vincent, James, \"Horny Robot Baby Voice: James Vincent on AI chatbots\", London Review of Books, vol. 46, no. 19 (10 October 2024), pp.\u00a029\u201332. \"[AI chatbot] programs are made possible by new technologies but rely on the timelelss human tendency to anthropomorphise.\" (p.\u00a029.)Adamopoulou, Eleni; Moussiades, Lefteris (2020). Maglogiannis, Ilias; Iliadis, Lazaros; Pimenidis, Elias (eds.). \"An Overview of Chatbot Technology\". Artificial Intelligence Applications and Innovations. 584. Cham: Springer: 373\u2013383. doi:10.1007/978-3-030-49186-4_31. PMC\u00a07256567.Ciesla, Robert (2024). The Book of Chatbots: From ELIZA to ChatGPT. Springer Cham. doi:10.1007/978-3-031-51004-5. ISBN\u00a0978-3-031-51004-5.External links[edit]@media screen{html.skin-theme-clientpref-night .mw-parser-output .sister-inline-image img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sister-inline-image img[src*=\"Wiktionary-logo-en-v2.svg\"]{filter:invert(1)brightness(55%)contrast(250%)hue-rotate(180deg)}} Media related to Chatbots at Wikimedia Commons.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteNatural language processingGeneral termsAI-completeBag-of-wordsn-gramBigramTrigramComputational linguisticsNatural language understandingStop wordsText processingText analysisArgument miningCollocation extractionConcept miningCoreference resolutionDeep linguistic processingDistant readingInformation extractionNamed-entity recognitionOntology learningParsingsemanticsyntacticPart-of-speech taggingSemantic analysisSemantic role labelingSemantic decompositionSemantic similaritySentiment analysisTerminology extractionText miningTextual entailmentTruecasingWord-sense disambiguationWord-sense inductionText segmentationCompound-term processingLemmatisationLexical analysisText chunkingStemmingSentence segmentationWord segmentationAutomatic summarizationMulti-document summarizationSentence extractionText simplificationMachine translationComputer-assistedExample-basedRule-basedStatisticalTransfer-basedNeuralDistributional semantics modelsBERTDocument-term matrixExplicit semantic analysisfastTextGloVeLanguage modellargesmallLatent semantic analysisLong short-term memorySeq2seqTransformerWord embeddingWord2vecLanguage resources,datasets and corporaTypes andstandardsCorpus linguisticsLexical resourceLinguistic Linked Open DataMachine-readable dictionaryParallel textPropBankSemantic networkSimple Knowledge Organization SystemSpeech corpusText corpusThesaurus (information retrieval)TreebankUniversal DependenciesDataBabelNetBank of EnglishDBpediaFrameNetGoogle Ngram ViewerUBYWordNetWikidataAutomatic identificationand data captureSpeech recognitionSpeech segmentationSpeech synthesisNatural language generationOptical character recognitionTopic modelDocument classificationLatent Dirichlet allocationPachinko allocationComputer-assistedreviewingAutomated essay scoringConcordancerGrammar checkerPredictive textPronunciation assessmentSpell checkerNatural languageuser interfaceChatbotInteractive fictionQuestion answeringVirtual assistantVoice user interfaceRelatedFormal semanticsHallucinationNatural Language ToolkitspaCy.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesInternationalGNDNationalCzech RepublicLatviaIsrael\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Chatbot&oldid=1319634585\"", "tags": ["en.wikipedia.org", "wiki", "chatbot"]}
{"url": "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "title": null, "text": ".mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}.mw-parser-output .multiple-issues-text{width:95%;margin:0.2em 0}.mw-parser-output .multiple-issues-text>.mw-collapsible-content{margin-top:0.3em}.mw-parser-output .compact-ambox .ambox{border:none;border-collapse:collapse;background-color:transparent;margin:0 0 0 1.6em!important;padding:0!important;width:auto;display:block}body.mediawiki .mw-parser-output .compact-ambox .ambox.mbox-small-left{font-size:100%;width:auto;margin:0}.mw-parser-output .compact-ambox .ambox .mbox-text{padding:0!important;margin:0!important}.mw-parser-output .compact-ambox .ambox .mbox-text-span{display:list-item;line-height:1.5em;list-style-type:disc}body.skin-minerva .mw-parser-output .multiple-issues-text>.mw-collapsible-toggle,.mw-parser-output .compact-ambox .ambox .mbox-image,.mw-parser-output .compact-ambox .ambox .mbox-imageright,.mw-parser-output .compact-ambox .ambox .mbox-empty-cell,.mw-parser-output .compact-ambox .hide-when-compact{display:none}This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these messages)\n      This article's tone or style may not reflect the encyclopedic tone used on Wikipedia. See Wikipedia's guide to writing better articles for suggestions.  (April 2022) (Learn how and when to remove this message)This article may lend undue weight to very obscure AI projects of questionable importance. Please help improve it by rewriting it in a balanced fashion that contextualises different points of view.  (April 2022) (Learn how and when to remove this message)\n     (Learn how and when to remove this message).mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onArtificial intelligence (AI)Major goalsArtificial general intelligenceIntelligent agentRecursive self-improvementPlanningComputer visionGeneral game playingKnowledge representationNatural language processingRoboticsAI safetyApproachesMachine learningSymbolicDeep learningBayesian networksEvolutionary algorithmsHybrid intelligent systemsSystems integrationOpen-sourceApplicationsBioinformaticsDeepfakeEarth sciences Finance Generative AIArtAudioMusicGovernmentHealthcareMental healthIndustrySoftware developmentTranslation Military PhysicsProjectsPhilosophyAI alignmentArtificial consciousnessThe bitter lessonChinese roomFriendly AIEthicsExistential riskTuring testUncanny valleyHistoryTimelineProgressAI winterAI boomAI bubbleControversiesDeepfake pornographyTaylor Swift deepfake pornography controversyGoogle Gemini image generation controversyPause Giant AI ExperimentsRemoval of Sam Altman from OpenAIStatement on AI RiskTay (chatbot)Th\u00e9\u00e2tre D'op\u00e9ra SpatialVoiceverse NFT plagiarism scandalGlossaryGlossary.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteArtificial intelligence is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. Artificial intelligence (AI) has been used in applications throughout industry and academia. Within the field of Artificial Intelligence, there are multiple subfields. The subfield of Machine learning has been used for various scientific and commercial purposes[1] including language translation, image recognition, decision-making,[2][3]credit scoring, and e-commerce. In recent years, there have been massive advancements in the field of Generative Artificial Intelligence, which uses generative models to produce text, images, videos or other forms of data[4]. This article describes applications of AI in different sectors. \nAgriculture[edit].mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}See also: Precision agriculture and Digital agricultureIn agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency.[5] AI has been used to attempt to classify livestock pig call emotions,[6] automate greenhouses,[7] detect diseases and pests,[8] and optimize irrigation.[9]Architecture and design[edit].mw-parser-output .excerpt-hat .mw-editsection-like{font-style:normal}This section is an excerpt from Artificial intelligence in architecture.[edit]A sketch being converted via AI to a 3D mesh of a similar-looking buildingArtificial intelligence in architecture is the use of artificial intelligence in automation, design, and planning in the architectural process or in assisting human skills in the field of architecture.[10]\nAI has been used by some architects for design, and has been proposed as a way to automate planning and routine tasks in the field.[11][12]Business[edit]See also: \u00a7\u00a0ServicesA 2023 study found that generative AI increased productivity by 15% in contact centers.[13] Another 2023 study found it increased productivity by up to 40% in writing tasks.[14] An August 2025 review by MIT found that of surveyed companies, 95% did not report any improvement in revenue from the use of AI.[15] A September 2025 article by the Harvard Business Review describes how increased use of AI does not automatically lead to increases in revenue or actual productivity. Referring to \"AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task\" the article coins the term workslop. Per studies done in collaboration with the Stanford Social Media Lab, workslop does not improve productivity and undermines trust and collaboration among colleagues.[16]Computer science[edit]Programming assistance[edit]See also: Automatic programming and Programming environmentAI-assisted software development[edit]AI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. AI-assisted software development systems differ in functionality, quality, speed, and approach to privacy. Creating software primarily via AI is known as \"vibe coding\". Code created or suggested by AI can be incorrect or inefficient, and should be carefully reviewed by software developers before being accepted.[citation needed] The use of AI-assisted coding can potentially speed-up software development, but can also slow-down the process by creating more work when debugging and testing.[17][18] The rush to prematurely adopt AI technology can also incur additional technical debt.[17] AI also requires additional consideration and careful review for cybersecurity, since AI coding software is trained on a wide range of code of inconsistent quality and often replicates poor practices.[19][20]Neural network design[edit]An overview of AI agent and its core capabilities (memory, tools usage, actions, and ability to plan)AI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.[21]Quantum computing[edit]Further information: Quantum machine learningSee also: \u00a7\u00a0Chemistry and biologyResearch and development of quantum computers has been performed with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications.[22][23] The use of quantum machine learning  for quantum simulators has been proposed for solving physics and chemistry problems.[24][25][better\u00a0source\u00a0needed]Historical contributions[edit]AI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:[26]Time sharingInteractive interpretersGraphical user interfaces and the computer mouseRapid application development environmentsThe linked list data structureAutomatic storage managementSymbolic programmingFunctional programmingDynamic programmingObject-oriented programmingOptical character recognitionConstraint satisfactionCustomer service[edit]Human resources[edit]Main article: Artificial intelligence in hiringAnother application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.[citation needed]Online and telephone customer service[edit]An automated online assistant providing customer service on a web pageAI underlies avatars (automated online assistants) on web pages.[27] It can reduce operation and training costs.[27]Pypestream automated customer service for its mobile application to streamline communication with customers.[28]A Google app analyzes language and converts speech into text.[29] The platform can identify angry customers through their language and respond appropriately.[30] Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative.[31] Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.[32]Hospitality[edit]In the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs.[33] AI hotel services come in the form of a chatbot,[34] application, virtual voice assistant and service robots.\nEducation[edit]See also: AI in educationIn educational institutions, AI has been used to automate routine tasks like attendance tracking, grading and marking. AI tools have been used to attempt to monitor student progress and analyze learning behaviors, with the intention of facilitating interventions for students facing academic problems.[35]Energy and environment[edit]Energy system[edit]The U.S. Department of Energy wrote in an April 2024 report that AI may have applications in modeling power grids, reviewing federal permits with large language models, predicting levels of renewable energy production, and improving the planning process for electrical vehicle charging networks.[36] Other studies have suggested that machine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).[37][38][39][40][41]Environmental monitoring[edit]See also: Climate-smart agricultureAutonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics[42] or remote sensing and other applications of environmental monitoring make use of machine learning.[43][44][45][46]For example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution \u2013 primarily ocean pollution \u2013 by helping identify who and where mismanages plastic waste, dumping it into oceans.[47][48]Early-warning systems[edit]Machine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics,[49][50] earthquakes,[51][52][53] landslides,[54] heavy rainfall,[55] long-term water supply vulnerability,[56] tipping-points of ecosystem collapse,[57]cyanobacterial bloom outbreaks,[58] and droughts.[59][60][61]Economic and social challenges[edit]See also: \u00a7\u00a0Environmental monitoringAI for Good is a platform launched in 2017 by the International Telecommunication Union (ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN's Sustainable Development Goals.[citation needed]The University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.[62]Entertainment and media[edit]Media[edit]See also: \u00a7\u00a0Telecommunications, and Synthetic mediaImage restorationAI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision.\nTypical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement.\nMotion interpolation[63]Pixel-art scaling algorithms[64]Image scaling[65]Image restoration[66][67]Photo colorization[68]Film restoration and video upscaling[69]Photo tagging[70]Automated species identification (such as identifying plants, fungi and animals with an app)Text-to-image models such as DALL-E, Midjourney and Stable DiffusionImage to video[71]Text to video such as Make-A-Video from Meta, Imagen video and Phenaki from GoogleText to music with AI models such as MusicLM[72][73]Text to speech such as ElevenLabs and 15.aiMotion capture[74]Deep-fakes[edit]Deep-fakes can be used for comedic purposes but are better known for fake news and hoaxes.\nDeepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof.[75]In January 2016,[76] the Horizon 2020 program financed the InVID Project[77][78] to help journalists and researchers detect fake documents, made available as browser plugins.[79][80]In June 2016, the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face,[81] a program that animates photographs of faces, mimicking the facial expressions of another person. The technology has been demonstrated animating the faces of people including Barack Obama and Vladimir Putin. Other methods have been demonstrated based on deep neural networks, from which the name deep fake was taken.\nIn September 2018, U.S. Senator Mark Warner proposed to penalize social media companies that allow sharing of deep-fake documents on their platforms.[82]In 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames.[83]DARPA gave 68 million dollars to work on deep-fake detection.[83]Audio deepfakes[84][85] and AI software capable of detecting deep-fakes and cloning human voices have been developed.[86][87]Respeecher is a program that enables one person to speak with the voice of another.\nVideo surveillance analysis and manipulated media detection[edit]See also: Web scraping, Photograph manipulation, and Video manipulationThis section is an excerpt from Video content analysis \u00a7 Artificial Intelligence.[edit]\nArtificial intelligence for video surveillance utilizes computer software programs that analyze the audio and images from video surveillance cameras in order to recognize humans, vehicles, objects and events. Security contractors program is the software to define restricted areas within the camera's view (such as a fenced off area, a parking lot but not the sidewalk or public street outside the lot) and program for times of day (such as after the close of business) for the property being protected by the camera surveillance. The artificial intelligence (\"A.I.\") sends an alert if it detects a trespasser breaking the \"rule\" set that no person is allowed in that area during that time of day.AI algorithms have been used to detect deepfake videos.[88][89]Video production[edit]Artificial intelligence is also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.[90]  Way mark Studios utilized the tools offered by both DALL-E and Mid-journey to create a fully AI generated film called The Frost in the summer of 2023.[90] Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.[90]  Yves Bergquist, a director of the AI & Neuroscience in Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology.[91]Music[edit]Main article: Music and artificial intelligenceAI has been used to compose music of various genres.\nDavid Cope created an AI called Emily Howell that managed to become well known in the field of algorithmic computer music.[92] The algorithm behind Emily Howell is registered as a US patent.[93]In 2012, AI Iamus created the first complete classical album.[94]AIVA (Artificial Intelligence Virtual Artist), composes symphonic music, mainly classical music for film scores.[95] It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association.[96]Melomics creates computer-generated music for stress and pain relief.[97]At Sony CSL Research Laboratory, the Flow Machines software creates pop songs by learning music styles from a huge database of songs. It can compose in multiple styles.\nThe Watson Beat uses reinforcement learning and deep belief networks to compose music on a simple seed input melody and a select style. The software was open sourced[98] and musicians such as Taryn Southern[99] collaborated with the project to create music.\nSouth Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO.[100]Writing and reporting[edit]See also: \u00a7\u00a0Web feeds and postsNarrative Science sells computer-generated news and reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses.[101]Automated Insights generates personalized recaps and previews for Yahoo SportsFantasy Football.[102]Yseop, uses AI to turn structured data into natural language comments and recommendations. Yseop writes financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German.[103]TALESPIN made up stories similar to the fables of Aesop. The program started with a set of characters who wanted to achieve certain goals. The story narrated their attempts to satisfy these goals.[citation needed] Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\".[104]While AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such as Little Red Riding Hood.[105] In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.[106]South Korean company Hanteo Global uses a journalism bot to write articles.[107]Literary authors are also exploring uses of AI. An example is David Jhave Johnston's work ReRites (2017\u20132019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications.\nSports writing[edit]In 2010, artificial intelligence used baseball statistics to automatically generate news articles. This was launched by The Big Ten Network using software from Narrative Science.[108]After being unable to cover every Minor League Baseball game with a large team, Associated Press collaborated with Automated Insights in 2016 to create game recaps that were automated by artificial intelligence.[109]UOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words on Google.[109]El Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use the Perspective API to moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it.[109]A local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team.[109]Lede AI has been used in 2023 to take scores from high school football games to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company, Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment.[110]Wikipedia[edit]This section is an excerpt from Artificial intelligence in Wikimedia projects.[edit]AI-generated draft article getting nominated for speedy deletion under G15 criteriaArtificial intelligence is used in Wikimedia projects for the purpose of developing those projects.[111] \nVarious articles on Wikipedia have been created entirely with or with the help of artificial intelligence. AI-generated content can be detrimental to Wikipedia when unreliable or containing fake citations.\n\nTo address the issue of low-quality AI-generated content, the Wikipedia community created in 2023 a WikiProject named AI Cleanup. In August 2025, Wikipedia adopted a policy that allowed editors to nominate suspected AI-generated articles for speedy deletion. Millions of its articles have been edited by bots[112] which however are usually not artificial intelligence software. Many AI platforms use Wikipedia data,[113] mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences,[114]detecting covert vandalism[115] or recommending articles and tasks to new editors.\nMachine translation .mw-parser-output div.crossreference{padding-left:0}(see above) has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages.[116][117]Video games[edit]Main article: Artificial intelligence in video gamesSee also: Video game bot and Artificial intelligence in video gamesIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010).[118][119] AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.[120]Games have been a major application[relevant?] of AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson),[121]Go (AlphaGo),[122][123][124][125][126][127][128]poker (Pluribus[129] and Cepheus),[130]E-sports (StarCraft),[131][132] and general game playing (AlphaZero[133][134][135] and MuZero).[136][137][138][139]Kuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool.[140][141]Character.ai is another example of a chatbot being used for recreation.[citation needed]Visual images[edit]A \"cyborg elf\" generated by Stable DiffusionMain article: Artificial intelligence artThe first AI art program, called AARON, was developed by Harold Cohen in 1968[142] with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen.[143]AI platforms such as DALL-E,[144]Stable Diffusion,[144]Imagen,[145] and Midjourney[146] have been used for generating visual images from inputs such as text or other images.[147] Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches.\nAI has been used to generate quantitative analysis of existing digital art collections.[148]\nTwo computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art.[149] While distant viewing includes the analysis of large collections, close reading involves one piece of artwork.\nComputer animation[edit]Pixar began experimenting with a machine learning project called \"Genesis\" in the early 2000s. It was designed to learn algorithms and create 3D models for its characters and props.[citation needed] \nIn 2023, Netflix of Japan's usage of AI to generate background images for short The Dog & the Boy was met with backlash online.[150]Finance[edit]Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking began in 1987 when Security Pacific National Bank launched a fraud prevention task-force to counter the unauthorized use of debit cards.[151]Banks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours.[152]AI is used to combat fraud and financial crimes by monitoring behavioral patterns for any abnormal changes or anomalies.[153][154][155]The use of AI in applications such as online trading and decision-making has changed major economic theories.[156] For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualized pricing. AI systems reduce information asymmetry in the market and thus make markets more efficient.[157] The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises.[158]Trading and investment[edit]Algorithmic trading involves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Such high-frequency trading represents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios. Automated trading systems are typically used by large institutional investors but include smaller firms trading with their own AI systems.[159]Large financial institutions use AI to assist with their investment practices.[160]BlackRock's AI engine, Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use of natural language processing to analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them with wealth management products.[161]Underwriting[edit]Online lender Upstart uses machine learning for underwriting.[162]ZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting.[163] This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.[164]Audit[edit]AI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration.[165][quantify]Continuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making.[166]Anti\u2013money laundering[edit]AI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used for anti\u2013money laundering (AML).[167][168]Anti\u2013money laundering\nCollections and Account Receivables[edit]In recent years, the debt collection industry has begun to adopt AI-driven \"agents\" to automate routine outreach and negotiation tasks. Platforms use natural-language processing and machine learning to interact with consumers.\nProponents claim these systems can handle high volumes of standard enquiries, freeing human collectors to focus on more complex cases, while delivering more consistent, 24/7 service. However, critics warn of potential compliance pitfalls, such as the risk of unintended bias in algorithmic decision-making.[169]History[edit]In the 1980s, AI started to become prominent in finance as expert systems were commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year.[170] One of the first systems was the Pro-trader expert system that predicted the 87-point drop in the Dow Jones Industrial Average in 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\"[171]One of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people.[172]In the 1990s, AI was applied to fraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases of money laundering equal to $1 billion.[173] These expert systems were later replaced by machine learning systems.[174]Outside finance, the late 1980s and early 1990s also saw expert systems used in technical and environmental domains. For example, researchers built a fishway design advisor to recommend fish passage structures under varying hydraulic and biological conditions using the VP-Expert shell.[175] Transportation researchers applied the same shell to balance airport capacity with noise-mitigation plans.[176] In agriculture, a potato insect expert system (PIES) supported pest management decisions for Colorado potato beetle.[177] The U.S. Environmental Protection Agency\u2019s CORMIX system for modeling pollutant discharges combined rules with Fortran hydrodynamic models.[178]AI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI.[179]Regulatory developments in the EU[edit]In the European Union, the Artificial Intelligence Act (Regulation\u202f(EU)\u202f2024/1689) classifies several finance\u2011sector uses of AI as \"high\u2011risk\", including systems used to evaluate the creditworthiness of natural persons or to establish a credit score and AI used for risk assessment and pricing in life or health insurance.[180][181][182] These systems must meet requirements on risk management, data governance, technical documentation and logging, transparency, and human oversight.[181][183]The Act's obligations are phased in: prohibitions and AI\u2011literacy rules apply from 2\u202fFebruary\u202f2025, governance and most GPAI duties from 2\u202fAugust\u202f2025, the bulk of obligations from 2\u202fAugust\u202f2026, and certain safety\u2011component high\u2011risk obligations from 2\u202fAugust\u202f2027.[182]Health[edit]Healthcare[edit]Main article: Artificial intelligence in healthcareX-ray of a hand, with automatic calculation of bone age by a computer softwareA patient-side surgical arm of Da Vinci Surgical SystemAI in healthcare is often used for classification, to evaluate a CT scan or electrocardiogram or to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16\u00a0billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients.[184] Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry.[185]The early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem.[186] Microsoft's AI project Hanover helps doctors choose cancer treatments from among the more than 800 medicines and vaccines.[187][188] Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient. Myeloid leukemia is one target. Another study reported on an AI that was as good as doctors in identifying skin cancers.[189] Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions.[190] In one study done with transfer learning, an AI diagnosed eye conditions similar to an ophthalmologist and recommended treatment referrals.[191]Another study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon.[192]Artificial neural networks are used as clinical decision support systems for medical diagnosis,[193] such as in concept processing technology in EMR software.\nOther healthcare tasks thought suitable for an AI that are in development include:\nScreening[194]Companion robots for elder care[195]Drug creation[196] (e.g. by identifying candidate drugs[197] and by using existing drug screening data such as in life extension research)[198]Clinical training[199]Identifying genomic pathogen signatures of novel pathogens[200] or identifying pathogens via physics-based fingerprints[201] (including pandemic pathogens)Helping link genes to their functions,[202] otherwise analyzing genes[203] and identification of novel biological targets[204]Help development of biomarkers[204]Help tailor therapies to individuals in personalized medicine/precision medicine[204][205]Workplace health and safety[edit]Main article: Workplace impact of artificial intelligence \u00a7\u00a0Health and safety applicationsAI-enabled chatbots decrease the need for humans to perform basic call center tasks, and machine learning in sentiment analysis can spot fatigue in order to prevent overwork.[206]Decision support systems can potentially prevent industrial disasters and make disaster response more efficient.[207] For manual workers in material handling, predictive analytics has been proposed to reduce musculoskeletal injury.[208] \nAI can attempt to process workers' compensation claims.[209][210] AI has been proposed for detection of accident near misses, which are underreported.[211]Biochemistry[edit]Machine learning has been used for drug design,[41]drug discovery and development, drug repurposing, improving pharmaceutical productivity, and clinical trials.[212]Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\",[213] has been used in drug-syntheses, and developing routes for recycling 200 industrial waste chemicals into important drugs and agrochemicals (chemical synthesis design).[214] It has also been used to explore the origins of life on Earth.[215] \nDeep learning has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene, DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results.[216]The AI program AlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).[217][218][219][220]Language processing[edit]Language translation[edit]Main article: Machine translationSpeech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another.[221]AI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator.[222] Additionally, research and development are in progress to decode and conduct animal communication.[6][223]Meaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.[224]Law and government[edit]Government[edit]Main article: Artificial intelligence in governmentAI facial recognition systems are used for mass surveillance, notably in China.[225][226] In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.[227]Law[edit]Main article: Legal informatics \u00a7\u00a0Artificial intelligenceLegal analysis[edit]AI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers.[228] While its use is common, it is not expected to replace most work done by lawyers in the near future.[229]The electronic discovery industry uses machine learning to reduce manual searching.[230]Law enforcement and legal proceedings[edit]Law enforcement has begun using facial recognition systems (FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants.[231]COMPAS is a commercial system used by U.S. courts to assess the likelihood of recidivism.[232]One concern relates to algorithmic bias, AI programs may become biased after processing data that exhibits bias.[233]ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants.[232]In 2019, the city of Hangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-related intellectual property claims.[234]:\u200a124\u200a Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards.[234]:\u200a124\u200aManufacturing[edit]Main articles: Artificial intelligence in industry and Artificial intelligence in heavy industrySensors[edit]Artificial intelligence has been combined with digital spectrometry by IdeaCuria Inc.,[235][236] enable applications such as at-home water quality monitoring.\nToys and games[edit]In the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.[237]Oil and gas[edit]Oil and gas companies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output.[238][239]Military[edit]Main article: Military applications of artificial intelligenceVarious countries are deploying AI military applications.[240] The main applications enhance command and control, communications, sensors, integration and interoperability.[citation needed] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[240] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both piloted and autonomous.[citation needed]AI has been used in military operations in Iraq, Syria, Israel and Ukraine.[240][241][242][243]Internet and e-commerce[edit]Main article: Marketing and artificial intelligenceWeb feeds and posts[edit]Machine learning has been used for recommendation systems in determining which posts should show up in social media feeds.[244][245] Various types of social media analysis also make use of machine learning[246][247] and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.[248][249][250]AI has been used to customize shopping options and personalize offers.[251]Online gambling companies have used AI for targeting gamblers.[252]Virtual assistants and search[edit]Main article: Virtual assistantIntelligent personal assistants use AI to attempt to respond to natural language requests. Siri, released in 2010 for Apple smartphones, popularized the concept.[253]Bing Chat has used artificial intelligence as part of its search engine.[254]Spam filtering[edit]Main article: Spam filterMachine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements.[255] Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails.[256] These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.[257]Facial recognition and image labeling[edit]Main articles: Automatic image annotation and Artificial intelligence for video surveillanceAI has been used in facial recognition systems. Some examples are Apple's Face ID and Android's Face Unlock, which are used to secure mobile devices.[258] \nChina has used facial recognition and artificial intelligence technology in Xinjiang. In 2017, reporters visiting the region found surveillance cameras installed every hundred meters or so in several cities, as well as facial recognition checkpoints at areas like gas stations, shopping centers, and mosque entrances.[259][260] Human rights groups have criticized the Chinese government for using artificial intelligence facial recognition technology for use in political suppression.[261][262]The Netherlands has deployed facial recognition and artificial intelligence technology since 2016.[263] The database of the Dutch police currently contains over 2.2\u00a0million pictures of 1.3\u00a0million Dutch citizens. This accounts for about 8% of the population. In The Netherlands, face recognition is not used by the police on municipal CCTV.[264]Image labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people.[222] Facebook's DeepFace identifies human faces in digital images.[citation needed]Scientific research[edit]Evidence of general impacts[edit]In April 2024, the Scientific Advice Mechanism to the European Commission published advice[265] including a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research.\nAs benefits, the evidence review[266] highlighted:\nits role in accelerating research and innovationits capacity to automate workflowsenhancing dissemination of scientific workAs challenges:\nlimitations and risks around transparency, reproducibility and interpretabilitypoor performance (inaccuracy)risk of harm through misuse or unintended usesocietal concerns including the spread of misinformation and increasing inequalitiesArchaeology, history and imaging of sites[edit]See also: Digital archaeologyMachine learning can help to restore and attribute ancient texts.[267] It can help to index texts for example to enable better and easier searching and classification of fragments.[268]\nArtificial intelligence can also be used to investigate genomes to uncover genetic history, such as interbreeding between archaic and modern humans by which for example the past existence of a ghost population, not Neanderthal or Denisovan, was inferred.[269]Further information: Ancient DNA \u00a7\u00a0Human aDNA, and Genetic history of Europe\nIt can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\".[270]Further information: Remote sensing in archaeologyPhysics[edit]Main article: Machine learning in physicsA deep learning system was reported to learn intuitive physics from visual data (of virtual 3D environments) based on an unpublished approach inspired by studies of visual cognition in infants.[271][272] Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.[273][274] In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.[273]Materials science[edit]In November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that the AI system GNoME had documented over 2 million new materials. GNoME uses deep learning techniques to examine potential material structures, and identify stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, with a success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database.[275][276][277]Reverse engineering[edit]Machine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts,[278] and for quickly understanding the behavior of malware.[279][280][281] It can be used to reverse engineer artificial intelligence models.[282] It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality[283] or protein design for pre-specified functional sites.[284][285] Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.[286]Astronomy, space activities and ufology[edit]See also: \u00a7\u00a0Novel types of machine learningArtificial intelligence is used in astronomy to analyze increasing amounts of available data[287][288] and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy.[289] It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance,[290] and more autonomous operation.[291][292][46][288]In the search for extraterrestrial intelligence (SETI), machine learning has been used in attempts to identify artificially generated electromagnetic waves in available data[293][294] \u2013 such as real-time observations[295] \u2013 and other technosignatures, e.g. via anomaly detection.[296] In ufology, the SkyCAM-5 project headed by Prof. Hakan Kayal[297] and the Galileo Project headed by Avi Loeb use machine learning to attempt to detect and classify types of UFOs.[298][299][300][301][302] The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI: 'Oumuamua-like interstellar objects, and non-manmade artificial satellites.[303][304]Machine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals \u2013 such as phosphine possibly detected on Venus \u2013 which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets.[305]Chemistry and biology[edit]See also: \u00a7\u00a0Health, \u00a7\u00a0Quantum computing, and Computational chemistry \u00a7\u00a0ApplicationsThere is research about which types of computer-aided chemistry would benefit from machine learning.[306] \nA deep learning AI-based process has been developed that uses genome databases to design novel proteins based on evolutionary algorithms.[307][308]\nMachine learning has also been used for protein design with pre-specified functional sites,[284][285] predicting molecular properties, and exploring large chemical/reaction spaces.[309]Using drug discovery AI algorithms, researchers generated 40,000 potential chemical weapon candidates, helping in the regulation of such chemicals to prevent synthesizing them for real harm.[310][311][312]There are various types of applications for machine learning in decoding human biology, such as helping to map gene expression patterns to functional activation patterns[313] or identifying functional DNA motifs.[314] It is widely used in genetic research.[315]\nThere also is some use of machine learning in synthetic biology,[316][317] disease biology,[317] nanotechnology (e.g. nanostructured materials and bionanotechnology),[318][319] and materials science.[320][321][322]Security and surveillance[edit]Cyber security[edit]Cyber security companies are adopting neural networks, machine learning, and natural language processing to improve their systems.[323]Applications of AI in cyber security include:\nNetwork protection: Machine learning improves intrusion detection systems by broadening the search beyond previously identified threats.[324]Endpoint protection: Attacks such as ransomware can be thwarted by learning typical malware behaviors.\nAI-related cyber security application cases vary in both benefit and complexity. Security features such as Security Orchestration, Automation, and Response (SOAR) and Extended Endpoint Detection and Response (XDR) offer significant benefits for businesses, but require significant integration and adaptation efforts.[325]Application security: can help counterattacks such as server-side request forgery, SQL injection, cross-site scripting, and distributed denial-of-service.\nAI technology can also be utilized to improve system security and safeguard our privacy. Randrianasolo (2012) suggested a security system based on artificial intelligence that can recognize intrusions and adapt to perform better.[326] In order to improve cloud computing security, Sahil (2015) created a user profile system for the cloud environment with AI techniques.[327]Suspect user behavior: Machine learning can identify fraud or compromised applications as they occur.[328]Transportation and logistics[edit]Automotive and public transit[edit]Main articles: Vehicular automation, Self-driving car, and Smart traffic lightSide view of a Waymo-branded self-driving carTransportation's complexity means that in most cases, training an AI in a real-world driving environment is impractical, and is achieved through simulator-based testing.[329] AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.[330] AI-based fuzzy logic controllers operate gearboxes. AI-based driver-assist systems include features such as self-parking and adaptive cruise control.[citation needed]Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals).[331][332]There are prototypes of autonomous automotive public transport vehicles such as autonomous rail transport in operation,[333][334][335] electric mini-buses,[336][337][338] and autonomous delivery vehicles,[339][340][332] including delivery robots.[341][342]Autonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018.[343] A group of autonomous trucks follow closely behind each other. German corporation Daimler is testing its Freightliner Inspiration.[344]AI has been used to optimize traffic management, which can reduce wait times, energy use, and emissions.[345].mw-parser-output .tmulti .multiimageinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .tmulti .multiimageinner span:not(.skin-invert-image):not(.skin-invert):not(.bg-transparent) img{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .tmulti .multiimageinner span:not(.skin-invert-image):not(.skin-invert):not(.bg-transparent) img{background-color:white}}Cameras with radar and ultrasonic acoustic location sensors, while using predictive algorithms to have artificially intelligent traffic lights to make traffic flow betterMilitary[edit]Aircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated.\nAI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or in swarms.[346]AOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information from TF-30 documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the F-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers.\nSpeech recognition allows traffic controllers to give verbal directions to drones.\nArtificial intelligence supported design of aircraft,[347] or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective.\nNASA[edit]In 2003 a Dryden Flight Research Center project created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved.[348] The software compensated for damaged components by relying on the remaining undamaged components.[349]The 2016 Intelligent Autopilot System combined apprenticeship learning and behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions.[350]Maritime[edit]Neural networks are used by situational awareness systems in ships and boats.[351] There also are autonomous boats.\nSee also[edit]Applications of artificial intelligence to legal informaticsApplications of deep learningApplications of machine learningArtificial intelligence and electionsCollective intelligence \u00a7\u00a0ApplicationsList of artificial intelligence projectsList of datasets for machine-learning researchOpen dataProgress in artificial intelligenceTimeline of computing 2020\u2013presentFootnotes[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Brynjolfsson, Erik; Mitchell, Tom (22 December 2017). \"What can machine learning do? Workforce implications\". Science. 358 (6370): 1530\u20131534. Bibcode:2017Sci...358.1530B. doi:10.1126/science.aap8062. PMID\u00a029269459.^Shin, Minkyu; Kim, Jin; van Opheusden, Bas; Griffiths, Thomas L. (2023). \"Superhuman artificial intelligence can improve human decision-making by increasing novelty\". Proceedings of the National Academy of Sciences. 120 (12) e2214840120. arXiv:2303.07462. Bibcode:2023PNAS..12014840S. doi:10.1073/pnas.2214840120. PMC\u00a010041097. PMID\u00a036913582.^Chen, Yiting; Liu, Tracy Xiao; Shan, You; Zhong, Songfa (2023). \"The emergence of economic rationality of GPT\". Proceedings of the National Academy of Sciences. 120 (51) e2316205120. arXiv:2305.12763. Bibcode:2023PNAS..12016205C. doi:10.1073/pnas.2316205120. PMC\u00a010740389. PMID\u00a038085780.^\"What is Generative AI? | IBM\". www.ibm.com. 2024-03-22. Retrieved 2025-07-22.^Gambhire, Akshaya; Shaikh Mohammad, Bilal N. (8 April 2020). Use of Artificial Intelligence in Agriculture. Proceedings of the 3rd International Conference on Advances in Science & Technology (ICAST) 2020. SSRN\u00a03571733.^ abBriefer, Elodie F.; Sypherd, Ciara C.-R.; Linhart, Pavel; Leliveld, Lisette M. C.; Padilla de la Torre, Monica; Read, Eva R.; Gu\u00e9rin, Carole; Deiss, V\u00e9ronique; Monestier, Chlo\u00e9; Rasmussen, Jeppe H.; \u0160pinka, Marek; D\u00fcpjan, Sandra; Boissy, Alain; Janczak, Andrew M.; Hillmann, Edna; Tallet, C\u00e9line (7 March 2022). \"Classification of pig calls produced from birth to slaughter according to their emotional valence and context of production\". Scientific Reports. 12 (1): 3409. Bibcode:2022NatSR..12.3409B. doi:10.1038/s41598-022-07174-8. PMC\u00a08901661. PMID\u00a035256620.^Moreno Mill\u00e1n, M; Sevilla Guzm\u00e1n, E; Demyda, S E (2011). \"Population, Poverty, Production, Food Security, Food Sovereignty, Biotechnology and Sustainable Development: Challenges for the XXI Century\". Bulletin of University of Agricultural Sciences and Veterinary Medicine Cluj-Napoca. Veterinary Medicine. 1 (68).^Liundi, Nicholas; Darma, Aditya Wirya; Gunarso, Rivaldi; Warnars, Harco Leslie Hendric Spits (2019). \"Improving Rice Productivity in Indonesia with Artificial Intelligence\". 2019 7th International Conference on Cyber and IT Service Management (CITSM). pp.\u00a01\u20135. doi:10.1109/CITSM47753.2019.8965385. ISBN\u00a0978-1-7281-2909-9.^Talaviya, Tanha; Shah, Dhara; Patel, Nivedita; Yagnik, Hiteshri; Shah, Manan (2020). \"Implementation of artificial intelligence in agriculture for optimisation of irrigation and application of pesticides and herbicides\". Artificial Intelligence in Agriculture. 4: 58\u201373. doi:10.1016/j.aiia.2020.04.002.^Bernstein, Phillip (2022). Machine Learning: Architecture in the Age of Artificial Intelligence. London: RIBA Publishing. ISBN\u00a0978-1-914124-01-3.^Heathcote, Edwin (20 January 2024). \"AI is coming for architecture\". Financial Times. Retrieved 2024-02-07.^\"Will Artificial Intelligence Replace Architects?\". ArchDaily. 2023-10-18. Retrieved 2024-02-07.^Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey (2025-02-04). \"Generative AI at Work\". The Quarterly Journal of Economics. 140 (2): 889\u2013942. doi:10.1093/qje/qjae044. ISSN\u00a00033-5533. Archived from the original on 2025-06-05.^Noy, Shakked; Zhang, Whitney (2023-07-14). \"Experimental evidence on the productivity effects of generative artificial intelligence\". Science. 381 (6654): 187\u2013192. Bibcode:2023Sci...381..187N. doi:10.1126/science.adh2586. PMID\u00a037440646.^Estrada, Sheryl (18 August 2025). \"MIT report: 95% of generative AI pilots at companies are failing\". Fortune. Retrieved 15 October 2025.^Niederhoffer, Kate; Kellerman, Gabriella Rosen; Lee, Angela; Liebscher, Alex; Rapuano, Kristina; Hancock, Jeffrey T. (22 September 2025). \"AI-Generated \"Workslop\" Is Destroying Productivity\". Harvard Business Review. Retrieved 15 October 2025.^ abNickelsburg, Monica (1 October 2025). \"The human coders hired to mop up AI slop\". www.kuow.org. NPR. Retrieved 25 October 2025.^Davis, Dominic-Madori (14 September 2025). \"Vibe coding has turned senior devs into 'AI babysitters,' but they say it's worth it\". TechCrunch. Retrieved 25 October 2025.^Newman, Lily Hay. \"Vibe Coding Is the New Open Source\u2014in the Worst Way Possible\". Wired. Retrieved 25 October 2025.^Tangermann, Victor (31 May 2025). \"Companies Are Discovering a Grim Problem With \"Vibe Coding\"\". Futurism. Retrieved 25 October 2025.^\"Google AI creates its own \"child\" bot\". The Independent. 5 December 2017. Retrieved 5 February 2018.^Spagnolo, Michele; Morris, Joshua; Piacentini, Simone; Antesberger, Michael; Massa, Francesco; Crespi, Andrea; Ceccarelli, Francesco; Osellame, Roberto; Walther, Philip (April 2022). \"Experimental photonic quantum memristor\". Nature Photonics. 16 (4): 318\u2013323. arXiv:2105.04867. Bibcode:2022NaPho..16..318S. doi:10.1038/s41566-022-00973-5.^Ramanathan, Shriram (July 2018). \"Quantum materials for brain sciences and artificial intelligence\". MRS Bulletin. 43 (7): 534\u2013540. Bibcode:2018MRSBu..43..534R. doi:10.1557/mrs.2018.147.^\"Artificial intelligence makes accurate quantum chemical simulations more affordable\". Nature Portfolio Chemistry Community. 2 December 2021. Retrieved 30 May 2022.^Guan, Wen; Perdue, Gabriel; Pesah, Arthur; Schuld, Maria; Terashi, Koji; Vallecorsa, Sofia; Vlimant, Jean-Roch (March 2021). \"Quantum machine learning in high energy physics\". Machine Learning: Science and Technology. 2 (1): 011003. arXiv:2005.08582. doi:10.1088/2632-2153/abc17d.^Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\u00a0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\u00a00-13-790395-2^ abKongthon, Alisa; Sangkeettrakarn, Chatchawal; Kongyoung, Sarawoot; Haruechaiyasak, Choochart (2009). \"Implementing an online help desk system based on conversational agent\". Proceedings of the International Conference on Management of Emergent Digital EcoSystems. pp.\u00a0450\u2013451. doi:10.1145/1643823.1643908. ISBN\u00a0978-1-60558-829-2.^Sara Ashley O'Brien (12 January 2016). \"Is this app the call center of the future?\". CNN. Retrieved 26 September 2016.^\"Using Google AI to convert speech to text\". Google Cloud. Retrieved 2025-09-07.^Clark, Jack (20 July 2016). \"New Google AI Brings Automation to Customer Service\". Bloomberg.com.^\"Amazon.com tests customer service chatbots\". Amazon Science. 25 February 2020. Retrieved 23 April 2021.^Malatya Turgut Ozal University, Malatya, Turkey; Isguzar, Seda; Fendoglu, Eda; Malatya Turgut Ozal University, Malatya, Turkey; SimSek, Ahmed Ihsan (May 2024). \"Innovative Applications in Businesses: An Evaluation on Generative Artificial Intelligence\"(PDF). Amfiteatru Economic. 26 (66): 511. doi:10.24818/EA/2024/66/511. Retrieved 13 June 2024.{{cite journal}}:  CS1 maint: multiple names: authors list (link)^\"Advanced analytics in hospitality\". McKinsey & Company. 2017. Retrieved 14 January 2020.^Zlatanov, Sonja; Popesku, Jovan (2019). \"Current Applications of Artificial Intelligence in Tourism and Hospitality\". Proceedings of the International Scientific Conference - Sinteza 2019. pp.\u00a084\u201390. doi:10.15308/Sinteza-2019-84-90. ISBN\u00a0978-86-7912-703-7.^\"The promises and perils of new technologies to improve education and employment opportunities\". Brookings. Retrieved 2024-04-20.^\"Role of AI in Energy\". DOE.^Bourhnane, Safae; Abid, Mohamed Riduan; Lghoul, Rachid; Zine-Dine, Khalid; Elkamoun, Najib; Benhaddou, Driss (30 January 2020). \"Machine learning for energy consumption prediction and scheduling in smart buildings\". SN Applied Sciences. 2 (2): 297. doi:10.1007/s42452-020-2024-9.^Kanwal, Sidra; Khan, Bilal; Muhammad Ali, Sahibzada (February 2021). \"Machine learning based weighted scheduling scheme for active power control of hybrid microgrid\". International Journal of Electrical Power & Energy Systems. 125 106461. Bibcode:2021IJEPE.12506461K. doi:10.1016/j.ijepes.2020.106461.^Mohanty, Prasanta Kumar; Jena, Premalata; Padhy, Narayana Prasad (2020). \"Home Electric Vehicle Charge Scheduling Using Machine Learning Technique\". 2020 IEEE International Conference on Power Systems Technology (POWERCON). pp.\u00a01\u20135. doi:10.1109/POWERCON48463.2020.9230627. ISBN\u00a0978-1-7281-6350-5.^Foster, Isabella (15 March 2021). \"Making Smart Grids Smarter with Machine Learning\". EIT | Engineering Institute of Technology. Retrieved 3 July 2022.^ abCiaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. p.\u00a0211. ISBN\u00a0978-88-947876-0-3.^Williams, Ben; Lamont, Timothy A. C.; Chapuis, Lucille; Harding, Harry R.; May, Eleanor B.; Prasetya, Mochyudho E.; Seraphim, Marie J.; Jompa, Jamaluddin; Smith, David J.; Janetski, Noel; Radford, Andrew N.; Simpson, Stephen D. (July 2022). \"Enhancing automated analysis of marine soundscapes using ecoacoustic indices and machine learning\". Ecological Indicators. 140 108986. Bibcode:2022EcInd.14008986W. doi:10.1016/j.ecolind.2022.108986. hdl:10871/129693.^Hino, M.; Benami, E.; Brooks, N. (October 2018). \"Machine learning for environmental monitoring\". Nature Sustainability. 1 (10): 583\u2013588. Bibcode:2018NatSu...1..583H. doi:10.1038/s41893-018-0142-9.^\"How machine learning can help environmental regulators\". Stanford News. Stanford University. 8 April 2019. Retrieved 29 May 2022.^\"AI empowers environmental regulators\". Stanford News. Stanford University. 19 April 2021. Retrieved 29 May 2022.^ ab\"Artificial intelligence in space\". www.esa.int. Retrieved 30 May 2022.^Frost, Rosie (9 May 2022). \"Plastic waste can now be found and monitored from space\". euronews. Retrieved 24 June 2022.^\"Global Plastic Watch\". www.globalplasticwatch.org. Retrieved 24 June 2022.^\"AI may predict the next virus to jump from animals to humans\". Public Library of Science. Retrieved 19 October 2021.^Mollentze, Nardus; Babayan, Simon A.; Streicker, Daniel G. (28 September 2021). \"Identifying and prioritizing potential human-infecting viruses from their genome sequences\". PLOS Biology. 19 (9) e3001390. doi:10.1371/journal.pbio.3001390. PMC\u00a08478193. PMID\u00a034582436.^Li, Zefeng; Meier, Men-Andrin; Hauksson, Egill; Zhan, Zhongwen; Andrews, Jennifer (28 May 2018). \"Machine Learning Seismic Wave Discrimination: Application to Earthquake Early Warning\". Geophysical Research Letters. 45 (10): 4773\u20134779. Bibcode:2018GeoRL..45.4773L. doi:10.1029/2018GL077870.^\"Machine learning and gravity signals could rapidly detect big earthquakes\". Science News. 11 May 2022. Retrieved 3 July 2022.^Fauvel, Kevin; Balouek-Thomert, Daniel; Melgar, Diego; Silva, Pedro; Simonet, Anthony; Antoniu, Gabriel; Costan, Alexandru; Masson, V\u00e9ronique; Parashar, Manish; Rodero, Ivan; Termier, Alexandre (3 April 2020). \"A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning\". Proceedings of the AAAI Conference on Artificial Intelligence. 34 (1): 403\u2013411. doi:10.1609/aaai.v34i01.5376.^Thirugnanam, Hemalatha; Ramesh, Maneesha Vinodini; Rangan, Venkat P. (September 2020). \"Enhancing the reliability of landslide early warning systems by machine learning\". Landslides. 17 (9): 2231\u20132246. Bibcode:2020Lands..17.2231T. doi:10.1007/s10346-020-01453-z.^Moon, Seung-Hyun; Kim, Yong-Hyuk; Lee, Yong Hee; Moon, Byung-Ro (2019). \"Application of machine learning to an early warning system for very short-term heavy rainfall\". Journal of Hydrology. 568: 1042\u20131054. Bibcode:2019JHyd..568.1042M. doi:10.1016/j.jhydrol.2018.11.060.^Robinson, Bethany; Cohen, Jonathan S.; Herman, Jonathan D. (September 2020). \"Detecting early warning signals of long-term water supply vulnerability using machine learning\". Environmental Modelling & Software. 131 104781. Bibcode:2020EnvMS.13104781R. doi:10.1016/j.envsoft.2020.104781.^Bury, Thomas M.; Sujith, R. I.; Pavithran, Induja; Scheffer, Marten; Lenton, Timothy M.; Anand, Madhur; Bauch, Chris T. (28 September 2021). \"Deep learning for early warning signals of tipping points\". Proceedings of the National Academy of Sciences. 118 (39) e2106140118. Bibcode:2021PNAS..11806140B. doi:10.1073/pnas.2106140118. PMC\u00a08488604. PMID\u00a034544867.^Park, Yongeun; Lee, Han Kyu; Shin, Jae-Ki; Chon, Kangmin; Kim, SungHwan; Cho, Kyung Hwa; Kim, Jin Hwi; Baek, Sang-Soo (15 June 2021). \"A machine learning approach for early warning of cyanobacterial bloom outbreaks in a freshwater reservoir\". Journal of Environmental Management. 288 112415. Bibcode:2021JEnvM.28812415P. doi:10.1016/j.jenvman.2021.112415. PMID\u00a033774562.^Li, Jun; Wang, Zhaoli; Wu, Xushu; Xu, Chong-Yu; Guo, Shenglian; Chen, Xiaohong; Zhang, Zhenxing (August 2021). \"Robust Meteorological Drought Prediction Using Antecedent SST Fluctuations and Machine Learning\". Water Resources Research. 57 (8) e2020WR029413. Bibcode:2021WRR....5729413L. doi:10.1029/2020WR029413. hdl:10852/92935.^Khan, Najeebullah; Sachindra, D. A.; Shahid, Shamsuddin; Ahmed, Kamal; Shiru, Mohammed Sanusi; Nawaz, Nadeem (May 2020). \"Prediction of droughts over Pakistan using machine learning algorithms\". Advances in Water Resources. 139 103562. Bibcode:2020AdWR..13903562K. doi:10.1016/j.advwatres.2020.103562.^Kaur, Amandeep; Sood, Sandeep K. (May 2020). \"Deep learning based drought assessment and prediction framework\". Ecological Informatics. 57 101067. Bibcode:2020EcInf..5701067K. doi:10.1016/j.ecoinf.2020.101067.^Preparing for the future of artificial intelligence. National Science and Technology Council. p.\u00a014. OCLC\u00a0965620122. Retrieved 7 December 2024.^\"Research at NVIDIA: Transforming Standard Video Into Slow Motion with AI\". 18 June 2018. Archived from the original on 21 December 2021 \u2013 via YouTube.^\"Artificial intelligence is helping old video games look like new\". The Verge. 18 April 2019.^\"Review: Topaz Sharpen AI is Amazing\". petapixel.com. 4 March 2019.^Griffin, Matthew (26 April 2018). \"AI can now restore your corrupted photos to their original condition\".^\"NVIDIA's AI can fix bad photos by looking at other bad photos\". Engadget. 10 July 2018.^\"Using AI to Colorize and Upscale a 109-Year-Old Video of New York City to 4K and 60fps\". petapixel.com. 24 February 2020.^\"YouTubers are upscaling the past to 4K. Historians want them to stop\". Wired UK.^\"Facebook's image outage reveals how the company's AI tags your photos\". The Verge. 3 July 2019.^\"Google's DeepMind AI can 'transframe' a single image into a video\". 18 August 2022.^\"Google's new AI turns text into music\". 28 January 2023.^\"Google's new AI music generator can create - and hold - a tune\". 30 January 2023.^\"CSDL | IEEE Computer Society\".^Jodka, Sara (February 1, 2024). \"Manipulating reality: the intersection of deepfakes and the law\". Reuters.com. Retrieved December 8, 2024.^\"InVID kick-off meeting\". InVID project. 22 January 2016. Retrieved 23 December 2021. We are kicking-off the new H2020 InVID research project.^(In Video Veritas)^\"Consortium of the InVID project\". InVID project. Retrieved 23 December 2021. The InVID vision: The InVID innovation action develops a knowledge verification platform to detect emerging stories and assess the reliability of newsworthy video files and content spread via social media.^Teyssou, Denis (2019). \"Applying Design Thinking Methodology: The InVID Verification Plugin\". Video Verification in the Fake News Era. pp.\u00a0263\u2013279. doi:10.1007/978-3-030-26752-0_9. ISBN\u00a0978-3-030-26751-3.^\"Fake news debunker by InVID & WeVerify\". Retrieved 23 December 2021.^\"TUM Visual Computing & Artificial Intelligence: Prof. Matthias Nie\u00dfner\". niessnerlab.org.^\"Will \"Deepfakes\" Disrupt the Midterm Election?\". Wired. November 2018.^ abAfchar, Darius; Nozick, Vincent; Yamagishi, Junichi; Echizen, Isao (2018). \"MesoNet: A Compact Facial Video Forgery Detection Network\". 2018 IEEE International Workshop on Information Forensics and Security (WIFS). pp.\u00a01\u20137. arXiv:1809.00888. doi:10.1109/WIFS.2018.8630761. ISBN\u00a0978-1-5386-6536-7.^Lyons, Kim (29 January 2020). \"FTC says the tech behind audio deepfakes is getting better\". The Verge.^\"Audio samples from \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\"\". google.github.io.^Strickland, Eliza (11 December 2019). \"Facebook AI Launches Its Deepfake Detection Challenge\". IEEE Spectrum.^\"Contributing Data to Deepfake Detection Research\". ai.googleblog.com. 24 September 2019.^Ober, Holly. \"New method detects deepfake videos with up to 99% accuracy\". University of California-Riverside. Retrieved 3 July 2022.^\"AI algorithm detects deepfake videos with high accuracy\". techxplore.com. Retrieved 3 July 2022.^ abc\"Welcome to the new surreal. How AI-generated video is changing film\". MIT Technology Review. Retrieved 2023-12-05.^Bean, Thomas H. Davenport and Randy (2023-06-19). \"The Impact of Generative AI on Hollywood and Entertainment\". MIT Sloan Management Review. Retrieved 2023-12-05.^Cheng, Jacqui (30 September 2009). \"Virtual composer makes beautiful music\u2014and stirs controversy\". Ars Technica.^.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US patent 7696426\u00a0^\"Computer composer honours Turing's centenary\". New Scientist. 4 July 2012. Archived from the original on 2016-04-13. Retrieved 27 December 2021.^Hick, Thierry (11 October 2016). \"La musique classique recompos\u00e9e\". Luxemburger Wort.^\"R\u00e9sultats de recherche - La Sacem\". repertoire.sacem.fr.^Requena, Gloria; S\u00e1nchez, Carlos; Corzo-Higueras, Jos\u00e9 Luis; Reyes-Alvarado, Sirenia; Rivas-Ruiz, Francisco; Vico, Francisco; Raglio, Alfredo (2014). \"Melomics music medicine (M3) to lessen pain perception during pediatric prick test procedure\". Pediatric Allergy and Immunology. 25 (7): 721\u2013724. doi:10.1111/pai.12263. PMID\u00a025115240.^\"Watson Beat on GitHub\". GitHub. 10 October 2018.^\"Songs in the Key of AI\". Wired. 17 May 2018.^\"Hayeon, sister of Girls' Generation's Taeyeon, debuts with song made by AI\". koreajoongangdaily.joins.com. 7 October 2020. Retrieved 23 October 2020.^business intelligence solutionsArchived 3 November 2011 at the Wayback Machine. Narrative Science. Retrieved 21 July 2013.^Eule, Alexander. \"Big Data and Yahoo's Quest for Mass Personalization\". Barron's.^\"Artificial Intelligence Software that Writes like a Human Being\". Archived from the original on 12 April 2013. Retrieved 11 March 2013.^Riedl, Mark Owen; Bulitko, Vadim (6 December 2012). \"Interactive Narrative: An Intelligent Systems Approach\". AI Magazine. 34 (1): 67. doi:10.1609/aimag.v34i1.2449.^Callaway, Charles B.; Lester, James C. (August 2002). \"Narrative prose generation\". Artificial Intelligence. 139 (2): 213\u2013252. doi:10.1016/S0004-3702(02)00230-8.^\"A Japanese AI program just wrote a short novel, and it almost won a literary prize\". Digital Trends. 23 March 2016. Retrieved 18 November 2016.^\"Bot News\". Hanteo News. 20 October 2020. Retrieved 20 October 2020.^Canavilhas, Jo\u00e3o (September 2022). \"Artificial Intelligence and Journalism: Current Situation and Expectations in the Portuguese Sports Media\". Journalism and Media. 3 (3): 510\u2013520. doi:10.3390/journalmedia3030035. hdl:10400.6/12308.^ abcdGalily, Yair (August 2018). \"Artificial intelligence and sports journalism: Is it a sweeping change?\". Technology in Society. 54: 47\u201351. doi:10.1016/j.techsoc.2018.03.001.^Wu, Daniel (2023-08-31). \"Gannett halts AI-written sports recaps after readers mocked the stories\". Washington Post. Retrieved 2023-10-31.^Gertner, Jon (18 July 2023). \"Wikipedia's Moment of Truth - Can the online encyclopedia help teach A.I. chatbots to get their facts right \u2014 without destroying itself in the process? + comment\". The New York Times. Archived from the original on 18 July 2023. Retrieved 19 July 2023.{{cite news}}:  CS1 maint: bot: original URL status unknown (link)^\"Study reveals bot-on-bot editing wars raging on Wikipedia's pages\". The Guardian. 23 February 2017. Retrieved 10 January 2023.^Cole, K. C. \"The Shaky Ground Truths of Wikipedia\". Wired. Retrieved 10 January 2023.^\"AI can automatically rewrite outdated text in Wikipedia articles\". Engadget. Retrieved 10 January 2023.^Metz, Cade. \"Wikipedia Deploys AI to Expand Its Ranks of Human Editors\". Wired. Retrieved 10 January 2023.^\"Wikipedia taps Google to help editors translate articles\". VentureBeat. 9 January 2019. Retrieved 9 January 2023.^Wilson, Kyle (8 May 2019). \"Wikipedia has a Google Translate problem\". The Verge. Retrieved 9 January 2023.^\"Why AI researchers like video games\". The Economist. Archived from the original on 5 October 2017.^Yannakakis, Geogios N. (2012). \"Game AI revisited\". Proceedings of the 9th conference on Computing Frontiers - CF '12. p.\u00a0285. doi:10.1145/2212908.2212954. ISBN\u00a0978-1-4503-1215-8.^Maass, Laura E. Shummon (1 July 2019). \"Artificial Intelligence in Video Games\". Medium. Retrieved 23 April 2021.^Markoff, John (16 February 2011). \"Computer Wins on 'Jeopardy!': Trivial, It's Not\". The New York Times. Archived from the original on 22 October 2014. Retrieved 25 October 2014.^\"AlphaGo \u2013 Google DeepMind\". Archived from the original on 10 March 2016.^\"Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol\". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016.^Metz, Cade (27 May 2017). \"After Win in China, AlphaGo's Designers Explore New AI\". Wired. Archived from the original on 2 June 2017.^\"World's Go Player Ratings\". May 2017. Archived from the original on 1 April 2017.^\"\u67ef\u6d01\u8fce19\u5c81\u751f\u65e5 \u96c4\u8e1e\u4eba\u7c7b\u4e16\u754c\u6392\u540d\u7b2c\u4e00\u5df2\u4e24\u5e74\" (in Chinese). May 2017. Archived from the original on 11 August 2017.^\"MuZero: Mastering Go, chess, shogi and Atari without rules\". Deepmind. 23 December 2020. Retrieved 1 March 2021.^Steven Borowiec; Tracey Lien (12 March 2016). \"AlphaGo beats human Go champ in milestone for artificial intelligence\". Los Angeles Times. Retrieved 13 March 2016.^Solly, Meilan. \"This Poker-Playing A.I. Knows When to Hold 'Em and When to Fold 'Em\". Smithsonian. Pluribus has bested poker pros in a series of six-player no-limit Texas Hold'em games, reaching a milestone in artificial intelligence research. It is the first bot to beat humans in a complex multiplayer competition.^Bowling, Michael; Burch, Neil; Johanson, Michael; Tammelin, Oskari (9 January 2015). \"Heads-up limit hold'em poker is solved\". Science. 347 (6218): 145\u2013149. Bibcode:2015Sci...347..145B. doi:10.1126/science.1259433. PMID\u00a025574016.^Ontanon, Santiago; Synnaeve, Gabriel; Uriarte, Alberto; Richoux, Florian; Churchill, David; Preuss, Mike (December 2013). \"A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft\". IEEE Transactions on Computational Intelligence and AI in Games. 5 (4): 293\u2013311. doi:10.1109/TCIAIG.2013.2286295.^\"Facebook Quietly Enters StarCraft War for AI Bots, and Loses\". WIRED. 2017. Retrieved 7 May 2018.^Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (7 December 2018). \"A general reinforcement learning algorithm that masters chess, shogi, and go through self-play\". Science. 362 (6419): 1140\u20131144. Bibcode:2018Sci...362.1140S. doi:10.1126/science.aar6404. PMID\u00a030523106.^Sample, Ian (18 October 2017). \"'It's able to create knowledge itself': Google unveils AI that learns on its own\". The Guardian. Retrieved 7 May 2018.^Appenzeller, Tim (7 July 2017). \"The AI revolution in science\". Science. doi:10.1126/science.aan7064.^\"The superhero of artificial intelligence: can this genius keep it in check?\". The Guardian. 16 February 2016. Archived from the original on 23 April 2018. Retrieved 26 April 2018.^Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529\u2013533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID\u00a025719670.^Sample, Ian (14 March 2017). \"Google's DeepMind makes AI program that can learn like a human\". The Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018.^Schrittwieser, Julian; Antonoglou, Ioannis; Hubert, Thomas; Simonyan, Karen; Sifre, Laurent; Schmitt, Simon; Guez, Arthur; Lockhart, Edward; Hassabis, Demis; Graepel, Thore; Lillicrap, Timothy; Silver, David (24 December 2020). \"Mastering Atari, Go, chess and shogi by planning with a learned model\". Nature. 588 (7839): 604\u2013609. arXiv:1911.08265. Bibcode:2020Natur.588..604S. doi:10.1038/s41586-020-03051-4. PMID\u00a033361790.^Ortiz, Sabrina. \"You can now chat with a famous AI character on Viber. Here's how\". zdnet.com. ZDNET. Retrieved 5 December 2024. ICONIQ created Kuki, an AI character whose sole purpose is to entertain humans and has even been used as a brand ambassador for H&M, modeled for Vogue, and starred in its own Roblox game.^Lewis, Nell (19 August 2020). \"Robot friends: Why people talk to chatbots in times of trouble\". cnn.com. CNN. Retrieved 5 December 2024. Since 2016, when the bot landed on major messaging platforms, an estimated 5 million unique users hailing from all corners of the world have chatted with her.^Poltronieri, Fabrizio Augusto; H\u00e4nska, Max (2019). \"Technical Images and Visual Art in the Era of Artificial Intelligence: From GOFAI to GANs\". Proceedings of the 9th International Conference on Digital and Interactive Arts. pp.\u00a01\u20138. doi:10.1145/3359852.3359865. ISBN\u00a0978-1-4503-7250-3.^\"Fine art print - crypto art\". Kate Vass Galerie. Retrieved 2022-05-07.^ ab\"Analysis | Is That Trump Photo Real? Free AI Tools Come With Risks\". Washington Post. Retrieved 30 August 2022.^\"Google's image generator rivals DALL-E in shiba inu drawing\". TechCrunch. Retrieved 30 August 2022.^\"Midjourney's enthralling AI art generator goes live for everyone\". PCWorld.^\"After Photos, Here's How AI Made A Trippy Music Video Out Of Thin Air\". Fossbytes. 19 May 2022. Retrieved 30 May 2022.^Cetinic, Eva; She, James (2022-02-16). \"Understanding and Creating Art with AI: Review and Outlook\". ACM Transactions on Multimedia Computing, Communications, and Applications. 18 (2): 66:1\u201366:22. arXiv:2102.09109. doi:10.1145/3475799.^Lang, Sabine; Ommer, Bjorn (2018). \"Reflecting on How Artworks Are Processed and Analyzed by Computer Vision: Supplementary Material\". Proceedings of the European Conference on Computer Vision (ECCV) Workshops \u2013 via Computer Vision Foundation.^Cole, Samantha (2023-02-01). \"Netflix Made an Anime Using AI Due to a 'Labor Shortage,' and Fans Are Pissed\". Vice. Retrieved 2023-12-04.^Christy, Charles A. (17 January 1990). \"Impact of Artificial Intelligence on Banking\". Los Angeles Times. Retrieved 10 September 2019.^O'Neill, Eleanor (31 July 2016). \"Accounting, automation and AI\". icas.com. Archived from the original on 18 November 2016. Retrieved 18 November 2016.^\"CTO Corner: Artificial Intelligence Use in Financial Services \u2013 Financial Services Roundtable\". Financial Services Roundtable. 2 April 2015. Archived from the original on 18 November 2016. Retrieved 18 November 2016.^\"Artificial Intelligence Solutions, AI Solutions\". sas.com.^Chapman, Lizette (7 January 2019). \"Palantir once mocked the idea of salespeople. Now it's hiring them\". Los Angeles Times. Retrieved 28 February 2019.^Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. 2017. doi:10.1007/978-3-319-66104-9. ISBN\u00a0978-3-319-66103-2.[page\u00a0needed]^Marwala, Tshilidzi; Hurwitz, Evan (2017). \"Efficient Market Hypothesis\". Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. pp.\u00a0101\u2013110. doi:10.1007/978-3-319-66104-9_9. ISBN\u00a0978-3-319-66103-2.^Shao, Jun; Lou, Zhukun; Wang, Chong; Mao, Jinye; Ye, Ailin (16 May 2022). \"The impact of artificial intelligence (AI) finance on financing constraints of non-SOE firms in emerging markets\". International Journal of Emerging Markets. 17 (4): 930\u2013944. doi:10.1108/IJOEM-02-2021-0299.^\"Algorithmic Trading\". Investopedia. 18 May 2005.^\"The Financial Stability Implications of Artificial Intelligence\"(PDF). FSB. Retrieved 2025-09-07.^\"Beyond Robo-Advisers: How AI Could Rewire Wealth Management\". 5 January 2017.^Asatryan, Diana (3 April 2017). \"Machine Learning Is the Future of Underwriting, But Startups Won't be Driving It\". bankinnovation.net. Retrieved 15 April 2022.^Laura, Blattner; Jann, Spiess. \"Explainability & Fairness in Machine Learning for Credit Underwriting\"(PDF). FinRegLab. Retrieved 2025-09-07.^\"ZestFinance Introduces Machine Learning Platform to Underwrite Millennials and Other Consumers with Limited Credit History\" (Press release). 14 February 2017.^Chang, Hsihui; Kao, Yi-Ching; Mashruwala, Raj; Sorensen, Susan M. (10 April 2017). \"Technical Inefficiency, Allocative Inefficiency, and Audit Pricing\". Journal of Accounting, Auditing & Finance. 33 (4): 580\u2013600. doi:10.1177/0148558X17696760.^Munoko, Ivy; Brown-Liburd, Helen L.; Vasarhelyi, Miklos (November 2020). \"The Ethical Implications of Using Artificial Intelligence in Auditing\". Journal of Business Ethics. 167 (2): 209\u2013234. doi:10.1007/s10551-019-04407-1.^Fadelli, Ingrid. \"LaundroGraph: Using deep learning to support anti\u2013money laundering efforts\". techxplore.com. Retrieved 18 December 2022.^Cardoso, M\u00e1rio; Saleiro, Pedro; Bizarro, Pedro (2022). \"LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\". Proceedings of the Third ACM International Conference on AI in Finance. pp.\u00a0130\u2013138. arXiv:2210.14360. doi:10.1145/3533271.3561727. ISBN\u00a0978-1-4503-9376-8.^Sivamayilvelan, Keerthana; Rajasekar, Elakkiya; Vairavasundaram, Subramaniyaswamy; Balachandran, Santhi; Suresh, Vishnu (2025-11-01). \"Building explainable artificial intelligence for reinforcement learning based debt collection recommender system using large language models\". Engineering Applications of Artificial Intelligence. 159 111622. doi:10.1016/j.engappai.2025.111622. ISSN\u00a00952-1976.^Durkin, J. (2002). \"History and applications\". Expert Systems. Vol.\u00a01. pp.\u00a01\u201322. doi:10.1016/B978-012443880-4/50045-4. ISBN\u00a0978-0-12-443880-4.^Chen, K.C.; Liang, Ting-peng (May 1989). \"Protrader: An Expert System for Program Trading\". Managerial Finance. 15 (5): 1\u20136. doi:10.1108/eb013623.^Nielson, Norma; Brown, Carol E.; Phillips, Mary Ellen (July 1990). \"Expert Systems for Personal Financial Planning\". Journal of Financial Planning: 137\u2013143. doi:10.11575/PRISM/33995. hdl:1880/48295.^Senator, Ted E.; Goldberg, Henry G.; Wooton, Jerry; Cottini, Matthew A.; Khan, A.F. Umar; Kilinger, Christina D.; Llamas, Winston M.; Marrone, MichaeI P.; Wong, Raphael W.H. (1995). \"The FinCEN Artificial Intelligence System: Identifying Potential Money Laundering from Reports of Large Cash Transactions\"(PDF). IAAI-95 Proceedings. Archived from the original(PDF) on 2015-10-20. Retrieved 2019-01-14.^Sutton, Steve G.; Holt, Matthew; Arnold, Vicky (September 2016). \"'The reports of my death are greatly exaggerated'\u2014Artificial intelligence research in accounting\". International Journal of Accounting Information Systems. 22: 60\u201373. doi:10.1016/j.accinf.2016.07.005.^Bender, Michael J.; Katopodis, Chris; Simonovic, Slobodan P. (1992). \"A prototype expert system for fishway design\". Environmental Monitoring and Assessment. 23 (1\u20133): 115\u2013127. Bibcode:1992EMnAs..23..115B. doi:10.1007/BF00406956. PMID\u00a024227094.^Wayson, Roger L. (1989). \"Use of a Knowledge-Based Expert System to Maximize Airport Capacity in Harmony with Noise-Mitigation Plans\"(PDF). Transportation Research Record. 1218: 31\u201340.^Vencill, A. M.; Speese, J. (1995). \"Potato Insect Expert System: Computerized Approach to Colorado Potato Beetle Management\". Journal of Economic Entomology. 88 (4): 944\u2013954. doi:10.1093/jee/88.4.944.^Jirka, Gerhard H.; Akar, Paul J. (1996). User's Manual for CORMIX: A Hydrodynamic Mixing Zone Model and Decision Support System for Pollutant Discharges into Surface Waters(PDF) (Report). U.S. Environmental Protection Agency.^Chalmers, Dominic; MacKenzie, Niall G.; Carter, Sara (September 2021). \"Artificial Intelligence and Entrepreneurship: Implications for Venture Creation in the Fourth Industrial Revolution\". Entrepreneurship Theory and Practice. 45 (5): 1028\u20131053. doi:10.1177/1042258720934581.^Thompsett, Louis (2025-02-04). \"What EU AI Act Means for Governance in Financial Sector\". fintechmagazine.com. Retrieved 2025-09-20.^ abSzczytko, Jacek (2025-08-15). \"How will the AI Act alter the landscape for fintechs? Key requirements and penalties\". Dudkowiak & Putyra. Retrieved 2025-09-20.^ ab\"Regulation - EU - 2024/1689 - EN - EUR-Lex\". eur-lex.europa.eu. Retrieved 2025-09-20.^\"AI Credit Regulations Affecting Lending Business 2025\". hesfintech. 10 October 2025. Archived from the original on 12 October 2025. Retrieved 10 October 2025.^\"10 Promising AI Applications in Health Care\". Harvard Business Review. 10 May 2018. Archived from the original on 15 December 2018. Retrieved 28 August 2018.^Lareyre, Fabien; L\u00ea, Cong Duy; Ballaith, Ali; Adam, C\u00e9dric; Carrier, Marion; Amrani, Samantha; Caradu, Caroline; Raffort, Juliette (August 2022). \"Applications of Artificial Intelligence in Non-cardiac Vascular Diseases: A Bibliographic Analysis\". Angiology. 73 (7): 606\u2013614. doi:10.1177/00033197211062280. PMID\u00a034996315.^\"What is artificial intelligence in medicine?\". IBM. 28 March 2024. Retrieved 19 April 2024.^\"Microsoft Using AI to Accelerate Cancer Precision Medicine\". HealthITAnalytics. 29 October 2019. Retrieved 29 November 2020.^Dina Bass (20 September 2016). \"Microsoft Develops AI to Help Cancer Doctors Find the Right Treatments\". Bloomberg L.P. Archived from the original on 11 May 2017.^Gallagher, James (26 January 2017). \"Artificial intelligence 'as good as cancer doctors'\". BBC News. Archived from the original on 26 January 2017. Retrieved 26 January 2017.^Langen, Pauline A.; Katz, Jeffrey S.; Dempsey, Gayle, eds. (18 October 1994), Remote monitoring of high-risk patients using artificial intelligence, archived from the original on 28 February 2017, retrieved 27 February 2017^Kermany, Daniel S.; Goldbaum, Michael; Cai, Wenjia; Valentim, Carolina C.S.; Liang, Huiying; Baxter, Sally L.; McKeown, Alex; Yang, Ge; Wu, Xiaokang; Yan, Fangbing; Dong, Justin; Prasadha, Made K.; Pei, Jacqueline; Ting, Magdalene Y.L.; Zhu, Jie; Li, Christina; Hewett, Sierra; Dong, Jason; Ziyar, Ian; Shi, Alexander; Zhang, Runze; Zheng, Lianghong; Hou, Rui; Shi, William; Fu, Xin; Duan, Yaou; Huu, Viet A.N.; Wen, Cindy; Zhang, Edward D.; Zhang, Charlotte L.; Li, Oulan; Wang, Xiaobo; Singer, Michael A.; Sun, Xiaodong; Xu, Jie; Tafreshi, Ali; Lewis, M. Anthony; Xia, Huimin; Zhang, Kang (February 2018). \"Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\". Cell. 172 (5): 1122\u20131131.e9. doi:10.1016/j.cell.2018.02.010. PMID\u00a029474911.^Senthilingam, Meera (12 May 2016). \"Are Autonomous Robots Your next Surgeons?\". CNN. Archived from the original on 3 December 2016. Retrieved 4 December 2016.^Pumplun L, Fecho M, Wahl N, Peters F, Buxmann P (2021). \"Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\". Journal of Medical Internet Research. 23 (10) e29301. doi:10.2196/29301. PMC\u00a08556641. PMID\u00a034652275.^Inglese, Marianna; Patel, Neva; Linton-Reid, Kristofer; Loreto, Flavia; Win, Zarni; Perry, Richard J.; Carswell, Christopher; Grech-Sollars, Matthew; Crum, William R.; Lu, Haonan; Malhotra, Paresh A.; Aboagye, Eric O. (20 June 2022). \"A predictive model using the mesoscopic architecture of the living brain to detect Alzheimer's disease\". Communications Medicine. 2 (1): 70. doi:10.1038/s43856-022-00133-4. PMC\u00a09209493. PMID\u00a035759330.News report: \"Single MRI scan of the brain could detect Alzheimer's disease\". Physics World. 13 July 2022. Retrieved 19 July 2022.^Yorita, Akihiro; Kubota, Naoyuki (2011). \"Cognitive Development in Partner Robots for Information Support to Elderly People\". IEEE Transactions on Autonomous Mental Development. 3 (1): 64\u201373. Bibcode:2011ITAMD...3...64Y. doi:10.1109/TAMD.2011.2105868.^\"Artificial Intelligence Will Redesign Healthcare \u2013 The Medical Futurist\". The Medical Futurist. 4 August 2016. Retrieved 18 November 2016.^D\u00f6nerta\u015f, Handan Melike; Fuentealba, Mat\u00edas; Partridge, Linda; Thornton, Janet M. (February 2019). \"Identifying Potential Ageing-Modulating Drugs In Silico\". Trends in Endocrinology & Metabolism. 30 (2): 118\u2013131. doi:10.1016/j.tem.2018.11.005. PMC\u00a06362144. PMID\u00a030581056.^Smer-Barreto, Vanessa; Quintanilla, Andrea; Elliot, Richard J. R.; Dawson, John C.; Sun, Jiugeng; Carragher, Neil O.; Acosta, Juan Carlos; Oyarz\u00fan, Diego A. (27 April 2022). \"Discovery of new senolytics using machine learning\". bioRxiv. doi:10.1101/2022.04.26.489505. hdl:10261/269843.^Luxton, David D. (2014). \"Artificial intelligence in psychological practice: Current and future applications and implications\". Professional Psychology: Research and Practice. 45 (5): 332\u2013339. doi:10.1037/a0034559.^Randhawa, Gurjit S.; Soltysiak, Maximillian P. M.; Roz, Hadi El; Souza, Camila P. E. de; Hill, Kathleen A.; Kari, Lila (24 April 2020). \"Machine learning using intrinsic genomic signatures for rapid classification of novel pathogens: COVID-19 case study\". PLOS ONE. 15 (4) e0232391. Bibcode:2020PLoSO..1532391R. doi:10.1371/journal.pone.0232391. PMC\u00a07182198. PMID\u00a032330208.^Ye, Jiarong; Yeh, Yin-Ting; Xue, Yuan; Wang, Ziyang; Zhang, Na; Liu, He; Zhang, Kunyan; Ricker, RyeAnne; Yu, Zhuohang; Roder, Allison; Perea Lopez, Nestor; Organtini, Lindsey; Greene, Wallace; Hafenstein, Susan; Lu, Huaguang; Ghedin, Elodie; Terrones, Mauricio; Huang, Shengxi; Huang, Sharon Xiaolei (7 June 2022). \"Accurate virus identification with interpretable Raman signatures by machine learning\". Proceedings of the National Academy of Sciences. 119 (23) e2118836119. arXiv:2206.02788. Bibcode:2022PNAS..11918836Y. doi:10.1073/pnas.2118836119. PMC\u00a09191668. PMID\u00a035653572.^\"Artificial intelligence finds disease-related genes\". Link\u00f6ping University. Retrieved 3 July 2022.^\"Researchers use AI to detect new family of genes in gut bacteria\". UT Southwestern Medical Center. Retrieved 3 July 2022.^ abcZhavoronkov, Alex; Mamoshina, Polina; Vanhaelen, Quentin; Scheibye-Knudsen, Morten; Moskalev, Alexey; Aliper, Alex (2019). \"Artificial intelligence for aging and longevity research: Recent advances and perspectives\". Ageing Research Reviews. 49: 49\u201366. doi:10.1016/j.arr.2018.11.003. PMID\u00a030472217.^Adir, Omer; Poley, Maria; Chen, Gal; Froim, Sahar; Krinsky, Nitzan; Shklover, Jeny; Shainsky-Roitman, Janna; Lammers, Twan; Schroeder, Avi (April 2020). \"Integrating Artificial Intelligence and Nanotechnology for Precision Cancer Medicine\". Advanced Materials. 32 (13) 1901989. Bibcode:2020AdM....3201989A. doi:10.1002/adma.201901989. PMC\u00a07124889. PMID\u00a031286573.^Moore, Phoebe V. (7 May 2019). \"OSH and the Future of Work: benefits and risks of artificial intelligence tools in workplaces\". EU-OSHA. pp.\u00a03\u20137. Retrieved 30 July 2020.^Howard, John (November 2019). \"Artificial intelligence: Implications for the future of work\". American Journal of Industrial Medicine. 62 (11): 917\u2013926. doi:10.1002/ajim.23037. PMID\u00a031436850.^Gianatti, Toni-Louise (14 May 2020). \"How AI-Driven Algorithms Improve an Individual's Ergonomic Safety\". Occupational Health & Safety. Retrieved 30 July 2020.^Meyers, Alysha R. (1 May 2019). \"AI and Workers' Comp\". NIOSH Science Blog. Retrieved 3 August 2020.^Webb, Sydney; Siordia, Carlos; Bertke, Stephen; Bartlett, Diana; Reitz, Dan (26 February 2020). \"Artificial Intelligence Crowdsourcing Competition for Injury Surveillance\". NIOSH Science Blog. Retrieved 3 August 2020.^Ferguson, Murray (19 April 2016). \"Artificial Intelligence: What's To Come for EHS... And When?\". EHS Today. Retrieved 30 July 2020.^Paul, Debleena; Sanap, Gaurav; Shenoy, Snehal; Kalyane, Dnyaneshwar; Kalia, Kiran; Tekade, Rakesh K. (January 2021). \"Artificial intelligence in drug discovery and development\". Drug Discovery Today. 26 (1): 80\u201393. doi:10.1016/j.drudis.2020.10.010. PMC\u00a07577280. PMID\u00a033099022.^\"Allchemy \u2013 Resource-aware AI for drug discovery\". Retrieved 29 May 2022.^Wo\u0142os, Agnieszka; Koszelewski, Dominik; Roszak, Rafa\u0142; Szymku\u0107, Sara; Moskal, Martyna; Ostaszewski, Ryszard; Herrera, Brenden T.; Maier, Josef M.; Brezicki, Gordon; Samuel, Jonathon; Lummiss, Justin A. M.; McQuade, D. Tyler; Rogers, Luke; Grzybowski, Bartosz A. (April 2022). \"Computer-designed repurposing of chemical wastes into drugs\". Nature. 604 (7907): 668\u2013676. Bibcode:2022Natur.604..668W. doi:10.1038/s41586-022-04503-9. PMID\u00a035478240.^Wo\u0142os, Agnieszka; Roszak, Rafa\u0142; \u017b\u0105d\u0142o-Dobrowolska, Anna; Beker, Wiktor; Mikulak-Klucznik, Barbara; Sp\u00f3lnik, Grzegorz; Dygas, Miros\u0142aw; Szymku\u0107, Sara; Grzybowski, Bartosz A. (25 September 2020). \"Synthetic connectivity, emergence, and self-regeneration in the network of prebiotic chemistry\". Science. 369 (6511) eaaw1955. doi:10.1126/science.aaw1955. PMID\u00a032973002.^Zhavoronkov, Alex; Ivanenkov, Yan A.; Aliper, Alex; Veselov, Mark S.; Aladinskiy, Vladimir A.; Aladinskaya, Anastasiya V.; Terentiev, Victor A.; Polykovskiy, Daniil A.; Kuznetsov, Maksim D.; Asadulaev, Arip; Volkov, Yury; Zholus, Artem; Shayakhmetov, Rim R.; Zhebrak, Alexander; Minaeva, Lidiya I.; Zagribelnyy, Bogdan A.; Lee, Lennart H.; Soll, Richard; Madge, David; Xing, Li; Guo, Tao; Aspuru-Guzik, Al\u00e1n (September 2019). \"Deep learning enables rapid identification of potent DDR1 kinase inhibitors\". Nature Biotechnology. 37 (9): 1038\u20131040. doi:10.1038/s41587-019-0224-x. PMID\u00a031477924.^\"DeepMind is answering one of biology's biggest challenges\". The Economist. 30 November 2020. Retrieved 30 November 2020.^Jeremy Kahn, Lessons from DeepMind's breakthrough in protein-folding A.I., Fortune, 1 December 2020^\"DeepMind uncovers structure of 200m proteins in scientific leap forward\". The Guardian. 2022-07-28. Retrieved 2022-07-28.^\"AlphaFold reveals the structure of the protein universe\". DeepMind. 2022-07-28. Retrieved 2022-07-28.^Nakamura, Satoshi (2009). \"Overcoming the language barrier with speech translation technology\". Science & Technology Trends Quarterly Review (31): 35\u201348. CORE output ID\u00a0236667511.^ abClark, Jack (8 December 2015). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com.^\"Can artificial intelligence really help us talk to the animals?\". The Guardian. 31 July 2022. Retrieved 30 August 2022.^K. Mandal, G. S. Pradeep Ghantasala, Firoz Khan, R. Sathiyaraj, B. Balamurugan (2020). Natural Language Processing in Artificial Intelligence (1st\u00a0ed.). Apple Academic Press. pp.\u00a053\u201354. ISBN\u00a0978-0-367-80849-5.{{cite book}}:  CS1 maint: multiple names: authors list (link)^Buckley, Chris; Mozur, Paul (22 May 2019). \"How China Uses High-Tech Surveillance to Subdue Minorities\". The New York Times.^\"Security lapse exposed a Chinese smart city surveillance system\". 3 May 2019. Archived from the original on 7 March 2021. Retrieved 14 September 2020.^\"AI traffic signals to be installed in Bengaluru soon\". NextBigWhat. 24 September 2019. Retrieved 1 October 2019.^Ashley, Kevin D. (2017). Artificial Intelligence and Legal Analytics. doi:10.1017/9781316761380. ISBN\u00a0978-1-107-17150-3.[page\u00a0needed]^Lohr, Steve (19 March 2017). \"A.I. Is Doing Legal Work. But It Won't Replace Lawyers, Yet\". The New York Times.^Croft, Jane (2 May 2019). \"AI learns to read Korean, so you don't have to\". Financial Times. Retrieved 19 December 2019.^Kleider-Offutt, Heather; Stevens, Beth; Mickes, Laura; Boogert, Stewart (3 April 2024). \"Application of artificial intelligence to eyewitness identification\". Cognitive Research: Principles and Implications. 9 (1): 19. doi:10.1186/s41235-024-00542-0. PMC\u00a010991253. PMID\u00a038568356.^ abJeff Larson; Julia Angwin (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020.^\"Commentary: Bad news. Artificial intelligence is biased\". CNA. 12 January 2019. Archived from the original on 12 January 2019. Retrieved 19 June 2020.^ ab\u0160imal\u010d\u00edk, Matej (2023). \"Rule by Law\". In Kironska, Kristina; Turscanyi, Richard Q. (eds.). Contemporary China: a New Superpower?. Routledge. ISBN\u00a0978-1-03-239508-1.^\"Digital Spectrometry\". 8 October 2018.^US 9967696B2, \"Digital Spectrometry Patent\", published 2018-10-08\u00a0^\"How artificial intelligence is moving from the lab to your kid's playroom\". The Washington Post. Retrieved 18 November 2016.^\"Application of artificial intelligence in oil and gas industry: Exploring its impact\". 15 May 2019.^Salvaterra, Neanda (14 October 2019). \"Oil and Gas Companies Turn to AI to Cut Costs\". The Wall Street Journal.^ abcCongressional Research Service (2019). Artificial Intelligence and National Security(PDF). Washington, DC: Congressional Research Service.PD-notice^Iraqi, Amjad (2024-04-03). \"'Lavender': The AI machine directing Israel's bombing spree in Gaza\". +972 Magazine. Retrieved 2024-04-06.^Davies, Harry; McKernan, Bethan; Sabbagh, Dan (2023-12-01). \"'The Gospel': how Israel uses AI to select bombing targets in Gaza\". The Guardian. Retrieved 2023-12-04.^Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf St\u00f6rsender \u2013 deshalb sollen sie jetzt autonom operieren\". Neue Z\u00fcrcher Zeitung (in German). Retrieved 10 August 2024.^\"What are the security risks of open sourcing the Twitter algorithm?\". VentureBeat. 27 May 2022. Retrieved 29 May 2022.^\"Examining algorithmic amplification of political content on Twitter\". Retrieved 29 May 2022.^Park, SoHyun; Oh, Heung-Kwon; Park, Gibeom; Suh, Bongwon; Bae, Woo Kyung; Kim, Jin Won; Yoon, Hyuk; Kim, Duck-Woo; Kang, Sung-Bum (February 2016). \"The Source and Credibility of Colorectal Cancer Information on Twitter\". Medicine. 95 (7) e2775. doi:10.1097/MD.0000000000002775. PMC\u00a04998625. PMID\u00a026886625.^Efthimion, Phillip; Payne, Scott; Proferes, Nicholas (20 July 2018). \"Supervised Machine Learning Bot Detection Techniques to Identify Social Twitter Bots\". SMU Data Science Review. 1 (2).^\"The online information environment\"(PDF). Retrieved 21 February 2022.^Islam, Md Rafiqul; Liu, Shaowu; Wang, Xianzhi; Xu, Guandong (29 September 2020). \"Deep learning for misinformation detection on online social networks: a survey and new perspectives\". Social Network Analysis and Mining. 10 (1): 82. doi:10.1007/s13278-020-00696-x. PMC\u00a07524036. PMID\u00a033014173.^Mohseni, Sina; Ragan, Eric (4 December 2018). \"Combating Fake News with Interpretable News Feed Algorithms\". arXiv:1811.12349 [cs.SI].^\"How artificial intelligence may be making you buy things\". BBC News. 9 November 2020. Retrieved 9 November 2020.^Busby, Mattha (30 April 2018). \"Revealed: how bookies use AI to keep gamblers hooked\". The Guardian.^Rowinski, Dan (15 January 2013). \"Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]\". ReadWrite. Archived from the original on 22 December 2015.^Roose, Kevin (16 February 2023). \"Bing's A.I. Chat: 'I Want to Be Alive. \ud83d\ude08'\". The New York Times.^Galego Hernandes, Paulo R.; Floret, Camila P.; Cardozo De Almeida, Katia F.; Da Silva, Vinicius Camargo; Papa, Joso Paulo; Pontara Da Costa, Kelton A. (2021). \"Phishing Detection Using URL-based XAI Techniques\". 2021 IEEE Symposium Series on Computational Intelligence (SSCI). pp.\u00a001\u201306. doi:10.1109/SSCI50451.2021.9659981. ISBN\u00a0978-1-7281-9048-8.^J\u00e1\u00f1ez-Martino, Francisco; Alaiz-Rodr\u00edguez, Roc\u00edo; Gonz\u00e1lez-Castro, V\u00edctor; Fidalgo, Eduardo; Alegre, Enrique (2023-02-01). \"A review of spam email detection: analysis of spammer strategies and the dataset shift problem\". Artificial Intelligence Review. 56 (2): 1145\u20131173. doi:10.1007/s10462-022-10195-4. hdl:10612/14967.^Kapan, Sibel; Sora Gunal, Efnan (January 2023). \"Improved Phishing Attack Detection with Machine Learning: A Comprehensive Evaluation of Classifiers and Features\". Applied Sciences. 13 (24) 13269. doi:10.3390/app132413269.^Heath, Nick (11 December 2020). \"What is AI? Everything you need to know about Artificial Intelligence\". ZDNet. Retrieved 1 March 2021.^\"China's massive investment in artificial intelligence has an insidious downside\". Science AAAS. February 7, 2018. Retrieved February 23, 2018.^\"China bets on facial recognition in big drive for total surveillance\". The Washington Post. 2018. Retrieved February 23, 2018.^\"Facial recognition forced on 800 million Chinese internet users\". Radio France Internationale. 15 October 2019. Retrieved April 21, 2024.^\"Country policy and information note: Falun Gong, China, November 2023 (accessible)\". The United Kingdom Government. April 4, 2024. Retrieved April 21, 2024.^Techredacteur, Joost Schellevis (December 16, 2016). \"Politie gaat verdachten opsporen met gezichtsherkenning\". nos.nl (in Dutch). Retrieved September 22, 2019.^Boon, Lex (August 25, 2018). \"Meekijken met de 226 gemeentecamera's\". Het Parool (in Dutch). Retrieved September 22, 2019.^\"Successful and timely uptake of artificial intelligence in science in the EU \u2013 Scientific Advice Mechanism\". Retrieved 2024-04-16.^\"AI in science evidence review report \u2013 Scientific Advice Mechanism\". Retrieved 2024-04-16.^Assael, Yannis; Sommerschield, Thea; Shillingford, Brendan; Bordbar, Mahyar; Pavlopoulos, John; Chatzipanagiotou, Marita; Androutsopoulos, Ion; Prag, Jonathan; de Freitas, Nando (March 2022). \"Restoring and attributing ancient texts using deep neural networks\". Nature. 603 (7900): 280\u2013283. Bibcode:2022Natur.603..280A. doi:10.1038/s41586-022-04448-z. PMC\u00a08907065. PMID\u00a035264762.^Mantovan, Lorenzo; Nanni, Loris (September 2020). \"The Computerization of Archaeology: Survey on Artificial Intelligence Techniques\". SN Computer Science. 1 (5) 267. arXiv:2005.02863. doi:10.1007/s42979-020-00286-w.^Mondal, Mayukh; Bertranpetit, Jaume; Lao, Oscar (December 2019). \"Approximate Bayesian computation with deep learning supports a third archaic introgression in Asia and Oceania\". Nature Communications. 10 (1): 246. Bibcode:2019NatCo..10..246M. doi:10.1038/s41467-018-08089-7. PMC\u00a06335398. PMID\u00a030651539.^Tanti, Marc; Berruyer, Camille; Tafforeau, Paul; Muscat, Adrian; Farrugia, Reuben; Scerri, Kenneth; Valentino, Gianluca; Sol\u00e9, V. Armando; Briffa, Johann A. (15 December 2021). \"Automated segmentation of microtomography imaging of Egyptian mummies\". PLOS ONE. 16 (12) e0260707. arXiv:2105.06738. Bibcode:2021PLoSO..1660707T. doi:10.1371/journal.pone.0260707. PMC\u00a08673632. PMID\u00a034910736.^\"DeepMind AI learns physics by watching videos that don't make sense\". New Scientist. Retrieved 21 August 2022.^Piloto, Luis S.; Weinstein, Ari; Battaglia, Peter; Botvinick, Matthew (11 July 2022). \"Intuitive physics learning in a deep-learning model inspired by developmental psychology\". Nature Human Behaviour. 6 (9): 1257\u20131267. doi:10.1038/s41562-022-01394-8. PMC\u00a09489531. PMID\u00a035817932.^ abFeldman, Andrey (11 August 2022). \"Artificial physicist to unravel the laws of nature\". Advanced Science News. Retrieved 21 August 2022.^Chen, Boyuan; Huang, Kuang; Raghupathi, Sunand; Chandratreya, Ishaan; Du, Qiang; Lipson, Hod (July 2022). \"Automated discovery of fundamental variables hidden in experimental data\". Nature Computational Science. 2 (7): 433\u2013442. doi:10.1038/s43588-022-00281-6. PMID\u00a038177869.^Nu\u00f1ez, Michael (2023-11-29). \"Google DeepMind's materials AI has already discovered 2.2 million new crystals\". VentureBeat. Retrieved 2023-12-19.^Merchant, Amil; Batzner, Simon; Schoenholz, Samuel S.; Aykol, Muratahan; Cheon, Gowoon; Cubuk, Ekin Dogus (December 2023). \"Scaling deep learning for materials discovery\". Nature. 624 (7990): 80\u201385. Bibcode:2023Natur.624...80M. doi:10.1038/s41586-023-06735-9. PMC\u00a010700131. PMID\u00a038030720.^Peplow, Mark (29 November 2023). \"Google AI and robots join forces to build new materials\". Nature. doi:10.1038/d41586-023-03745-5. PMID\u00a038030771.^Yanamandra, Kaushik; Chen, Guan Lin; Xu, Xianbo; Mac, Gary; Gupta, Nikhil (29 September 2020). \"Reverse engineering of additive manufactured composite part by toolpath reconstruction using imaging and machine learning\". Composites Science and Technology. 198 108318. doi:10.1016/j.compscitech.2020.108318.^Anderson, Blake; Storlie, Curtis; Yates, Micah; McPhall, Aaron (2014). \"Automating Reverse Engineering with Machine Learning Techniques\". Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop. pp.\u00a0103\u2013112. doi:10.1145/2666652.2666665. ISBN\u00a0978-1-4503-3153-1.^Liu, Wenye; Chang, Chip-Hong; Wang, Xueyang; Liu, Chen; Fung, Jason M.; Ebrahimabadi, Mohammad; Karimi, Naghmeh; Meng, Xingyu; Basu, Kanad (June 2021). \"Two Sides of the Same Coin: Boons and Banes of Machine Learning in Hardware Security\". IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 11 (2): 228\u2013251. Bibcode:2021IJEST..11..228L. doi:10.1109/JETCAS.2021.3084400. hdl:10356/155876.^\"DARPA Taps GrammaTech for Artificial Intelligence Exploration (AIE) Program\". www.businesswire.com. 7 January 2021. Retrieved 10 January 2023.^Greenberg, Andy. \"How to Steal an AI\". Wired. Retrieved 10 January 2023.^Sanchez-Lengeling, Benjamin; Aspuru-Guzik, Al\u00e1n (27 July 2018). \"Inverse molecular design using machine learning: Generative models for matter engineering\". Science. 361 (6400): 360\u2013365. Bibcode:2018Sci...361..360S. doi:10.1126/science.aat2663. PMID\u00a030049875.^ ab\"Biologists train AI to generate medicines and vaccines\". University of Washington-Harborview Medical Center.^ abWang, Jue; Lisanza, Sidney; Juergens, David; Tischer, Doug; Watson, Joseph L.; Castro, Karla M.; Ragotte, Robert; Saragovi, Amijai; Milles, Lukas F.; Baek, Minkyung; Anishchenko, Ivan; Yang, Wei; Hicks, Derrick R.; Exp\u00f2sit, Marc; Schlichthaerle, Thomas; Chun, Jung-Ho; Dauparas, Justas; Bennett, Nathaniel; Wicky, Basile I. M.; Muenks, Andrew; DiMaio, Frank; Correia, Bruno; Ovchinnikov, Sergey; Baker, David (22 July 2022). \"Scaffolding protein functional sites using deep learning\". Science. 377 (6604): 387\u2013394. Bibcode:2022Sci...377..387W. doi:10.1126/science.abn2100. PMC\u00a09621694. PMID\u00a035862514.^Teemu, Rintala (17 June 2019). Using Boolean network extraction of trained neural networks to reverse-engineer gene-regulatory networks from time-series data (Master's in Life Science Technologies thesis). Aalto University.[page\u00a0needed]^Ball, Nicholas M.; Brunner, Robert J. (July 2010). \"Data mining and machine learning in astronomy\". International Journal of Modern Physics D. 19 (7): 1049\u20131106. arXiv:0906.2173. Bibcode:2010IJMPD..19.1049B. doi:10.1142/S0218271810017160.^ abShekhtman, Svetlana (15 November 2019). \"NASA Applying AI Technologies to Problems in Space Science\". NASA. Retrieved 30 May 2022.^Fluke, Christopher J.; Jacobs, Colin (March 2020). \"Surveying the reach and maturity of machine learning and artificial intelligence in astronomy\". WIREs Data Mining and Knowledge Discovery. 10 (2) e1349. arXiv:1912.02934. Bibcode:2020WDMKD..10.1349F. doi:10.1002/widm.1349.^Pultarova, Tereza (29 April 2021). \"Artificial intelligence is learning how to dodge space junk in orbit\". Space.com. Retrieved 3 July 2022.^Mohan, Jaya Preethi; Tejaswi, N. (2020). \"A Study on Embedding the Artificial Intelligence and Machine Learning into Space Exploration and Astronomy\". Emerging Trends in Computing and Expert Technology. Lecture Notes on Data Engineering and Communications Technologies. Vol.\u00a035. pp.\u00a01295\u20131302. doi:10.1007/978-3-030-32150-5_131. ISBN\u00a0978-3-030-32149-9.^Rees, Martin (30 April 2022). \"Could space-going billionaires be the vanguard of a cosmic revolution? | Martin Rees\". The Guardian. Retrieved 29 May 2022.^Gutowska, Ma\u0142gorzata; Scriney, Michael; McCarren, Andrew (December 2019). Identifying extra-terrestrial intelligence using machine learning. 27th AIAI Irish Conference on Artificial Intelligence and Cognitive Science.^Zhang, Yunfan Gerry; Gajjar, Vishal; Foster, Griffin; Siemion, Andrew; Cordes, James; Law, Casey; Wang, Yu (2018). \"Fast Radio Burst 121102 Pulse Detection and Periodicity: A Machine Learning Approach\". The Astrophysical Journal. 866 (2): 149. arXiv:1809.03043. Bibcode:2018ApJ...866..149Z. doi:10.3847/1538-4357/aadf31.^Nanda, Lakshay; V, Santhi (2019). \"SETI (Search for Extra Terrestrial Intelligence) Signal Classification using Machine Learning\". 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). pp.\u00a0499\u2013504. doi:10.1109/ICSSIT46314.2019.8987793. ISBN\u00a0978-1-7281-2119-2.^Gajjar, Vishal; Siemion, Andrew; Croft, Steve; Brzycki, Bryan; Burgay, Marta; Carozzi, Tobia; Concu, Raimondo; Czech, Daniel; DeBoer, David; DeMarines, Julia; Drew, Jamie; Enriquez, J. Emilio; Fawcett, James; Gallagher, Peter; Garrett, Michael; Gizani, Nectaria; Hellbourg, Greg; Holder, Jamie; Isaacson, Howard; Kudale, Sanjay; Lacki, Brian; Lebofsky, Matthew; Li, Di; MacMahon, David H. E.; McCauley, Joe; Melis, Andrea; Molinari, Emilio; Murphy, Pearse; Perrodin, Delphine; Pilia, Maura; Price, Danny C.; Webb, Claire; Werthimer, Dan; Williams, David; Worden, Pete; Zarka, Philippe; Zhang, Yunfan Gerry (2 August 2019). \"The Breakthrough Listen Search for Extraterrestrial Intelligence\". Bulletin of the American Astronomical Society. 51 (7): 223. arXiv:1907.05519. Bibcode:2019BAAS...51g.223G.^\"SkyCAM-5 - Chair of Computer Science VIII - Aerospace Information Technology\". University of W\u00fcrzburg. Retrieved 29 May 2022.^\"Project Galileo: The search for alien tech hiding in our Solar System\". BBC Science Focus Magazine. Retrieved 29 May 2022.^\"'Something's coming': is America finally ready to take UFOs seriously?\". The Guardian. 5 February 2022. Retrieved 29 May 2022.^David, Leonard (27 January 2022). \"2022 could be a turning point in the study of UFOs\". livescience.com. Retrieved 29 May 2022.^Gritz, Jennie Rothenberg. \"The Wonder of Avi Loeb\". Retrieved 29 May 2022.^Mann, Adam. \"Avi Loeb's Galileo Project Will Search for Evidence of Alien Visitation\". Scientific American. Retrieved 29 May 2022.^\"Galileo Project \u2013 Activities\". projects.iq.harvard.edu. Retrieved 29 May 2022.^\"The Galileo Project: Harvard researchers to search for signs of alien technology\". Sky News.^Zapata Trujillo, Juan C.; Syme, Anna-Maree; Rowell, Keiran N.; Burns, Brendan P.; Clark, Ebubekir S.; Gorman, Maire N.; Jacob, Lorrie S. D.; Kapodistrias, Panayioti; Kedziora, David J.; Lempriere, Felix A. R.; Medcraft, Chris; O'Sullivan, Jensen; Robertson, Evan G.; Soares, Georgia G.; Steller, Luke; Teece, Bronwyn L.; Tremblay, Chenoa D.; Sousa-Silva, Clara; McKemmish, Laura K. (2021). \"Computational Infrared Spectroscopy of 958 Phosphorus-Bearing Molecules\". Frontiers in Astronomy and Space Sciences. 8 639068: 43. arXiv:2105.08897. Bibcode:2021FrASS...8...43Z. doi:10.3389/fspas.2021.639068.^\"Chemists debate machine learning's future in synthesis planning and ask for open data\". cen.acs.org. Retrieved 29 May 2022.^\"Machine learning reveals recipe for building artificial proteins\". phys.org. Retrieved 17 August 2020.^Russ, William P.; Figliuzzi, Matteo; Stocker, Christian; Barrat-Charlaix, Pierre; Socolich, Michael; Kast, Peter; Hilvert, Donald; Monasson, Remi; Cocco, Simona; Weigt, Martin; Ranganathan, Rama (2020). \"An evolution-based model for designing chorismatemutase enzymes\". Science. 369 (6502): 440\u2013445. Bibcode:2020Sci...369..440R. doi:10.1126/science.aba3304. PMID\u00a032703877. S2CID\u00a0220714458.^Stocker, Sina; Cs\u00e1nyi, G\u00e1bor; Reuter, Karsten; Margraf, Johannes T. (30 October 2020). \"Machine learning in chemical reaction space\". Nature Communications. 11 (1): 5505. Bibcode:2020NatCo..11.5505S. doi:10.1038/s41467-020-19267-x. PMC\u00a07603480. PMID\u00a033127879.^Yirka, Bob. \"Repurposed drug-seeking AI system generates 40,000 possible chemical weapons in just six hours\". techxplore.com. Retrieved 19 April 2022.^Urbina, Fabio; Lentzos, Filippa; Invernizzi, C\u00e9dric; Ekins, Sean (March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189\u2013191. doi:10.1038/s42256-022-00465-9. ISSN\u00a02522-5839. PMC\u00a09544280. PMID\u00a036211133. S2CID\u00a0247302391.^\"AI drug algorithms can be flipped to generate bioweapons\". www.theregister.com. Retrieved 24 April 2022.^Hansen, Justine Y.; Markello, Ross D.; Vogel, Jacob W.; Seidlitz, Jakob; Bzdok, Danilo; Misic, Bratislav (September 2021). \"Mapping gene transcription and neurocognition across human neocortex\". Nature Human Behaviour. 5 (9): 1240\u20131250. doi:10.1038/s41562-021-01082-z. PMID\u00a033767429.^Vo ngoc, Long; Huang, Cassidy Yunjing; Cassidy, California Jack; Medrano, Claudia; Kadonaga, James T. (September 2020). \"Identification of the human DPR core promoter element using machine learning\". Nature. 585 (7825): 459\u2013463. Bibcode:2020Natur.585..459V. doi:10.1038/s41586-020-2689-7. PMC\u00a07501168. PMID\u00a032908305.^Bijun, Zhang; Ting, Fan (2022). \"Knowledge structure and emerging trends in the application of deep learning in genetics research: A bibliometric analysis [2000\u20132021]\". Frontiers in Genetics. 13 951939. doi:10.3389/fgene.2022.951939. PMC\u00a09445221. PMID\u00a036081985.^Radivojevi\u0107, Tijana; Costello, Zak; Workman, Kenneth; Garcia Martin, Hector (25 September 2020). \"A machine learning Automated Recommendation Tool for synthetic biology\". Nature Communications. 11 (1): 4879. arXiv:1911.11091. Bibcode:2020NatCo..11.4879R. doi:10.1038/s41467-020-18008-4. PMC\u00a07519645. PMID\u00a032978379.^ abPablo Carbonell; Tijana Radivojevic; H\u00e9ctor Garc\u00eda Mart\u00edn* (2019). \"Opportunities at the Intersection of Synthetic Biology, Machine Learning, and Automation\". ACS Synthetic Biology. 8 (7): 1474\u20131477. doi:10.1021/acssynbio.8b00540. hdl:20.500.11824/998. PMID\u00a031319671.^Gadzhimagomedova, Z. M.; Pashkov, D. M.; Kirsanova, D. Yu.; Soldatov, S. A.; Butakova, M. A.; Chernov, A. V.; Soldatov, A. V. (February 2022). \"Artificial Intelligence for Nanostructured Materials\". Nanobiotechnology Reports. 17 (1): 1\u20139. doi:10.1134/S2635167622010049.^Mirzaei, Mahsa; Furxhi, Irini; Murphy, Finbarr; Mullins, Martin (July 2021). \"A Machine Learning Tool to Predict the Antibacterial Capacity of Nanoparticles\". Nanomaterials. 11 (7): 1774. doi:10.3390/nano11071774. PMC\u00a08308172. PMID\u00a034361160.^Chen, Angela (25 April 2018). \"How AI is helping us discover materials faster than ever\". The Verge. Retrieved 30 May 2022.^Talapatra, Anjana; Boluki, S.; Duong, T.; Qian, X.; Dougherty, E.; Arr\u00f3yave, R. (26 November 2018). \"Autonomous efficient experiment design for materials discovery with Bayesian model averaging\". Physical Review Materials. 2 (11) 113803. arXiv:1803.05460. Bibcode:2018PhRvM...2k3803T. doi:10.1103/PhysRevMaterials.2.113803.^Zhao, Yicheng; Zhang, Jiyun; Xu, Zhengwei; Sun, Shijing; Langner, Stefan; Hartono, Noor Titan Putri; Heumueller, Thomas; Hou, Yi; Elia, Jack; Li, Ning; Matt, Gebhard J.; Du, Xiaoyan; Meng, Wei; Osvet, Andres; Zhang, Kaicheng; Stubhan, Tobias; Feng, Yexin; Hauch, Jens; Sargent, Edward H.; Buonassisi, Tonio; Brabec, Christoph J. (13 April 2021). \"Discovery of temperature-induced stability reversal in perovskites using high-throughput robotic learning\". Nature Communications. 12 (1): 2191. Bibcode:2021NatCo..12.2191Z. doi:10.1038/s41467-021-22472-x. PMC\u00a08044090. PMID\u00a033850155.^Anne Johnson; Emily Grumbling (2019). Implications of artificial intelligence for cybersecurity: proceedings of a workshop. Washington, DC: National Academies Press. pp.\u00a04\u20135. ISBN\u00a0978-0-309-49451-9. OCLC\u00a01134854973. Retrieved 2025-05-12.^Kocher, Geeta; Kumar, Gulshan (August 2021). \"Machine learning and deep learning methods for intrusion detection systems: recent developments and challenges\". Soft Computing. 25 (15): 9731\u20139763. doi:10.1007/s00500-021-05893-0.^Kant, Daniel; Johannsen, Andreas (16 January 2022). \"Evaluation of AI-based use cases for enhancing the cyber security defense of small and medium-sized companies (SMEs)\". Electronic Imaging. 34 (3): 387\u20131\u2013387\u20138. doi:10.2352/EI.2022.34.3.MOBMU-387.^Randrianasolo, Arisoa (2012). Artificial intelligence in computer security: Detection, temporary repair and defense (Thesis). p.\u00a0vii. hdl:2346/45196.^Sahil; Sood, Sandeep; Mehmi, Sandeep; Dogra, Shikha (2015). \"Artificial intelligence for designing user profiling system for cloud computing security: Experiment\". 2015 International Conference on Advances in Computer Engineering and Applications. pp.\u00a051\u201358. doi:10.1109/ICACEA.2015.7164645. ISBN\u00a0978-1-4673-6911-4.^Parisi, Alessandro (2019). Hands-On Artificial Intelligence for Cybersecurity: Implement smart AI systems for preventing cyber attacks and detecting threats and network anomalies. Packt Publishing Ltd. ISBN\u00a0978-1-78980-517-8. OCLC\u00a01111967955.[page\u00a0needed]^Hallerbach, Sven; Xia, Yiqun; Eberle, Ulrich; Koester, Frank (3 April 2018). \"Simulation-Based Identification of Critical Scenarios for Cooperative and Automated Vehicles\". SAE International Journal of Connected and Automated Vehicles. 1 (2): 93\u2013106. doi:10.4271/2018-01-1066.^West, Darrell M. (20 September 2016). \"Moving forward: Self-driving vehicles in China, Europe, Japan, Korea, and the United States\". Brookings.^\"Programming safety into self-driving cars\". National Science Foundation. 2 February 2015.^ ab\"Self-driving delivery van ditches \"human controls\"\". BBC News. 7 February 2020. Retrieved 28 April 2022.^\"Transportation Germany Unveils the World's First Fully Automated Train in Hamburg\". 12 October 2021. Retrieved 3 July 2022.^\"Railway digitalisation using drones\". www.euspa.europa.eu. 25 February 2021. Retrieved 3 July 2022.^\"World's fastest driverless bullet train launches in China\". The Guardian. 9 January 2020. Retrieved 3 July 2022.^Benson, Thor. \"Self-driving buses to appear on public roads for the first time\". Inverse. Retrieved 26 August 2021.^\"Europe's first full-sized self-driving urban electric bus has arrived\". World Economic Forum. Retrieved 26 August 2021.^Huber, Dominik; Viere, Tobias; Horschutz Nemoto, Eliane; Jaroudi, Ines; Korbee, Dorien; Fournier, Guy (2022). \"Climate and environmental impacts of automated minibuses in future public transportation\". Transportation Research Part D: Transport and Environment. 102 103160. Bibcode:2022TRPD..10203160H. doi:10.1016/j.trd.2021.103160.^Hawkins, Andrew J. (22 July 2020). \"Waymo is designing a self-driving Ram delivery van with FCA\". The Verge. Retrieved 28 April 2022.^Buss, Dale (31 Aug 2021). \"Walmart Presses Its Distribution Legacy To Lead In Automated Delivery\". Forbes. Retrieved 28 April 2022.^Rita Liao (25 May 2021). \"JD.com, Meituan and Neolix to test autonomous deliveries on Beijing public roads\". TechCrunch. Retrieved 28 April 2022.^Cooley, Patrick; Dispatch, The Columbus (1 September 2021). \"Grubhub testing delivery robots\". techxplore.com. Retrieved 28 April 2022.^Burgess, Matt (24 August 2017). \"The UK is about to Start Testing Self-Driving Truck Platoons\". Wired UK. Archived from the original on 22 September 2017. Retrieved 20 September 2017.^Davies, Alex (5 May 2015). \"World's First Self-Driving Semi-Truck Hits the Road\". Wired. Archived from the original on 28 October 2017. Retrieved 20 September 2017.^Preparing for the future of artificial intelligence. National Science and Technology Council. OCLC\u00a0965620122.^Jones, Randolph M.; Laird, John E.; Nielsen, Paul E.; Coulter, Karen J.; Kenny, Patrick; Koss, Frank V. (15 March 1999). \"Automated Intelligent Pilots for Combat Flight Simulation\". AI Magazine. 20 (1): 27. doi:10.1609/aimag.v20i1.1438.^AIDA Homepage. Kbs.twi.tudelft.nl (17 April 1997). Retrieved 21 July 2013.^The Story of Self-Repairing Flight Control Systems. NASA Dryden. (April 2003). Retrieved 25 August 2016.^Adams, Eric (28 March 2017). \"AI Wields the Power to Make Flying Safer\u2014and Maybe Even Pleasant\". Wired. Retrieved 7 October 2017.^Baomar, Haitham; Bentley, Peter J. (2016). \"An Intelligent Autopilot System that learns flight emergency procedures by imitating human pilots\". 2016 IEEE Symposium Series on Computational Intelligence (SSCI). pp.\u00a01\u20139. doi:10.1109/SSCI.2016.7849881. ISBN\u00a0978-1-5090-4240-1.^\"UB invests in student-founded startup\". buffalo.edu. Retrieved 24 December 2020.Further reading[edit]Kaplan, A.M.; Haenlein, M. (2018). \"Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence\". Business Horizons. 62 (1): 15\u201325. doi:10.1016/j.bushor.2018.08.004.Kurzweil, Ray (2005). The Singularity is Near: When Humans Transcend Biology. New York: Viking. ISBN\u00a0978-0-670-03384-3.National Research Council (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press. ISBN\u00a0978-0-309-06278-7. OCLC\u00a0246584055.Moghaddam, M. J.; Soleymani, M. R.; Farsi, M. A. (2015). \"Sequence planning for stamping operations in progressive dies\". Journal of Intelligent Manufacturing. 26 (2): 347\u2013357. doi:10.1007/s10845-013-0788-0.Felten, Ed (3 May 2016). \"Preparing for the Future of Artificial Intelligence\"..mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteEmerging technologiesFieldsInformation andcommunicationsAmbient intelligenceInternet of thingsArtificial intelligenceApplications of artificial intelligenceMachine translationMachine visionMobile translationProgress in artificial intelligenceSemantic WebSpeech recognitionAtomtronicsCarbon nanotube field-effect transistorCybermethodologyAugmented realityFourth-generation optical discs3D optical data storageHolographic data storageGPGPUMemory\nCBRAMECRAMFRAMMillipedeMRAMNRAMPRAMRacetrack memoryRRAMSONOSUltraRAMOptical computingRFIDChipless RFIDSoftware-defined radioThree-dimensional integrated circuitTopicsAutomationCollingridge dilemmaDifferential technological developmentDisruptive innovationEphemeralizationEthicsAIBioethicsCyberethicsNeuroethicsRobot ethicsExploratory engineeringProactionary principleTechnological changeTechnological unemploymentTechnological convergenceTechnological evolutionTechnological paradigmTechnology forecastingAccelerating changeFuture-oriented technology analysisHorizon scanningMoore's lawTechnological singularityTechnology scoutingTechnology in science fictionTechnology readiness levelTechnology roadmapTranshumanismList\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Applications_of_artificial_intelligence&oldid=1319003784\"", "tags": ["en.wikipedia.org", "wiki", "applications", "artificial", "intelligence"]}
{"url": "https://en.wikipedia.org/wiki/Android_(robot)", "title": null, "text": "Robot resembling a human.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}\"Mechanoid\" redirects here. For other uses, see Mechanoid (disambiguation).\"Androids\" redirects here. For other uses, see Androids (disambiguation).For the mascot, see Android (operating system) \u00a7\u00a0Mascot.Repliee Q2, an android, can mimic human functions such as blinking, breathing and speaking, with the ability to recognize and process speech and touch, and then respond in kind.\nAn android is a humanoid robot or other artificial being, often made from a flesh-like material.[1][2][3][4] Historically, androids existed only in the domain of science fiction and were frequently seen in film and television, but advances in robot technology have allowed the creation of similar robots in real life.[5][6]Terminology[edit]Early example of the term androides used to describe human-like mechanical devices, London Times, 22 December 1795The Oxford English Dictionary traces the earliest use (as \"Androides\") to Ephraim Chambers' 1728 Cyclopaedia, in reference to an automaton that St. Albertus Magnus allegedly created.[3][7] By the late 1700s, \"androides\", elaborate mechanical devices resembling humans performing human activities, were displayed in exhibit halls.[8]\nThe term \"android\" appears in US patents as early as 1863 in reference to miniature human-like toy automatons.[9] The term android was used in a more modern sense by the French author Auguste Villiers de l'Isle-Adam in his work Tomorrow's Eve (1886), featuring an artificial humanoid robot named Hadaly.[3] The term made an impact into English pulp science fiction starting from Jack Williamson's The Cometeers (1936) and the distinction between mechanical robots and fleshy androids was popularized by Edmond Hamilton's Captain Future stories (1940\u20131944).[3]Although Karel \u010capek's robots in R.U.R. (Rossum's Universal Robots) (1921)\u2014the play that introduced the word robot to the world\u2014were organic artificial humans, the word \"robot\" has come to primarily refer to mechanical humans, animals, and other beings.[3] The term \"android\" can mean either one of these,[3] while a cyborg (\"cybernetic organism\" or \"bionic man\") would be a creature that is a combination of organic and mechanical parts.\nThe term \"droid\", popularized by George Lucas in the original Star Wars film and now used widely within science fiction, originated as an abridgment of \"android\", but has been used by Lucas and others to mean any robot, including distinctly non-human form machines like R2-D2. The word \"android\" was used in Star Trek: The Original Series episode \"What Are Little Girls Made Of?\" The abbreviation \"andy\", coined as a pejorative by writer Philip K. Dick in his novel Do Androids Dream of Electric Sheep?, has seen some further usage, such as within the TV series Total Recall 2070.[10]While the term \"android\" is used in reference to human-looking robots in general (not necessarily male-looking humanoid robots), a robot with a female appearance can also be referred to as a gynoid. Besides one can refer to robots without alluding to their sexual appearance by calling them anthrobots (a portmanteau of anthr\u014dpos and robot; see anthrobotics) or anthropoids (short for anthropoid robots; the term humanoids is not appropriate because it is already commonly used to refer to human-like organic species in the context of science fiction, futurism and speculative astrobiology).[11]Authors have used the term android in more diverse ways than robot or cyborg. In some fictional works, the difference between a robot and android is only superficial, with androids being made to look like humans on the outside but with robot-like internal mechanics.[3] In other stories, authors have used the word \"android\" to mean a wholly organic, yet artificial, creation.[3] Other fictional depictions of androids fall somewhere in between.[3]Eric G. Wilson, who defines an android as a \"synthetic human being\", distinguishes between three types of android, based on their body's composition:\nthe mummy type \u2013 made of \"dead things\" or \"stiff, inanimate, natural material\", such as mummies, puppets, dolls and statuesthe golem type \u2013 made from flexible, possibly organic material, including golems and homunculithe automaton type \u2013 made from a mix of dead and living parts, including automatons and robots[4]Although human morphology is not necessarily the ideal form for working robots, the fascination in developing robots that can mimic it can be found historically in the assimilation of two concepts: simulacra (devices that exhibit likeness) and automata (devices that have independence).\nProjects[edit]Several projects aiming to create androids that look, and, to a certain degree, speak or act like a human being have been launched or are underway.\nJapan[edit].mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This section needs expansion with: more recent examples and additional citations. You can help by adding to it.  (October 2018)Repliee Q2, a Japanese androidJapanese robotics have been leading the field since the 1970s.[12]Waseda University initiated the WABOT project in 1967, and in 1972 completed the WABOT-1, the first android, a full-scale humanoid intelligent robot.[13][14] Its limb control system allowed it to walk with the lower limbs, and to grip and transport objects with hands, using tactile sensors. Its vision system allowed it to measure distances and directions to objects using external receptors, artificial eyes and ears. And its conversation system allowed it to communicate with a person in Japanese, with an artificial mouth.[14][15][16]In 1984, WABOT-2 was revealed, and made a number of improvements. It was capable of playing the organ. Wabot-2 had ten fingers and two feet, and was able to read a score of music. It was also able to accompany a person.[17] In 1986, Honda began its humanoid research and development program, to create humanoid robots capable of interacting successfully with humans.[18]The Intelligent Robotics Lab, directed by Hiroshi Ishiguro at Osaka University, and the Kokoro company demonstrated the Actroid at Expo 2005 in Aichi Prefecture, Japan and released the Telenoid R1 in 2010. In 2006, Kokoro developed a new DER 2 android. The height of the human body part of DER2 is 165\u00a0cm. There are 47 mobile points. DER2 can not only change its expression but also move its hands and feet and twist its body. The \"air servosystem\" which Kokoro developed originally is used for the actuator. As a result of having an actuator controlled precisely with air pressure via a servosystem, the movement is very fluid and there is very little noise. DER2 realized a slimmer body than that of the former version by using a smaller cylinder. Outwardly DER2 has a more beautiful proportion. Compared to the previous model, DER2 has thinner arms and a wider repertoire of expressions. Once programmed, it is able to choreograph its motions and gestures with its voice.\nThe Intelligent Mechatronics Lab, directed by Hiroshi Kobayashi at the Tokyo University of Science, has developed an android head called Saya, which was exhibited at Robodex 2002 in Yokohama, Japan. There are several other initiatives around the world involving humanoid research and development at this time, which will hopefully introduce a broader spectrum of realized technology in the near future. Now Saya is working at the Science University of Tokyo as a guide.\nThe Waseda University (Japan) and NTT docomo's manufacturers have succeeded in creating a shape-shifting robot WD-2. It is capable of changing its face. At first, the creators decided the positions of the necessary points to express the outline, eyes, nose, and so on of a certain person. The robot expresses its face by moving all points to the decided positions, they say. The first version of the robot was first developed back in 2003. After that, a year later, they made a couple of major improvements to the design. The robot features an elastic mask made from the average head dummy. It uses a driving system with a 3DOF unit. The WD-2 robot can change its facial features by activating specific facial points on a mask, with each point possessing three degrees of freedom. This one has 17 facial points, for a total of 56 degrees of freedom. As for the materials they used, the WD-2's mask is fabricated with a highly elastic material called Septom, with bits of steel wool mixed in for added strength. Other technical features reveal a shaft driven behind the mask at the desired facial point, driven by a DC motor with a simple pulley and a slide screw. Apparently, the researchers can also modify the shape of the mask based on actual human faces. To \"copy\" a face, they need only a 3D scanner to determine the locations of an individual's 17 facial points. After that, they are then driven into position using a laptop and 56 motor control boards. In addition, the researchers also mention that the shifting robot can even display an individual's hair style and skin color if a photo of their face is projected onto the 3D Mask.\nSingapore[edit]Prof Nadia Thalmann, a Nanyang Technological University scientist, directed efforts of the Institute for Media Innovation along with the School of Computer Engineering in the development of a social robot, Nadine. Nadine is powered by software similar to Apple's Siri or Microsoft's Cortana. Nadine may become a personal assistant in offices and homes in future, or she may become a companion for the young and the elderly.\nAssoc Prof Gerald Seet from the School of Mechanical & Aerospace Engineering and the BeingThere Centre led a three-year R&D development in tele-presence robotics, creating EDGAR. A remote user can control EDGAR with the user's face and expressions displayed on the robot's face in real time. The robot also mimics their upper body movements.\n[19]South Korea[edit]EveR-2, the first android that can singKITECH researched and developed EveR-1, an android interpersonal communications model capable of emulating human emotional expression via facial \"musculature\" and capable of rudimentary conversation, having a vocabulary of around 400 words. She is 160 cm tall and weighs 50 kg, matching the average figure of a Korean woman in her twenties. EveR-1's name derives from the Biblical Eve, plus the letter r for robot. EveR-1's advanced computing processing power enables speech recognition and vocal synthesis, at the same time processing lip synchronization and visual recognition by 90-degree micro-CCD cameras with face recognition technology. An independent microchip inside her artificial brain handles gesture expression, body coordination, and emotion expression. Her whole body is made of highly advanced synthetic jelly silicon and with 60 artificial joints in her face, neck, and lower body; she is able to demonstrate realistic facial expressions and sing while simultaneously dancing. In South Korea, the Ministry of Information and Communication had an ambitious plan to put a robot in every household by 2020.[20] Several robot cities have been planned for the country: the first will be built in 2016 at a cost of 500 billion won (US$440 million), of which 50 billion is direct government investment.[21] The new robot city will feature research and development centers for manufacturers and part suppliers, as well as exhibition halls and a stadium for robot competitions. The country's new Robotics Ethics Charter will establish ground rules and laws for human interaction with robots in the future, setting standards for robotics users and manufacturers, as well as guidelines on ethical standards to be programmed into robots to prevent human abuse of robots and vice versa.[22]United States[edit]Walt Disney and a staff of Imagineers created Great Moments with Mr. Lincoln that debuted at the 1964 New York World's Fair.[23]Dr. William Barry, an Education Futurist and former visiting West Point Professor of Philosophy and Ethical Reasoning at the United States Military Academy, created an AI android character named \"Maria Bot\". This Interface AI android was named after the infamous fictional robot Maria in the 1927 film Metropolis, as a well-behaved distant relative. Maria Bot is the first AI Android Teaching Assistant at the university level.[24][25] Maria Bot has appeared as a keynote speaker as a duo with Barry for a TEDx talk in Everett, Washington in February 2020.[26]Resembling a human from the shoulders up, Maria Bot is a virtual being android that has complex facial expressions and head movement and engages in conversation about a variety of subjects. She uses AI to process and synthesize information to make her own decisions on how to talk and engage. She collects data through conversations, direct data inputs such as books or articles, and through internet sources.\nMaria Bot was built by an international high-tech company for Barry to help improve education quality and eliminate education poverty. Maria Bot is designed to create new ways for students to engage and discuss ethical issues raised by the increasing presence of robots and artificial intelligence. Barry also uses Maria Bot to demonstrate that programming a robot with life-affirming, ethical framework makes them more likely to help humans to do the same.[27]Maria Bot is an ambassador robot for good and ethical AI technology.[28]Hanson Robotics, Inc., of Texas and KAIST produced an android portrait of Albert Einstein, using Hanson's facial android technology mounted on KAIST's life-size walking bipedal robot body. This Einstein android, also called \"Albert Hubo\", thus represents the first full-body walking android in history.[29] Hanson Robotics, the FedEx Institute of Technology,[30] and the University of Texas at Arlington also developed the android portrait of sci-fi author Philip K. Dick (creator of Do Androids Dream of Electric Sheep?, the basis for the film Blade Runner), with full conversational capabilities that incorporated thousands of pages of the author's works.[31] In 2005, the PKD android won a first-place artificial intelligence award from AAAI.\nChina[edit]On April 19, 2025, 21 humanoid robots participated along with 12,000 human runners in a half-marathon in Beijing. While almost every robot fell down and had overheating problems, and the robots were continuously being controlled by human handlers accompanying them, six of the robots did reach the finish line. Two of them, Tiangong Ultra by Chinese robotics company UBTech, and N2 by Chinese company Noetix Robotics, which took first and second place respectively among robots in the race, stood out for their consistent (albeit slow) pace.[32]Use in fiction[edit]See also: List of fictional robots and androidsAndroids are a staple of science fiction. Isaac Asimov pioneered the fictionalization of the science of robotics and artificial intelligence, notably in his 1950s series I, Robot.[33] One thing common to most fictional androids is that the real-life technological challenges associated with creating thoroughly human-like robots \u2014 such as the creation of strong artificial intelligence\u2014are assumed to have been solved.[34] Fictional androids are often depicted as mentally and physically equal or superior to humans\u2014moving, thinking and speaking as fluidly as them.[3][34]The tension between the nonhuman substance and the human appearance\u2014or even human ambitions\u2014of androids is the dramatic impetus behind most of their fictional depictions.[4][34] Some android heroes seek, like Pinocchio, to become human, as in the film Bicentennial Man,[34] or Data in Star Trek: The Next Generation. Others, as in the film Westworld, rebel against abuse by careless humans.[34] Android hunter Deckard in Do Androids Dream of Electric Sheep? and its film adaptation Blade Runner discovers that his targets appear to be, in some ways, more \"human\" than he is.[34] The sequel Blade Runner 2049 involves android hunter K, himself an android, discovering the same thing. Android stories, therefore, are not essentially stories \"about\" androids; they are stories about the human condition and what it means to be human.[34] \nOne aspect of writing about the meaning of humanity is to use discrimination against androids as a mechanism for exploring racism in society, as in Blade Runner.[35] Perhaps the clearest example of this is John Brunner's 1968 novel Into the Slave Nebula, where the blue-skinned android slaves are explicitly shown to be fully human.[36] More recently, the androids Bishop and Annalee Call in the films Aliens and Alien Resurrection are used as vehicles for exploring how humans deal with the presence of an \"Other\".[37] The 2018 video game Detroit: Become Human also explores how androids are treated as second class citizens in a near future society.\nFemale androids, or \"gynoids\", are often seen in science fiction, and can be viewed as a continuation of the long tradition of men attempting to create the stereotypical \"perfect woman\".[38] Examples include the Greek myth of Pygmalion and the female robot Maria in Fritz Lang's Metropolis. Some gynoids, like Pris in Blade Runner, are designed as sex-objects, with the intent of \"pleasing men's violent sexual desires\",[39] or as submissive, servile companions, such as in The Stepford Wives. Fiction about gynoids has therefore been described as reinforcing \"essentialist ideas of femininity\",[40] although others have suggested that the treatment of androids is a way of exploring racism and misogyny in society.[41]The 2015 Japanese film Sayonara, starring Geminoid F, was promoted as \"the first movie to feature an android performing opposite a human actor\".[42]The 2023 Dutch film I'm Not a Robot won the Academy Award for Best Live Action Short Film in 2025.\nSee also[edit].mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}ActroidAndroid scienceAnimatronicsAudio-AnimatronicsAutomatonCyborgDomestic robotGynoidHumanoid robotNeuroroboticsReplicantSynthoidUncanny valleyReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Van Riper, A. Bowdoin (2002). Science in popular culture: a reference guide. Westport: Greenwood Press. p.\u00a010. ISBN\u00a00-313-31822-0.^Prucher, Jeff (2007). \"android\". Brave New Words: The Oxford Dictionary of Science Fiction. Oxford University Press. pp.\u00a06\u20137. ISBN\u00a0978-0-19-530567-8.^ abcdefghijBrian M. Stableford (2006). Science fact and science fiction: an encyclopedia. CRC Press. pp.\u00a022\u201323. ISBN\u00a0978-0-415-97460-8.^ abcEric G. Wilson (2006). The melancholy android: on the psychology of sacred machines. SUNY Press. pp.\u00a027\u201328. ISBN\u00a0978-0-7914-6846-3.^McCaw, Caroline (2001). Http. [University of Otago?]. OCLC\u00a0225915408.^Ishiguro, Hiroshi. \"Android science.\", Cognitive Science Society, Osaka, 2005. Retrieved on 3 October 2013.^OED at \"android\" citing Ephraim Chambers, Cyclop\u00e6dia; or, a universal dictionary of arts and sciences. 1728.^\"At the Mechanical Theater\". London Times. 22 December 1795.^\"U.S. Patent and Trademark Office, Patent# 40891, Toy Automation\". Google Patents. Retrieved 7 January 2007.[dead link]^Levin, Drew S. (exec. prod.) (23 February 1999). \"Rough Whimper of Insanity\". Total Recall 2070. Season 1. Episode 7. Toronto.  2:10 minutes in. Channel Zero. CHCH-TV. Archived from the original on 5 February 2010.^\"Anthrobotics: Where The Human Ends and the Robot Begins\". Futurism. 7 March 2017. Archived from the original on 9 April 2024. Retrieved 19 February 2022.^Zeghloul, Sa\u00efd; Laribi, Med Amine; Gazeau, Jean-Pierre (21 September 2015). Robotics and Mechatronics: Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics. Springer. ISBN\u00a09783319223681.^\"Humanoid History -WABOT-\". www.humanoid.waseda.ac.jp. Archived from the original on 1 September 2017. Retrieved 6 May 2017.^ ab\"Historical Android Projects\". androidworld.com. Archived from the original on 25 November 2005. Retrieved 6 May 2017.^Robots: From Science Fiction to Technological Revolution, page 130^Duffy, Vincent G. (19 April 2016). Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering. CRC Press. ISBN\u00a09781420063523.^\"2history\". Archived from the original on 12 October 2007. Retrieved 31 August 2007.^\"P3\". Honda Worldwide. Archived from the original on 15 November 2018. Retrieved 1 September 2007.^\"NTU scientists unveil social and telepresence robots\". Archived from the original on 3 September 2019. Retrieved 31 December 2015.^\"A Robot in Every Home by 2020, South Korea Says\". News.nationalgeographic.com. 28 October 2010. Archived from the original on 14 November 2006. Retrieved 22 November 2011.^\"South Korea set to build \"Robot Land\"\". Engadget. 27 August 2007. Archived from the original on 13 January 2012. Retrieved 22 November 2011.^\"Robot Code of Ethics to Prevent Android Abuse, Protect Humans\". News.nationalgeographic.com. 28 October 2010. Archived from the original on 19 March 2007. Retrieved 22 November 2011.^\"Pavilions & Attractions \u2013 Illinois \u2013 Page Two\". Archived from the original on 2 September 2023. Retrieved 23 March 2011.^\"The Education of an Android Teacher \u2013 EdSurge News\". 9 March 2020. Archived from the original on 17 July 2024. Retrieved 15 March 2020.^\"First Android Teaching Assistant at NDNU | Media Center\". Archived from the original on 28 July 2020. Retrieved 15 March 2020.^\"William Barry | tedxeverettcom\". Archived from the original on 28 July 2020. Retrieved 15 March 2020.^\"Maria Bot\". Archived from the original on 12 August 2021. Retrieved 15 March 2020.^\"Mesh conference announces AI robot as keynote speaker\". 24 February 2020. Archived from the original on 7 November 2023. Retrieved 15 March 2020.^\"(no title)\". www.hansonrobotics.wordpress.com. Archived from the original on 16 July 2024. Retrieved 5 August 2010.{{cite web}}: Cite uses generic title (help)^\"FIT \u2013 FedEx Institute of Technology \u2013 The University of Memphis\". www.fedex.memphis.edu. Archived from the original on 10 December 2008. Retrieved 24 October 2006.^\"about \" PKD Android\". www.pkdandroid.org. Archived from the original on 14 August 2009. Retrieved 7 August 2009.^Yang, Zeyi (19 April 2025). \"Stumbling and Overheating, Most Humanoid Robots Fail to Finish Half-Marathon in Beijing\". Wired. Archived from the original on 21 April 2025. Retrieved 22 April 2025.^Jonathan Barra, Roger Caille; et\u00a0al. \"The Android Generation\". West Coast Midnight Run/Citadel Consulting Group LLC. Archived from the original on 24 February 2014. Retrieved 9 February 2013.^ abcdefgVan Riper, op.cit., p. 11.^Dinello, Daniel (2005). Technophobia!: Science Fiction Visions of Posthuman Technology. University of Texas Press. p.\u00a076. ISBN\u00a09780292709867.^D'Ammassa, Don (2005). Encyclopedia of Science Fiction. Facts on File. p.\u00a058. ISBN\u00a0978-0-8160-5924-9.^Nishime, LeiLani (Winter 2005). \"The Mulatto Cyborg: Imagining a Multiracial Future\". Cinema Journal. 44 (2). University of Texas Press: 34\u201349. doi:10.1353/cj.2005.0011.^Melzer, Patricia (2006). Alien Constructions: Science Fiction and Feminist Thought. University of Texas Press. p.\u00a0202. ISBN\u00a0978-0-292-71307-9.^Melzer, p. 204^Grebowicz, Margret; L. Timmel Duchamp; Nicola Griffith; Terry Bisson (2007). SciFi in the mind's eye: reading science through science fiction. Open Court. p.\u00a0xviii. ISBN\u00a0978-0-8126-9630-1.^Dinello, op. cit., p 77.^James Hadfield (24 October 2015). \"Tokyo: 'Sayonara' Filmmakers Debate Future of Robot Actors\". variety.com. Archived from the original on 7 November 2015. Retrieved 9 November 2015.Further reading[edit]Kerman, Judith B. (1991). Retrofitting Blade Runner: Issues in Ridley Scott's Blade Runner and Philip K. Dick's Do Androids Dream of Electric Sheep? Bowling Green, OH: Bowling Green State University Popular Press. ISBN\u00a00-87972-509-5.Perkowitz, Sidney (2004). Digital People: From Bionic Humans to Androids. Joseph Henry Press. ISBN\u00a00-309-09619-7.Shelde, Per (1993). Androids, Humanoids, and Other Science Fiction Monsters: Science and Soul in Science Fiction Films. New York: New York University Press. ISBN\u00a00-8147-7930-1.Ishiguro, Hiroshi. \"Android science.\" Cognitive Science Society. 2005.Glaser, Horst Albert and Rossbach, Sabine: The Artificial Human, Frankfurt/M., Bern, New York 2011 \"The Artificial Human\"TechCast Article Series, Jason Rupinski and Richard Mix, \"Public Attitudes to Androids: Robot Gender, Tasks, & Pricing\"Carpenter, J. (2009). Why send the Terminator to do R2D2s job?: Designing androids as rhetorical phenomena. Proceedings of HCI 2009: Beyond Gray Droids: Domestic Robot Design for the 21st Century. Cambridge, UK. 1 September.Telotte, J.P. Replications: A Robotic History of the Science Fiction Film. University of Illinois Press, 1995.External links[edit].mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);color:inherit;display:flow-root}.mw-parser-output .infobox .side-box{font-size:100%}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:640px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}.mw-parser-output .sister-box .side-box-abovebelow{padding:0.75em 0;text-align:center}.mw-parser-output .sister-box .side-box-abovebelow>b{display:block}.mw-parser-output .sister-box .side-box-text>ul{border-top:1px solid #aaa;padding:0.75em 0;width:220px;margin:0 auto}.mw-parser-output .sister-box .side-box-text>ul>li{min-height:31px}.mw-parser-output .sister-logo{display:inline-block;width:31px;line-height:31px;vertical-align:middle;text-align:center}.mw-parser-output .sister-link{display:inline-block;margin-left:7px;width:182px;vertical-align:middle}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Android (robot)  at Wikipedia's sister projectsDefinitions from WiktionaryMedia from Commons.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteAndroidsGynoidsActroidAi-DaEveRHRP-4CMein\u00fc robotRepliee Q1ExpoMale (androids)Ibn Sina RobotGeminoidBabies and childreniCubSee alsoFictional robots and androidsFictional gynoidsAndroid scienceHumanoid robotsCyborgsCategoryvteHumanoid robotsLeggedMiniBioloidCocoFemiSapienRoboSapienRobosapien v2RopidRS MediaHOAPJO-ZEROKHR-1Kirobo and MirataManavNaoPINOPlenQRIOSmall,mediumArchieASIMOFlameGuRooHUBOiCubMurata Boy and Murata GirlREEMToyota Partner RobotXianxingzheHuman-sizedAi-DaAmecaAtlasE seriesEricFEDORGeorgeIsaacRobotKobianLeonardo's robotMAHRU & AHRAMusaOptimusP seriesPETMANRobot Man of SzegedSophiaSurenaTOPIOBigElektroLand WalkerWheeledGuRooEMIEWEnoni-SOBOTJustinPepperSanbotSeropiTOPIO DioWakamaruMitra RobotTrackedBattlefield Extraction-Assist Robot (BEAR)Upper torsoDomoGakutensokuGeoff PetersonMindarRobonautShaluTelenoid R1RelatedAndroidsCyborgsList of fictional robots and androidsRobot fetishismvteMobile robots and uncrewed vehiclesAerialUnmanned aerial vehicle (UAV)Unmanned combat air vehicle (UCAV)AerobotHelicamList of unmanned aerial vehicle applicationsOrnithopterGroundWalkingHumanoidAndroidHexapodlistOtherUnmanned ground vehicle (UGV)Automated guided vehicle (AGV)Self-driving carAutomatic train operation (ATO)listUnderwaterUnmanned underwater vehicle (UUV)Autonomous underwater vehicle (AUV)Intervention AUV (I-AUV)Remotely operated underwater vehicle (ROUV)Underwater gliderSurfaceUnmanned surface vehicle (USV)SpaceUncrewed spacecraftlist of probeslist by programlist of orbitersCargo spacecraftspaceflights to the ISSSpace telescopelistOtherDomesticMilitaryRescueMedicalDisabilityAgriculturalBEAM roboticsMicroboticsNanoroboticsRoboticsRobot locomotionAutonomous robotAutonomous logisticsRadio-controlled modelRemote control vehicleRemote control animalCategoriesRadio controlUnmanned vehiclesvteRoboticsMain articlesOutlineGlossaryIndexHistoryGeographyHall of FameEthicsLawsCompetitionsAI competitionsTypesAerobotAnthropomorphicHumanoidAndroidCyborgGynoidClaytronicsCompanionAutomatonAnimatronicAudio-AnimatronicsIndustrialArticulatedarmDomesticEducationalEntertainmentJugglingMilitaryMedicalServiceDisabilityAgriculturalFood serviceRetailBEAM roboticsSoft roboticsClassificationsBioroboticsCloud roboticsContinuum robotUnmanned vehicleaerialgroundMobile robotMicroboticsNanoroboticsNecroboticsRobotic spacecraftSpace probeSwarmTeleroboticsUnderwaterremotely-operatedRobotic fishLocomotionTracksWalkingHexapodClimbingElectric unicycleRobotic finsNavigation and mappingMotion planningSimultaneous localization and mappingVisual odometryVision-guided robot systemsResearchEvolutionaryKitsSimulatorSuiteOpen-sourceSoftwareAdaptableDevelopmentalHuman\u2013robot interactionParadigmsPerceptualSituatedUbiquitousCompaniesABBAmazon RoboticsAnybotsBarrett TechnologyBoston DynamicsDoosan RoboticsEnergid TechnologiesFarmWiseFANUCFigure AIFoster-MillerHarvest AutomationHD Hyundai RoboticsHoneybee RoboticsIntuitive SurgicalIRobotKUKARainbow RoboticsStarship TechnologiesSymboticUniversal RoboticsWolf RoboticsYaskawaRelatedCritique of workPowered exoskeletonWorkplace robotics safetyRobotic tech vestTechnological unemploymentTerrainabilityFictional robotsCategoryOutline.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}Authority control databasesNationalUnited StatesFranceBnF dataCzech RepublicIsraelOtherYale LUX\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Android_(robot)&oldid=1319722735\"", "tags": ["en.wikipedia.org", "wiki", "android", "robot"]}
